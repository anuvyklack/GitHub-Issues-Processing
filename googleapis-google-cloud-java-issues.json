[
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4241",
        "number": 4241,
        "title": " \"Maven Central\" badge shows old version",
        "labels": [],
        "state": "open",
        "body": "The \"Maven Central\" badge in the main README shows version `v0.47.0-alpha` as the latest version of google-cloud-java because it is based on the `google-cloud` artifact which was deprecated and no longer exists. The badge should be changed to look up a different version (since the latest is now v0.74.0).\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4237",
        "number": 4237,
        "title": "Convert BQ Table schema to Avro Schema",
        "labels": [
            "triage me"
        ],
        "state": "open",
        "body": "I'm trying to convert a BigQuery schema into an Avro Schema, is this possible?\r\n\r\nI want to do this so that in a DataFlow job I can write BQ data as Parquet on GCS. For some reason the Parquet writer expects an Avro schema:\r\n \r\n#### Environment details\r\n\r\n- OS: Mac\r\n- Java version: 1.8\r\n- google-cloud-java version(s): 1.5.6 \r\n\r\n#### Code snippet\r\n\r\n```java\r\nSchema schema = bigQuery.getTable(\"\", \"\")..getDefinition().getSchema();\r\n```\r\n\r\n```java\r\n//Beam writer\r\nFileIO.write().via(ParquetIO.sink(schema))\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4235",
        "number": 4235,
        "title": "Firestore: ",
        "labels": [
            "triage me"
        ],
        "state": "open",
        "body": "Hey all, \r\nwe see a very rare error when writing data from a app engine application to firestore ('com.google.cloud:google-cloud-firestore:0.71.0-beta').\r\nIt seems to be a too old connection to firestore and therefore the connection is being reset:\r\n`io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR Received Goaway max_age`\r\nShould we expect such errors when using the google-cloud-java lib or this something the library itself should handle?\r\n\r\n#### Environment details\r\n\r\n- OS: Google app engine standard - java 8\r\n- Java version: Google app engine standard - java 8\r\n- google-cloud-java version(s): 0.71.0-beta\r\n\r\n#### Steps to reproduce\r\n\r\n1. Have app engine instance running and write stuff to Firestore.\r\n2. Wait for error.\r\n\r\n#### Stacktrace\r\n\r\n```\r\norg.eclipse.jetty.servlet.ServletHandler doHandle:  (ServletHandler.java:624)\r\njavax.servlet.ServletException: Exception while trying to write to firestore.\r\n\tat com.processing.Process.doPost(Process.java:75)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n\tat com.google.apphosting.utils.servlet.JdbcMySqlConnectionCleanupFilter.doFilter(JdbcMySqlConnectionCleanupFilter.java:60)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:524)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat com.google.apphosting.runtime.jetty9.ParseBlobUploadHandler.handle(ParseBlobUploadHandler.java:119)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1182)\r\n\tat com.google.apphosting.runtime.jetty9.AppEngineWebAppContext.doHandle(AppEngineWebAppContext.java:171)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat com.google.apphosting.runtime.jetty9.AppVersionHandlerMap.handle(AppVersionHandlerMap.java:296)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\r\n\tat com.google.apphosting.runtime.jetty9.RpcConnection.handle(RpcConnection.java:202)\r\n\tat com.google.apphosting.runtime.jetty9.RpcConnector.serviceRequest(RpcConnector.java:81)\r\n\tat com.google.apphosting.runtime.jetty9.JettyServletEngineAdapter.serviceRequest(JettyServletEngineAdapter.java:123)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.dispatchServletRequest(JavaRuntime.java:699)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.dispatchRequest(JavaRuntime.java:661)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.run(JavaRuntime.java:631)\r\n\tat com.google.apphosting.runtime.JavaRuntime$NullSandboxRequestRunnable.run(JavaRuntime.java:825)\r\n\tat com.google.apphosting.runtime.ThreadGroupPool$PoolEntry.run(ThreadGroupPool.java:273)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.util.concurrent.ExecutionException: com.google.api.gax.rpc.UnavailableException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR\r\nReceived Goaway\r\nmax_age\r\n\tat com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:531)\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:423)\r\n\tat com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:90)\r\n\tat com.google.common.util.concurrent.ForwardingFuture.get(ForwardingFuture.java:68)\r\n\tat com.FirestoreConnector.addOrUpdate(FirestoreConnector.java:94)\r\n\tat com.FirestoreConnector.addOrUpdate(FirestoreConnector.java:61)\r\n\tat com.processing.Process.doPost(Process.java:60)\r\n\t... 32 more\r\nCaused by: com.google.api.gax.rpc.UnavailableException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR\r\nReceived Goaway\r\nmax_age\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:69)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:97)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:68)\r\n\tat com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1052)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:507)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:482)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:295)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\nCaused by: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR\r\nReceived Goaway\r\nmax_age\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 23 more\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\nprivate final Firestore db = FirestoreOptions\r\n            .newBuilder()\r\n            .setTimestampsInSnapshotsEnabled(true)\r\n            .build()\r\n            .getService();\r\n\r\npublic <T> String addOrUpdate(T input) throws Exception {\r\n            return db.collection(collection)\r\n                    .add(data)\r\n                    .get(60, TimeUnit.SECONDS)\r\n                    .getId();\r\n}\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\n- ?\r\n\r\n#### Any additional information below\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4234",
        "number": 4234,
        "title": "Getting GCP available regions without doing a request",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "open",
        "body": "Hello,\r\nI would like to know if there is a way to get all GCP available regions without doing a request to GCP.\r\nI've been looking at the source code, and the only way that I found to retrieve all the regions is doing a request: https://github.com/googleapis/google-cloud-java/blob/969bbeef18f004fd51fd46c5def1ae5c644cae3c/google-cloud-clients/google-cloud-compute/src/main/java/com/google/cloud/compute/v1/RegionClient.java#L272\r\n\r\nSo, maybe it's not possible \ud83d\ude13 \r\n\r\nDo you thing this could be a cool feature? I've been working with others [cloud competitors SDK](https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-core/src/main/java/com/amazonaws/regions/Regions.java) and they have this feature, and I think it's useful."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4233",
        "number": 4233,
        "title": "What should we use instead since ApiFutures. addCallback(  future,callback) is deprecated",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Linux/Windows\r\n- Java version: 1.8\r\n- google-cloud-java version(s):1.50\r\n\r\n#### Steps to reproduce\r\n\r\n1.ApiFuture.addCallback(future,callback) method is deprecated and new method with ApiFuture.addCallback (future,callback,exectuor) is added in API . I am not exactly sure what is the significance/correct way to use this executor and if should we use it at  all . \r\n2. We are seeing Run time Exceptions in logs because of deprecated method usage possibly.\r\n\r\n#### Stacktrace\r\n```\r\nc.g.c.util.concurrent.AbstractFuture - RuntimeException while executing runnable com.google.common.util.concurrent.Futures$4@1ce5789e with executor MoreExecutors.directExecutor()\r\n```\r\n\r\n#### Code snippet\r\n```\r\nfinal ApiFuture<String> result = publisher.publish(pubsubMessage);\r\nApiFutures.addCallback(result, new ApiFutureCallback<String>() {\r\n                public void onSuccess(String result) {\r\n                }\r\n                public void onFailure(Throwable ex) {\r\n                }\r\n            })\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4231",
        "number": 4231,
        "title": "BigQuery : using the Maximum Bytes Billed property",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "open",
        "body": "How can we set the \"Maximum Bytes Billed\" property on a query created with the BigQuery cloud library (`com.google.cloud.bigquery.*` namespace) ?\r\n\r\nThe non-cloud library has the property on the [JobConfigurationQuery](https://developers.google.com/resources/api-libraries/documentation/bigquery/v2/java/latest/com/google/api/services/bigquery/model/JobConfigurationQuery.html#setMaximumBytesBilled-java.lang.Long-) property.  I was looking for the same thing on the `QueryJobConfiguration` object to no avail.\r\n\r\nUsing v1.55.0 of the cloud library. \r\n\r\nHow do we use this property on a query ?\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4229",
        "number": 4229,
        "title": "bigtable: add docs demonstrating stream cancellation",
        "labels": [
            "api: bigtable",
            "type: docs"
        ],
        "state": "open",
        "body": "docs for readRowsAsync should give an example of how to cancel the stream using the StreamController "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4228",
        "number": 4228,
        "title": "API doc links are broken",
        "labels": [
            "type: bug",
            "type: docs"
        ],
        "state": "closed",
        "body": "For example:\r\n- bigtable's readme has: https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/bigtable/package-summary.html\r\n- spanner's readme has: https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/spanner/package-summary.html\r\n\r\nBoth lead to a 404"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4226",
        "number": 4226,
        "title": "Documentation link gives 404  File not found",
        "labels": [],
        "state": "closed",
        "body": "While clicking on the [Dialogflow client library docs](https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/dialogflow/v2beta1/package-summary.html) link, I get: \r\n\r\n404\r\n\r\nFile not found\r\n\r\nThe site configured at this address does not contain the requested file.\r\n\r\nIf this is your site, make sure that the filename case matches the URL.\r\nFor root URLs (like http://example.com/) you must provide an index.html file. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4223",
        "number": 4223,
        "title": "Specify versions of dependencies in one central location for pom.xml files",
        "labels": [
            "type: cleanup"
        ],
        "state": "open",
        "body": "Cleanup properties like `<gax.version>` in pom.xml files and have them located in one place to reference."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4221",
        "number": 4221,
        "title": "Daemon threads spawned by Spanner client not stopped",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "#### Environment details\r\n\r\n- OS: Alpine Linux, MacOS\r\n- Java version: 1.8\r\n- google-cloud-java version(s): 0.38.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Please see code snippet below\r\n\r\n#### Code snippet\r\n\r\n        Spanner spanner = null;\r\n        try{\r\n            spanner = SpannerOptions.newBuilder()\r\n                    .setProjectId(project)\r\n                    .setCredentials(creds)\r\n                    .build().getService();\r\n\r\n            Map<String, Map<String, String>> propsByID = new HashMap<>();\r\n            Page<Instance> instances = spanner.getInstanceAdminClient().listInstances();\r\n\r\n            for (Instance instance : instances.iterateAll()) {\r\n                Map<String, String> props = new HashMap<>();\r\n                String instanceId = instance.getId().getInstance();\r\n                // Do stuff\r\n            }\r\n        } catch(SpannerException e) {\r\n            throw new GCPException(\"GCP Exception fetching spanner properties\", e);\r\n        } finally {\r\n            if (spanner != null) {\r\n                spanner.close();\r\n            }\r\n        }\r\n\r\n#### Any additional information below\r\n\r\nI see that daemon threads are spawned on initializing the Spanner client in this and are not stopped when the Spanner client itself is closed which is leaking threads.\r\n\r\nFrom thread dump:\r\n\r\n```\r\n\"Cloud-Spanner-WatchdogInterceptor-0\" #642 daemon prio=5 os_prio=0 tid=0x00007fe80c508000 nid=0x293 waiting on condition [0x00007fe6fdf29000]\r\n   java.lang.Thread.State: TIMED_WAITING (parking)\r\n    at sun.misc.Unsafe.park(Native Method)\r\n    - parking to wait for  <0x00000006f6841bd8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\r\n    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\r\n    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)\r\n    at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n    at java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nPlease let me know if I could provide more information to help debug and TIA!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4220",
        "number": 4220,
        "title": "DEADLINE_EXCEEDED: deadline exceeded after 11998656733ns",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "I'm trying to run PubSub sync. pull with long-running tasks, e.g. 15-60 min, but I get DEADLINE errors after 10 minutes. The subscription has an ack deadline of 120 seconds. I'm extending the ack deadline at every 110 seconds using a ScheduledExecutorService. The worker task is simulated with a sleep of 15 minutes. One message is pulled and handled at a time.\r\n\r\n#### Environment details\r\n- OS: Ubuntu 18.04.1 LTS \r\n- Java version:\r\n  - openjdk version \"1.8.0_162\"\r\n  - OpenJDK Runtime Environment (build 1.8.0_162-8u162-b12-1-b12)\r\n  - OpenJDK 64-Bit Server VM (build 25.162-b12, mixed mode)\r\n- Maven:\r\n  - google-cloud-pubsub: 1.55.0\r\n  - gax-grpc: 1.35.0\r\n\r\n#### Steps to reproduce\r\n1. Create a new topic\r\n2. Create a new pull subscription with 120 seconds ack deadline\r\n3. Update SUBSCRIPTION variable with your project and subscription\r\n4. Start program\r\n5. Publish a new message on topic\r\n6. Wait 10 minutes\r\n\r\n#### Stacktrace\r\n```\r\nDec 13, 2018 1:24:26 PM com.dummy.PubSubSyncPull init INFO: Setting up synchronous pull...\r\nDec 13, 2018 1:24:30 PM com.dummy.PubSubSyncPull init INFO: Got 1 message(s)...\r\nDec 13, 2018 1:24:30 PM com.dummy.PubSubSyncPull$WorkerRunnable run INFO: Handling task 197502272691014 using thread: pool-1-thread-1\r\nDec 13, 2018 1:26:20 PM com.dummy.PubSubSyncPull$ModAckDeadlineRunnable run INFO: Extending ack deadline for task 197502272691014\r\nDec 13, 2018 1:28:10 PM com.dummy.PubSubSyncPull$ModAckDeadlineRunnable run INFO: Extending ack deadline for task 197502272691014\r\nDec 13, 2018 1:30:00 PM com.dummy.PubSubSyncPull$ModAckDeadlineRunnable run INFO: Extending ack deadline for task 197502272691014\r\nDec 13, 2018 1:31:50 PM com.dummy.PubSubSyncPull$ModAckDeadlineRunnable run INFO: Extending ack deadline for task 197502272691014\r\nDec 13, 2018 1:33:40 PM com.dummy.PubSubSyncPull$ModAckDeadlineRunnable run INFO: Extending ack deadline for task 197502272691014\r\nDec 13, 2018 1:34:17 PM com.dummy.PubSubSyncPull init\r\nWARNING: Error\r\ncom.google.api.gax.rpc.DeadlineExceededException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 11998988342ns\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:51)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:97)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:68)\r\n\tat com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1052)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:507)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:482)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\tSuppressed: com.google.api.gax.rpc.AsyncTaskException: Asynchronous task failed\r\n\t\tat com.google.api.gax.rpc.ApiExceptions.callAndTranslateApiException(ApiExceptions.java:57)\r\n\t\tat com.google.api.gax.rpc.UnaryCallable.call(UnaryCallable.java:112)\r\n\t\tat com.dummy.PubSubSyncPull.init(PubSubSyncPull.java:44)\r\n\t\tat com.dummy.MainApplication.main(MainApplication.java:6)\r\nCaused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 11998988342ns\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 23 more\r\n```\r\n\r\n#### Code snippet\r\nMainApplication.java\r\n```java\r\npackage com.dummy;\r\n\r\npublic class MainApplication {\r\n    public static void main(String[] args) throws Exception {\r\n        PubSubSyncPull puller = new PubSubSyncPull();\r\n        puller.init();\r\n    }\r\n}\r\n```\r\n\r\nPubSubSyncPull.java\r\n```java\r\npackage com.dummy;\r\n\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.concurrent.ScheduledExecutorService;\r\nimport java.util.concurrent.ScheduledFuture;\r\nimport java.util.concurrent.TimeUnit;\r\nimport java.util.logging.Logger;\r\n\r\nimport com.google.cloud.pubsub.v1.stub.GrpcSubscriberStub;\r\nimport com.google.cloud.pubsub.v1.stub.SubscriberStub;\r\nimport com.google.cloud.pubsub.v1.stub.SubscriberStubSettings;\r\nimport com.google.pubsub.v1.AcknowledgeRequest;\r\nimport com.google.pubsub.v1.ModifyAckDeadlineRequest;\r\nimport com.google.pubsub.v1.ProjectSubscriptionName;\r\nimport com.google.pubsub.v1.PullRequest;\r\nimport com.google.pubsub.v1.PullResponse;\r\nimport com.google.pubsub.v1.ReceivedMessage;\r\n\r\npublic class PubSubSyncPull {\r\n    private final Logger logger = Logger.getLogger(this.getClass().getName());\r\n\r\n    private static final long FAKE_WORKER_DURATION_IN_MILLISECONDS = 15 * 60 * 1_000L; // 15 min.\r\n    private static final int ACK_DEADLINE_IN_SECONDS = 120;\r\n    private static final int EXTEND_ACK_DEADLINE_SAFETY_MARGIN_IN_SECONDS = 10;\r\n    private static final TimeUnit EXTEND_ACK_DEADLINE_UNIT = TimeUnit.SECONDS;\r\n    private static final String SUBSCRIPTION = ProjectSubscriptionName.format(\"PROJECT_ID\", \"SUBSCRIPTION_ID\");\r\n\r\n    public void init() {\r\n        final ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\r\n        final ScheduledExecutorService ackDeadlineModifier = Executors\r\n                .newScheduledThreadPool(Runtime.getRuntime().availableProcessors());\r\n\r\n        try {\r\n            logger.info(\"Setting up synchronous pull...\");\r\n\r\n            SubscriberStubSettings subscriberStubSettings = SubscriberStubSettings.newBuilder().build();\r\n\r\n            try (SubscriberStub subscriber = GrpcSubscriberStub.create(subscriberStubSettings)) {\r\n                PullRequest pullRequest = PullRequest.newBuilder()\r\n                    .setMaxMessages(1)\r\n                    .setReturnImmediately(false)\r\n                    .setSubscription(SUBSCRIPTION)\r\n                    .build();\r\n\r\n                while (true) {\r\n                    PullResponse pullResponse = subscriber.pullCallable().call(pullRequest);\r\n\r\n                    if (pullResponse.getReceivedMessagesList().size() == 0) {\r\n                        continue;\r\n                    }\r\n\r\n                    logger.info(String.format(\"Got %d message(s)...\", pullResponse.getReceivedMessagesList().size()));\r\n\r\n                    for (ReceivedMessage message : pullResponse.getReceivedMessagesList()) {\r\n                        final Runnable modAckDeadlineTask = new ModAckDeadlineRunnable(subscriber, message);\r\n                        final ScheduledFuture<?> modAckDeadLineFuture = ackDeadlineModifier.scheduleAtFixedRate(\r\n                                modAckDeadlineTask,\r\n                                ACK_DEADLINE_IN_SECONDS - EXTEND_ACK_DEADLINE_SAFETY_MARGIN_IN_SECONDS,\r\n                                ACK_DEADLINE_IN_SECONDS - EXTEND_ACK_DEADLINE_SAFETY_MARGIN_IN_SECONDS,\r\n                                EXTEND_ACK_DEADLINE_UNIT);\r\n\r\n                        final Runnable worker = new WorkerRunnable(subscriber, modAckDeadLineFuture, message);\r\n                        executor.submit(worker);\r\n                    }\r\n                }\r\n            }\r\n\r\n        } catch (Exception e) {\r\n            logger.warning(\"Error\");\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    class WorkerRunnable implements Runnable {\r\n        private final SubscriberStub subscriber;\r\n        private final ScheduledFuture<?> modAckDeadLineFuture;\r\n        private final ReceivedMessage message;\r\n\r\n        public WorkerRunnable(final SubscriberStub subscriber, final ScheduledFuture<?> modAckDeadLineFuture,\r\n                final ReceivedMessage message) {\r\n            this.subscriber = subscriber;\r\n            this.modAckDeadLineFuture = modAckDeadLineFuture;\r\n            this.message = message;\r\n        }\r\n\r\n        @Override\r\n        public void run() {\r\n            try {\r\n                String id = message.getMessage().getMessageId();\r\n\r\n                logger.info(String.format(\"Handling task %s using thread: %s\", id, Thread.currentThread().getName()));\r\n\r\n                try {\r\n                    Thread.sleep(FAKE_WORKER_DURATION_IN_MILLISECONDS);\r\n\r\n                } catch (Exception e) {\r\n                    logger.warning(\"Thread error\");\r\n                    e.printStackTrace();\r\n                }\r\n\r\n                logger.info(String.format(\"Finishing task: %s\", id));\r\n\r\n                AcknowledgeRequest request = AcknowledgeRequest.newBuilder()\r\n                    .setSubscription(SUBSCRIPTION)\r\n                    .addAckIds(message.getAckId())\r\n                    .build();\r\n\r\n                modAckDeadLineFuture.cancel(true);\r\n                subscriber.acknowledgeCallable().call(request);\r\n\r\n            } catch (Exception e) {\r\n                logger.warning(\"Error\");\r\n                e.printStackTrace();\r\n            }\r\n        }\r\n    }\r\n\r\n    class ModAckDeadlineRunnable implements Runnable {\r\n        private final SubscriberStub subscriber;\r\n        private final ReceivedMessage message;\r\n\r\n        public ModAckDeadlineRunnable(final SubscriberStub subscriber, final ReceivedMessage message) {\r\n            this.subscriber = subscriber;\r\n            this.message = message;\r\n        }\r\n\r\n        @Override\r\n        public void run() {\r\n            try {\r\n                logger.info(String.format(\"Extending ack deadline for task %s\", message.getMessage().getMessageId()));\r\n                ModifyAckDeadlineRequest request = ModifyAckDeadlineRequest.newBuilder()\r\n                    .setSubscription(SUBSCRIPTION)\r\n                    .setAckDeadlineSeconds(ACK_DEADLINE_IN_SECONDS)\r\n                    .addAckIds(message.getAckId())\r\n                    .build();\r\n\r\n                subscriber.modifyAckDeadlineCallable().call(request);\r\n\r\n            } catch (Exception e) {\r\n                logger.warning(\"Error\");\r\n                e.printStackTrace();\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n#### External references such as API reference guides used\r\n- [https://cloud.google.com/pubsub/docs/pull#synchronous-pull](https://cloud.google.com/pubsub/docs/pull#synchronous-pull)\r\n- [https://github.com/googleapis/google-cloud-java/issues/3779#issuecomment-429305836](https://github.com/googleapis/google-cloud-java/issues/3779#issuecomment-429305836)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4219",
        "number": 4219,
        "title": "Spanner java api 1.0.0 - java.util.concurrent.RejectedExecutionException on createDatabase",
        "labels": [
            "api: spanner",
            "type: question"
        ],
        "state": "open",
        "body": "Hello,\r\n\r\nI'm trying to implement a Spanner utility package to wrap customary calls such as create/drop/update database/table for my project and I'm running into exceptions on Database creation with the 1.0.0 version of the library on a Scala project\r\n\r\nI didn't find any reference to a 1.0.0 release on this repo but the jar is available on maven repositories and I'd prefer to avoid a beta version if possible. In the meantime I'm reverting to `v0.68.0-beta`.\r\n\r\nI've seen references to the same exception in other issues but they were all old and closed.\r\n\r\n#### Environment details\r\n\r\n- OS: ArchLinux\r\n- Java version: 1.8.0_112\r\n- Scala version: 2.11.12\r\n- google-cloud-spanner version(s): 1.0.0\r\n\r\n#### Stacktrace\r\n\r\n```\r\nUNKNOWN: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4267c4d8 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7f3fe94d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\r\ncom.google.cloud.spanner.SpannerException: UNKNOWN: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4267c4d8 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7f3fe94d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerExceptionPreformatted(SpannerExceptionFactory.java:119)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:43)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:80)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:58)\r\n\tat com.google.cloud.spanner.SpannerImpl$DatabaseAdminClientImpl$2.apply(SpannerImpl.java:478)\r\n\tat com.google.cloud.spanner.SpannerImpl$DatabaseAdminClientImpl$2.apply(SpannerImpl.java:475)\r\n\tat com.google.api.core.ApiFutures$GaxFunctionToGuavaFunction.apply(ApiFutures.java:204)\r\n\tat com.google.common.util.concurrent.AbstractCatchingFuture$CatchingFuture.doFallback(AbstractCatchingFuture.java:206)\r\n\tat com.google.common.util.concurrent.AbstractCatchingFuture$CatchingFuture.doFallback(AbstractCatchingFuture.java:194)\r\n\tat com.google.common.util.concurrent.AbstractCatchingFuture.run(AbstractCatchingFuture.java:107)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:92)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat com.google.api.gax.retrying.BasicRetryingFuture.handleAttempt(BasicRetryingFuture.java:148)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.handle(CallbackChainRetryingFuture.java:135)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.run(CallbackChainRetryingFuture.java:117)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:92)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat com.google.api.gax.retrying.BasicRetryingFuture.handleAttempt(BasicRetryingFuture.java:148)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.handle(CallbackChainRetryingFuture.java:135)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.run(CallbackChainRetryingFuture.java:117)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:675)\r\n\tat com.google.common.util.concurrent.AbstractFuture$TrustedFuture.addListener(AbstractFuture.java:105)\r\n\tat com.google.common.util.concurrent.ForwardingListenableFuture.addListener(ForwardingListenableFuture.java:45)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture.setAttemptFuture(CallbackChainRetryingFuture.java:93)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.handle(CallbackChainRetryingFuture.java:138)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.run(CallbackChainRetryingFuture.java:117)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat com.google.api.core.AbstractApiFuture$InternalSettableFuture.setException(AbstractApiFuture.java:95)\r\n\tat com.google.api.core.AbstractApiFuture.setException(AbstractApiFuture.java:77)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:97)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:68)\r\n\tat com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1052)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1030)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:871)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:716)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:507)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:482)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat com.google.cloud.spanner.spi.v1.SpannerErrorInterceptor$1$1.onClose(SpannerErrorInterceptor.java:100)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4267c4d8 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7f3fe94d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\r\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)\r\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)\r\n\tat com.google.common.util.concurrent.MoreExecutors$ScheduledListeningDecorator.schedule(MoreExecutors.java:563)\r\n\tat com.google.api.gax.retrying.ScheduledRetryingExecutor.submit(ScheduledRetryingExecutor.java:116)\r\n\tat com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.handle(CallbackChainRetryingFuture.java:137)\r\n\t... 42 more\r\n```\r\n\r\n#### Code snippet\r\n\r\n```scala\r\nval opts = SpannerOptions.newBuilder().build()\r\nval spanner: Spanner = opts.getService\r\nval dbClient: DatabaseAdminClient = spanner.getDatabaseAdminClient\r\n\r\nval op: OperationFuture[Database, CreateDatabaseMetadata] = dbClient.createDatabase(instance, database, Iterable.empty[String])\r\n\r\ntry {\r\n  op.get()\r\n} catch {\r\n  case e: ExecutionException   => throw e.getCause.asInstanceOf[SpannerException]\r\n  case e: InterruptedException => throw SpannerExceptionFactory.propagateInterrupt(e)\r\n}\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\n- https://github.com/googleapis/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/spanner/snippets/DatabaseAdminClientSnippets.java\r\n\r\n#### Any additional information below\r\n\r\nThanks for your help!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4218",
        "number": 4218,
        "title": "Synthesis failed for compute",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate compute. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-compute'\nRunning synthtool\n['/tmpfs/src/git/autosynth/env/bin/python3', '-m', 'synthtool', 'synth.py', '--']\nsynthtool > Executing /tmpfs/src/git/autosynth/working_repo/google-cloud-clients/google-cloud-compute/synth.py.\nsynthtool > Cloning discovery-artifact-manager.\nsynthtool > Running generator for gapic/google/compute/artman_compute.yaml.\nsynthtool > Ensuring dependencies.\nsynthtool > Pulling artman image.\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\nsynthtool > Failed executing docker run --name artman-docker --rm -i -e HOST_USER_ID=1000 -e HOST_GROUP_ID=1000 -e RUNNING_IN_ARTMAN_DOCKER=True -v /home/kbuilder/.cache/synthtool/discovery-artifact-manager:/home/kbuilder/.cache/synthtool/discovery-artifact-manager -v /home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles:/home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles -w /home/kbuilder/.cache/synthtool/discovery-artifact-manager googleapis/artman:latest /bin/bash -c artman --local --config gapic/google/compute/artman_compute.yaml generate java_discogapic:\n\nartman> Final args:\nartman>   api_name: compute\nartman>   api_version: v1\nartman>   artifact_type: DISCOGAPIC\nartman>   aspect: ALL\nartman>   discovery_doc: discoveries/compute.v1.json\nartman>   gapic_code_dir: /home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles/java/gapic-google-cloud-compute-v1\nartman>   gapic_yaml: /home/kbuilder/.cache/synthtool/discovery-artifact-manager/gapic/google/compute/v1/compute_gapic.yaml\nartman>   generator_args: null\nartman>   import_proto_path:\nartman>     - /home/kbuilder/.cache/synthtool/discovery-artifact-manager\nartman>   language: java\nartman>   organization_name: google-cloud\nartman>   output_dir: /home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles\nartman>   proto_deps: []\nartman>   root_dir: /home/kbuilder/.cache/synthtool/discovery-artifact-manager\nartman>   service_yaml: ''\nartman>   src_proto_path: []\nartman>   toolkit_path: /toolkit\nartman>   \nartman> Creating DiscoGapicClientPipeline.\nartman.output >\nException in thread \"main\" java.lang.NullPointerException\n\tat com.google.api.codegen.discogapic.transformer.java.JavaDiscoGapicResourceNameToViewTransformer.generateResourceNameClass(JavaDiscoGapicResourceNameToViewTransformer.java:172)\n\tat com.google.api.codegen.discogapic.transformer.java.JavaDiscoGapicResourceNameToViewTransformer.transform(JavaDiscoGapicResourceNameToViewTransformer.java:123)\n\tat com.google.api.codegen.discogapic.transformer.java.JavaDiscoGapicResourceNameToViewTransformer.transform(JavaDiscoGapicResourceNameToViewTransformer.java:61)\n\tat com.google.api.codegen.discogapic.DiscoGapicGenerator.generate(DiscoGapicGenerator.java:66)\n\tat com.google.api.codegen.discogapic.DiscoGapicGeneratorApp.run(DiscoGapicGeneratorApp.java:191)\n\tat com.google.api.codegen.GeneratorMain.discoGapicMain(GeneratorMain.java:448)\n\tat com.google.api.codegen.GeneratorMain.main(GeneratorMain.java:182)\n\nartman> Traceback (most recent call last):\n  File \"/artman/artman/cli/main.py\", line 71, in main\n    engine.run()\n  File \"/usr/local/lib/python3.5/dist-packages/taskflow/engines/action_engine/engine.py\", line 159, in run\n    for _state in self.run_iter():\n  File \"/usr/local/lib/python3.5/dist-packages/taskflow/engines/action_engine/engine.py\", line 223, in run_iter\n    failure.Failure.reraise_if_any(it)\n  File \"/usr/local/lib/python3.5/dist-packages/taskflow/types/failure.py\", line 292, in reraise_if_any\n    failures[0].reraise()\n  File \"/usr/local/lib/python3.5/dist-packages/taskflow/types/failure.py\", line 299, in reraise\n    six.reraise(*self._exc_info)\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/taskflow/engines/action_engine/executor.py\", line 82, in _execute_task\n    result = task.execute(**arguments)\n  File \"/artman/artman/tasks/gapic_tasks.py\", line 159, in execute\n    task_utils.gapic_gen_task(toolkit_path, ['LEGACY_DISCOGAPIC_AND_PACKAGE'] + args))\n  File \"/artman/artman/tasks/task_base.py\", line 64, in exec_command\n    raise e\n  File \"/artman/artman/tasks/task_base.py\", line 56, in exec_command\n    output = subprocess.check_output(args, stderr=subprocess.STDOUT)\n  File \"/usr/lib/python3.5/subprocess.py\", line 626, in check_output\n    **kwargs).stdout\n  File \"/usr/lib/python3.5/subprocess.py\", line 708, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['java', '-cp', '/toolkit/build/libs/gapic-generator-latest-fatjar.jar', 'com.google.api.codegen.GeneratorMain', 'LEGACY_DISCOGAPIC_AND_PACKAGE', '--discovery_doc=/home/kbuilder/.cache/synthtool/discovery-artifact-manager/discoveries/compute.v1.json', '--package_yaml2=/home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles/java_google-cloud-compute-v1_package2.yaml', '--output=/home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles/java/gapic-google-cloud-compute-v1', '--language=java', '--gapic_yaml=/home/kbuilder/.cache/synthtool/discovery-artifact-manager/gapic/google/compute/v1/compute_gapic.yaml']' returned non-zero exit status 1\n\n\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/__main__.py\", line 87, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/click/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/click/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/click/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/click/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/__main__.py\", line 79, in main\n    spec.loader.exec_module(synth_module)\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n  File \"/tmpfs/src/git/autosynth/working_repo/google-cloud-clients/google-cloud-compute/synth.py\", line 32, in <module>\n    artman_output_name='')\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/discogapic_generator.py\", line 52, in java_library\n    return self._generate_code(service, version, \"java\", **kwargs)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/discogapic_generator.py\", line 98, in _generate_code\n    gapic_language_arg,\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/artman.py\", line 102, in run\n    shell.run(cmd, cwd=root_dir)\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/shell.py\", line 39, in run\n    raise exc\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/shell.py\", line 33, in run\n    encoding=\"utf-8\",\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'run', '--name', 'artman-docker', '--rm', '-i', '-e', 'HOST_USER_ID=1000', '-e', 'HOST_GROUP_ID=1000', '-e', 'RUNNING_IN_ARTMAN_DOCKER=True', '-v', '/home/kbuilder/.cache/synthtool/discovery-artifact-manager:/home/kbuilder/.cache/synthtool/discovery-artifact-manager', '-v', '/home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles:/home/kbuilder/.cache/synthtool/discovery-artifact-manager/artman-genfiles', '-w', PosixPath('/home/kbuilder/.cache/synthtool/discovery-artifact-manager'), 'googleapis/artman:latest', '/bin/bash', '-c', 'artman --local --config gapic/google/compute/artman_compute.yaml generate java_discogapic']' returned non-zero exit status 32.\nsynthtool > Cleaned up 0 temporary directories.\nsynthtool > Wrote metadata to synth.metadata.\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/a5bdb0db-c99f-423d-a43a-d46b581e37b9).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4212",
        "number": 4212,
        "title": "Spanner: Better document the difference between singleUse() and singleUseReadOnlyTransaction().",
        "labels": [
            "api: spanner",
            "type: docs"
        ],
        "state": "open",
        "body": "Hi,\r\nI think the documentation of the difference between `DatabaseClient.singleUse()` and `DatabaseClient.singleUseReadOnlyTransaction()` needs to be more verbose.\r\n\r\nThis is the documentation for both of these:\r\n> Returns a context in which a single read can be performed using TimestampBound.strong() concurrency.\r\n\r\n> Returns a read-only transaction context in which a single read or query can be performed using TimestampBound.strong() concurrency.\r\n\r\nBy looking at the code, the only difference I can really find is that `ReadOnlyTransaction` (returned by `singleUseReadOnlyTransaction()`) holds the `read_timestamp` selected internally by Spanner once the `Read` or query finishes. If I'm reading it correctly, that means that `singleUse()` is not less transactional than `singleUseReadOnlyTransaction()` is. Is there any reason (beyond compatibility) not to remove `singleUse()` from the `DatabaseClient`?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4211",
        "number": 4211,
        "title": "Stopping the receivers in Google pubsub?",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "open",
        "body": "Is there a way for me to stop the PubSub Subscriber message receivers _without_ calling the `stopAsync()`?\r\n\r\nThe use case is that I want to shutdown the Subscriber but I also want to nack any messages that have been received and queued locally or are in the process of being received as I shutdown my application.  Right now my only recourse is to call `stopAsync()`, nack the messages by the calling thread, and then once my queues are empty, join with the Subscriber being stopped.  I assume that this means that a certain number of the nacks will not get delivered to the Pubsub servers because the Subscriber is coming down.  This means that I have to rely on the ack timeouts for the messages to be retransmitted which is not optimal.\r\n\r\nSorry if I'm not understanding how the nack/ack/retransmit system works.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4205",
        "number": 4205,
        "title": "Java async pull subscriber stops receiving messages",
        "labels": [
            ":rotating_light:",
            "api: pubsub",
            "needs more info",
            "triage me",
            "type: bug"
        ],
        "state": "open",
        "body": "#### Environment details\r\n\r\n- OS: ubuntu0.18.04.1-b12\r\n- Java version: openjdk version \"1.8.0_191\"\r\n- google-cloud-java version(s): 1.40.0\r\n\r\n#### Steps to reproduce\r\n\r\nJava async pull subscriber abruptly stops pulling messages. \r\n\r\n#### Code snippet\r\n\r\nFlow control settings:\r\n\r\n```java\r\n    FlowControlSettings flowControlSettings = \r\n        FlowControlSettings.newBuilder()\r\n        .setMaxOutstandingElementCount(10000)\r\n        .setMaxOutstandingRequestBytes( 640000 ).build();\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4203",
        "number": 4203,
        "title": "Exception in thread \"Thread-4\" com.google.api.gax.rpc.UnavailableException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception",
        "labels": [
            "api: dialogflow",
            "type: question"
        ],
        "state": "open",
        "body": "I am trying to access a list of intents for a dialogflow project using a service json file. Running my program on my development MacBooks works flawlessly but using the same .jar on the target machines running Windows fails with the exception detailed below.\r\n#### Environment details\r\n\r\n- OS: Windows 7 64bit\r\n- Java version:\r\n`java version \"1.8.0_131\"`\r\n`Java(TM) SE Runtime Environment (build 1.8.0_131-b11)`\r\n`Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)`\r\n- google-cloud-java version(s):\r\n`com.google.cloud:google-cloud-dialogflow:0.70.0-alpha`\r\n\r\n#### Stacktrace\r\n\r\n```\r\nException in thread \"Thread-4\" com.google.api.gax.rpc.UnavailableException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception\r\nat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:69)\r\nat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\nat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\nat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:97)\r\nat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:68)\r\nat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\nat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\nat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\nat com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:634)\r\nat com.google.common.util.concurrent.ForwardingListenableFuture.addListener(ForwardingListenableFuture.java:45)\r\nat com.google.api.core.ApiFutureToListenableFuture.addListener(ApiFutureToListenableFuture.java:52)\r\nat com.google.common.util.concurrent.Futures.addCallback(Futures.java:1135)\r\nat com.google.api.core.ApiFutures.addCallback(ApiFutures.java:63)\r\nat com.google.api.gax.grpc.GrpcExceptionCallable.futureCall(GrpcExceptionCallable.java:67)\r\nat com.google.api.gax.rpc.AttemptCallable.call(AttemptCallable.java:81)\r\nat com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:111)\r\nat com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:58)\r\nat com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:75)\r\n```\r\n\r\n#### Code snippet\r\n_Setup code_\r\n```java\r\nServiceAccountCredentials credentials = ServiceAccountCredentials.fromStream(new FileInputStream(serviceJsonPath));\r\nIntentsSettings settings = IntentsSettings.newBuilder().setCredentialsProvider(FixedCredentialsProvider.create(credentials)).build();\r\n```\r\n\r\n_The program fails somewhere here_\r\n```java\r\nIntentsClient client = IntentsClient.create(settings);\r\nIterable<Intent> intents = client.listIntents(String.format(\"projects/%s/agent\", projectId)).iterateAll();\r\n```\r\n\r\n\r\n#### External references such as API reference guides used\r\n\r\n- https://dialogflow.com/docs/reference/api-v2/rest/v2/projects.agent.intents/list\r\n\r\n#### Any additional information below\r\n\r\nThe Windows machine needs a proxy to connect to the internet which I configured using `http.proxyHost`, `http.proxyPort`, `https.proxyHost` and `https.proxyPort`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4198",
        "number": 4198,
        "title": "Document dependency convergence issues / approach",
        "labels": [
            "type: docs"
        ],
        "state": "open",
        "body": "Our team has a sprawling set of dependencies that we own or influence and will never be able to have dependency convergence.  We will also have issues in projects that use our libraries like Apache Beam.  \r\n\r\nDocument the problems, our approach and how to use the tools we created in order to solve common problems."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4188",
        "number": 4188,
        "title": "Feature suggestion: auto content-type on blob creation",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "What if the API saves the blob setting it's content-type automatically? I guess it would make sense at least for public blobs. Do you have an opinion on that?\r\n\r\nCheers\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4187",
        "number": 4187,
        "title": "Bigtable: The new emulator is not available from maven central",
        "labels": [
            "api: bigtable",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I see it on the website:\r\nhttps://search.maven.org/artifact/com.google.cloud/google-cloud-bigtable-emulator/0.72.0-alpha/jar\r\n\r\nBut maven can't get it:\r\n`mvn dependency:get -Dartifact=com.google.cloud:google-cloud-bigtable-emulator:0.72.0-alpha`\r\n\r\n```\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:2.8:get (default-cli) on project standalone-pom: Couldn't download artifact: Unable to get dependency information for com.google.cloud:google-cloud-bigtable-emulator:jar:0.72.0-alpha: Failed to process POM for com.google.cloud:google-cloud-bigtable-emulator:jar:0.72.0-alpha: Non-resolvable parent POM for com.google.cloud:google-cloud-bigtable-emulator:0.72.0-alpha: Could not find artifact com.google.cloud:google-cloud-testing:pom:0.72.0-alpha in central (https://repo.maven.apache.org/maven2)\r\n[ERROR]   com.google.cloud:google-cloud-bigtable-emulator:jar:0.72.0-alpha\r\n[ERROR] \r\n[ERROR] from the specified remote repositories:\r\n[ERROR]   central (https://repo.maven.apache.org/maven2, releases=true, snapshots=false)\r\n[ERROR] Path to dependency: \r\n[ERROR] \t1) org.apache.maven.plugins:maven-downloader-plugin:jar:1.0\r\n```\r\n\r\nLooks like we have to publish the google-cloud-testing pom as well. \r\nHowever, that pom is explicitly marked not to be published to avoid publishing the child modules. I'm not sure what's the best way to proceed here.\r\n\r\n@chingor13  Any ideas?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4186",
        "number": 4186,
        "title": "Program type already present: com.google.api.CustomHttpPattern$1",
        "labels": [
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "#### Environment details\r\n\r\n- OS: MAC\r\n- Java version: 1.8\r\n- google-cloud-java version(s): 1.54.0\r\n\r\n#### Steps to reproduce\r\n1. Integrated google cloud Speech To Text sample from in my Android project https://github.com/GoogleCloudPlatform/android-docs-samples/tree/master/speech/Speech\r\nafter that, I added Google cloud storage dependency. After adding this dependency my build is getting failed. By saying \"Program type already present: com.google.api.CustomHttpPattern$1\" or sometimes logging \"Program type already present: com.google.api.AnnotationsProto\"\r\n\r\n#### Stacktrace\r\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':presentation:transformClassesWithMultidexlistForEdCastAppDebug'.\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:103)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:73)\r\n\tat org.gradle.api.internal.tasks.execution.OutputDirectoryCreatingTaskExecuter.execute(OutputDirectoryCreatingTaskExecuter.java:51)\r\n\tat org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:59)\r\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskOutputCachingStateExecuter.execute(ResolveTaskOutputCachingStateExecuter.java:54)\r\n\tat org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:59)\r\n\tat org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:101)\r\n\tat org.gradle.api.internal.tasks.execution.FinalizeInputFilePropertiesTaskExecuter.execute(FinalizeInputFilePropertiesTaskExecuter.java:44)\r\n\tat org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:91)\r\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:62)\r\n\tat org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:59)\r\n\tat org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\r\n\tat org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.run(DefaultTaskGraphExecuter.java:256)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:199)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:110)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:249)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:238)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:123)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:79)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:104)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:98)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:663)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:597)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:98)\r\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)\r\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.lang.RuntimeException: com.android.build.api.transform.TransformException: Error while generating the main dex list.\r\n\tat com.android.builder.profile.Recorder$Block.handleException(Recorder.java:55)\r\n\tat com.android.builder.profile.ThreadRecorder.record(ThreadRecorder.java:104)\r\n\tat com.android.build.gradle.internal.pipeline.TransformTask.transform(TransformTask.java:230)\r\n\tat sun.reflect.GeneratedMethodAccessor1642.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)\r\n\tat org.gradle.api.internal.project.taskfactory.IncrementalTaskAction.doExecute(IncrementalTaskAction.java:50)\r\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:39)\r\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:26)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActionsTaskExecuter.java:124)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:199)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:110)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:113)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:95)\r\n\t... 33 more\r\nCaused by: com.android.build.api.transform.TransformException: Error while generating the main dex list.\r\n\tat com.android.build.gradle.internal.transforms.D8MainDexListTransform.transform(D8MainDexListTransform.kt:144)\r\n\tat com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:239)\r\n\tat com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:235)\r\n\tat com.android.builder.profile.ThreadRecorder.record(ThreadRecorder.java:102)\r\n\t... 48 more\r\nCaused by: com.android.builder.multidex.D8MainDexList$MainDexListException: com.android.tools.r8.errors.CompilationError: Program type already present: com.google.api.CustomHttpPattern$1\r\n\tat com.android.builder.multidex.D8MainDexList.generate(D8MainDexList.java:87)\r\n\tat com.android.build.gradle.internal.transforms.D8MainDexListTransform.transform(D8MainDexListTransform.kt:131)\r\n\t... 51 more\r\nCaused by: com.android.tools.r8.errors.CompilationError: Program type already present: com.google.api.CustomHttpPattern$1\r\n\tat com.android.tools.r8.utils.ProgramClassCollection.resolveClassConflictImpl(ProgramClassCollection.java:64)\r\n\tat com.android.tools.r8.utils.ProgramClassCollection.lambda$create$0(ProgramClassCollection.java:25)\r\n\tat java.util.concurrent.ConcurrentHashMap.merge(ConcurrentHashMap.java:1990)\r\n\tat com.android.tools.r8.utils.ProgramClassCollection.create(ProgramClassCollection.java:24)\r\n\tat com.android.tools.r8.graph.LazyLoadedDexApplication$Builder.build(LazyLoadedDexApplication.java:124)\r\n\tat com.android.tools.r8.dex.ApplicationReader.read(ApplicationReader.java:123)\r\n\tat com.android.tools.r8.dex.ApplicationReader.read(ApplicationReader.java:86)\r\n\tat com.android.tools.r8.GenerateMainDexList.run(GenerateMainDexList.java:40)\r\n\tat com.android.tools.r8.GenerateMainDexList.run(GenerateMainDexList.java:110)\r\n\tat com.android.builder.multidex.D8MainDexList.generate(D8MainDexList.java:83)\r\n\r\n```\r\n#### External references such as API reference guides used\r\n I am using https://github.com/GoogleCloudPlatform/android-docs-samples/tree/master/speech/Speech with Google Cloud Storage\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4179",
        "number": 4179,
        "title": "Logback Appender for Google Cloud Logging does not comply with Error Reporting",
        "labels": [
            "api: clouderrorreporting",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Logback Appender for Google Cloud Logging does not comply with STACKDRIVER ERROR REPORTING.\r\n\r\n See https://cloud.google.com/error-reporting/docs/formatting-error-messages\r\n\r\nField\"serviceContext\" is mandatory and is not being generated by com.google.cloud.logging.logback.LoggingAppender\r\n\r\nThe following method should be changed:\r\n\r\n```java\r\n  private LogEntry logEntryFor(ILoggingEvent e) {\r\n    StringBuilder payload = new StringBuilder(e.getFormattedMessage()).append('\\n');\r\n    writeStack(e.getThrowableProxy(), \"\", payload);\r\n\r\n    Level level = e.getLevel();\r\n    LogEntry.Builder builder =\r\n        LogEntry.newBuilder(Payload.StringPayload.of(payload.toString().trim()))\r\n            .setTimestamp(e.getTimeStamp())\r\n            .setSeverity(severityFor(level));\r\n\r\n    builder\r\n        .addLabel(LEVEL_NAME_KEY, level.toString())\r\n        .addLabel(LEVEL_VALUE_KEY, String.valueOf(level.toInt()));\r\n\r\n    if (loggingEnhancers != null) {\r\n      for (LoggingEnhancer enhancer : loggingEnhancers) {\r\n        enhancer.enhanceLogEntry(builder);\r\n      }\r\n    }\r\n\r\n    if (loggingEventEnhancers != null) {\r\n      for (LoggingEventEnhancer enhancer : loggingEventEnhancers) {\r\n        enhancer.enhanceLogEntry(builder, e);\r\n      }\r\n    }\r\n\r\n    return builder.build();\r\n  }\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4175",
        "number": 4175,
        "title": "Dependency issue in cloud storage API",
        "labels": [
            "type: question"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Linux\r\n- Java version: 8\r\n- google-cloud-java version(s): 1.54 (and previous)\r\n\r\n#### Steps to reproduce\r\n\r\n1. untar the archive\r\n[Issue_Example.tar.gz](https://github.com/googleapis/google-cloud-java/files/2645801/Issue_Example.tar.gz)\r\n\r\n2. mvn install\r\n\r\n3. see the output :\r\nThe compilation failed cause of many \"Dependency convergence error\"\r\n\r\n\r\n#### Stacktrace\r\n\r\n[Issue_mvn_output.txt](https://github.com/googleapis/google-cloud-java/files/2645808/Issue_mvn_output.txt)\r\n\r\n#### Code snippet\r\n\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n\txsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n\t<modelVersion>4.0.0</modelVersion>\r\n\t<groupId>com.total</groupId>\r\n\t<artifactId>Example</artifactId>\r\n\t<version>0.0.1-SNAPSHOT</version>\r\n\r\n\t<build>\r\n\t\t<plugins>\r\n\t\t\t<plugin>\r\n\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\r\n\t\t\t\t<version>3.7.0</version>\r\n\t\t\t\t<configuration>\r\n\t\t\t\t\t<source>1.8</source>\r\n\t\t\t\t\t<target>1.8</target>\r\n\t\t\t\t</configuration>\r\n\t\t\t</plugin>\r\n\t\t\t<plugin>\r\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\r\n\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\r\n\t\t\t\t<version>3.0.0-M2</version>\r\n\t\t\t\t<executions>\r\n\t\t\t\t\t<execution>\r\n\t\t\t\t\t\t<id>enforce</id>\r\n\t\t\t\t\t\t<phase>compile</phase>\r\n\t\t\t\t\t\t<goals>\r\n\t\t\t\t\t\t\t<goal>enforce</goal>\r\n\t\t\t\t\t\t</goals>\r\n\t\t\t\t\t\t<configuration>\r\n\t\t\t\t\t\t\t<rules>\r\n\t\t\t\t\t\t\t\t<dependencyConvergence />\r\n\t\t\t\t\t\t\t</rules>\r\n\t\t\t\t\t\t</configuration>\r\n\t\t\t\t\t</execution>\r\n\t\t\t\t</executions>\r\n\t\t\t</plugin>\r\n\t\t</plugins>\r\n\t</build>\r\n\r\n\t<dependencies>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-storage</artifactId>\r\n\t\t\t<version>1.54.0</version>\r\n\t\t</dependency>\r\n\t</dependencies>\r\n</project>\r\n\r\n#### External references such as API reference guides used\r\n\r\n- ?\r\n\r\n#### Any additional information below\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4169",
        "number": 4169,
        "title": "Bad link on Storage docs page",
        "labels": [
            "api: storage",
            "type: docs"
        ],
        "state": "closed",
        "body": "There is a bad at\r\nhttps://github.com/googleapis/google-cloud-java/tree/master/google-cloud-clients/google-cloud-storage\r\n\r\nThe link in the text\r\n\"application on the StorageExample docs page\"\r\npoints to a 404\r\nhttps://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/?com/google/cloud/examples/storage/StorageExample.html\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4166",
        "number": 4166,
        "title": "Spanner: Flaky integration tests",
        "labels": [
            "api: spanner",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Spanner IT tests are occasionally failing with transaction aborted status\r\n\r\nExample:\r\nhttps://source.cloud.google.com/results/invocations/676bd73d-427e-48e7-b824-62b79e3288e0/targets/github%2Fgoogle-cloud-java%2Fgoogle-cloud-clients%2Fgoogle-cloud-spanner%2Ftarget%2Ffailsafe-reports/tests\r\n\r\nLast 9 failures:\r\n* [build 647](https://source.cloud.google.com/results/invocations/ff0d2ef9-3895-4788-b497-18ccbfab6714/targets) - timeout\r\n* [build 643](https://source.cloud.google.com/results/invocations/baee83ce-402c-4ed8-b8d6-0a5d7792efde/targets) - timeout\r\n* [build 642](https://source.cloud.google.com/results/invocations/e9e22a80-3fc7-4655-9f88-590ee9d7266e/targets) - Table already exists\r\n* [build 640](https://source.cloud.google.com/results/invocations/98d65ba1-e840-4944-be10-3cd28f9a9608/targets) - ABORTED in abort and retry test\r\n* [build 635](https://source.cloud.google.com/results/invocations/f99196f2-117f-4bd2-a3df-c83a6aab39ef/targets) - ABORTED in abort and retry test\r\n* [build 630](https://source.cloud.google.com/results/invocations/f00b00bc-c4ee-4f4f-b290-861a39c49978/targets) - timeout\r\n* [build 629](https://source.cloud.google.com/results/invocations/cc3ffbdb-e2db-4348-9b70-f883f966a969/targets) - timeout\r\n* [build 628](https://source.cloud.google.com/results/invocations/36d4d872-e281-4851-b135-df5c52b3faf8/targets) - ABORTED in abort and retry test\r\n* [build 626](https://source.cloud.google.com/results/invocations/676bd73d-427e-48e7-b824-62b79e3288e0/targets) - ABORTED w/ transaction not found in Partitioned DML test"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4162",
        "number": 4162,
        "title": "Random com.google.cloud.storage.StorageException: Socket closed",
        "labels": [
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "We randomly receive `com.google.cloud.storage.StorageException: Socket closed` when uploading files.\r\n\r\n#### Environment details\r\n\r\n- OS: Ubuntu 16\r\n- Java version: 11\r\n- google-cloud-java version(s): google-cloud-storage 1.53.0\r\n\r\n\r\n#### Stacktrace\r\n\r\n```\r\ncom.google.cloud.storage.StorageException: Socket closed\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220)\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.write(HttpStorageRpc.java:704)\r\n        at com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:51)\r\n        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\r\n        at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105)\r\n        at com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n        at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n        at com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:47)\r\n        at com.google.cloud.BaseWriteChannel.close(BaseWriteChannel.java:161)\r\n        ....\r\nCaused by: javax.net.ssl.SSLProtocolException: Socket closed\r\n        at java.base/sun.security.ssl.Alert.createSSLException(Alert.java:126)\r\n        at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:321)\r\n        at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:264)\r\n        at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:259)\r\n        at java.base/sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1314)\r\n        at java.base/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:839)\r\n        at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)\r\n        at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292)\r\n        at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)\r\n        at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:746)\r\n        at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:689)\r\n        at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1604)\r\n        at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1509)\r\n        at java.base/java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527)\r\n        at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:329)\r\n        at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37)\r\n        at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143)\r\n        at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84)\r\n        at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1011)\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.write(HttpStorageRpc.java:685)\r\n        ... 105 common frames omitted\r\nCaused by: java.net.SocketException: Socket closed\r\n        at java.base/java.net.SocketInputStream.read(SocketInputStream.java:183)\r\n        at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)\r\n        at java.base/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:448)\r\n        at java.base/sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(SSLSocketInputRecord.java:68)\r\n        at java.base/sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1104)\r\n        at java.base/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:823)\r\n        ... 119 common frames omitted\r\n```\r\n\r\nCan you add `SocketException` to retryable exceptions? Or any hints how to diagnose the root cause?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4152",
        "number": 4152,
        "title": "Inconsistent behavior between LocalStorageHelper and real google storage",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Mac\r\n- Java version: 8\r\n- google-cloud-java version(s):\r\n  val googleStorageNew: ModuleID = \"com.google.cloud\" % \"google-cloud-storage\" % \"1.53.0\"\r\n  val googleStorageLocal: ModuleID = \"com.google.cloud\" % \"google-cloud-nio\" % \"0.71.0-alpha\" % \"test\"\r\n\r\n#### Steps to reproduce\r\n\r\n**Code is in scala**\r\n```\r\nval page = db.list(bucketName.value, BlobListOption.prefix(objectNamePrefix), BlobListOption.pageSize(1), BlobListOption.currentDirectory())\r\n```\r\nif `db` is `LocalStorageHelper`, `page.iterateAll()` only gives me one page of object; if `db` is `com.google.cloud.storage.Storage`, then `page.iterateAll` will indeed give me multiple pages as documented.\r\n\r\n#### Stacktrace\r\n\r\n```\r\nAny relevant stacktrace here.\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\nAny relevant code snippet to help reproduce the issue.\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\n- ?\r\n\r\n#### Any additional information below\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4117",
        "number": 4117,
        "title": "blob.getMd5() doesn't work as expected",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "When I get any blob MD5 checksum using java API, the result is a Base64 string, that, when decoded, is not a MD5 string.\r\n\r\nExpected result: the file MD5 checksum string.\r\n\r\nCan anyone explain me why getMd5() returns a base64 of a MD5 instead of the MD5 itself?\r\n\r\n#### Environment details\r\n\r\n- OS: Linux\r\n- Java version: 1.8.0_172\r\n- google-cloud-java version(s): google-cloud-storage:1.53.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Save a blob using bucket.create(completeFilePath, fileByteArray)\r\n2. Get the file metadata using storage.get(blobId)\r\n3. Get the file MD5 using blob.getMd5()\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4107",
        "number": 4107,
        "title": "WriteChannel for GCS doesn't read response body, leaks connections",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "#### Environment details\r\n\r\n- OS: linux / centos7\r\n- Java version: 1.9\r\n- google-cloud-java version(s): \r\n  - com.google.cloud:google-cloud-storage:1.52.0\r\n  - com.google.cloud:google-cloud-core-http:1.52.0\r\n  - org.apache.httpcomponents:httpclient:4.5.5\r\n\r\n#### Steps to reproduce\r\n\r\nAt a high level we're trying to upload 100s of objects to GCS ~quickly. We want to do this using an Apache HTTP client because we need to use a custom resolver. That said, I think this is broken on both Apache and other http clients, it just may not manifest itself the same way.\r\n\r\n1. Use a custom transport factory builder in order to use Apache HTTP Client\r\n2. Allocate a PoolingHttpClientConnectionManager in your transport, set the pool size to 1\r\n3. Instantiate the Storage service using this transport factory\r\n4. Allocate a write channel\r\n5. Write to it\r\n6. Close it\r\n7. Allocate another write channel\r\n8. Try to write to it.\r\n\r\nUnder the hood the client will try to find an available connection from the pool and fail. It thinks the one we used earlier is still in use.\r\n\r\nIf you run ss or netstat on the machine at this point you can see an established connection to GCS with ~165 bytes sitting in the socket's receive buffer.\r\n\r\nThe reason is that we don't read the body of the response. See here:\r\n\r\nhttps://github.com/googleapis/google-cloud-java/blob/master/google-cloud-clients/google-cloud-storage/src/main/java/com/google/cloud/storage/spi/v1/HttpStorageRpc.java#L685\r\n\r\nThe response in both success and exception cases is discarded without ever reading or closing the response.\r\n\r\nHttpRequest's execute() method pretty clearly states we need to do something with the response:\r\n\r\nhttps://developers.google.com/api-client-library/java/google-http-java-client/reference/1.20.0/com/google/api/client/http/HttpRequest#execute()\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4101",
        "number": 4101,
        "title": "How to add formats to the logging logback",
        "labels": [],
        "state": "closed",
        "body": "#### Environment details\r\n\r\n- OS: Ubuntu\r\n- Java version: 1.8\r\n- 0.71.0-alpha\r\n\r\nI'm getting the whole log in one logentry, I think I need to setup format but I can't set the encoder.\r\nAny workaround/ support for this? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4098",
        "number": 4098,
        "title": "Synthesis failed for os-login",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "triage me",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate os-login. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-os-login'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nError response from daemon: error parsing HTTP 404 response body: invalid character 'p' after top-level value: \"404 page not found\\n\"\n\u001b[35msynthtool > \u001b[33mFailed executing docker pull googleapis/artman:latest:\n\nNone\u001b[0m\nTraceback (most recent call last):\n  File \"synth.py\", line 20, in <module>\n    gapic = gcp.GAPICGenerator()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 33, in __init__\n    self._artman = artman.Artman()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/artman.py\", line 35, in __init__\n    self._install_artman()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/artman.py\", line 124, in _install_artman\n    [\"docker\", \"pull\", f\"googleapis/artman:{ARTMAN_VERSION}\"], hide_output=False\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/shell.py\", line 39, in run\n    raise exc\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/shell.py\", line 33, in run\n    encoding=\"utf-8\",\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'pull', 'googleapis/artman:latest']' returned non-zero exit status 1.\n\u001b[35msynthtool > \u001b[36mCleaned up 0 temporary directories.\u001b[0m\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/260bb9ed-7455-47dc-bb2e-93251718430e).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4096",
        "number": 4096,
        "title": "Synthesis failed for video-intelligence",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "triage me",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate video-intelligence. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-video-intelligence'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nError response from daemon: error parsing HTTP 404 response body: invalid character 'p' after top-level value: \"404 page not found\\n\"\n\u001b[35msynthtool > \u001b[33mFailed executing docker pull googleapis/artman:latest:\n\nNone\u001b[0m\nTraceback (most recent call last):\n  File \"synth.py\", line 20, in <module>\n    gapic = gcp.GAPICGenerator()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 33, in __init__\n    self._artman = artman.Artman()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/artman.py\", line 35, in __init__\n    self._install_artman()\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/gcp/artman.py\", line 124, in _install_artman\n    [\"docker\", \"pull\", f\"googleapis/artman:{ARTMAN_VERSION}\"], hide_output=False\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/shell.py\", line 39, in run\n    raise exc\n  File \"/tmpfs/src/git/autosynth/env/lib/python3.6/site-packages/synthtool/shell.py\", line 33, in run\n    encoding=\"utf-8\",\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['docker', 'pull', 'googleapis/artman:latest']' returned non-zero exit status 1.\n\u001b[35msynthtool > \u001b[36mCleaned up 0 temporary directories.\u001b[0m\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/315ada17-78fd-4519-9160-4a22a00155a0).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4095",
        "number": 4095,
        "title": "Dependency issue with google-cloud-pubsub and Apache Beam packages",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I get a Maven install conflict between the Google Cloud pub/sub artifact:\r\n\r\n```\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-pubsub</artifactId>\r\n  <version>1.53.0</version>\r\n</dependency>\r\n```\r\n\r\nand the Apache Beam `google-cloud-dataflow-java-sdk-all` artifact:\r\n\r\n```\r\n    <dependency>\r\n      <groupId>com.google.cloud.dataflow</groupId>\r\n      <artifactId>google-cloud-dataflow-java-sdk-all</artifactId>\r\n      <version>2.5.0</version>\r\n    </dependency>\r\n```\r\n\r\n`google-cloud-pubsub` has various sub-dependencies  that rely on `io.grpc:grpc-core:jar:1.16.1`, and subdependencies of `google-cloud-dataflow-java-sdk-all` depend on  various versions of `io.grpc:grpc-core:jar` that do not match this. \r\n\r\nThe full Maven conflict error message I get is\r\n\r\n`Could not resolve version conflict among [com.google.cloud:google-cloud-pubsub:jar:1.53.0 -> com.google.cloud:google-cloud-core-grpc:jar:1.53.0 -> io.grpc:grpc-protobuf:jar:1.16.1 -> io.grpc:grpc-core:jar:1.16.1, com.google.cloud:google-cloud-pubsub:jar:1.53.0 -> com.google.cloud:google-cloud-core-grpc:jar:1.53.0 -> io.grpc:grpc-protobuf:jar:1.16.1 -> io.grpc:grpc-protobuf-lite:jar:1.16.1 -> io.grpc:grpc-core:jar:1.16.1, com.google.cloud:google-cloud-pubsub:jar:1.53.0 -> io.grpc:grpc-netty-shaded:jar:1.16.1 -> io.grpc:grpc-core:jar:[1.16.1,1.16.1], com.google.cloud:google-cloud-pubsub:jar:1.53.0 -> io.grpc:grpc-stub:jar:1.16.1 -> io.grpc:grpc-core:jar:1.16.1, com.google.cloud:google-cloud-pubsub:jar:1.53.0 -> io.grpc:grpc-auth:jar:1.16.1 -> io.grpc:grpc-core:jar:[1.16.1,1.16.1], com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> io.grpc:grpc-netty:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0], com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3 -> io.grpc:grpc-core:jar:1.5.0, com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -> io.grpc:grpc-core:jar:1.7.0, com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -> io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0 -> io.grpc:grpc-core:jar:1.6.1, com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0], com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-okhttp:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0], com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:jar:2.5.0 -> org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.5.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-protobuf-nano:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0`\r\n\r\nI've documented my specific issue and attempts to fix it more fully here:\r\n\r\nhttps://stackoverflow.com/questions/53424272/maven-conflict-in-java-app-with-google-cloud-core-grpc-dependency\r\n\r\nCan someone please recommend a workaround? I need one urgently.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4094",
        "number": 4094,
        "title": "Unable to stream audio signal in chunks via Java Servlet",
        "labels": [
            "api: dialogflow",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "Hi,\r\n \r\nwe are facing an issue while we are processing a binary stream with the google-cloud-dialogflow v2 Java API version 0.59.0-alpha.\r\nIn our scenario we built a servlet which provides a websocket to receive binary audio signal chunks. The implementation is based on \r\nhttps://cloud.google.com/dialogflow-enterprise/docs/detect-intent-stream#detect-intent-text-java and runs on a tomcat 8 instance with a Java 8. The issue occurs independent of using \r\na deprecated bidiStreamingCall or invoking a send() on a ClientStream<StreamingDetectIntentRequest>. \r\nIn case we buffer the bytes from @OnMessage executions and send all bytes at once when closing the websocket connection our\r\nResponseObserver<StreamingDetectIntentResponse> will get called so we are sure the audio signal is correct. If the bytes are send in a streamed manner,\r\nthe observer never receives a response. The cause is, that no requests will be sent by the google-cloud-dialogflow v2 API. The following error, which is raised\r\nafter some time, points to it:\r\ncom.google.api.gax.rpc.InvalidArgumentException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Request payload size exceeds the limit: 9961472 bytes.\r\nThe error occurs when the thread.sleep in line 111 is skipped. With skipping the thread.sleep, the client permanently sends chunks after the connection was openend.\r\nThough the invocation of drainPendingCallbacks in io.grpc.internal.DelayedStream never sets the boolean passThrough = true.\r\nIn case the thread.sleep is executed and causes the passThrough flag to be set to true, all runnables within delayOrExecute of io.grpc.internal.DelayedStream\r\nwill be invoked and the following exception appears(which is reproducable with the deprecated bidiStreamingCall or a send() on a ClientStream<StreamingDetectIntentRequest>):\r\n\r\n\r\nAfter updating google-cloud-dialogflow to 0.71.0-alpha the error still persists.\r\n\r\nour use case is quite simple. We would like to open a ClientStream with your Java library when a client opens a Websocket connection. The Client will constantly deliver the audio signal as binary which is treated onMessage within the Socket connection and send tot he ClientStream.\r\nOur expectations are to get called in the StreamingDetectResponseObserver with the QueryResults as well as a Webhook execution triggered by the DialogFlow Intent.\r\nUnfortunately the audio signal won\u00b4t get sent from your Code as it is described in the documentation. \r\n\r\n#### Environment details\r\n\r\n- OS: Windows\r\n- Java version: 1.8.0_151\r\n- google-cloud-java version(s): 0.71.0-alpha\r\n\r\n#### Steps to reproduce\r\n\r\nUse send() requests in a streaming manner instead of sending complete byte[] with the full audio signal\r\n\r\n#### Stacktrace\r\n\r\njava.util.concurrent.RejectedExecutionException: event executor terminated\r\n            at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.reject(SingleThreadEventExecutor.java:842)\r\n            at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.offerTask(SingleThreadEventExecutor.java:328)\r\n            at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.addTask(SingleThreadEventExecutor.java:321)\r\n            at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:765)\r\n            at io.grpc.netty.shaded.io.grpc.netty.WriteQueue.scheduleFlush(WriteQueue.java:65)\r\n            at io.grpc.netty.shaded.io.grpc.netty.WriteQueue.enqueue(WriteQueue.java:97)\r\n            at io.grpc.netty.shaded.io.grpc.netty.NettyClientStream$Sink.writeFrame(NettyClientStream.java:168)\r\n            at io.grpc.internal.AbstractClientStream.deliverFrame(AbstractClientStream.java:184)\r\n            at io.grpc.internal.MessageFramer.commitToSink(MessageFramer.java:350)\r\n            at io.grpc.internal.MessageFramer.flush(MessageFramer.java:300)\r\n            at io.grpc.internal.AbstractStream.flush(AbstractStream.java:63)\r\n            at io.grpc.internal.ForwardingClientStream.flush(ForwardingClientStream.java:42)\r\n            at io.grpc.internal.DelayedStream.flush(DelayedStream.java:238)\r\n            at io.grpc.internal.ClientCallImpl.sendMessage(ClientCallImpl.java:435)\r\n            at io.grpc.ForwardingClientCall.sendMessage(ForwardingClientCall.java:37)\r\n            at io.grpc.ForwardingClientCall.sendMessage(ForwardingClientCall.java:37)\r\n            at io.grpc.ForwardingClientCall.sendMessage(ForwardingClientCall.java:37)\r\n            at com.google.api.gax.grpc.GrpcDirectBidiStreamingCallable$1.send(GrpcDirectBidiStreamingCallable.java:67)\r\n            at com.google.api.gax.rpc.BidiStreamingCallable$3.onNext(BidiStreamingCallable.java:214)\r\n            at com.axians.itsolutions.ui5.convention.demo2018.web.NMSMPClientSpeechWebSocketEndpoint.processBinaryMessage(NMSMPClientSpeechWebSocketEndpoint.java:164)\r\n            at sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)\r\n            at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n            at java.lang.reflect.Method.invoke(Method.java:498)\r\n            at org.apache.tomcat.websocket.pojo.PojoMessageHandlerPartialBase.onMessage(PojoMessageHandlerPartialBase.java:71)\r\n            at org.apache.tomcat.websocket.WsFrameBase.sendMessageBinary(WsFrameBase.java:579)\r\n            at org.apache.tomcat.websocket.server.WsFrameServer.sendMessageBinary(WsFrameServer.java:131)\r\n            at org.apache.tomcat.websocket.WsFrameBase.processDataBinary(WsFrameBase.java:526)\r\n            at org.apache.tomcat.websocket.WsFrameBase.processData(WsFrameBase.java:300)\r\n            at org.apache.tomcat.websocket.WsFrameBase.processInputBuffer(WsFrameBase.java:133)\r\n            at org.apache.tomcat.websocket.server.WsFrameServer.onDataAvailable(WsFrameServer.java:82)\r\n            at org.apache.tomcat.websocket.server.WsFrameServer.doOnDataAvailable(WsFrameServer.java:171)\r\n            at org.apache.tomcat.websocket.server.WsFrameServer.notifyDataAvailable(WsFrameServer.java:151)\r\n            at org.apache.tomcat.websocket.server.WsHttpUpgradeHandler.upgradeDispatch(WsHttpUpgradeHandler.java:148)\r\n            at org.apache.coyote.http11.upgrade.UpgradeProcessorInternal.dispatch(UpgradeProcessorInternal.java:54)\r\n            at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:53)\r\n            at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:800)\r\n            at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1471)\r\n            at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\r\n            at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n            at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\r\n            at java.lang.Thread.run(Thread.java:836)\r\n\r\n#### Code snippet\r\n\r\npackage com.axians.itsolutions.ui5.convention.demo2018.web;\r\n\r\nimport java.io.ByteArrayOutputStream;\r\nimport java.io.IOException;\r\nimport java.util.HashMap;\r\nimport java.util.concurrent.CountDownLatch;\r\nimport java.util.concurrent.SynchronousQueue;\r\n\r\nimport javax.websocket.EndpointConfig;\r\nimport javax.websocket.OnClose;\r\nimport javax.websocket.OnError;\r\nimport javax.websocket.OnMessage;\r\nimport javax.websocket.OnOpen;\r\nimport javax.websocket.Session;\r\nimport javax.websocket.server.PathParam;\r\nimport javax.websocket.server.ServerEndpoint;\r\n\r\nimport org.json.JSONObject;\r\nimport org.slf4j.Logger;\r\nimport org.slf4j.LoggerFactory;\r\n\r\nimport com.google.api.gax.rpc.ClientStream;\r\nimport com.google.api.gax.rpc.ResponseObserver;\r\nimport com.google.cloud.dialogflow.v2.AudioEncoding;\r\nimport com.google.cloud.dialogflow.v2.InputAudioConfig;\r\nimport com.google.cloud.dialogflow.v2.QueryInput;\r\nimport com.google.cloud.dialogflow.v2.SessionName;\r\nimport com.google.cloud.dialogflow.v2.SessionsClient;\r\nimport com.google.cloud.dialogflow.v2.SessionsSettings;\r\nimport com.google.cloud.dialogflow.v2.StreamingDetectIntentRequest;\r\nimport com.google.cloud.dialogflow.v2.StreamingDetectIntentResponse;\r\nimport com.google.protobuf.ByteString;\r\n\r\n@ServerEndpoint(value=\"/speech/{conversationId}/{sampleRate}/{locale}/{dialogFlowId}\")\r\npublic class NMSMPClientSpeechWebSocketEndpoint {\r\n\t\r\n\tprivate ClientStream<StreamingDetectIntentRequest> clientStream;\r\n\t\r\n\tprivate ByteArrayOutputStream receivedBytes = new ByteArrayOutputStream();\r\n\t\r\n\tprivate NMSMPFixedGoogleCredentialsProvider credentialsProvider = new NMSMPFixedGoogleCredentialsProvider();\r\n\t\r\n\tprivate ResponseObserver<StreamingDetectIntentResponse> responseObserver;\r\n\r\n\tprivate CountDownLatch notification;\r\n\t\r\n\tprivate SessionName dialogFlowSession;\r\n\t\r\n\tprivate SessionsClient sessionClient;\r\n\r\n\tprivate final Logger logger = LoggerFactory.getLogger(this.getClass());\r\n\t\r\n\tpublic static final HashMap<String,Session> clientSpeechConnections = new HashMap<String, Session>();\r\n\t\r\n\tprivate int sampleRate;\r\n\t\r\n\tprivate String locale;\r\n\t\r\n\t@OnOpen\r\n    public void onOpen(@PathParam(\"conversationId\") String conversationId, @PathParam(\"sampleRate\") Integer sampleRate, @PathParam(\"locale\") String locale, @PathParam(\"dialogFlowId\") String dialogFlowId, Session webSession, EndpointConfig config) throws Throwable {\r\n\t\t\r\n\t\tgetLogger().error(\"onOpen::\" + webSession.getId());\r\n        \r\n\t\tif(conversationId != null ) {\r\n\r\n\t\t\t// Set the session name using the sessionId (UUID) and projectID (my-project-id)\r\n            setDialogFlowSession(SessionName.of(dialogFlowId, conversationId));\r\n\t\t\t\r\n        \tclientSpeechConnections.put(getDialogFlowSession().toString(), webSession);\r\n            setNotification(new CountDownLatch(1));\r\n            setSampleRate(sampleRate);\r\n            setLocale(locale);\r\n\t\t\t\r\n\t\t\tif (getClientStream() == null) {\r\n\t    \t\tlong time = System.currentTimeMillis();\r\n\t    \t\ttry (SessionsClient sessionsClient = SessionsClient.create(SessionsSettings.newBuilder().setCredentialsProvider(getCredentialsProvider()).build())) {\r\n\t                getLogger().error(\"Session Path: \" + getDialogFlowSession().toString());\r\n\r\n\t                setSessionClient(sessionsClient);\r\n\t                \r\n\t                // Note: hard coding audioEncoding and sampleRateHertz for simplicity.\r\n\t\t            // Audio encoding of the audio content sent in the query request.\r\n\t\t            AudioEncoding audioEncoding = AudioEncoding.AUDIO_ENCODING_LINEAR_16;\r\n\t\t            int sampleRateHertz = getSampleRate();\r\n\t\t\r\n\t\t            // Instructs the speech recognizer how to process the audio content.\r\n\t\t            InputAudioConfig inputAudioConfig = InputAudioConfig.newBuilder()\r\n\t\t                .setAudioEncoding(audioEncoding) // audioEncoding = AudioEncoding.AUDIO_ENCODING_LINEAR_16\r\n\t\t                .setLanguageCode(getLocale())\r\n\t\t                .setSampleRateHertz(sampleRateHertz)\r\n\t\t                .build();\r\n\t\t            \r\n\t\t            setResponseObserver(new NMSMPStreamingDetectResponseObserver(getNotification()));\r\n\t\t              \r\n\t\t           // Performs the streaming detect intent callable request\r\n\t\t            setClientStream(getSessionClient().streamingDetectIntentCallable().splitCall(getResponseObserver()));\r\n\t\t                \r\n\t\t            // The first request contains the configuration\r\n\t\t            StreamingDetectIntentRequest request = StreamingDetectIntentRequest.newBuilder()\r\n\t\t                .setSession(getDialogFlowSession().toString())\r\n\t\t                .setQueryInput(QueryInput.newBuilder().setAudioConfig(inputAudioConfig).build())\r\n\t\t//                    .setSingleUtterance(false)\r\n\t\t                .build();\r\n\t\t                \r\n\t                // Make the first request\r\n\t\t            getClientStream().send(request);\r\n\t\t            \r\n\t\t            getLogger().error(\"Stream establishment took: \" + String.valueOf(System.currentTimeMillis() - time));\r\n\t\t            \r\n\t    \t\t} catch (Exception e) {\r\n\t              \tgetLogger().error(\"sessionClient runtimeException:\", e);\r\n\t                  // Cancel stream and close Websocket.\r\n\t    \t\t}\r\n\t    \t}\r\n        }\r\n    }\r\n    \r\n    @OnMessage\r\n    public void onMessage(String message, Session session) {\r\n    \tif (message.equals(\"stop\")) {\r\n    \t\tgetLogger().error(\"onMessage received stop from client\");\r\n    \t} else {\r\n    \t\tSynchronousQueue<JSONObject> fulfillmentQueue = com.axians.itsolutions.ui5.convention.demo2018.web.rest.DialogFlowServlet.fulfillmentQueues.get(getDialogFlowSession().toString());\r\n    \t\tgetLogger().error(\"onMessage client responded fulFillment:\", message);\r\n    \t\tif (fulfillmentQueue != null) {\r\n    \t\t\tgetLogger().error(\"onMessage found fulFillmentQueue... offering message\");\r\n    \t\t\tfulfillmentQueue.offer(new JSONObject(message));\r\n    \t\t}\r\n    \t\tSession webSession = clientSpeechConnections.get(getDialogFlowSession().toString());\r\n    \t\tif (webSession != null) {\r\n    \t\t\ttry {\r\n\t\t\t\t\twebSession.close();\r\n\t\t\t\t\tgetLogger().error(\"client speech connection was closed:\");\r\n\t\t\t\t} catch (IOException e) {\r\n\t\t\t\t\tgetLogger().error(\"error while closing the client speech connection:\", e);\r\n\t\t\t\t}\r\n    \t\t}\r\n    \t}\r\n    }\r\n    \r\n    private void sendCollectedBytes(byte[] bytes) {\r\n        getClientStream().send(\r\n\t              StreamingDetectIntentRequest.newBuilder().setSession(getDialogFlowSession().toString())\r\n\t                  .setInputAudio(ByteString.copyFrom(bytes, 0, bytes.length))\r\n\t                  .build());\r\n    }\r\n\r\n    @OnMessage\r\n    public void processBinaryMessage(byte[] bytes, boolean last, Session session) throws Throwable {\r\n    \t// Ensure grpc max payload size does not exceed\r\n\t\tif(bytes != null && bytes.length > 0 && getReceivedBytes().size() < 9800000) {\r\n\t\t\tsendCollectedBytes(bytes);\r\n\t\t}\r\n    }\r\n    \r\n    @OnClose\r\n    public void onClose(Session session) throws Throwable {\r\n    \tgetLogger().error(\"onClose:: removing from sessions sessionId: \" +  session.getId() + \" conversationId: \" + session.getRequestParameterMap().get(\"conversationId\").toString());\r\n    \t\r\n    \ttry {\r\n\t\t\tgetNotification().await();\r\n\t\t} catch (InterruptedException e) {\r\n\t\t\tgetLogger().error(\"error while closing the client speech connection:\", e);\r\n\t\t}\r\n        \r\n        if (getSessionClient() != null) {\r\n    \t\tgetSessionClient().close();\r\n    \t}\r\n    \tsetClientStream(null);\r\n    \tclientSpeechConnections.remove(session.getRequestParameterMap().get(\"conversationId\").toString());\r\n    }\r\n    \r\n    @OnError\r\n    public void onError(Throwable t) {\r\n        getLogger().error(\"onError:\", t);\r\n    }\r\n\r\n\tpublic CountDownLatch getNotification() {\r\n\t\treturn notification;\r\n\t}\r\n\r\n\r\n\tpublic void setNotification(CountDownLatch notification) {\r\n\t\tthis.notification = notification;\r\n\t}\r\n\r\n\r\n\tpublic SessionName getDialogFlowSession() {\r\n\t\treturn dialogFlowSession;\r\n\t}\r\n\r\n\r\n\tpublic void setDialogFlowSession(SessionName dialogFlowSession) {\r\n\t\tthis.dialogFlowSession = dialogFlowSession;\r\n\t}\r\n    \r\n\tpublic Logger getLogger() {\r\n\t\treturn logger;\r\n\t}\r\n\r\n\r\n\tpublic NMSMPFixedGoogleCredentialsProvider getCredentialsProvider() {\r\n\t\treturn credentialsProvider;\r\n\t}\r\n\r\n\tpublic void setCredentialsProvider(NMSMPFixedGoogleCredentialsProvider credentialsProvider) {\r\n\t\tthis.credentialsProvider = credentialsProvider;\r\n\t}\r\n\r\n\tpublic ResponseObserver<StreamingDetectIntentResponse> getResponseObserver() {\r\n\t\treturn responseObserver;\r\n\t}\r\n\r\n\tpublic void setResponseObserver(ResponseObserver<StreamingDetectIntentResponse> responseObserver) {\r\n\t\tthis.responseObserver = responseObserver;\r\n\t}\r\n\r\n\tpublic ClientStream<StreamingDetectIntentRequest> getClientStream() {\r\n\t\treturn clientStream;\r\n\t}\r\n\r\n\tpublic void setClientStream(ClientStream<StreamingDetectIntentRequest> clientStream) {\r\n\t\tthis.clientStream = clientStream;\r\n\t}\r\n\r\n\tpublic ByteArrayOutputStream getReceivedBytes() {\r\n\t\treturn receivedBytes;\r\n\t}\r\n\r\n\tpublic void setReceivedBytes(ByteArrayOutputStream receivedBytes) {\r\n\t\tthis.receivedBytes = receivedBytes;\r\n\t}\r\n\r\n\tpublic int getSampleRate() {\r\n\t\treturn sampleRate;\r\n\t}\r\n\r\n\tpublic void setSampleRate(int sampleRate) {\r\n\t\tthis.sampleRate = sampleRate;\r\n\t}\r\n\r\n\tpublic String getLocale() {\r\n\t\treturn locale;\r\n\t}\r\n\r\n\tpublic void setLocale(String locale) {\r\n\t\tthis.locale = locale;\r\n\t}\r\n\r\n\tpublic SessionsClient getSessionClient() {\r\n\t\treturn sessionClient;\r\n\t}\r\n\r\n\tpublic void setSessionClient(SessionsClient sessionClient) {\r\n\t\tthis.sessionClient = sessionClient;\r\n\t}\r\n\r\n}\r\n\r\n#### External references such as API reference guides used\r\n\r\n\r\n\r\n#### Any additional information below\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4091",
        "number": 4091,
        "title": "Bigtable: Remove typesafe names from the api",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "open",
        "body": "Currently they create more issues than they solve:\r\n- Some names are duplicated between the admin and data namespace\r\n- Some names are only available in the admin namespace, which means they are duplicated in the models namespace instead.\r\n\r\nTo avoid all of these issues, we should just use strings for now."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4090",
        "number": 4090,
        "title": "Bigtable: update create table docs to demonstrate GCRules usage",
        "labels": [
            "api: bigtable",
            "type: docs"
        ],
        "state": "open",
        "body": "Due to naming similarity of the corresponding proto class it's easy to mistakenly use proto classes \r\nExample of confusion:\r\nhttps://gist.github.com/emmmile/2ffc8e390c05ecb40421e285de54f504"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4089",
        "number": 4089,
        "title": "0.71.0 has an upper bounds failure",
        "labels": [
            "dependencies",
            "type: feature request"
        ],
        "state": "open",
        "body": "I'm sending PRs to fix this upstream but we might want to work around this her in the meantime.\r\n\r\n```\r\n[WARNING] Rule 0: org.apache.maven.plugins.enforcer.RequireUpperBoundDeps failed with message:\r\nFailed while enforcing RequireUpperBoundDeps. The error(s) are [\r\nRequire upper bound dependencies error for com.google.auth:google-auth-library-oauth2-http:0.11.0 paths to dependency are:\r\n+-com.google.cloud:upper-bounds-check:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-core:1.53.0\r\n    +-com.google.api:gax:1.35.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.11.0\r\nand\r\n+-com.google.cloud:upper-bounds-check:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-storage:1.53.0\r\n    +-com.google.cloud:google-cloud-core-http:1.53.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.12.0\r\nand\r\n+-com.google.cloud:upper-bounds-check:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-storage:1.53.0\r\n    +-com.google.cloud:google-cloud-core-http:1.53.0\r\n      +-com.google.api:gax-httpjson:0.52.0\r\n        +-com.google.auth:google-auth-library-oauth2-http:0.11.0\r\n]\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4088",
        "number": 4088,
        "title": "Synthesis failed for video-intelligence",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate video-intelligence. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-video-intelligence'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/videointelligence/artman_videointelligence_v1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/videointelligence/artman_videointelligence_v1beta1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/videointelligence/artman_videointelligence_v1beta2.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/videointelligence/artman_videointelligence_v1p1beta1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/videointelligence/artman_videointelligence_v1p2beta1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-video-intelligence\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate video-intelligence client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4087",
        "number": 4087,
        "title": "Synthesis failed for texttospeech",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate texttospeech. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-texttospeech'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/texttospeech/artman_texttospeech_v1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/texttospeech/artman_texttospeech_v1beta1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-texttospeech\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate texttospeech client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4086",
        "number": 4086,
        "title": "Synthesis failed for os-login",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate os-login. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-os-login'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/oslogin/artman_oslogin_v1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-os-login\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate os-login client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4085",
        "number": 4085,
        "title": "Synthesis failed for datastore",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate datastore. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-datastore'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/datastore/artman_datastore.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-datastore\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate datastore client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4084",
        "number": 4084,
        "title": "Synthesis failed for container",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate container. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-container'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/container/artman_container_v1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-container\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate container client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4083",
        "number": 4083,
        "title": "Synthesis failed for bigtable",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate bigtable. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-bigtable'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/bigtable/artman_bigtable.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-bigtable\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate bigtable client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4082",
        "number": 4082,
        "title": "Synthesis failed for bigquerystorage",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate bigquerystorage. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-bigquerystorage'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Image is up to date for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/bigquery/storage/artman_bigquerystorage_v1beta1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-bigquerystorage\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate bigquerystorage client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4081",
        "number": 4081,
        "title": "Synthesis failed for asset",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate asset. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-asset'\n\u001b[35msynthtool > \u001b[31m\u001b[43mYou are running the synthesis script directly, this will be disabled in a future release of Synthtool. Please use python3 -m synthtool instead.\u001b[0m\n\u001b[35msynthtool > \u001b[36mEnsuring dependencies.\u001b[0m\n\u001b[35msynthtool > \u001b[36mPulling artman image.\u001b[0m\nlatest: Pulling from googleapis/artman\n7b8b6451c85f: Pulling fs layer\nab4d1096d9ba: Pulling fs layer\ne6797d1788ac: Pulling fs layer\ne25c5c290bde: Pulling fs layer\n64cc7778860a: Pulling fs layer\nfba400fd4e72: Pulling fs layer\n034dbb0beb6d: Pulling fs layer\n2fc51e8f92f3: Pulling fs layer\na4a5249d2639: Pulling fs layer\nc9a6f6bfc96b: Pulling fs layer\nfba0f0f727c2: Pulling fs layer\n1059a6b2506e: Pulling fs layer\nf3756e52e4de: Pulling fs layer\n43bc6a5b7b95: Pulling fs layer\n2de0922ea8ee: Pulling fs layer\nf048d7833b62: Pulling fs layer\na79871e06993: Pulling fs layer\ne7b11ec69700: Pulling fs layer\n7408620fa0d1: Pulling fs layer\n71c0765ba0e5: Pulling fs layer\n5a2dfcfff060: Pulling fs layer\n3724d328eeed: Pulling fs layer\na82857489f90: Pulling fs layer\ne25c5c290bde: Waiting\n64cc7778860a: Waiting\nfba400fd4e72: Waiting\n034dbb0beb6d: Waiting\n2fc51e8f92f3: Waiting\n1059a6b2506e: Waiting\na4a5249d2639: Waiting\nf3756e52e4de: Waiting\n43bc6a5b7b95: Waiting\n2de0922ea8ee: Waiting\nc9a6f6bfc96b: Waiting\nf048d7833b62: Waiting\na79871e06993: Waiting\n5a2dfcfff060: Waiting\nfba0f0f727c2: Waiting\n3724d328eeed: Waiting\na82857489f90: Waiting\n71c0765ba0e5: Waiting\ne7b11ec69700: Waiting\nab4d1096d9ba: Verifying Checksum\nab4d1096d9ba: Download complete\ne6797d1788ac: Download complete\ne25c5c290bde: Download complete\n7b8b6451c85f: Verifying Checksum\n7b8b6451c85f: Download complete\n64cc7778860a: Verifying Checksum\n64cc7778860a: Download complete\n034dbb0beb6d: Verifying Checksum\n034dbb0beb6d: Download complete\na4a5249d2639: Verifying Checksum\na4a5249d2639: Download complete\nc9a6f6bfc96b: Verifying Checksum\nc9a6f6bfc96b: Download complete\n2fc51e8f92f3: Verifying Checksum\n2fc51e8f92f3: Download complete\n7b8b6451c85f: Pull complete\nab4d1096d9ba: Pull complete\ne6797d1788ac: Pull complete\ne25c5c290bde: Pull complete\n1059a6b2506e: Verifying Checksum\n1059a6b2506e: Download complete\nfba400fd4e72: Verifying Checksum\nfba400fd4e72: Download complete\n43bc6a5b7b95: Verifying Checksum\n43bc6a5b7b95: Download complete\nfba0f0f727c2: Verifying Checksum\nfba0f0f727c2: Download complete\n64cc7778860a: Pull complete\n2de0922ea8ee: Verifying Checksum\n2de0922ea8ee: Download complete\nf048d7833b62: Verifying Checksum\nf048d7833b62: Download complete\nf3756e52e4de: Verifying Checksum\nf3756e52e4de: Download complete\ne7b11ec69700: Verifying Checksum\ne7b11ec69700: Download complete\n71c0765ba0e5: Verifying Checksum\n71c0765ba0e5: Download complete\n5a2dfcfff060: Verifying Checksum\n5a2dfcfff060: Download complete\na79871e06993: Verifying Checksum\na79871e06993: Download complete\n3724d328eeed: Verifying Checksum\n3724d328eeed: Download complete\na82857489f90: Verifying Checksum\na82857489f90: Download complete\n7408620fa0d1: Verifying Checksum\n7408620fa0d1: Download complete\nfba400fd4e72: Pull complete\n034dbb0beb6d: Pull complete\n2fc51e8f92f3: Pull complete\na4a5249d2639: Pull complete\nc9a6f6bfc96b: Pull complete\nfba0f0f727c2: Pull complete\n1059a6b2506e: Pull complete\nf3756e52e4de: Pull complete\n43bc6a5b7b95: Pull complete\n2de0922ea8ee: Pull complete\nf048d7833b62: Pull complete\na79871e06993: Pull complete\ne7b11ec69700: Pull complete\n7408620fa0d1: Pull complete\n71c0765ba0e5: Pull complete\n5a2dfcfff060: Pull complete\n3724d328eeed: Pull complete\na82857489f90: Pull complete\nDigest: sha256:2f6b261ee7fe1aedf238991c93a20b3820de37a343d0cacf3e3e9555c2aaf2ea\nStatus: Downloaded newer image for googleapis/artman:latest\n\u001b[35msynthtool > \u001b[36mCloning googleapis.\u001b[0m\n\u001b[35msynthtool > \u001b[36mRunning generator for google/cloud/asset/artman_cloudasset_v1beta1.yaml.\u001b[0m\n\u001b[35msynthtool > \u001b[32mGenerated code into /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java.\u001b[0m\n\u001b[35msynthtool > \u001b[36mCleaned up 1 temporary directories.\u001b[0m\n\nChanged files:\n\nOn branch autosynth-asset\nnothing to commit, working tree clean\nTraceback (most recent call last):\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 166, in <module>\n    main()\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 151, in main\n    commit_changes(pr_title)\n  File \"/tmpfs/src/git/autosynth/autosynth/synth.py\", line 95, in commit_changes\n    subprocess.check_call([\"git\", \"commit\", \"-m\", message])\n  File \"/home/kbuilder/.pyenv/versions/3.6.1/lib/python3.6/subprocess.py\", line 291, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['git', 'commit', '-m', 'Regenerate asset client']' returned non-zero exit status 1.\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/6ff08a8f-712e-441a-b12f-c2a8765203d4).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4057",
        "number": 4057,
        "title": "Bigtable: investigate GCRule.fromProto being incorrect",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "open",
        "body": "From a user:\r\n\r\n> GCRule and GcRule classes are confusing and .fromProto() conversion does not work properly in some cases. Not 100% sure which scenario it was, but I think we were setting maxversions and maxage, and only one of them was in the final result after calling .fromProto()."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4056",
        "number": 4056,
        "title": "Bigtable: document that GCRules are only applied during compaction",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "open",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4055",
        "number": 4055,
        "title": "Bigtable: add helper methods to Rows to efficiently fetch qualifier values",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "open",
        "body": "A Row is currently a flat list of cells. The cells have a particular order: all cells for a column family are clustered (NOTE: column families are not sorted, only clustered.) and then sorted lexicographically by qualifier. To expose this behavior to the user we should have 3 methods that on the Row class:\r\n\r\n```java\r\nList<RowCell> getCells(String family)\r\nList<RowCell> getCells(String family, ByteString qualifier)\r\nList<RowCell> getCells(String family, String qualifier)\r\n```\r\n\r\nThese methods should efficiently return a list of matching cells. To implement this efficiently, the `Row` class should include `Map` of index ranges for each family cluster, which should populated by the `RowMerger`. Then the 3 methods could use a combination of index lookups (for the family) and binary searches (for the qualifier) to return the matching cells.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4054",
        "number": 4054,
        "title": "Bigtable: Improve docs to make it clear that all methods are wrappers around callables",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "open",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4053",
        "number": 4053,
        "title": "Bigtable: There should be versions of readRowAsync() and readRowsAsync() that takes a Query as argument",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4021",
        "number": 4021,
        "title": "Integration tests should output matching .log files",
        "labels": [
            "type: cleanup"
        ],
        "state": "open",
        "body": "Currently, the tests output junit xml files. The associated log output should match the filename of the xml file.\r\n\r\nExample:\r\n`TEST-com.google.cloud.bigtable.data.v2.it.SampleRowsIT-sponge_log.log` and\r\n`TEST-com.google.cloud.bigtable.data.v2.it.SampleRowsIT-sponge_log.xml`\r\n\r\nWe should also merge the output files or sponge thinks the test is flakey and has been retried for each .xml file."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4019",
        "number": 4019,
        "title": "Quick start guide ends with NoSuchMethod error",
        "labels": [
            "api: dialogflow",
            "dependencies",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "I'm trying to create an API which, when triggered, sends a request to Dialogflow.\r\nTo do that, I'm using the Java SDK, as found [here](https://github.com/googleapis/google-cloud-java/tree/master/google-cloud-clients/google-cloud-dialogflow).\r\n\r\nThe problematic code snippet is copy-pasted from [here](https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/dialogflow/v2beta1/package-summary.html), to the bottom of the page.\r\n\r\n```\r\ntry (SessionsClient sessionsClient = SessionsClient.create()) {\r\n    SessionName session = SessionName.of(genericProjectId, genericSessionId);\r\n    QueryInput queryInput = QueryInput.newBuilder().build();\r\n    DetectIntentResponse response = sessionsClient.detectIntent(session, \r\n    queryInput);\r\n}\r\n```\r\nWhen I run \"SessionsClient.create()\", the error\r\n\r\n```\r\njavax.ejb.TransactionRolledbackLocalException: Exception thrown from bean: java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;CLjava/lang/Object;)V\r\n```\r\nis thrown at runtime. Knowing this has something to do with either guava or protobuf, I have trimmed down everything from my pom.xml file, so that the only libraries loaded are those from the SDK. That's the current POM.\r\n```\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n     xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n    <modelVersion>4.0.0</modelVersion>\r\n    <groupId>com.mycompany</groupId>\r\n    <artifactId>MYPROJECTNAME</artifactId>\r\n    <version>1.0-SNAPSHOT</version>\r\n    <packaging>war</packaging>\r\n    <!--START EDIT 1: ADDED AS A TEST-->\r\n    <dependencyManagement>\r\n        <dependencies>\r\n            <dependency>\r\n                <groupId>com.google.cloud</groupId>\r\n                <artifactId>google-cloud-bom</artifactId>\r\n                <version>0.71.0-alpha</version>\r\n                <type>pom</type>\r\n                <scope>import</scope>\r\n            </dependency>\r\n        </dependencies>\r\n    </dependencyManagement>\r\n    <!--END EDIT 1-->\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-dialogflow</artifactId>\r\n            <version>0.71.0-alpha</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>javax</groupId>\r\n            <artifactId>javaee-api</artifactId>\r\n            <version>7.0</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n    </dependencies>\r\n    <build>\r\n        <finalName>MYPROJECTNAME</finalName>\r\n        <plugins>\r\n        </plugins>\r\n    </build>\r\n    <properties>\r\n        <maven.compiler.source>1.8</maven.compiler.source>\r\n        <maven.compiler.target>1.8</maven.compiler.target>\r\n        <failOnMissingWebXml>false</failOnMissingWebXml>\r\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n        <projectId>MYPROJECTID</projectId>\r\n    </properties>\r\n</project>\r\n```\r\nRunning mvn depenceny:tree doesn't show any problems, and by opening the WAR archive created I can't see any duplicate library. Below is the verbose dependency tree\r\n```\r\n+- com.google.cloud:google-cloud-dialogflow:jar:0.71.0-alpha:compile\r\n|  +- com.google.cloud:google-cloud-core:jar:1.53.0:compile\r\n|  |  +- com.google.guava:guava:jar:26.0-android:compile\r\n|  |  |  +- (com.google.code.findbugs:jsr305:jar:3.0.2:compile - omitted for duplicate)\r\n|  |  |  +- org.checkerframework:checker-compat-qual:jar:2.5.2:compile\r\n|  |  |  +- com.google.errorprone:error_prone_annotations:jar:2.1.3:compile\r\n|  |  |  +- com.google.j2objc:j2objc-annotations:jar:1.1:compile\r\n|  |  |  \\- org.codehaus.mojo:animal-sniffer-annotations:jar:1.14:compile\r\n|  |  +- joda-time:joda-time:jar:2.9.2:compile\r\n|  |  +- com.google.http-client:google-http-client:jar:1.27.0:compile\r\n|  |  |  +- (com.google.guava:guava:jar:20.0:compile - omitted for conflict with 26.0-android)\r\n|  |  |  +- org.apache.httpcomponents:httpclient:jar:4.5.5:compile\r\n|  |  |  |  +- org.apache.httpcomponents:httpcore:jar:4.4.9:compile\r\n|  |  |  |  +- commons-logging:commons-logging:jar:1.2:compile\r\n|  |  |  |  \\- commons-codec:commons-codec:jar:1.10:compile\r\n|  |  |  \\- (com.google.j2objc:j2objc-annotations:jar:1.1:compile - omitted for duplicate)\r\n|  |  +- com.google.code.findbugs:jsr305:jar:3.0.2:compile\r\n|  |  +- com.google.api:api-common:jar:1.7.0:compile\r\n|  |  |  +- (com.google.code.findbugs:jsr305:jar:3.0.2:compile - omitted for duplicate)\r\n|  |  |  \\- (com.google.guava:guava:jar:19.0:compile - omitted for conflict with 26.0-android)\r\n|  |  +- com.google.api:gax:jar:1.35.0:compile\r\n|  |  |  +- (com.google.guava:guava:jar:26.0-android:compile - omitted for duplicate)\r\n|  |  |  +- (com.google.code.findbugs:jsr305:jar:3.0.2:compile - omitted for duplicate)\r\n|  |  |  +- org.threeten:threetenbp:jar:1.3.3:compile\r\n|  |  |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.11.0:compile\r\n|  |  |  |  +- (com.google.auth:google-auth-library-credentials:jar:0.11.0:compile - omitted for conflict with 0.12.0)\r\n|  |  |  |  +- (com.google.http-client:google-http-client:jar:1.24.1:compile - omitted for conflict with 1.27.0)\r\n|  |  |  |  +- com.google.http-client:google-http-client-jackson2:jar:1.24.1:compile\r\n|  |  |  |  |  +- (com.google.http-client:google-http-client:jar:1.24.1:compile - omitted for conflict with 1.27.0)\r\n|  |  |  |  |  \\- com.fasterxml.jackson.core:jackson-core:jar:2.9.2:compile\r\n|  |  |  |  \\- (com.google.guava:guava:jar:20.0:compile - omitted for conflict with 26.0-android)\r\n|  |  |  \\- (com.google.api:api-common:jar:1.7.0:compile - omitted for duplicate)\r\n|  |  +- com.google.protobuf:protobuf-java-util:jar:3.6.1:compile\r\n|  |  |  +- (com.google.protobuf:protobuf-java:jar:3.6.1:compile - omitted for duplicate)\r\n|  |  |  +- (com.google.guava:guava:jar:19.0:compile - omitted for conflict with 26.0-android)\r\n|  |  |  \\- com.google.code.gson:gson:jar:2.7:compile\r\n|  |  +- com.google.api.grpc:proto-google-common-protos:jar:1.12.0:compile\r\n|  |  |  \\- (com.google.protobuf:protobuf-java:jar:3.5.1:compile - omitted for conflict with 3.6.1)\r\n|  |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.12.0:compile\r\n|  |     +- (com.google.protobuf:protobuf-java:jar:3.5.1:compile - omitted for conflict with 3.6.1)\r\n|  |     +- (com.google.api:api-common:jar:1.7.0:compile - version managed from 1.5.0; omitted for duplicate)\r\n|  |     \\- (com.google.api.grpc:proto-google-common-protos:jar:1.12.0:compile - version managed from 1.11.0; omitted for duplicate)\r\n|  +- com.google.cloud:google-cloud-core-grpc:jar:1.53.0:compile\r\n|  |  +- com.google.auth:google-auth-library-credentials:jar:0.12.0:compile\r\n|  |  +- (com.google.cloud:google-cloud-core:jar:1.53.0:compile - omitted for duplicate)\r\n|  |  +- (com.google.guava:guava:jar:26.0-android:compile - omitted for duplicate)\r\n|  |  +- com.google.protobuf:protobuf-java:jar:3.6.1:compile\r\n|  |  +- (com.google.protobuf:protobuf-java-util:jar:3.6.1:compile - omitted for duplicate)\r\n|  |  +- io.grpc:grpc-protobuf:jar:1.16.1:compile\r\n|  |  |  +- (io.grpc:grpc-core:jar:1.16.1:compile - omitted for duplicate)\r\n|  |  |  +- (com.google.protobuf:protobuf-java:jar:3.5.1:compile - omitted for conflict with 3.6.1)\r\n|  |  |  +- (com.google.guava:guava:jar:26.0-android:compile - omitted for duplicate)\r\n|  |  |  +- (com.google.api.grpc:proto-google-common-protos:jar:1.12.0:compile - version managed from 1.0.0; omitted for duplicate)\r\n|  |  |  \\- io.grpc:grpc-protobuf-lite:jar:1.16.1:compile\r\n|  |  |     +- (io.grpc:grpc-core:jar:1.16.1:compile - omitted for duplicate)\r\n|  |  |     \\- (com.google.guava:guava:jar:26.0-android:compile - omitted for duplicate)\r\n|  |  +- io.grpc:grpc-context:jar:1.16.1:compile\r\n|  |  +- (io.grpc:grpc-netty-shaded:jar:1.16.1:compile - omitted for duplicate)\r\n|  |  +- (io.grpc:grpc-stub:jar:1.16.1:compile - omitted for duplicate)\r\n|  |  +- (io.grpc:grpc-auth:jar:1.16.1:compile - omitted for duplicate)\r\n|  |  \\- com.google.api:gax-grpc:jar:1.35.0:compile\r\n|  |     +- (com.google.api:gax:jar:1.35.0:compile - omitted for duplicate)\r\n|  |     +- (io.grpc:grpc-stub:jar:1.16.1:compile - omitted for duplicate)\r\n|  |     +- (io.grpc:grpc-auth:jar:1.16.1:compile - omitted for duplicate)\r\n|  |     +- (io.grpc:grpc-protobuf:jar:1.16.1:compile - omitted for duplicate)\r\n|  |     +- (com.google.guava:guava:jar:26.0-android:compile - omitted for duplicate)\r\n|  |     +- (com.google.code.findbugs:jsr305:jar:3.0.2:compile - omitted for duplicate)\r\n|  |     +- (org.threeten:threetenbp:jar:1.3.3:compile - omitted for duplicate)\r\n|  |     +- (com.google.auth:google-auth-library-oauth2-http:jar:0.11.0:compile - omitted for duplicate)\r\n|  |     +- (com.google.auth:google-auth-library-credentials:jar:0.11.0:compile - omitted for conflict with 0.12.0)\r\n|  |     +- (com.google.api.grpc:proto-google-common-protos:jar:1.12.0:compile - version managed from 1.0.0; omitted for duplicate)\r\n|  |     +- (com.google.api:api-common:jar:1.7.0:compile - version managed from 1.5.0; omitted for duplicate)\r\n|  |     \\- (io.grpc:grpc-netty-shaded:jar:1.16.1:compile - omitted for duplicate)\r\n|  +- com.google.api.grpc:proto-google-cloud-dialogflow-v2beta1:jar:0.36.0:compile\r\n|  |  +- (com.google.protobuf:protobuf-java:jar:3.6.1:compile - omitted for duplicate)\r\n|  |  +- (com.google.api:api-common:jar:1.7.0:compile - version managed from 1.5.0; omitted for duplicate)\r\n|  |  \\- (com.google.api.grpc:proto-google-common-protos:jar:1.12.0:compile - version managed from 1.0.0; omitted for duplicate)\r\n|  +- com.google.api.grpc:proto-google-cloud-dialogflow-v2:jar:0.36.0:compile\r\n|  |  +- (com.google.protobuf:protobuf-java:jar:3.6.1:compile - omitted for duplicate)\r\n|  |  +- (com.google.api:api-common:jar:1.7.0:compile - version managed from 1.5.0; omitted for duplicate)\r\n|  |  \\- (com.google.api.grpc:proto-google-common-protos:jar:1.12.0:compile - version managed from 1.0.0; omitted for duplicate)\r\n|  +- io.grpc:grpc-netty-shaded:jar:1.16.1:compile\r\n|  |  \\- (io.grpc:grpc-core:jar:1.16.1:compile - scope updated from runtime; omitted for duplicate)\r\n|  +- io.grpc:grpc-stub:jar:1.16.1:compile\r\n|  |  \\- io.grpc:grpc-core:jar:1.16.1:compile\r\n|  |     +- (io.grpc:grpc-context:jar:1.16.1:compile - omitted for duplicate)\r\n|  |     +- (com.google.code.gson:gson:jar:2.7:compile - omitted for duplicate)\r\n|  |     +- (com.google.errorprone:error_prone_annotations:jar:2.2.0:compile - omitted for conflict with 2.1.3)\r\n|  |     +- (com.google.code.findbugs:jsr305:jar:3.0.2:compile - omitted for duplicate)\r\n|  |     +- (org.codehaus.mojo:animal-sniffer-annotations:jar:1.17:compile - omitted for conflict with 1.14)\r\n|  |     +- (com.google.guava:guava:jar:26.0-android:compile - omitted for duplicate)\r\n|  |     +- io.opencensus:opencensus-api:jar:0.12.3:compile\r\n|  |     |  \\- (com.google.errorprone:error_prone_annotations:jar:2.2.0:compile - omitted for conflict with 2.1.3)\r\n|  |     \\- io.opencensus:opencensus-contrib-grpc-metrics:jar:0.12.3:compile\r\n|  |        +- (com.google.errorprone:error_prone_annotations:jar:2.2.0:compile - omitted for conflict with 2.1.3)\r\n|  |        \\- (io.opencensus:opencensus-api:jar:0.12.3:compile - omitted for duplicate)\r\n|  \\- io.grpc:grpc-auth:jar:1.16.1:compile\r\n|     +- (io.grpc:grpc-core:jar:1.16.1:compile - omitted for duplicate)\r\n|     \\- (com.google.auth:google-auth-library-credentials:jar:0.9.0:compile - omitted for conflict with 0.12.0)\r\n\\- javax:javaee-api:jar:7.0:provided\r\n   \\- com.sun.mail:javax.mail:jar:1.5.0:provided\r\n      \\- javax.activation:activation:jar:1.1:provided\r\n```\r\n\r\nTried compiling both with NetBeans and by command line, the problem still persists.\r\nAs per the [troubleshooting guide](https://github.com/googleapis/google-cloud-java/blob/master/TROUBLESHOOTING.md) I have tried using the maven shade plugin, with no success. Tried also referencing in the pom all the possible versions of Guava from 20.0 onward, but the error still persist.\r\n\r\nThanks in advance\r\n\r\n#### Environment details\r\n\r\n- OS: Windows 10\r\n- Java version: 8\r\n- google-cloud-java version(s): 0.7.1\r\n- Server: Payara 5.183\r\n- Endpoints: developed with JAX-RS\r\n\r\n#### Stacktrace\r\n```\r\njava.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;CLjava/lang/Object;)V\r\n\tat io.grpc.Metadata$Key.validateName(Metadata.java:628)\r\n\tat io.grpc.Metadata$Key.<init>(Metadata.java:636)\r\n\tat io.grpc.Metadata$Key.<init>(Metadata.java:566)\r\n\tat io.grpc.Metadata$AsciiKey.<init>(Metadata.java:740)\r\n\tat io.grpc.Metadata$AsciiKey.<init>(Metadata.java:735)\r\n\tat io.grpc.Metadata$Key.of(Metadata.java:592)\r\n\tat io.grpc.Metadata$Key.of(Metadata.java:588)\r\n\tat com.google.api.gax.grpc.GrpcHeaderInterceptor.<init>(GrpcHeaderInterceptor.java:61)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:176)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:160)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:152)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:149)\r\n\tat com.google.cloud.dialogflow.v2.stub.GrpcSessionsStub.create(GrpcSessionsStub.java:75)\r\n\tat com.google.cloud.dialogflow.v2.stub.SessionsStubSettings.createStub(SessionsStubSettings.java:100)\r\n\tat com.google.cloud.dialogflow.v2.SessionsClient.<init>(SessionsClient.java:132)\r\n\tat com.google.cloud.dialogflow.v2.SessionsClient.create(SessionsClient.java:114)\r\n\tat com.google.cloud.dialogflow.v2.SessionsClient.create(SessionsClient.java:106)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4016",
        "number": 4016,
        "title": "DataProc com.google.cloud.dataproc.v1.ClusterControllerClient.getCluster supports only region global",
        "labels": [
            "api: dataproc",
            "type: feature request"
        ],
        "state": "open",
        "body": "DataProc com.google.cloud.dataproc.v1.ClusterControllerClient.getCluster supports only region global.\r\nIt should support other regions as well.\r\nI cannot get the cluster details using Java API for clusters on regions other than global.\r\n\r\n#### Environment details\r\n\r\n- OS: mac OS mojave\r\n- Java version: jdk1.8.0_151\r\n- google-cloud-java version(s):\r\n- google-cloud-dataproc version: 0.71.0-alpha\r\n- google-api-services-compute version: v1-rev201-1.24.1\r\n\r\n#### Steps to reproduce\r\n\r\n1. Invoke the following method with the path to service account json, name of the cluster, project id, region\r\n2. You will get this error.\r\n3. Change to region to global and no error will appear\r\n\r\n#### Stacktrace\r\n\r\n```\r\nException in thread \"main\" com.google.api.gax.rpc.InvalidArgumentException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Region 'us-west1' is invalid. Please see https://cloud.google.com/dataproc/docs/concepts/regional-endpoints for additional information on regional endpoints\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:49)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:97)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:68)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:507)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:482)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:397)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\tSuppressed: com.google.api.gax.rpc.AsyncTaskException: Asynchronous task failed\r\n\t\tat com.google.api.gax.rpc.ApiExceptions.callAndTranslateApiException(ApiExceptions.java:57)\r\n\t\tat com.google.api.gax.rpc.UnaryCallable.call(UnaryCallable.java:112)\r\n\t\tat com.google.cloud.dataproc.v1.ClusterControllerClient.getCluster(ClusterControllerClient.java:567)\r\n\t\tat co.cask.cdap.runtime.spi.provisioner.dataproc.DataprocTool.getCluster(DataprocTool.java:276)\r\n\t\tat co.cask.cdap.runtime.spi.provisioner.dataproc.DataprocTool.main(DataprocTool.java:130)\r\nCaused by: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Region 'us-west1' is invalid. Please see https://cloud.google.com/dataproc/docs/concepts/regional-endpoints for additional information on regional endpoints\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 24 more\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\npublic static void getCluster(String accountKeyJsonFilePath, String name, String projectId, String region) throws IOException {\r\n    String accountKey = new String(Files.readAllBytes(\r\n            new File(accountKeyJsonFilePath).toPath()));\r\n    GoogleCredentials credentials;\r\n    try (InputStream is = new ByteArrayInputStream(accountKey.getBytes(StandardCharsets.UTF_8))) {\r\n      credentials = GoogleCredentials.fromStream(is);\r\n    }\r\n    CredentialsProvider credentialsProvider = FixedCredentialsProvider.create(credentials);\r\n\r\n    ClusterControllerSettings controllerSettings = ClusterControllerSettings.newBuilder()\r\n            .setCredentialsProvider(credentialsProvider)\r\n            .build();\r\n    try (ClusterControllerClient client = ClusterControllerClient.create(controllerSettings)) {\r\n\r\n      com.google.cloud.dataproc.v1.Cluster cluster = client.getCluster(GetClusterRequest.newBuilder()\r\n              .setClusterName(name)\r\n              .setProjectId(projectId)\r\n              .setRegion(region)\r\n              .build());\r\n      System.out.println(cluster.getConfig());\r\n    }\r\n  }\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\n- https://developers.google.com/resources/api-libraries/documentation/dataproc/v1/java/latest/com/google/api/services/dataproc/Dataproc.Projects.Regions.Clusters.Get.html"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4015",
        "number": 4015,
        "title": "OperationCallable ran out of place??",
        "labels": [
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS:\r\n- Java version:\r\n- google-cloud-java version(s):\r\n\r\n#### Steps to reproduce\r\n\r\n1. ?\r\n2. ?\r\n\r\n#### Stacktrace\r\n\r\n```\r\nAny relevant stacktrace here.\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\nAny relevant code snippet to help reproduce the issue.\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\n- ?\r\n\r\n#### Any additional information below\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3983",
        "number": 3983,
        "title": "Incorrect links for Cloud Asset?",
        "labels": [
            "type: docs"
        ],
        "state": "closed",
        "body": "In the [Cloud Asset README file](https://github.com/googleapis/google-cloud-java/blob/master/google-cloud-clients/google-cloud-asset/README.md), the links to Cloud Asset and the documentation for Cloud Asset go to the main [GCP landing page](https://cloud.google.com/). Is this WAI, or should we point to the [Cloud Asset API page](https://cloud.google.com/resource-manager/docs/cloud-asset-inventory/overview)?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3982",
        "number": 3982,
        "title": "BigQuery client throws NullPointerException when estimatedFields is empty",
        "labels": [
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "#### Environment details\r\n\r\n- OS: linux /macos\r\n- Java version: 8\r\n- google-cloud-java version(s): ???\r\n\r\n#### Steps to reproduce\r\n\r\n1. Run the following code:\r\n\r\n```java\r\nBigQueryOptions options = BigQueryOptions.newBuilder().build();\r\nBigQuery client = options.getService();\r\n\r\nTableId tableId = TableId.of(projectId, dataset, tableName);\r\n\r\n// no options - all table fields are fetched\r\nclient.getTable(tableId);\r\n```\r\n\r\n#### Stacktrace\r\n\r\n```\r\nException in thread \"main\"\r\njava.lang.NullPointerException\r\nat com.google.cloud.bigquery.StandardTableDefinition$StreamingBuffer.fromPb(StandardTableDefinition.java:116)\r\nat com.google.cloud.bigquery.StandardTableDefinition.fromPb(StandardTableDefinition.java:225)\r\nat com.google.cloud.bigquery.TableDefinition.fromPb(TableDefinition.java:155)\r\nat com.google.cloud.bigquery.TableInfo$BuilderImpl.<init>(TableInfo.java:183)\r\nat com.google.cloud.bigquery.Table.fromPb(Table.java:593)\r\nat com.google.cloud.bigquery.BigQueryImpl.getTable(BigQueryImpl.java:410)\r\nat org.apache.beam.sdk.testutils.publishing.BigQueryClient.createTableIfNotExists(BigQueryClient.java:74)\r\nat org.apache.beam.sdk.nexmark.Main.savePerfsToBigQuery(Main.java:184)\r\nat org.apache.beam.sdk.nexmark.Main.runAll(Main.java:148)\r\nat org.apache.beam.sdk.nexmark.Main.runAll(Main.java:98)\r\nat org.apache.beam.sdk.nexmark.Main.main(Main.java:423)\r\n```\r\n\r\n#### Any additional information below\r\n\r\nThis happens only if table.streamingBuffer.estimatedFields field is null in table. This is not allways the case but when it is null the exception appears. \r\n\r\nSee more info here: https://issues.apache.org/jira/browse/BEAM-6076\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3977",
        "number": 3977,
        "title": "Synthesis failed for websecurityscanner",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate websecurityscanner. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-websecurityscanner'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3976",
        "number": 3976,
        "title": "Synthesis failed for video-intelligence",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate video-intelligence. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-video-intelligence'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3975",
        "number": 3975,
        "title": "Synthesis failed for trace",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate trace. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-trace'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3974",
        "number": 3974,
        "title": "Synthesis failed for texttospeech",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate texttospeech. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-texttospeech'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3973",
        "number": 3973,
        "title": "Synthesis failed for tasks",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate tasks. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-tasks'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3972",
        "number": 3972,
        "title": "Synthesis failed for speech",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate speech. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-speech'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3971",
        "number": 3971,
        "title": "Synthesis failed for spanner",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate spanner. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-spanner'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3970",
        "number": 3970,
        "title": "Synthesis failed for securitycenter",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate securitycenter. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-securitycenter'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3969",
        "number": 3969,
        "title": "Synthesis failed for scheduler",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate scheduler. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-scheduler'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3968",
        "number": 3968,
        "title": "Synthesis failed for redis",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate redis. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-redis'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3967",
        "number": 3967,
        "title": "Synthesis failed for os-login",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate os-login. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-os-login'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3966",
        "number": 3966,
        "title": "Synthesis failed for logging",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate logging. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-logging'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3965",
        "number": 3965,
        "title": "Synthesis failed for language",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate language. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-language'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3964",
        "number": 3964,
        "title": "Synthesis failed for kms",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate kms. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-kms'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3963",
        "number": 3963,
        "title": "Synthesis failed for iot",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate iot. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-iot'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3962",
        "number": 3962,
        "title": "Synthesis failed for firestore",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate firestore. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-firestore'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3961",
        "number": 3961,
        "title": "Synthesis failed for errorreporting",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate errorreporting. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-errorreporting'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3960",
        "number": 3960,
        "title": "Synthesis failed for dlp",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate dlp. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-dlp'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3959",
        "number": 3959,
        "title": "Synthesis failed for dialogflow",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate dialogflow. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-dialogflow'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3958",
        "number": 3958,
        "title": "Synthesis failed for datastore",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate datastore. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-datastore'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3957",
        "number": 3957,
        "title": "Synthesis failed for dataproc",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate dataproc. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-dataproc'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3956",
        "number": 3956,
        "title": "Synthesis failed for containeranalysis",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate containeranalysis. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-containeranalysis'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3955",
        "number": 3955,
        "title": "Synthesis failed for container",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate container. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-container'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3954",
        "number": 3954,
        "title": "Synthesis failed for compute",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate compute. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-compute'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3953",
        "number": 3953,
        "title": "Synthesis failed for bigtable",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate bigtable. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-bigtable'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3952",
        "number": 3952,
        "title": "Synthesis failed for bigtable-admin",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate bigtable-admin. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-bigtable-admin'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3951",
        "number": 3951,
        "title": "Synthesis failed for bigquerystorage",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate bigquerystorage. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-bigquerystorage'\nTraceback (most recent call last):\n  File \"synth.py\", line 17, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3950",
        "number": 3950,
        "title": "Synthesis failed for bigquerydatatransfer",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate bigquerydatatransfer. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-bigquerydatatransfer'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3949",
        "number": 3949,
        "title": "Synthesis failed for automl",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate automl. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-automl'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3948",
        "number": 3948,
        "title": "Synthesis failed for asset",
        "labels": [
            "autosynth failure",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello! Autosynth couldn't regenerate asset. :broken_heart:\n\nHere's the output from running `synth.py`:\n\n```\nCloning into 'working_repo'...\nSwitched to branch 'autosynth-asset'\nTraceback (most recent call last):\n  File \"synth.py\", line 18, in <module>\n    import synthtool.gcp as gcp\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/__init__.py\", line 15, in <module>\n    from . import gapic_generator\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 22, in <module>\n    from synthtool.sources import git\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/sources/git.py\", line 24, in <module>\n    from synthtool import metadata\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/metadata.py\", line 22, in <module>\n    from synthtool.protos import metadata_pb2\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/protos/metadata_pb2.py\", line 28, in <module>\n    dependencies=[google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR],\nTypeError: __new__() got an unexpected keyword argument 'serialized_options'\n\nSynthesis failed\n\n```\n\nGoogle internal developers can see the full log [here](https://sponge/996ff636-7eb9-4f75-b313-839d2d07fd49).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3947",
        "number": 3947,
        "title": "Javadoc: fix relative links to cloud.google.com in generated code",
        "labels": [
            "type: docs"
        ],
        "state": "open",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3942",
        "number": 3942,
        "title": "StringEnumValue does not support reference equality after Serialization",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "#### Environment details\r\n\r\n- OS: Linux (Debian 9)\r\n- Java version: openjdk version \"1.8.0_181\"\r\n- google-cloud-java version(s): 1.52.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Serialize StringEnumValue \r\n2. Deserialize StringEnumValue\r\n3. Use it in a way that requires reference equality\r\n4. Crash\r\n\r\n#### Stacktrace\r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalArgumentException: Only RECORD fields can have sub-fields\r\n        at com.google.cloud.bigquery.Field$Builder.setType(Field.java:137)\r\n        at com.google.cloud.bigquery.Field.newBuilder(Field.java:275)\r\n        at com.google.cloud.bigquery.Field.of(Field.java:261)\r\n        at App.main(App.java:27)\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\nLegacySQLTypeName record = SerializationUtils.clone(LegacySQLTypeName.RECORD);\r\nSystem.out.println(LegacySQLTypeName.RECORD == record); // false\r\nField.of(\"foo\", record, Field.of(\"bar\", LegacySQLTypeName.BOOLEAN)); // throws\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3938",
        "number": 3938,
        "title": "Translate does not preserve new line or enter",
        "labels": [
            "api: translation",
            "type: question"
        ],
        "state": "closed",
        "body": "- OS: Debian 9\r\n- Java version: java-1.8.0-openjdk\r\n- google-cloud-java version(s): 1.40.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Hello how are you? \\n I am fine.\r\n2. Translated text does not preserve new line.\r\n\r\n#### Code snippet\r\n\r\n\r\n            String text = \"how are you\\n I am fine\";\r\n\r\n\r\n            Translation translation =\r\n                    CGlobals.g_Translate.translate(\r\n                            text,\r\n                            Translate.TranslateOption.model(\"nmt\"),\r\n                            com.google.cloud.translate.Translate.TranslateOption.sourceLanguage(\"en\"),\r\n                            com.google.cloud.translate.Translate.TranslateOption.targetLanguage(\"mr\"));\r\n\r\n            //System.out.printf(\"Text: %s%n\", text);\r\n            String translatedText = translation.getTranslatedText();\r\n\r\n            System.out.printf(\"Translation: %s%n\", translatedText);\r\n\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3934",
        "number": 3934,
        "title": "Javadoc: convert Markdown to javadoc links",
        "labels": [
            "status: blocked",
            "type: docs"
        ],
        "state": "open",
        "body": "Example: https://googleapis.github.io/google-cloud-java/google-api-grpc/apidocs/com/google/cloud/speech/v1/RecognitionAudioOrBuilder.html#getUri--\r\n\r\n```\r\nURI that points to a file that contains audio data bytes as specified in\r\n`RecognitionConfig`. The file must not be compressed (for example, gzip).\r\nCurrently, only Google Cloud Storage URIs are\r\nsupported, which must be specified in the following format:\r\n`gs://bucket_name/object_name` (other URI formats return\r\n[google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see\r\n[Request URIs](https://cloud.google.com/storage/docs/reference-uris).\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3931",
        "number": 3931,
        "title": "Upgrade Guava to the latest version",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": "[Spring Cloud GCP](https://github.com/spring-cloud/spring-cloud-gcp) uses `google-cloud-bom` for the common dependencies. We have recently turned on Snyk vulnerability detection, and it found a [deserialization issue](https://snyk.io/vuln/SNYK-JAVA-COMGOOGLEGUAVA-32236) with Guava 20.0. \r\nThe recommended remediation step is to upgrade to 24.1.1 or higher.\r\n\r\nWould it be possible to upgrade Guava version in [google-cloud-clients POM](https://github.com/googleapis/google-cloud-java/blob/a7bd8a5717e70d7df2ee8e57ed1a37dac0bde94e/google-cloud-clients/pom.xml#L163)?\r\n\r\nSpring Cloud GCP tracking issue: spring-cloud/spring-cloud-gcp#1207"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3930",
        "number": 3930,
        "title": "When a table is not found, the exception is swallowed up and `null` is returned",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "open",
        "body": "#### Environment details\r\n\r\n- OS: Mac (10.13.6)\r\n- Java version: 1.8.0_181\r\n- google-cloud-java version(s): 1.52.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. n/a\r\n2. n/a\r\n\r\n#### Stacktrace\r\n\r\nn/a\r\n\r\n#### Code snippet\r\n\r\nhttps://github.com/googleapis/google-cloud-java/blob/7a72784076308bb31786b9138efe856845a86fde/google-cloud-clients/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/spi/v2/HttpBigQueryRpc.java#L234\r\n\r\n#### External references such as API reference guides used\r\n\r\nhttps://github.com/googleapis/google-cloud-java/blob/7a72784076308bb31786b9138efe856845a86fde/google-cloud-clients/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/spi/v2/HttpBigQueryRpc.java#L234\r\n\r\n#### Any additional information below\r\n\r\nWhen a table is not found, `null` is returned instead of the actual HTTP code and BigQuery error message. This makes debugging much harder and is not intuitive for clients calling this method that `null` is actually returned when the table is not found. Instead, the exception should be propagated back up to the client so it can be handled accordingly.\r\n\r\n```\r\n@Override\r\n  public Table getTable(String projectId, String datasetId, String tableId,\r\n      Map<Option, ?> options) {\r\n    try {\r\n      return bigquery.tables()\r\n          .get(projectId, datasetId, tableId)\r\n          .setFields(Option.FIELDS.getString(options))\r\n          .execute();\r\n    } catch (IOException ex) {\r\n      BigQueryException serviceException = translate(ex);\r\n      if (serviceException.getCode() == HTTP_NOT_FOUND) {\r\n        return null;\r\n      }\r\n      throw serviceException;\r\n    }\r\n  }\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3929",
        "number": 3929,
        "title": "Slow download performance for Storage API ",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "The new version of the storage client (com.google.cloud:google-cloud-storage:1.52.0) appears download storage content at a MUCH slower rate than the legacy client (com.google.apis:google-api-services-storage:v1-rev141-1.25.0).\r\n\r\n\r\nLegacy client (~40MB/s):\r\n\r\n```\r\n@Test\r\npublic void download() throws Exception {\r\n    Storage storage = buildStorage();\r\n    Storage.Objects.Get get = storage.objects().get(BUCKET_NAME, BUCKET_PATH);\r\n    StorageObject storageObject = get.execute();\r\n\r\n    File tempFile = createTempFile();\r\n    try (OutputStream out = new FileOutputStream(tempFile)) {\r\n        Stopwatch stopwatch = Stopwatch.createStarted();\r\n        get.getMediaHttpDownloader().setDirectDownloadEnabled(true);\r\n        get.executeMediaAndDownloadTo(out);\r\n        long elapsedSeconds = stopwatch.stop().elapsed(TimeUnit.SECONDS);\r\n        double fileSizeMb = storageObject.getSize().doubleValue() / 1024 / 1024;\r\n        double throughput = fileSizeMb / elapsedSeconds;\r\n        log.info(\"Completed download: elapsed={}s,fileSize={}MB,throughput={}MB/s\",\r\n                elapsedSeconds, fileSizeMb, throughput);\r\n        assertTrue(\"Expected at least 20MB/s\", throughput > 20);\r\n    }\r\n}\r\n```\r\n\r\n\r\nNew client (~10MB/s):\r\n\r\n```\r\n@Test\r\n   public void download() throws Exception {\r\n       Storage storage = StorageOptions.getDefaultInstance().getService();\r\n       Blob blob = storage.get(BLOB_ID);\r\n       Path tempFile = createTempFile();\r\n\r\n       Stopwatch stopwatch = Stopwatch.createStarted();\r\n       blob.downloadTo(tempFile);\r\n       long elapsedSeconds = stopwatch.stop().elapsed(TimeUnit.SECONDS);\r\n       double fileSizeMb = blob.getSize().doubleValue() / 1024 / 1024;\r\n       double throughput = fileSizeMb / elapsedSeconds;\r\n       log.info(\"Completed download: elapsed={}s,fileSize={}MB,throughput={}MB/s\",\r\n               elapsedSeconds, fileSizeMb, throughput);\r\n       assertTrue(\"Expected at least 20MB/s\", throughput > 20);\r\n   }\r\n```\r\n\r\n\r\nI'm attaching a couple of test cases that I've ran from a GCE instance (Ubuntu 16.04 with Java 1.8.0_191):\r\n\r\n[storage-performance-legacy.zip](https://github.com/googleapis/google-cloud-java/files/2567343/storage-performance-legacy.zip)\r\n[storage-performance-new.zip](https://github.com/googleapis/google-cloud-java/files/2567344/storage-performance-new.zip)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3924",
        "number": 3924,
        "title": "ExtractJobConfiguration's setProjectId makes cross-project BQ extracts impossible",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hi! I was looking into migrating one of our projects from `google-api-services-bigquery` to `google-cloud-bigquery` & noticed a possible regression in the Extract job config in the client library. One of our integration tests extracts data from `bigquery-public-data:samples.shakespeare` into a GCS bucket in our own GCP project. However, after migrating, the test fails because the extract job can't find the BQ table `{OUR_GCP_PROJECT}:samples.shakespeare`.\r\n\r\nsome scala code replicating the issue:\r\n```\r\nval gcpProject = \"some-gcp-project\"\r\nval bqClient: com.google.cloud.bigquery.BigQuery = ... // authenticated to $gcpProject\r\n\r\nval sourceTableId = TableId.of(\"bigquery-public-data\", \"samples\", \"shakespeare\")\r\nval destGcsUri = s\"gs://$gcpProject/it/${UUID.randomUUID}\"\r\n\r\nval config = ExtractJobConfiguration\r\n    .newBuilder(sourceTableId, destGcsUri)\r\n    .setFormat(\"AVRO\")\r\n\r\nval jobInfo = JobInfo.newBuilder(config.build()).build()\r\nprint(jobInfo)\r\n\r\nval job = bqClient.create(jobInfo).waitFor()\r\nprint(job.getStatus.getError)\r\n```\r\n\r\nthis prints\r\n\r\n`JobInfo{job=null, status=null, statistics=null, userEmail=null, etag=null, generatedId=null, selfLink=null, configuration=ExtractJobConfiguration{type=EXTRACT, sourceTable={datasetId=samples, projectId=bigquery-public-data, tableId=shakespeare}, destinationUris=[gs://some-gcp-project/it/9270d23f-de63-41e8-a56a-e7c140297e38], format=AVRO, printHeader=null, fieldDelimiter=null, compression=null}}`\r\n\r\nand\r\n\r\n `BigQueryError{reason=notFound, location=null, message=Not found: Table some-gcp-project:samples.shakespeare was not found in location US}[info]`.\r\n\r\nI think the reason is because `ExtractJobConfiguration` [overrides `setProjectId`](https://github.com/googleapis/google-cloud-java/blob/675ace7601e2c09474ce986d5d2223af5cb15f28/google-cloud-clients/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/ExtractJobConfiguration.java#L237) to apply the credentialed `projectId` param specifically to the source table, overriding what it was originally set to.\r\n\r\nwdyt? Am I just mis-using the new API?\r\n\r\nthanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3920",
        "number": 3920,
        "title": "Pub/Sub: ApiFutures.addCallback() deprecated in code example",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "https://github.com/googleapis/google-cloud-java/blob/7e635696cb6d04aca1aa81016c8c934d4daa80ce/google-cloud-clients/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/v1/Publisher.java#L177\r\n\r\nI [updated this method](https://github.com/googleapis/google-cloud-java/blob/7e635696cb6d04aca1aa81016c8c934d4daa80ce/google-cloud-examples/src/main/java/com/google/cloud/examples/pubsub/snippets/PublisherSnippets.java#L58) in `google-cloud-examples`, but it also needs to be updated in `google-cloud-client/google-cloud-pubsub`. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3919",
        "number": 3919,
        "title": "Cloud Client Documentation: missing lib versions",
        "labels": [
            "type: docs"
        ],
        "state": "open",
        "body": "For instance, when Pub/Sub users land on [https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html\r\n?](https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html), it's not clear which version the documentation is for. \r\n\r\nIn fact, the screen quickly flashes version 0.69.XX, which is behind 1.51.0 (current). "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3918",
        "number": 3918,
        "title": "GCS NIO readAttributes returns CloudStorageObjectAttributes for directory like objects",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- google-cloud-java version(s): google-cloud-nio:0.69.0-alpha\r\n\r\n#### Steps to reproduce\r\n\r\n1. In the GCS UI within a bucket, press create folder button and create a folder called `dir`\r\n2. Upload a file within `dir` call this `fileA`\r\n\r\n\r\n#### Code snippet\r\n\r\n```java\r\n    FileSystem fs = ....\r\n    Files.walkFileTree(fs.getPath(\"dir\") new SimpleFileVisitor<Path>() {\r\n      @Override\r\n      public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {\r\n        System.out.println(file);\r\n        return FileVisitResult.CONTINUE;\r\n      }\r\n```\r\n\r\n#### Any additional information below\r\n\r\nThe GCS UI creates a 0 byte object called `dir/` This causes `readAttributes` to return https://github.com/googleapis/google-cloud-java/blob/v0.69.0/google-cloud-clients/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.java#L765, which prevents further traversal of objects within that directory. \r\n\r\nDoes it make sense to do a check like https://github.com/googleapis/google-cloud-java/blob/v0.69.0/google-cloud-clients/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.java#L756 `usePseudoDirectories` is enabled and it is a 0 byte object?\r\n\r\nI saw this related merged PR https://github.com/googleapis/google-cloud-java/pull/3775/files by  @jean-philippe-martin "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3914",
        "number": 3914,
        "title": "NIO should have a feature to list the buckets in a project.",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "NIO should have a feature to list the buckets in a project.\r\n\r\nIt can already list files given a bucket, but doesn't yet have a way to list buckets."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3912",
        "number": 3912,
        "title": "Channel ManagedChannelImpl{logId=589, target=vision.googleapis.com:443} was not terminated properly",
        "labels": [
            "api: vision",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "In a concurrent environment, the Vision API client will occasionally log the following error:\r\n\r\n```\r\nNov 06, 2018 8:07:35 AM io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue\r\nSEVERE: *~*~*~ Channel ManagedChannelImpl{logId=589, target=vision.googleapis.com:443} was not terminated properly!!! ~*~*~*\r\n    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.\r\njava.lang.RuntimeException: ManagedChannel allocation site\r\n\tat io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)\r\n\tat io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)\r\n\tat io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:410)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:206)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:157)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:149)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:149)\r\n\tat com.google.cloud.vision.v1.stub.GrpcImageAnnotatorStub.create(GrpcImageAnnotatorStub.java:84)\r\n\tat com.google.cloud.vision.v1.stub.ImageAnnotatorStubSettings.createStub(ImageAnnotatorStubSettings.java:120)\r\n\tat com.google.cloud.vision.v1.ImageAnnotatorClient.<init>(ImageAnnotatorClient.java:136)\r\n\tat com.google.cloud.vision.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:117)\r\n\tat com.google.cloud.vision.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:108)\r\n\tat com.acme.vision.support.VisionTerminationErrorTest.executeOcrRequest(VisionTerminationErrorTest.java:60)\r\n\tat com.acme.vision.support.VisionTerminationErrorTest.lambda$ocrImage$0(VisionTerminationErrorTest.java:28)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nNo error is actually thrown, just logged. I'm attaching a sample project to replicate the condition. Since it doesn't actually throw an exception, I cannot fail the test. You'll need to inspect the log output. You may also need to tweak the number of threads to replicate on your system.\r\n\r\n\r\n[vision-termination-error.zip](https://github.com/googleapis/google-cloud-java/files/2553646/vision-termination-error.zip)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3903",
        "number": 3903,
        "title": "Duplicate/combined word (lists) when using the response 'SpeechRecognitionResult' from longRunningRecognizeAsync",
        "labels": [
            "type: question"
        ],
        "state": "open",
        "body": "When looping trough the 'SpeechRecognitionResult' objects, I noticed that the transcript attribute and the 'words_' list do not match for (at least) the last result. In our app, we always use the first and only alternative. I noticed that the word lists do match the transcript from the first few results, but for the last result, all words including the last one will be returned in words. I would expect that the last result only contains the words which are related to that specific transcript.\r\n\r\nI assume this is a bug. If not; please advice.\r\n\r\n#### Environment details\r\n\r\n- OS: Windows 10\r\n- Java version: 1.8.0_102\r\n- google-cloud-java version(s): google-cloud-speech-0.67.0-beta\r\n\r\n#### Code snippet\r\n\r\nIn order to clarify this, I added a simplified code snippet below.\r\n\r\n```java\r\nList<SpeechRecognitionResult> results = response.getResultsList();\r\n\r\nfor (SpeechRecognitionResult result : results) {\r\n     SpeechRecognitionAlternative alternative = result.getAlternativesList().get(0);\r\n     String transcript = alternative.getTranscript();\r\n     for (WordInfo wordInfo : alternative.getWordsList()) {\r\n           String word = wordInfo.getWord();\r\n     }\r\n}\r\n```\r\n\r\nIn my current example, we have 3 results. The number of words are correct for the first two, but the third (last) is incorrect and includes all words from the whole text.\r\n\r\nResult 0: Only the word Jaguar (both the transcript and the only word)\r\n![image](https://user-images.githubusercontent.com/25738583/48007577-3cc7ec80-e118-11e8-8123-1457a5c70484.png)\r\n\r\nResult 1: A longer transcript, with 102 (correct) words in total\r\n![image](https://user-images.githubusercontent.com/25738583/48007530-228e0e80-e118-11e8-9b26-f771d19b8b79.png)\r\n\r\nResult 2: A short transcript with only 23 words. As you can see, the list with words includes all 126 words (1+102+23).\r\n![image](https://user-images.githubusercontent.com/25738583/48007702-7d276a80-e118-11e8-945d-3a4df263b967.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3902",
        "number": 3902,
        "title": "Creating dialogflow follow-up intent doesn't create context",
        "labels": [],
        "state": "closed",
        "body": "#### Environment details\r\n\r\n- OS: macOS High Sierra (10.13.6)\r\n- Java version: 8\r\n- google-cloud-java version(s): google-cloud-dialogflow 0.67.0-alpha\r\n\r\n#### Steps to reproduce\r\n\r\n1. Create an intent through the api\r\n2. Create a follow-up intent with the previous intent as a parent i.e using `builder.setParentFollowupIntentName`\r\n\r\n#### External references such as API reference guides used\r\n\r\nHave not seen a guide showing how to create follow-up intents via the API\r\n\r\n#### Any additional information below\r\n\r\nI may not be understanding how follow-up intents are intended to work through the API. When creating a follow-up intent through the API - the UI shows the correct relationship:\r\n\r\n![screen shot 2018-11-05 at 7 36 21 am](https://user-images.githubusercontent.com/636651/47998532-9e169e00-e0cd-11e8-9936-1dd45497d430.png)\r\n\r\nHowever, the output and input context fields are empty for both the parent and child. Creating a follow-up through the UI automatically establishes this context, but the API does not.\r\n\r\nThe image above was produced by creating 2 intents, and calling `intentBuilder.setParentFollowupIntentName(parentName)` on the second intent during creation.\r\n\r\nIs this a bug? Is extra information in the request required to establish the context for both?\r\n\r\nMany thanks for the library and help \ud83d\ude04 "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3901",
        "number": 3901,
        "title": "Why cacerts update is needed in GCE/GKE",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "When reading files from a Google Storage Bucket from within a container running in GKE or GCE. The following code fails:\r\n\r\n    public String readSmallTextFileFromBucket(String bucketName, String textFile) {\r\n\r\n        Blob blob = storage.get(bucketName, textFile);\r\n        String fileContent = new String(blob.getContent());\r\n        return fileContent;\r\n        }\r\n\r\nWith the error:\r\n\r\n`com.google.cloud.storage.StorageException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target`\r\n\r\nIf I replace the default `java/jdk-10.0.2/lib/security/cacerts` file you get when you download OpenJDK with the one from my desktop, the code above works.\r\n\r\nWhy is that? and what is the correct way to enable the Java API to read from a storage bucket from within a container?\r\n\r\n#### Environment details\r\n- OpenJDK 10\r\n- Google Kubernetes\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3897",
        "number": 3897,
        "title": "ITGcsNIO doesn't delete all the buckets it creates",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "The NIO integration test (ITGcsNIO) creates buckets as part of its testing, but it doesn't delete them all when it's done. Clearly, it should."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3896",
        "number": 3896,
        "title": "Speech api test hang-up",
        "labels": [
            "api: speech",
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "#### Environment details\r\n\r\n- OS: Windows 10\r\n- Java version: JDK 8\r\n- google-cloud-java version(s): 0.66.0-beta\r\n\r\n#### Steps to reproduce\r\n\r\n1. I have set my credentials and pass the translate API testing\r\n\r\n#### Stacktrace\r\n\r\n```\r\nJust long time hang-up no response\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\n// Imports the Google Cloud client library\r\nimport com.google.cloud.speech.v1p1beta1.RecognitionAudio;\r\nimport com.google.cloud.speech.v1p1beta1.RecognitionConfig;\r\nimport com.google.cloud.speech.v1p1beta1.RecognitionConfig.AudioEncoding;\r\nimport com.google.cloud.speech.v1p1beta1.RecognizeResponse;\r\nimport com.google.cloud.speech.v1p1beta1.SpeechClient;\r\nimport com.google.cloud.speech.v1p1beta1.SpeechRecognitionAlternative;\r\nimport com.google.cloud.speech.v1p1beta1.SpeechRecognitionResult;\r\nimport com.google.protobuf.ByteString;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Path;\r\nimport java.nio.file.Paths;\r\nimport java.util.List;\r\n\r\npublic class App {\r\n\r\n  /**\r\n   * Demonstrates using the Speech API to transcribe an audio file.\r\n   */\r\n  public static void main(String... args) throws Exception {\r\n\t  System.setProperty(\"https.proxyHost\", \"127.0.0.1\");\r\n\t\tSystem.setProperty(\"https.proxyPort\", \"1080\");\r\n    // Instantiates a client\r\n    try (SpeechClient speechClient = SpeechClient.create()) {\r\n\r\n      // The path to the audio file to transcribe\r\n      String fileName = \"a.m4a\";\r\n\r\n      // Reads the audio file into memory\r\n      Path path = Paths.get(fileName);\r\n      byte[] data = Files.readAllBytes(path);\r\n      ByteString audioBytes = ByteString.copyFrom(data);\r\n\r\n      // Builds the sync recognize request\r\n      RecognitionConfig config = RecognitionConfig.newBuilder()\r\n          .setEncoding(AudioEncoding.LINEAR16)\r\n          .setSampleRateHertz(16000)\r\n          .setLanguageCode(\"en-US\")\r\n          .build();\r\n      RecognitionAudio audio = RecognitionAudio.newBuilder()\r\n          .setContent(audioBytes)\r\n          .build();\r\n\r\n      // Performs speech recognition on the audio file\r\n      RecognizeResponse response = speechClient.recognize(config, audio);\r\n      List<SpeechRecognitionResult> results = response.getResultsList();\r\n\r\n      for (SpeechRecognitionResult result : results) {\r\n        // There can be several alternative transcripts for a given chunk of speech. Just use the\r\n        // first (most likely) one here.\r\n        SpeechRecognitionAlternative alternative = result.getAlternativesList().get(0);\r\n        System.out.printf(\"Transcription: %s%n\", alternative.getTranscript());\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3894",
        "number": 3894,
        "title": "Issue mapping Telegram request",
        "labels": [
            "api: dialogflow",
            "type: question"
        ],
        "state": "open",
        "body": "Hi!,\r\nwe are having problems mapping Telegram request through Dialogflow. This is the request JSON:\r\n\r\n```\r\n{\r\n  \"responseId\": \"70702caf-d9e9-4018-a4d1-9b0126f3f472\",\r\n  \"queryResult\": {\r\n    \"queryText\": \"\\u27a1\\ufe0f Iniciar\",\r\n    \"parameters\": {\r\n      \r\n    },\r\n    \"allRequiredParamsPresent\": true,\r\n    \"outputContexts\": [\r\n      {\r\n        \"name\": \"projects\\/newagent-40706\\/agent\\/sessions\\/f714cd33-842e-4e85-825f-af49048dca35\\/contexts\\/generic\",\r\n        \"lifespanCount\": 4,\r\n        \"parameters\": {\r\n          \"telegram_chat_id\": XXXXXXX\r\n        }\r\n      }\r\n    ],\r\n    \"intent\": {\r\n      \"name\": \"projects\\/newagent-XXXXX\\/agent\\/intents\\/69f8f864-a2d5-4f03-bf64-820b8e6dd4d2\",\r\n      \"displayName\": \"operation\"\r\n    },\r\n    \"intentDetectionConfidence\": 1,\r\n    \"languageCode\": \"es\"\r\n  },\r\n  \"originalDetectIntentRequest\": {\r\n    \"payload\": {\r\n      \"data\": {\r\n        \"update_id\":XXXXXX,\r\n        \"message\": {\r\n          \"date\": 1541148665,\r\n          \"chat\": {\r\n            \"last_name\": \"P\\u00e9rez\",\r\n            \"id\": XXXXXX,\r\n            \"type\": \"private\",\r\n            \"first_name\": \"Javi\"\r\n          },\r\n          \"message_id\": 14074,\r\n          \"from\": {\r\n            \"language_code\": \"es\",\r\n            \"last_name\": \"P\\u00e9rez\",\r\n            \"id\": 327498690,\r\n            \"is_bot\": false,\r\n            \"first_name\": \"Javi\"\r\n          },\r\n          \"text\": \"\\u27a1\\ufe0f Iniciar\"\r\n        }\r\n      },\r\n      \"source\": \"telegram\"\r\n    }\r\n  },\r\n  \"session\": \"projects\\/newagent-XXXXX\\/agent\\/sessions\\/f714cd33-842e-4e85-825f-af49048dca35\"\r\n}\r\n````\r\nand in our Java code is like this:\r\n\r\n\r\n```\r\n(...)\r\nimport com.google.protobuf.util.JsonFormat;\r\nimport com.google.cloud.dialogflow.v2.WebhookRequest;\r\n(...)\r\nWebhookRequest.Builder builder = WebhookRequest.newBuilder();\r\nJsonFormat.parser().ignoringUnknownFields().merge(json, builder);\r\n\r\n```\r\nand the result is that \r\n`request.getOriginalDetectIntentRequest().getSource() == null`\r\n\r\n<img width=\"709\" alt=\"captura de pantalla 2018-11-02 a las 10 26 43\" src=\"https://user-images.githubusercontent.com/15786291/47906598-e47bbb00-de89-11e8-925d-b6976e7c57fc.png\">\r\n\r\nWe are using Java 1.8\r\n\r\n```\r\n<!-- https://mvnrepository.com/artifact/com.google.cloud/google-cloud-dialogflow -->\r\n<dependency>\r\n    <groupId>com.google.cloud</groupId>\r\n    <artifactId>google-cloud-dialogflow</artifactId>\r\n    <version>0.69.0-alpha</version>\r\n</dependency>\r\n```\r\n\r\nthis happened a few days ago and I have not solved it with the latest version.\r\n\r\ncould you help me?\r\n\r\nThank you for all!!\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3889",
        "number": 3889,
        "title": "Google-cloud-spanner:Error in connection java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "open",
        "body": "I am trying to run my application which connects to google cloud spanner in a yarn container and the application gets blocked. Upon further investigation I found that the following error was being thrown \r\n\r\n`java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception`\r\n\r\n\r\n Environment details\r\n\r\n- OS: linux\r\n- Java version: 1.8\r\n- google-cloud-java version(s): google-spanner-0.52-beta\r\n\r\nThe code I am trying to execute:\r\n\r\n```java\r\n  Spanner spannerClient=SpannerOptions.newBuilder().build().getService();\r\nInstanceAdminClient instanceAdminClient = spannerClient.getInstanceAdminClient();\r\n            Page<Database> databasePage = instanceAdminClient.getInstance(instanceID).listDatabases();\r\n            for (Database database : databasePage.getValues()) {\r\n                String databaseName = database.getId().getDatabase();\r\n                log.info(\"Database-->\"+databaseName);\r\n            }\r\n```\r\nThis code gets blocked while running in yarn container. Upon inspecting I got the following thread dump:\r\n\r\n```\r\nsun.misc.Unsafe.park(boolean, long) @bci=0 (Compiled frame; information may be imprecise)\r\n - java.util.concurrent.locks.LockSupport.parkNanos(java.lang.Object, long) @bci=20, line=215 (Compiled frame)\r\n - java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(int, long) @bci=139, line=1037 (Interpreted frame)\r\n - java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(int, long) @bci=25, line=1328 (Interpreted frame)\r\n - java.util.concurrent.CountDownLatch.await(long, java.util.concurrent.TimeUnit) @bci=10, line=277 (Interpreted frame)\r\n - com.google.cloud.spanner.SpannerImpl.backoffSleep(io.grpc.Context, long) @bci=67, line=200 (Interpreted frame)\r\n - com.google.cloud.spanner.SpannerImpl.backoffSleep(io.grpc.Context, com.shaded.scanner.google.api.client.util.BackOff) @bci=5, line=170 (Interpreted frame)\r\n - com.google.cloud.spanner.SpannerImpl.runWithRetries(java.util.concurrent.Callable) @bci=105, line=238 (Interpreted frame)\r\n - com.google.cloud.spanner.SpannerImpl$InstanceAdminClientImpl.getInstance(java.lang.String) @bci=25, line=660 (Interpreted frame)\r\n - com.test.spannerscanner.utils.GoogleSpannerManager.execute() @bci=289, line=93 (Interpreted frame)\r\n```\r\n\r\nUpon further debugging I found the runWithRetries method in SpannerImpl is throwing SpannerException due to which the code is getting blocked. I examined the SpannerException and in the detailed message I found \r\n\r\n`java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception`\r\n\r\nThe code works fine in my local environment but in yarn container it gets blocked due to the SpannerException. Any guidance in how to resolve the issue is greatly appreciated.\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3884",
        "number": 3884,
        "title": "Question about setting maxOutstandingByteCount to null on FlowControlSettings",
        "labels": [
            "type: question"
        ],
        "state": "open",
        "body": "Sorry for the question but I didn't get any answers to my [SO question](https://stackoverflow.com/q/52932362/179850).\r\n\r\nWhat are the ramifications of setting the max-outstanding value on `FlowControlSettings` to be null or some large integer? Does this only impact client side memory storage of outstanding GUIDs or other telemetry? Anything else we need to worry about?\r\n\r\nWe have our own flow-control that will limit the outstanding messages but we need to vary the record-count based on our own triggers.\r\n\r\nThanks.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3883",
        "number": 3883,
        "title": "BigTableAdmin integration tests fail when run in parallel",
        "labels": [
            "api: bigtable",
            "priority: p2",
            "type: bug",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "When multiple jobs are running the BigTableAdmin integration tests, they collide as they share table names. Make the tables unique per run so they can be run in parallel.\r\n\r\nThe storage integration tests do something similar with buckets to prevent collisions."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3880",
        "number": 3880,
        "title": "Threads leak with Logback Appender for Google Cloud Logging",
        "labels": [
            "api: logging",
            "priority: p2"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Ubuntu 16\r\n- Java version: 1.8\r\n- google-cloud-java version(s): gcp_logback_logging: '0.68.0-alpha'\r\n\r\n#### Steps to reproduce\r\nAfter turned on gcp logging in a few days my app stop to response. Generally my app consumes twice less threads than without  gcp logging. \r\nI really want using stackdriver for my app but such behave of it stop me.\r\n\r\nThanks \r\nVolodymyr"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3877",
        "number": 3877,
        "title": "BigQuery Data Transfer autosynthesis fails",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "```\r\nCloning into 'working_repo'...\r\nSwitched to branch 'autosynth-bigquerydatatransfer'\r\nsynthtool > Cloning googleapis.\r\nsynthtool > Running generator for google/cloud/bigquery/datatransfer/artman_bigquerydatatransfer.yaml.\r\nsynthtool > Ensuring dependencies.\r\nsynthtool > Pulling artman image.\r\nTraceback (most recent call last):\r\n  File \"synth.py\", line 27, in <module>\r\n    artman_output_name='google-cloud-bigquerydatatransfer-v1')\r\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 53, in java_library\r\n    return self._generate_code(service, version, \"java\", **kwargs)\r\n  File \"/home/kbuilder/.local/lib/python3.6/site-packages/synthtool/gcp/gapic_generator.py\", line 123, in _generate_code\r\n    f\"Unable to find generated output of artman: {genfiles}.\"\r\nFileNotFoundError: Unable to find generated output of artman: /home/kbuilder/.cache/synthtool/googleapis/artman-genfiles/java/google-cloud-bigquerydatatransfer-v1.\r\nsynthtool > Cleaned up 1 temporary directories.\r\n\r\nSynthesis failed\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3872",
        "number": 3872,
        "title": "Firestore authentication doesn't work",
        "labels": [
            ":rotating_light:",
            "api: firestore",
            "priority: p1",
            "status: investigating"
        ],
        "state": "closed",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS:\r\n- Java version: 1.8\r\n- google-cloud-java version(s): \"com.google.cloud\" % \"google-cloud-firestore\" % \"0.68.0-beta\"\r\n\r\n#### Steps to reproduce\r\n\r\nThis is Scala code, but it should be simple enough to translate it to java\r\n\r\n```\r\nscala> :paste\r\n// Entering paste mode (ctrl-D to finish)\r\n\r\nimport com.google.auth.oauth2.ServiceAccountCredentials\r\nimport java.io.FileInputStream\r\nimport com.google.cloud.firestore.{Firestore, FirestoreOptions}\r\nFirestoreOptions\r\n    .newBuilder()\r\n    .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(\"pathToMyJsonFile\")))\r\n    .build()\r\n    .getService\r\n\r\n// Exiting paste mode, now interpreting.\r\n\r\njava.lang.NoSuchFieldError: transportTracerFactory\r\n  at io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:335)\r\n  at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:325)\r\n  at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:246)\r\n  at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:160)\r\n  at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:152)\r\n  at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:149)\r\n  at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:114)\r\n  at com.google.cloud.firestore.spi.v1beta1.GrpcFirestoreRpc.<init>(GrpcFirestoreRpc.java:122)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:80)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:72)\r\n  at com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:512)\r\n  at com.google.cloud.firestore.FirestoreOptions.getFirestoreRpc(FirestoreOptions.java:315)\r\n  at com.google.cloud.firestore.FirestoreImpl.<init>(FirestoreImpl.java:76)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreFactory.create(FirestoreOptions.java:63)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreFactory.create(FirestoreOptions.java:56)\r\n  at com.google.cloud.ServiceOptions.getService(ServiceOptions.java:499)\r\n  ... 44 elided\r\n```\r\n\r\n#### Stacktrace\r\n\r\n```\r\njava.lang.NoSuchFieldError: transportTracerFactory\r\n  at io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:335)\r\n  at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:325)\r\n  at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:246)\r\n  at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:160)\r\n  at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:152)\r\n  at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:149)\r\n  at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:114)\r\n  at com.google.cloud.firestore.spi.v1beta1.GrpcFirestoreRpc.<init>(GrpcFirestoreRpc.java:122)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:80)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:72)\r\n  at com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:512)\r\n  at com.google.cloud.firestore.FirestoreOptions.getFirestoreRpc(FirestoreOptions.java:315)\r\n  at com.google.cloud.firestore.FirestoreImpl.<init>(FirestoreImpl.java:76)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreFactory.create(FirestoreOptions.java:63)\r\n  at com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreFactory.create(FirestoreOptions.java:56)\r\n  at com.google.cloud.ServiceOptions.getService(ServiceOptions.java:499)\r\n  ... 44 elided\r\n```\r\n\r\n#### Code snippet\r\n\r\n```scala\r\nimport com.google.auth.oauth2.ServiceAccountCredentials\r\nimport java.io.FileInputStream\r\nimport com.google.cloud.firestore.{Firestore, FirestoreOptions}\r\nFirestoreOptions\r\n    .newBuilder()\r\n    .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(\"pathToMyJsonFile\")))\r\n    .build()\r\n    .getService\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\n- Number 2 in https://github.com/googleapis/google-cloud-java#authentication\r\n\r\n#### Any additional information below\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3871",
        "number": 3871,
        "title": "com.google.cloud.logging.logback.LoggingAppender is re-entrant",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "open",
        "body": "Similarly to JUL logging handler in #1386, the Logback appender can be re-entrant."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3868",
        "number": 3868,
        "title": "google-cloud-nio: implement configurable retries/reopens",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "google-cloud-nio currently will retry and even reopen channels on a number of conditions (if turned on in configuration). It would be nice to be able to specify which exceptions to reopen for, and which HTTP codes to retry on (in addition to the codes that already have `.isRetriable()` return true)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3867",
        "number": 3867,
        "title": "Pub Sub messages failed due to due to DEADLINE_EXCEEDED:",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Linux\r\n- Java version: 8\r\n- google-cloud-java version(s): <spring-cloud-gcp.version>1.0.0.M3</spring-cloud-gcp.version>\r\n\r\n#### Steps to reproduce\r\n\r\n1. Publishing 20m records which post messages on pub sub continuously\r\n\r\n#### Stacktrace\r\no.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: .\r\ngrpc-default-worker-ELG-2-2]` 7267 --- INFO i.g.n.s.i.n.h.c.h.DefaultHttp2ConnectionDecoder - [id: 0x204dac20, L:/10.8.61.36:58898 - R:pubsub.googleapis.com/172.217.20.74:443] ignoring HEADERS frame for stream RST_STREAM sent. {}\r\n``\r\n\r\n\r\n#### Code snippet\r\ncom.google.cloud.pubsub.v1.Publisher.publish(com.google.pubsub.v1.PubsubMessage;)\r\n\r\n\r\n#### Any additional information below\r\nWe are publishing some bulk messages to pub sub and intermittently we keep seeing few messages getting failed due to :\r\n\r\nI checked one the previous open issues googleapis/google-cloud-java#2722 which states the issues is resolved. I am not sure what is the resolution ?\r\n\r\njust upgrading to the higher versions will fix the issue or\r\nwe need to add some custom timeout settings (if yes where , RetrySettings?)\r\n@pongad @kir-titievsky\r\n\r\nFollowing these steps will guarantee the quickest resolution possible.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3866",
        "number": 3866,
        "title": "com.google.cloud.logging.logback.LoggingAppender.close doesn't flush logging",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "It makes google-cloud-java unusable with asynchronous logging (DelayingShutdownHook doesn't work)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3861",
        "number": 3861,
        "title": "Pub/Sub ApiFutures.addCallback() deprecated",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "What should people use to add an asynchronous callback on the Api Futures instead now since it's deprecated? \r\n\r\nhttps://github.com/googleapis/google-cloud-java/blob/9cc799fcf68c82ab431d425fefa58ef615ce8e5b/google-cloud-examples/src/main/java/com/google/cloud/examples/pubsub/snippets/CreateTopicAndPublishMessages.java#L103"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3860",
        "number": 3860,
        "title": "Pub/Sub broken links in documentation",
        "labels": [
            "api: pubsub",
            "type: docs"
        ],
        "state": "closed",
        "body": "#### Steps to reproduce\r\n\r\n1. http://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html\r\n2. Go to Publisher\r\n3. Links for `com.google.api.core.ApiFuture` are broken. \r\n4. Go to Subscriber\r\n5. Links for `com.google.api.core.AbstractApiService` are broken. \r\n6. etc. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3859",
        "number": 3859,
        "title": "Pub/Sub clients not closing properly `java.lang.IllegalThreadStateException`",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "#### Environment details\r\n\r\n- OS/Java version:\r\n```\r\nApache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T11:33:14-07:00)\r\nMaven home: /Users/.../apache-maven-3.5.4\r\nJava version: 1.8.0_151, vendor: Oracle Corporation, runtime: /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre\r\nDefault locale: en_US, platform encoding: UTF-8\r\nOS name: \"mac os x\", version: \"10.13.6\", arch: \"x86_64\", family: \"mac\"\r\n```\r\n- google-cloud-java version(s):\r\n```\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-pubsub</artifactId>\r\n      <version>1.48.0</version>\r\n    </dependency>\r\n```\r\n\r\n#### Steps to reproduce\r\n\r\n## In which file did you encounter the issue?\r\n\r\n1. https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/pubsub/cloud-client/src/main/java/com/example/pubsub/CreatePullSubscriptionExample.java\r\n2. https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/pubsub/cloud-client/src/main/java/com/example/pubsub/CreateTopicExample.java\r\n3. https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/pubsub/cloud-client/src/main/java/com/example/pubsub/PublisherExample.java\r\n\r\n## Describe the issue\r\n\r\nThe try-with-resource block fails to close topicAdminClient properly as stated in the documentation.\r\n\r\nOnly by adding `System.exit(0)` in main will users be able to avoid this `java.lang.IllegalThreadStateException`. \r\n\r\n#### Stacktrace\r\n\r\n```\r\n~ $ mvn exec:java -Dexec.mainClass=com.example.pubsub.CreateTopicExample -Dexec.args=october\r\n\r\n[INFO] Scanning for projects...\r\n[INFO] \r\n[INFO] -----------< com.example.pubsub:pubsub-google-cloud-samples >-----------\r\n[INFO] Building pubsub-google-cloud-samples 1.0.9\r\n[INFO] --------------------------------[ jar ]---------------------------------\r\n[INFO] \r\n[INFO] --- exec-maven-plugin:1.6.0:java (default-cli) @ pubsub-google-cloud-samples ---\r\n\r\nTopic java-docs-samples-testing:october created.\r\n\r\n[WARNING] thread Thread[ObjectCleanerThread,1,com.example.pubsub.CreateTopicExample] was interrupted but is still alive after waiting at least 14999msecs\r\n[WARNING] thread Thread[ObjectCleanerThread,1,com.example.pubsub.CreateTopicExample] will linger despite being asked to die via interruption\r\n[WARNING] thread Thread[grpc-default-worker-ELG-1-1,5,com.example.pubsub.CreateTopicExample] will linger despite being asked to die via interruption\r\n[WARNING] thread Thread[grpc-default-worker-ELG-1-2,5,com.example.pubsub.CreateTopicExample] will linger despite being asked to die via interruption\r\n[WARNING] thread Thread[grpc-default-worker-ELG-1-3,5,com.example.pubsub.CreateTopicExample] will linger despite being asked to die via interruption\r\n[WARNING] thread Thread[grpc-shared-destroyer-0,5,com.example.pubsub.CreateTopicExample] will linger despite being asked to die via interruption\r\n[WARNING] NOTE: 5 thread(s) did not finish despite being asked to  via interruption. This is not a problem with exec:java, it is a problem with the running code. Although not serious, it should be remedied.\r\n[WARNING] Couldn't destroy threadgroup org.codehaus.mojo.exec.ExecJavaMojo$IsolatedThreadGroup[name=com.example.pubsub.CreateTopicExample,maxpri=10]\r\njava.lang.IllegalThreadStateException\r\n    at java.lang.ThreadGroup.destroy (ThreadGroup.java:778)\r\n    at org.codehaus.mojo.exec.ExecJavaMojo.execute (ExecJavaMojo.java:321)\r\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)\r\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\r\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\r\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\r\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\r\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\r\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\r\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:954)\r\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:288)\r\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:192)\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\r\n    at java.lang.reflect.Method.invoke (Method.java:498)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)\r\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)\r\n\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 19.158 s\r\n[INFO] Finished at: 2018-10-25T10:37:47-07:00\r\n[INFO] ------------------------------------------------------------------------\r\n```\r\n\r\n#### Code snippet\r\n\r\n```java\r\nimport com.google.api.gax.rpc.ApiException;\r\nimport com.google.cloud.ServiceOptions;\r\nimport com.google.cloud.pubsub.v1.TopicAdminClient;\r\nimport com.google.pubsub.v1.ProjectTopicName;\r\n\r\npublic class CreateTopicExample {\r\n\r\n  /**\r\n   * Create a topic.\r\n   *\r\n   * @param args topicId\r\n   * @throws Exception exception thrown if operation is unsuccessful\r\n   */\r\n  public static void main(String... args) throws Exception {\r\n\r\n    // Your Google Cloud Platform project ID\r\n    String projectId = ServiceOptions.getDefaultProjectId();\r\n\r\n    // Your topic ID, eg. \"my-topic\"\r\n    String topicId = args[0];\r\n\r\n    // Create a new topic\r\n    ProjectTopicName topic = ProjectTopicName.of(projectId, topicId);\r\n    try (TopicAdminClient topicAdminClient = TopicAdminClient.create()) {\r\n      topicAdminClient.createTopic(topic);\r\n    } catch (ApiException e) {\r\n      // example : code = ALREADY_EXISTS(409) implies topic already exists\r\n      System.out.print(e.getStatusCode().getCode());\r\n      System.out.print(e.isRetryable());\r\n    }\r\n\r\n    System.out.printf(\"Topic %s:%s created.\\n\", topic.getProject(), topic.getTopic());\r\n  }\r\n}\r\n```\r\n\r\n#### External references such as API reference guides used\r\n\r\nhttp://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html\r\n\r\n#### Any additional information below\r\n\r\nSuggested adding `System.exit(0)` in comments in this [PR](https://github.com/GoogleCloudPlatform/java-docs-samples/pull/1240), but that doesn't seem to be right solution. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3854",
        "number": 3854,
        "title": "PubSub : add the concept of message abandonment",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "`PusubMessage` / `AckReplyConsumer` needs the concept of \"abandoning\" a message.\r\n\r\nAbandoning a message would mean that the message ack deadline would no longer be auto-extended.\r\n\r\n```\r\npublic void receiveMessage(final PubsubMessage message, final AckReplyConsumer consumer) {\r\n\ttry {\r\n\r\n\t\t// message processing\r\n\r\n\t\tconsumer.ack();\r\n\t} catch (Throwable t) {\r\n\t\t// In an effort to prevent a tight message delivery / processing loop,\r\n\t\t// we want to abandon the message (stop extending the ack deadline and\r\n\t\t// let the message expire \"naturally\")\r\n\t\t\r\n\t\tconsumer.abandon();\r\n\t}\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3852",
        "number": 3852,
        "title": "PubSub : add AckReplyConsumer to PubsubMessage",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "Currently for asynchronous subscribers, they must implement `MessageReceiver` ...\r\n\r\nCurrent interface ...\r\n\r\n```\r\npublic interface MessageReceiver {\r\n    void receiveMessage(final PubsubMessage message, final AckReplyConsumer consumer);\r\n}\r\n```\r\n\r\nThe decoupling of `PubsubMessage` and `AckReplyConsumer` for this interface provides no benefit to developers and requires another object to contain both `AckReplyConsumer` and `PubsubMessage` for easy processing, etc.\r\n\r\nNew interface ...\r\n\r\n```\r\npublic interface MessageReceiver {\r\n    void receiveMessage(final PubsubMessage message);\r\n}\r\n```\r\n\r\n`AckReplyConsumer` then can be retrieved from a `PubsubMessage` via a new method `getAckReplyConsumer()`.\r\n\r\nThis provides a cleaner interface contract and allows a developer to dispatch the `PubsubMessage` to various handler methods as a single object.\r\n\r\nAn an even cleaner alternative would be to add the `ack()` and `nack()` methods to the `PubsubMessage` and remove the `AckReplyConsumer` altogether, which is the approach that `spring-cloud-gcp` has taken."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3850",
        "number": 3850,
        "title": "can't parse WebHookRequest",
        "labels": [
            "api: dialogflow",
            "type: question"
        ],
        "state": "open",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Windows 10 Pro X64\r\n- Java version: 1.8.131\r\n- google-cloud-java version(s): 0.67.0-alpha\r\n\r\n#### Steps to reproduce\r\n\r\n1. ? send request from Dialogflow\r\n2. ? parse WebHookRequest from Controller on Spring\r\n\r\n#### Stacktrace\r\n`\r\ncom.google.protobuf.InvalidProtocolBufferException$InvalidWireTypeException: Protocol message tag had invalid wire type.\r\n\tat com.google.protobuf.InvalidProtocolBufferException.invalidWireType(InvalidProtocolBufferException.java:115)\r\n\tat com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:551)\r\n\tat com.google.protobuf.UnknownFieldSet$Builder.mergeFrom(UnknownFieldSet.java:514)\r\n\tat com.google.protobuf.UnknownFieldSet$Builder.mergeFrom(UnknownFieldSet.java:633)\r\n\tat com.google.protobuf.UnknownFieldSet$Builder.mergeFrom(UnknownFieldSet.java:295)\r\n\tat com.google.protobuf.CodedInputStream$StreamDecoder.readGroup(CodedInputStream.java:2369)\r\n\tat com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:541)\r\n\tat com.google.protobuf.GeneratedMessageV3.parseUnknownFieldProto3(GeneratedMessageV3.java:305)\r\n\tat com.google.cloud.dialogflow.v2beta1.WebhookRequest.<init>(WebhookRequest.java:100)\r\n\tat com.google.cloud.dialogflow.v2beta1.WebhookRequest.<init>(WebhookRequest.java:13)\r\n\tat com.google.cloud.dialogflow.v2beta1.WebhookRequest$1.parsePartialFrom(WebhookRequest.java:1656)\r\n\tat com.google.cloud.dialogflow.v2beta1.WebhookRequest$1.parsePartialFrom(WebhookRequest.java:1650)\r\n\tat com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:221)\r\n\tat com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:239)\r\n\tat com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:244)\r\n\tat com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:49)\r\n\tat com.google.protobuf.GeneratedMessageV3.parseWithIOException(GeneratedMessageV3.java:311)\r\n\tat com.google.cloud.dialogflow.v2beta1.WebhookRequest.parseFrom(WebhookRequest.java:507)\r\n\tat it.joaquin.test.web.rest.ProductResource.searchByName(ProductResource.java:42)\r\n`\r\n\r\n```\r\n\r\ncom.google.protobuf.InvalidProtocolBufferException$InvalidWireTypeException: Protocol message tag had invalid wire type.\r\n\tat com.google.protobuf.InvalidProtocolBufferException.invalidWireType(InvalidProtocolBufferException.java:115)\r\n\r\n```\r\n\r\n#### Code snippet\r\n```java\r\n@PostMapping(\"/search-by-name\")\r\n    public ResponseEntity<String> searchByName(@RequestBody String body) throws IOException {\r\n        InputStream stream = new ByteArrayInputStream(body.getBytes(StandardCharsets.UTF_8));\r\n        WebhookRequest webhookRequest = WebhookRequest.parseFrom(stream);\r\n```\r\n \r\n\r\n#### External references such as API reference guides used\r\n- ?\r\n\r\n#### Any additional information below\r\n\r\nMessage from Dialogflow\r\n`[{\r\n  \"responseId\": \"ff6d0d81-e09d-46e8-a3f2-41b6058729bd\",\r\n  \"queryResult\": {\r\n    \"queryText\": \"2 confezioni di pane\",\r\n    \"action\": \"input.buy\",\r\n    \"parameters\": {\r\n      \"product\": \"pane\",\r\n      \"quantity\": 2.0,\r\n      \"measureUnit\": \"confezioni\"\r\n    },\r\n    \"allRequiredParamsPresent\": true,\r\n    \"fulfillmentText\": \"vedo cosa trovo per 2 confezioni di pane\",\r\n    \"fulfillmentMessages\": [{\r\n      \"text\": {\r\n        \"text\": [\"ho capito che vuoi comprare 2 confezioni di pane\"]\r\n      }\r\n    }],\r\n    \"intent\": {\r\n      \"name\": \"projects/test-181222/agent/intents/d060e25c-2e4e-4c7e-903b-5cb55c13a6f0\",\r\n      \"displayName\": \"start shopping\"\r\n    },\r\n    \"intentDetectionConfidence\": 0.9,\r\n    \"languageCode\": \"it\"\r\n  },\r\n  \"originalDetectIntentRequest\": {\r\n    \"payload\": {\r\n    }\r\n  },\r\n  \"session\": \"projects/test-181222/agent/sessions/fa784619-43bd-f263-858f-8dd51ff7a69d\"\r\n}]`\r\n\r\nThanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3843",
        "number": 3843,
        "title": "Best practice to send data to bigquery from multiple services",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "open",
        "body": "Hi,\r\n\r\nI have a use case where I have 1000s of micro services. And all these services will be generate some json data that needs to be stored in big query. If I have to call big query from individual service and store the data in bug query, what is the recommended way of doing  ? Should I use streaming insert or do a load job ? Max should be 100 services calling big query in parallel to send their json data.  \r\n\r\nThanks,\r\nMani"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3834",
        "number": 3834,
        "title": "Include source proto files in jar for extensibility",
        "labels": [
            "api: dialogflow",
            "type: feature request"
        ],
        "state": "closed",
        "body": "#### Environment details\r\n\r\n- OS: Ubuntu 18.04\r\n- Java version: 1.8\r\n- google-cloud-java version(s): 1.49.0\r\n\r\n#### Steps to reproduce\r\n\r\nCreate a project that has a proto import dependency on one of the .proto files. \r\n\r\nFor example, \r\ngoogle/cloud/dialogflow/v2/webhook.proto\r\n\r\n#### Code snippet\r\n\r\nimport \"google/cloud/dialogflow/v2/webhook.proto\";\r\nimport \"google/api/annotations.proto\";\r\n\r\nservice WikiDialogue {\r\n    // Send the response from agent using when a webhookrequest is received.\r\n    rpc GetResponseFromAgent (google.cloud.dialogflow.v2.WebhookRequest) returns (google.cloud.dialogflow.v2.WebhookResponse) {\r\n        option (google.api.http) = { post: \"/v1/wikitalk/talk\" };\r\n    }\r\n}\r\n\r\nThis results in a build error because the proto will not be found; it is not included in the jar file. \r\n\r\nThe fix for this is to modify the pom file to include the proto file in the jar file when it is constructed, e.g.:\r\n\r\nTo include all the proto files:\r\n <resources>\r\n      <resource>\r\n        <directory>src/main/proto</directory>\r\n        <includes>\r\n          <include>google/cloud/dialogflow/v2/webhook.proto</include>\r\n          <include>google/cloud/dialogflow/v2/intent.proto</include>\r\n          <include>google/cloud/dialogflow/v2/session.proto</include>\r\n          <include>google/cloud/dialogflow/v2/session_entity_type.proto</include>\r\n          <include>google/cloud/dialogflow/v2/entity_type.proto</include>\r\n          <include>google/cloud/dialogflow/v2/agent.proto</include>\r\n          <include>google/cloud/dialogflow/v2/context.proto</include>\r\n        </includes>\r\n      </resource>\r\n    </resources>\r\n\r\nThis would allow us to import and use the proto files in developing service APIs that build on top of Google APIs.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3827",
        "number": 3827,
        "title": "Once g-c-j supports Java 11, add note that g-c-j can be used on Alpine and ARM (e.g. Raspberry Pi)",
        "labels": [
            "type: docs"
        ],
        "state": "open",
        "body": "Reason: ALPN is available by default in Java 11, so netty-tcnative is not necessary."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3822",
        "number": 3822,
        "title": "Give users the ability to disable gzip content encoding to increase throughput",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "- OS: all\r\n- Java version: 1.8  (probably all)\r\n- google-cloud-java version(s): 1.23.0\r\n\r\n#### Steps to reproduce\r\n\r\n1. Upload to GCS using the cloud storage library.\r\n2. Observe poor throughput (20 MiB/s)_ and that lots of time is spent compressing the content. \r\n\r\nOn GCE I'm able to achieve 70 MiB/s if I disable gzip encoding when uploading to GCS.  With gzip encoding it's  much worse at 20 MiB/s. However  disabling gzip encoding isn't an option exposed in the interface. This makes google-cloud-java poor in comparison to the REST api it's wrapping.  \r\n\r\nThis is a request to expose the gzip encoding of the stream as a storage option.  See code in com.google.cloud.storage.spi.v1.HttpStorageRpc.create  there is no code to call StorageRequest.setDisableGZipContent  (which defaults to false) on the underling com.google.api.services.storage.StorageRequest:\r\n\r\n      Storage.Objects.Insert insert = storage.objects()\r\n          .insert(storageObject.getBucket(), storageObject,\r\n              new InputStreamContent(storageObject.getContentType(), content));\r\n      insert.getMediaHttpUploader().setDirectUploadEnabled(true);\r\n      setEncryptionHeaders(insert.getRequestHeaders(), ENCRYPTION_KEY_PREFIX, options);\r\n      return insert.\r\n      ... .execute();\r\n\r\nCan we please provide this feature to maintain comparable performance with the com.google.api.services.storage.*  client?\r\n\r\nthanks\r\n\r\n#### Code snippet\r\nUploading an object to GCS and observe performance, then do so with gzip disabled: \r\n\r\n        /// USING THE OLD CLIENT\r\n        Storage client = getService();\r\n        Storage.Objects.Insert insertRequest =\r\n                client.objects().insert(bucketName, objectMetadata, contentStream);\r\n\r\n        /// Currently NO ability to this in google-cloud-java, need this for much faster throughput on GCE.\r\n        insertRequest.setDisableGZipContent(true);\r\n        insertRequest.getMediaHttpUploader().setDisableGZipContent(true);\r\n\r\n        insertRequest.getMediaHttpUploader().setDirectUploadEnabled(true);\r\n        long start = System.currentTimeMillis();\r\n        insertRequest.execute();\r\n        long end = System.currentTimeMillis();\r\n        System.out.println( String.format(\"%.02f MiB/s \",(length / (1024*1024.0) )/ ((end - start) / 1000.0)));\r\n\r\n\r\n#### Any additional information below\r\nAlso, perhaps document somewhere that in order to get any reasonable performance on Java8 it's necessary to disable Galios/Counter mode in java.security:  https://stackoverflow.com/questions/25992131/slow-aes-gcm-encryption-and-decryption-with-java-8u20\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3819",
        "number": 3819,
        "title": "dependency:go-offline fails to pull in required surefire testing dependency.",
        "labels": [
            "dependencies",
            "priority: p2",
            "status: in progress",
            "type: bug"
        ],
        "state": "closed",
        "body": "Thanks for stopping by to let us know something could be better!\r\n\r\nPlease include as much information as possible:\r\n\r\n#### Environment details\r\n\r\n- OS: Linux\r\n- Java version: java8\r\n- google-cloud-java version(s):\r\n\r\n#### Steps to reproduce\r\n0. Start with a completely clean environment. \r\n1. Run a command that builds the project without running tests: mvn install -DskipTests\r\n2. Pull down the dependencies:  dependency:go-offline\r\n3. Trying running the tests off line: mvn --fail-at-end -o verify\r\n\r\n#### Stacktrace\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project google-cloud-core: Unable to generate classpath: org.apache.maven.artifact.resolver.MultipleArtifactsNotFoundException: Missing:\r\n[ERROR] ----------\r\n[ERROR] 1) org.apache.maven.surefire:surefire-junit4:jar:2.19.1\r\n[ERROR]\r\n[ERROR] Try downloading the file manually from the project website.\r\n[ERROR]\r\n[ERROR] Then, install it using the command:\r\n[ERROR] mvn install:install-file -DgroupId=org.apache.maven.surefire -DartifactId=surefire-junit4 -Dversion=2.19.1 -Dpackaging=jar -Dfile=/path/to/file\r\n[ERROR]\r\n[ERROR] Alternatively, if you host your own repository you can deploy the file there:\r\n[ERROR] mvn deploy:deploy-file -DgroupId=org.apache.maven.surefire -DartifactId=surefire-junit4 -Dversion=2.19.1 -Dpackaging=jar -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id]\r\n[ERROR]\r\n[ERROR] Path to dependency:\r\n[ERROR] 1) dummy:dummy:jar:1.0\r\n[ERROR] 2) org.apache.maven.surefire:surefire-junit4:jar:2.19.1\r\n[ERROR]\r\n[ERROR] ----------\r\n[ERROR] 1 required artifact is missing.\r\n[ERROR]\r\n[ERROR] for artifact:\r\n[ERROR] dummy:dummy:jar:1.0\r\n[ERROR]\r\n[ERROR] from the specified remote repositories:\r\n[ERROR] central (http://repo.maven.apache.org/maven2, releases=true, snapshots=false)\r\n[ERROR] -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3817",
        "number": 3817,
        "title": "BigQuery table labels not retrieved from getTable",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "\"Labels\" field has been added in the issue #2865 but no Field selector \"Labels\" is defined in the TableField enum.\r\n\r\nSo, there is no way to retrieve the labels of a table. \r\n\r\n#### Environment details\r\n\r\n- cloud java version : 0.49.0"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3816",
        "number": 3816,
        "title": "PubSub : add source projectId, topic and subscription to PubsubMessage",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "Some use cases require that source (projectId, topic and subscription) of a PubsubMessage ... yet the message doesn't have this information.\r\n\r\nAdded this should at the server shouldn't cause any issues as it's adding data to the message."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3815",
        "number": 3815,
        "title": "Bigtable: Many APIs have outdated exmples",
        "labels": [
            "api: bigtable",
            "type: docs"
        ],
        "state": "closed",
        "body": "For example, many code snippets use `BigtableClient` which was renamed to `BigtableDataClient`.  Find and fix those issues.\r\n\r\nIn the longer term, it would be great to use references to snippets in other documents.  See [this node.js PR](https://github.com/googleapis/nodejs-bigtable/pull/262) as an example of how these references work."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3812",
        "number": 3812,
        "title": "PubSub : Implement a clean first-class pull based PubSub implementation.",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "The gRPC based pull implementation, while usable, is very cumbersome.\r\n\r\nA first-class pull based implementation would be nice for a handful of use cases and would help with https://github.com/googleapis/google-cloud-java/issues/3500\r\n\r\nSpring has a great interface with pull methods ...\r\n\r\nhttps://github.com/spring-cloud/spring-cloud-gcp/blob/master/spring-cloud-gcp-pubsub/src/main/java/org/springframework/cloud/gcp/pubsub/core/subscriber/PubSubSubscriberOperations.java\r\n\r\nAlso, ack deadline keep-alives could be implemented ...\r\n\r\nhttps://github.com/googleapis/google-cloud-java/issues/3779"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3808",
        "number": 3808,
        "title": "Change in TableId behaviour for non default BigQueryClient project 1.44 -> 1.45",
        "labels": [
            ":rotating_light:",
            "api: bigquery",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "When using the getTable method of the BigQuery client the project of the TableId is overwritten. TableId would previously ignore this if a project had been set. Table Id has been changed such that the project is always overwritten. There is now no way to get a table for a project other than the one the client was created for.\r\n\r\n```\r\nTableId tableId = TableId.of(project, schema, tableName);\r\nTable table = client.getTable(tableId);\r\n// table returns null if project != client.getOptions().getProjectId()\r\n```\r\n\r\n_this is due to the change in TableId_\r\n\r\nIn BigQueryImpl:\r\n```\r\npublic Table getTable(TableId tableId, TableOption... options) {\r\n    final TableId completeTableId = tableId.setProjectId(getOptions().getProjectId());\r\n    ...\r\n```\r\n\r\nTableId old code:\r\n```\r\nTableId setProjectId(String projectId) {\r\n  return getProject() != null ? this : TableId.of(projectId, getDataset(), getTable());\r\n}\r\n```\r\n\r\nTableId new code:\r\n```\r\nTableId setProjectId(String projectId) {\r\n  Preconditions\r\n    .checkArgument(!Strings.isNullOrEmpty(projectId), \"Provided projectId is null or empty\");\r\n  return TableId.of(projectId, getDataset(), getTable());\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3805",
        "number": 3805,
        "title": "Update BigQuery Table's schema",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "open",
        "body": "Hi, I was curious as to how I can update my BigQuery Table's schema based on my input data from a Streaming Dataflow Pipeline?\r\n\r\nThe input events that I get can have varied incremental schema and I want my BigQuery to adopt to the changes.\r\n\r\nI [looked up an article on Google Cloud Blog](https://cloud.google.com/blog/products/gcp/how-to-handle-mutating-json-schemas-in-a-streaming-pipeline-with-square-enix) on a very similar topic, but there's no explanation on how the mutation was done (see the attached image)\r\n\r\n<img width=\"1096\" alt=\"screenshot 2018-10-09 at 7 48 13 pm\" src=\"https://user-images.githubusercontent.com/6565270/46770883-c994ab80-cd0e-11e8-8e62-025d2d8da4dd.png\">\r\n\r\nAny ideas/leads on how I can do this?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3802",
        "number": 3802,
        "title": "Need mechanism to keep dependencies up to date",
        "labels": [
            "type: process"
        ],
        "state": "open",
        "body": "We should be notified automatically when dependencies are out of date so we can update them without the need for external contributors discovering them and filing ad hoc issues."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3801",
        "number": 3801,
        "title": "com.google.cloud:google-cloud-storage:jar:1.48.0 is invalid, transitive dependencies (if any) will not be available",
        "labels": [
            ":rotating_light:",
            "api: storage",
            "triage me",
            "type: bug"
        ],
        "state": "closed",
        "body": "Encountered this warning today while testing the dashboard. Noting here until I can dig into it. Perhaps someone else can explain this?\r\n\r\n\r\n```\r\n[INFO] ------------------------------------------------------------------------\r\n[WARNING] The POM for com.google.cloud:google-cloud-storage:jar:1.48.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\r\n[INFO] \r\n[INFO] --- maven-enforcer-plugin:3.0.0-M2:enforce (enforce) @ upper-bounds-check ---\r\n[WARNING] Invalid POM for com.google.cloud:google-cloud-storage:jar:1.48.0, transitive dependencies (if any) will not be available, enable debug logging for more details\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3797",
        "number": 3797,
        "title": "Stackdriver Monitoring: NoSuchMethodError when having a Dataflow dependency",
        "labels": [
            ":rotating_light:",
            "triage me"
        ],
        "state": "closed",
        "body": "I cannot build a simple metric from a java application using the Stackdriver Monitoring client when I have a dependency to the Google Dataflow client. \r\n\r\nI get the exception: \r\n```\r\nException in thread \"main\" java.lang.NoSuchMethodError: io.grpc.okhttp.OkHttpChannelProvider.isAndroid()Z\r\n\tat io.grpc.okhttp.OkHttpChannelProvider.priority(OkHttpChannelProvider.java:51)\r\n\tat io.grpc.ManagedChannelProvider$1.getPriority(ManagedChannelProvider.java:49)\r\n\tat io.grpc.ManagedChannelProvider$1.getPriority(ManagedChannelProvider.java:41)\r\n\tat io.grpc.ServiceProviders$1.compare(ServiceProviders.java:78)\r\n\tat java.util.Collections$ReverseComparator2.compare(Collections.java:5178)\r\n\tat java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)\r\n\tat java.util.TimSort.sort(TimSort.java:220)\r\n\tat java.util.Arrays.sort(Arrays.java:1512)\r\n\tat java.util.ArrayList.sort(ArrayList.java:1462)\r\n\tat java.util.Collections.sort(Collections.java:175)\r\n\tat io.grpc.ServiceProviders.loadAll(ServiceProviders.java:75)\r\n\tat io.grpc.ServiceProviders.load(ServiceProviders.java:42)\r\n\tat io.grpc.ManagedChannelProvider.<clinit>(ManagedChannelProvider.java:37)\r\n\tat io.grpc.ManagedChannelBuilder.forAddress(ManagedChannelBuilder.java:36)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:185)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:157)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:149)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:151)\r\n\tat com.google.cloud.monitoring.v3.stub.GrpcMetricServiceStub.create(GrpcMetricServiceStub.java:173)\r\n\tat com.google.cloud.monitoring.v3.stub.MetricServiceStubSettings.createStub(MetricServiceStubSettings.java:184)\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.<init>(MetricServiceClient.java:158)\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.create(MetricServiceClient.java:139)\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.create(MetricServiceClient.java:130)\r\n\tat SimpleMetric.main(SimpleMetric.java:7)\r\n```\r\non the create method:\r\n```\r\nimport com.google.cloud.monitoring.v3.MetricServiceClient;\r\n\r\nimport java.io.IOException;\r\n\r\npublic class SimpleMetric {\r\n    public static void main(String... args) throws IOException {\r\n        MetricServiceClient metricServiceClient = MetricServiceClient.create();\r\n    }\r\n}\r\n```\r\n\r\nonly when I add:\r\ncompile 'com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:2.5.0'\r\n\r\nas in my gradle file as a dependency. \r\n```\r\nplugins {\r\n    id 'java'\r\n}\r\n\r\nsourceCompatibility = 1.8\r\n\r\nrepositories {\r\n    mavenCentral()\r\n}\r\n\r\ndependencies {\r\n    compile 'com.google.cloud:google-cloud-monitoring:1.48.0'\r\n    // exception with the dependency below\r\n    compile 'com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:2.5.0'\r\n\r\n}\r\n\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3791",
        "number": 3791,
        "title": "Create GitHub Issue/PR templates",
        "labels": [
            "status: in progress",
            "type: process"
        ],
        "state": "closed",
        "body": "This should help users file more detailed bug reports and aid us in reproducing and fixing bugs."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3788",
        "number": 3788,
        "title": "stackdriver Page<LogEntry> java.util.concurrent.RejectedExecutionException",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "When i try to run below code, it throws me RejectedExecutionException.\r\n\r\n```java\r\ndo {\r\n    for (LogEntry entry : entryPage.iterateAll()) {\r\n\t......\r\n    }\r\n    if (entryPage.hasNextPage())\r\n        entryPage = entryPage.getNextPage();\r\n} while(entryPage!=null);\r\n```\r\n\r\nThe code works when there is no next page but it throws RejectedExecutionException for entryPage.getNextPage() when search result has more pages.\r\n\r\n```\r\nCaused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5f609937 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@66e0adf6[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 8]\r\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)\r\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.execute(ScheduledThreadPoolExecutor.java:622)\r\n\tat io.grpc.internal.SerializingExecutor.schedule(SerializingExecutor.java:93)\r\n\tat io.grpc.internal.SerializingExecutor.execute(SerializingExecutor.java:86)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.closed(ClientCallImpl.java:594)\r\n\tat io.grpc.internal.FailingClientStream.start(FailingClientStream.java:43)\r\n\tat io.grpc.internal.ClientCallImpl.start(ClientCallImpl.java:265)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1.start(CensusTracingModule.java:387)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1.start(CensusStatsModule.java:679)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:32)\r\n\tat com.google.api.gax.grpc.GrpcHeaderInterceptor$1.start(GrpcHeaderInterceptor.java:95)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:293)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:268)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:177)\r\n\tat com.google.api.gax.grpc.GrpcDirectCallable.futureCall(GrpcDirectCallable.java:58)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable.futureCall(GrpcExceptionCallable.java:62)\r\n\tat com.google.api.gax.rpc.AttemptCallable.call(AttemptCallable.java:75)\r\n\tat com.google.api.gax.rpc.RetryingCallable.futureCall(RetryingCallable.java:63)\r\n\tat com.google.api.gax.rpc.RetryingCallable.futureCall(RetryingCallable.java:41)\r\n\tat com.google.api.gax.rpc.UnaryCallable$1.futureCall(UnaryCallable.java:126)\r\n\tat com.google.api.gax.rpc.UnaryCallable.futureCall(UnaryCallable.java:87)\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.list(GrpcLoggingRpc.java:228)\r\n\tat com.google.cloud.logging.LoggingImpl.listLogEntriesAsync(LoggingImpl.java:624)\r\n\tat com.google.cloud.logging.LoggingImpl.access$400(LoggingImpl.java:79)\r\n\tat com.google.cloud.logging.LoggingImpl$LogEntryPageFetcher.getNextPage(LoggingImpl.java:230)\r\n\tat com.google.cloud.AsyncPageImpl$SyncNextPageFetcher.getNextPage(AsyncPageImpl.java:65)\r\n\tat com.google.cloud.PageImpl.getNextPage(PageImpl.java:117)\r\n\t... 62 more\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3786",
        "number": 3786,
        "title": "Spanner: RESOURCE_EXHAUSTED No session available in the pool. ",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using the Spanner client library for Java and i configure the client using Spring (Java 10 and Docker)\r\n\r\nAfter a while, the application start to log the following message but i don't understand why. The application concurrency is minimal. It's seem the sessions aren't reused.\r\n\r\nI monitor the session with Stackdriver and they are below 20. \r\n\r\nIf i remove setFailIfPoolExhausted the applicacion hang instead of throwing exception RESOURCE_EXHAUSTED.\r\n\r\n> RESOURCE_EXHAUSTED: No session available in the pool. Maximum number of sessions in the pool can be overridden by invoking SessionPoolOptions#Builder#setMaxSessions. Client can be made to block rather than fail by setting SessionPoolOptions#Builder#setBlockIfPoolExhausted.\r\n\r\n```java\r\n\r\n@Configuration\r\npublic class SpannerConfig {\r\n\r\n    @Value(\"${datasource.instanceId}\")\r\n    private String instance;\r\n\r\n    @Value(\"${datasource.databaseId}\")\r\n    private String database;\r\n\r\n    @Bean\r\n    public Spanner spannerService() throws IOException {\r\n\r\n        SessionPoolOptions sessionPoolOptions = SessionPoolOptions.newBuilder()\r\n                .setFailIfPoolExhausted()\r\n                .setMinSessions(5)\r\n                .setMaxSessions(100)\r\n                .build();\r\n\r\n        SpannerOptions options = SpannerOptions.newBuilder()\r\n                .setSessionPoolOption(sessionPoolOptions)\r\n                .build();\r\n\r\n        return options.getService();\r\n    }\r\n\r\n\r\n    @Bean\r\n    public DatabaseClient spannerClient(Spanner spannerService) {\r\n        DatabaseId databaseId = DatabaseId.of(spannerService.getOptions().getProjectId(), instance, database);\r\n        return spannerService.getDatabaseClient(databaseId);\r\n    }\r\n}\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3779",
        "number": 3779,
        "title": "PubSub : repeatedly extend the acknowledgement deadline for backlogged pull messages",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "For the asynchronous subscriber, backlogged messages have automatic acknowledgement deadline processing.\r\n\r\n\"<snip> Because the client library repeatedly extends the acknowledgement deadline for backlogged messages <snip>\"\r\n\r\nThis feature would be useful for messages that are being processed via synchronous (pull.)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3778",
        "number": 3778,
        "title": "Kafka Connect DEADLINE_EXCEEDED Excpetion keeps happening until i restart Kafka Connect",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "I have an issue which keeps happening until i restart my Kafka Connect sh\r\n\r\nGCP keeps throwing DEADLINE_EXCEEDED exception until restart kafka Connect.\r\nOnce Its restarted the processing of message goes smoothlyin Pubsub Sink Connector\r\nMay i know why i have this issue?\r\n\r\nEven though i get the DEADLINE_EXCEEDED exception the message is getting posted to Pubsub.\r\nTHe only problem is the offsets are not getting updated so i keep publishing the same message to the Pubsub topic and everytime i publish the message i get the DEADLINE_EXCEEDED exception\r\nPlease help"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3777",
        "number": 3777,
        "title": "Move version management scripts to releasetool",
        "labels": [
            "status: in progress",
            "type: process"
        ],
        "state": "closed",
        "body": "In particular, these two scripts:\r\n\r\n* https://github.com/googleapis/google-cloud-java/blob/master/utilities/bump_versions.py\r\n* https://github.com/googleapis/google-cloud-java/blob/master/utilities/replace_versions.py\r\n\r\nKey functionality that should probably be retained:\r\n\r\n* The two-phase process of bump & replace\r\n* The replacement of versions only at locations that are tagged\r\n* A master version file (currently https://github.com/googleapis/google-cloud-java/blob/master/versions.txt )\r\n* The tracking of last-released version and current version (which can be either last-released or a snapshot version)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3776",
        "number": 3776,
        "title": "Can not add Enable billing for Project (Cloud API)",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I got this Error when I wanted to add payment method : \r\n### Unable to complete transaction: prepaid cards can't be used\r\n\r\nWhy is that ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3774",
        "number": 3774,
        "title": "Detect directories even when not ending with \"/\"",
        "labels": [
            "api: storage",
            "priority: p2",
            "status: in progress",
            "type: bug"
        ],
        "state": "closed",
        "body": "The current implementation of PseudoDirectories has Files.isDirectory(path) return true only if path ends with a slash.\r\n\r\nUsers would be less surprised if instead of this behavior, we tried harder to identify things that look like directories.\r\n\r\nSo for example if `foo/bar.txt` exists, the following paths should be treated as directories:\r\n\r\n* `foo/`\r\n* `foo`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3772",
        "number": 3772,
        "title": "walkFileTree should return consistently absolute or relative paths.",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "The expected behavior from `Files.walkFileTree` is that if the starting path is absolute, then all the visited paths are absolute. If the starting path is relative, then all the visited paths are relative.\r\n\r\nHowever, the output of `Files.walkFileTree(\"/dir/\")` is something like this:\r\n\r\n```\r\ndir/file.txt\r\ndir/dir2/another.txt\r\ndir/dir2/\r\n/dir/\r\n```\r\n\r\nAs you can see, only the last entry is absolute. They should be consistent (in this case, they should be absolute)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3763",
        "number": 3763,
        "title": "Cloud Vision API - Authentication using API Key",
        "labels": [
            "api: vision",
            "type: question"
        ],
        "state": "closed",
        "body": "Using an API key with the `https://vision.googleapis.com/v1/images:annotate` endpoint via curl works as expected which means API keys can be used with the cloud vision API.\r\n\r\nAs per discussion here https://github.com/googleapis/google-cloud-java/issues/1405 supplying a `GOOGLE_API_KEY` environment variable while ensuring no `GOOGLE_APPLICATION_CREDENTIALS` variable is set should mean that API key based authentication should be used by the client lib. However the following code:\r\n\r\n```java\r\nclass GCPCloudVisionClient {\r\n\r\n    public void initialiseClient() throws IOException {\r\n        ImageAnnotatorClient imageAnnotatorClient = ImageAnnotatorClient.create();\r\n    }\r\n\r\n    public static void main(String[] args) {\r\n        GCPCloudVisionClient gcpCloudVisionClient = new GCPCloudVisionClient();\r\n        try {\r\n            gcpCloudVisionClient.initialiseClient();\r\n        } catch (IOException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n}\r\n``` \r\n\r\nfails with the following exception\r\n```text\r\njava.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.\r\n\tat com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:131)\r\n\tat com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127)\r\n\tat com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100)\r\n\tat com.google.api.gax.core.GoogleCredentialsProvider.getCredentials(GoogleCredentialsProvider.java:59)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:132)\r\n\tat com.google.cloud.vision.v1.stub.GrpcImageAnnotatorStub.create(GrpcImageAnnotatorStub.java:84)\r\n\tat com.google.cloud.vision.v1.stub.ImageAnnotatorStubSettings.createStub(ImageAnnotatorStubSettings.java:120)\r\n\tat com.google.cloud.vision.v1.ImageAnnotatorClient.<init>(ImageAnnotatorClient.java:136)\r\n\tat com.google.cloud.vision.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:117)\r\n\tat com.google.cloud.vision.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:108)\r\n```\r\n\r\nDoes this indicate a bug in the client library where in it doesn't use the API key supplied as expected?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3757",
        "number": 3757,
        "title": "Javadoc builder is more strict than the javadoc tests",
        "labels": [
            "status: in progress",
            "type: cleanup",
            "type: docs"
        ],
        "state": "closed",
        "body": "- [ ] f6b93fa0305dacb1f40c88aca7c811016bf86ee0 fixed some documentation errors that were not caught by the javadoc tests. The tests should ensure that the full documentation site can build and not block a release\r\n- [ ] Update to maven-javadoc-plugin 3.0+ and set doclint configuration option"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3754",
        "number": 3754,
        "title": "Dataproc Client API: Job in state SETUP_DONE not cancellable",
        "labels": [
            "api: dataproc",
            "type: question"
        ],
        "state": "open",
        "body": "Hi,\r\nthe dataproc API does not allow cancelling a job which is in state SETUP_DONE. Is there any specific reason why or is this a bug? Cancellation in states PENDING or RUNNING is working fine for me. From my understanding a job usually gets transferred from PENDING to SETUP_DONE and SETUP_DONE to RUNNING.\r\n\r\nSpecifically I am using this method for cancellation:\r\nhttps://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/com/google/cloud/dataproc/v1/JobControllerClient.html#cancelJob-java.lang.String-java.lang.String-java.lang.String-\r\n\r\nThis is the exception I am getting:\r\n```\r\ncom.google.api.gax.rpc.FailedPreconditionException: io.grpc.StatusRuntimeException: FAILED_PRECONDITION: Cannot cancel jobId '4e41f6fb-xxx' in projectId 'xxx' in state: 'SETUP_DONE'; cancellable states: '[PENDING, RUNNING]'\r\n```\r\n\r\nCurrently I am using the dataproc API version _0.58.0-alpha_.\r\n\r\nThank you!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3753",
        "number": 3753,
        "title": "Parquet Redshift Copy Schema mismatch",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "open",
        "body": "Parquet Redshift Copy does not seem to error on a mismatch of schema, it performs the copy but all column values are null. Orc Redshift copy in comparison gives an error of and does not populate the given bigquery table:\r\n\r\n```Error while reading data, error message: Mismatch between schema...```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3752",
        "number": 3752,
        "title": "PubSub Subscriber will not stop when messages have not been acked or nacked",
        "labels": [
            "api: pubsub",
            "triage me"
        ],
        "state": "closed",
        "body": "**Issue**\r\nWhen using the Subscriber of the PubSub client, if any message is not ack'ed or nack'ed the subscriber does not shut down anymore.\r\n\r\n**Why would I want this?**\r\nIn my case, I want to read PubSub messages using [Apache Flink](https://flink.apache.org/). Flink has a technique to keep itself consistent called checkpointing. Only on every checkpoint will should I ack messages. When a part of Flink crashes/exits/shuts down we want to ignore all messages since the last checkpoint and have PubSub resend them.\r\n\r\nThis means messages will only be acknowledged on a checkpoint (maybe every 500ms) and when shutting down the last couple of messages won't be acknowledged.\r\n\r\n**How to reproduce**\r\nI've edited the [pubsub example](https://github.com/googleapis/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/pubsub/snippets/CreateSubscriptionAndConsumeMessages.java) in this repo to show what I mean:\r\n\r\n```    \r\npublic static void main(String... args) throws Exception {\r\n    ProjectSubscriptionName subscription = ProjectSubscriptionName.of(\"bolcom-stg-jey-streaming-886\", \"streaming-test\");\r\n    MessageReceiver receiver =\r\n            new MessageReceiver() {\r\n                @Override\r\n                public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n                    System.out.println(\"Received message: \" + message.getData().toStringUtf8());\r\n                    //DO NOT ack() or nack() and the subscriber will never stop\r\n                    //consumer.ack();\r\n                }\r\n            };\r\n    Subscriber subscriber = null;\r\n    try {\r\n        subscriber = Subscriber.newBuilder(subscription, receiver)\r\n                               .build();\r\n        subscriber.addListener(\r\n                new Subscriber.Listener() {\r\n                    @Override\r\n                    public void failed(Subscriber.State from, Throwable failure) {\r\n                        // Handle failure. This is called when the Subscriber encountered a fatal error and is shutting down.\r\n                       System.err.println(failure);\r\n                    }\r\n               },\r\n                MoreExecutors.directExecutor());\r\n        subscriber.startAsync().awaitRunning();\r\n\r\n        // In this example, we will pull messages for one minute (60,000ms) then stop.\r\n        // In a real application, this sleep-then-stop is not necessary.\r\n        // Simply call stopAsync().awaitTerminated() when the server is shutting down, etc.\r\n        Thread.sleep(5000);\r\n    } finally {\r\n        if (subscriber != null) {\r\n            System.out.println(\"Stopping\");\r\n            subscriber.stopAsync().awaitTerminated();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nbut basically, all that has changed is I do not ack() or nack() anything.\r\n\r\n**Question:**\r\nThe example above won't ever return from the awaitTerminated() call and thus will not exit. Is this behavior by design? Or should I terminate in a different manner?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3751",
        "number": 3751,
        "title": "Add code coverage to this repo",
        "labels": [
            "status: in progress",
            "type: feature request",
            "type: process"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3749",
        "number": 3749,
        "title": "PubSub Synchronous Pull hang",
        "labels": [
            ":rotating_light:",
            "api: pubsub",
            "priority: p1",
            "type: bug"
        ],
        "state": "open",
        "body": "I'm using the synchronous pull to retrive events. My code is based on the Google documentation (https://cloud.google.com/pubsub/docs/pull)\r\n\r\nWhen I call the following method the thread is blocked indefinitely. I paste you the logs. \r\n\r\nThanks\r\n\r\n```java\r\nsubscriber.pullCallable().call(pullRequest)\r\n```\r\n\r\n```java\r\n20405 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.n.handler.ssl.SslHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] HANDSHAKEN: TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 \r\n20405 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] OUTBOUND SETTINGS: ack=false settings={ENABLE_PUSH=0, MAX_CONCURRENT_STREAMS=0, INITIAL_WINDOW_SIZE=1048576, MAX_HEADER_LIST_SIZE=8192} \r\n20405 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] OUTBOUND WINDOW_UPDATE: streamId=0 windowSizeIncrement=983041 \r\n20407 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] INBOUND SETTINGS: ack=false settings={MAX_CONCURRENT_STREAMS=100, INITIAL_WINDOW_SIZE=1048576, MAX_HEADER_LIST_SIZE=16384} \r\n20407 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] OUTBOUND SETTINGS: ack=true \r\n20414 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] INBOUND WINDOW_UPDATE: streamId=0 windowSizeIncrement=983041 \r\n20414 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] OUTBOUND HEADERS: streamId=3 headers=GrpcHttp2OutboundHeaders[:authority: pubsub.googleapis.com:443, :path: /google.pubsub.v1.Subscriber/Pull, :method: POST, :scheme: https, content-type: application/grpc, te: trailers, user-agent: grpc-java-netty/1.13.1, x-goog-api-client: gl-java/ gapic/1.46.0 gax/1.32.0 grpc/1.13.1, grpc-accept-encoding: gzip, authorization: Bearer ya29.Gl0mBujH07mMLwNgT82zS1UPHvO2mI-i722sRPAloMt_7VhC2fH-DYG4nKxRE4jLM_6-15NPBEG2ZtjAzSz4vHeHNpBEiXHJZiBy615vphO8gdJ4ByxX65Z--8t4j2Y, grpc-trace-bin: AABdNAaFMePVCGCr/ImmLt5LAS7dwboVxNSMAgA=, grpc-timeout: 11930421u] streamDependency=0 weight=16 exclusive=false padding=0 endStream=false \r\n20415 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] OUTBOUND DATA: streamId=3 padding=0 endStream=true length=91 bytes=00000000560a5270726f6a656374732f6a632d70726570726f2d626c75652d636f6c6c61722f737562736372697074696f6e732f6c6f63616c2d6a6f622d6e6f... \r\n20416 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] INBOUND SETTINGS: ack=true \r\n32346 [grpc-default-worker-ELG-1-5] DEBUG i.g.n.s.i.g.n.NettyClientHandler - [id: 0x72c947db, L:/192.168.30.31:44592 - R:pubsub.googleapis.com/172.217.162.10:443] OUTBOUND RST_STREAM: streamId=3 errorCode=8 \r\n89339 [ObjectCleanerThread] DEBUG i.g.n.s.i.n.buffer.PoolThreadCache - Freed 1 thread-local buffer(s) from thread: ObjectCleanerThread \r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3747",
        "number": 3747,
        "title": "Follow these instructions link has no instructions",
        "labels": [
            "good newbie task",
            "type: docs"
        ],
        "state": "closed",
        "body": "On most, perhaps all, of the client READMEs we find:\r\n\r\nYou will need a Google Developers Console project with the Cloud Asset API enabled. Follow these instructions to get your project set up. \r\n\r\nThe link on Follow these instructions goes to: https://cloud.google.com/docs/authentication#preparation\r\n\r\nThe linked page has no instructions. It does not tell the user what to to. It especially does not tell them how to enable the relevant API and doesn't even mention the API console. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3746",
        "number": 3746,
        "title": "Cloud Asset Product documentation link in README points to cloud.google.com",
        "labels": [
            "api: cloudasset",
            "type: docs"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-asset\r\n\r\nThere should be a more specific page."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3745",
        "number": 3745,
        "title": "Dependency status image broken for Cloud Asset",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-asset"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3740",
        "number": 3740,
        "title": "Failing due to HTTP_FORBIDDEN without any log whatsoever",
        "labels": [
            "api: cloudresourcemanager",
            "type: feature request"
        ],
        "state": "open",
        "body": "What is the reasoning behind returning null without any kind of log at all, if an API call fails with 403? The biggest advantage of these new libraries compared to the 'older' com.google.api.* libraries is supposed to be the handier/quicker/more robust usage, but when I encountered a null due to a 403 - that appeared only on GAE as locally it worked just fine -, it took so much more to debug it than it would have, if it would have a single log.info in there.\r\n\r\nIn my current example I called ```com.google.cloud.resourcemanager.ResourceManager.getPolicy(String)```, which returned null. It wasn't hard to find that the try-catch inside ```com.google.cloud.resourcemanager.spi.v1beta1.HttpResourceManagerRpc.getPolicy(String)``` was the culprit.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/626e4d1d183100f242341f54c966ee33e7586ccc/google-cloud-clients/google-cloud-resourcemanager/src/main/java/com/google/cloud/resourcemanager/spi/v1beta1/HttpResourceManagerRpc.java#L252-L266\r\n\r\nIt turns out it returns 403 even if the API is disabled. Which would have been an easy fix as it has a handy, descriptive content actually _(domain -> usageLimits, reason -> accessNotConfigured, message -> Cloud Resource Manager API has not been used in project *** before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/cloudresourcemanager.googleapis.com/overview?project=*** then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.)_... which is completely ignored here, and I had to modify my code and deploy again to actually get this printed out.\r\n\r\nThis pattern is used multiple times in that file. Can't we have an info logging and/or smarter check there instead of just using 'HTTP_FORBIDDEN' equality check?\r\n\r\n(This would have been a PR would I have known the reasoning why was it implemented like this in the first place.)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3739",
        "number": 3739,
        "title": "Listing redacted BigQuery jobs results in an NPE",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "When run without \"bigquery.jobs.listAll\"  permissions on a project   (like \"Viewer\")  that contains other user's jobs this program results in an NPE .   \r\n\r\npackage com.bmenasha;\r\n\r\nimport com.google.cloud.Page;\r\nimport com.google.cloud.bigquery.BigQuery;\r\nimport com.google.cloud.bigquery.BigQueryOptions;\r\nimport com.google.cloud.bigquery.Job;\r\n\r\npublic class Main {\r\n    public static void main(String[] args){\r\n        BigQuery service = BigQueryOptions.builder().projectId(args[0]).build().service();\r\n        Page<Job> jobPage = service.listJobs(BigQuery.JobListOption.allUsers());\r\n        for(Job job: jobPage.values()){\r\n            System.out.println(\"status:\" + job.status());\r\n        }\r\n    }\r\n}\r\n\r\n\r\nException in thread \"main\" java.lang.NullPointerException\r\n\tat com.google.cloud.bigquery.JobConfiguration.fromPb(JobConfiguration.java:132)\r\n\tat com.google.cloud.bigquery.JobInfo$BuilderImpl.<init>(JobInfo.java:166)\r\n\tat com.google.cloud.bigquery.Job.fromPb(Job.java:264)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$19.apply(BigQueryImpl.java:498)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$19.apply(BigQueryImpl.java:495)\r\n\tat com.google.common.collect.Iterators$8.transform(Iterators.java:817)\r\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\r\n\tat com.bmenasha.Main.main(Main.java:16)\r\n\r\n\r\nBigQuery is redacting the metadata from these jobs as described here: \r\n\r\nhttps://cloud.google.com/bigquery/docs/managing-jobs\r\n\r\nThe libraries should be able to parse these redacted job responses and not error when the metadata is missing.\r\nthanks\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3736",
        "number": 3736,
        "title": "Compute v1: NPE in iterateAll()",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Using `\"com.google.cloud\" % \"google-cloud-compute\" % \"0.63.0-alpha\"`, `com.google.api.gax.paging.AbstractPagedListResponse.iterateAll().iterator()` throws `NullPointerException` when there are no results:\r\n\r\nUsing scala console:\r\n\r\n```scala\r\nimport com.google.cloud.compute.v1._\r\nimport com.google.cloud.ServiceOptions\r\n\r\nval zone = ProjectZoneName.of(ServiceOptions.getDefaultProjectId(), \"us-west1-a\")\r\nval instanceClient: InstanceClient = InstanceClient.create()\r\nval diskClient: DiskClient = DiskClient.create()\r\n\r\ninstanceClient.listInstances(ListInstancesHttpRequest.newBuilder()\r\n  .setZone(zone.toString())\r\n  .setFilter(\"labels.app=nonexistant\")\r\n  .build()\r\n).iterateAll().iterator()\r\n\r\ndiskClient.listDisks(ListDisksHttpRequest.newBuilder()\r\n  .setZone(zone.toString())\r\n  .setFilter(s\"labels.app=nonexistant status=READY\")\r\n  .build()\r\n).iterateAll().iterator()\r\n```\r\nthrows\r\n```\r\njava.lang.NullPointerException\r\n  at com.google.api.gax.paging.AbstractPage$AllResourcesIterator.<init>(AbstractPage.java:168)\r\n  at com.google.api.gax.paging.AbstractPage$AllResourcesIterator.<init>(AbstractPage.java:162)\r\n  at com.google.api.gax.paging.AbstractPage$2.iterator(AbstractPage.java:136)\r\n  ... 47 elided\r\n```\r\n\r\nPossibly related to #2973"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3735",
        "number": 3735,
        "title": "Unrecognized http status code: 411 when detaching disk via InstanceClient#detachDiskInstance",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "When trying to detach disk via InstanceClient#detachDiskInstance the operation fails with the stacktrace\r\n```java\r\nSep 26, 2018 10:51:28 PM com.google.common.util.concurrent.AbstractFuture executeListener\r\nSEVERE: RuntimeException while executing runnable com.google.common.util.concurrent.Futures$4@7b8f7c5c with executor MoreExecutors.directExecutor()\r\njava.lang.IllegalArgumentException: Unrecognized http status code: 411\r\n\tat com.google.api.gax.httpjson.HttpJsonStatusCode.httpStatusToStatusCode(HttpJsonStatusCode.java:102)\r\n\tat com.google.api.gax.httpjson.HttpJsonExceptionCallable$ExceptionTransformingFuture.onFailure(HttpJsonExceptionCallable.java:99)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:68)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat com.google.api.core.AbstractApiFuture$InternalSettableFuture.setException(AbstractApiFuture.java:95)\r\n\tat com.google.api.core.AbstractApiFuture.setException(AbstractApiFuture.java:77)\r\n\tat com.google.api.core.SettableApiFuture.setException(SettableApiFuture.java:52)\r\n\tat com.google.api.gax.httpjson.HttpRequestRunnable.run(HttpRequestRunnable.java:145)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3731",
        "number": 3731,
        "title": "Duplicate cloudasset grpc/proto folders",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3730",
        "number": 3730,
        "title": "This BOM is only available starting at version 0.32.0-alpha.",
        "labels": [
            "status: in progress",
            "type: cleanup",
            "type: docs"
        ],
        "state": "closed",
        "body": "We're almost double that now. Let's remove the section from the README that covers these very old versions of google-cloud-java."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3729",
        "number": 3729,
        "title": "Illegal Reflective Access in Java 10",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "When using `[com.google.cloud/google-cloud \"0.47.0-alpha\"]` in Clojure `[org.clojure/clojure \"1.9.0\"]` using `openjdk version \"10.0.2\" 2018-07-17`, when my application starts, I receive the following warnings from the JVM:\r\n```\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by io.grpc.netty.shaded.io.netty.util.internal.ReflectionUtil (file:/usr/local/bin/lrm-logging-service.jar) to constructor java.nio.DirectByteBuffer(long,int)\r\nWARNING: Please consider reporting this to the maintainers of io.grpc.netty.shaded.io.netty.util.internal.ReflectionUtil\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\n```\r\n\r\nThe project producing this error is using the following class imports from the Google Cloud library:\r\n\r\n`com.google.cloud.datastore`: `Key KeyFactory Datastore DatastoreOptions`\r\n`com.google.cloud.logging`: `Logging Logging$WriteOption LoggingOptions LogEntry Payload Payload$JsonPayload`\r\n`com.google.cloud`: `MonitoredResource`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3728",
        "number": 3728,
        "title": "Don't bundle tests in jars",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "I downloaded and unzipped google-cloud-dns-0.63.0-alpha-tests.jar. Here's what I found inside it. We're definitely bundling the actual tests into these jars. We either shouldn't do this (just include mocks and the like) or otherwise not put these in the BOM.\r\n\r\n```\r\n$ jar tvf google-cloud-dns-0.63.0-alpha-tests.jar\r\n     0 Thu Sep 20 16:47:10 EDT 2018 META-INF/\r\n   617 Thu Sep 20 16:47:10 EDT 2018 META-INF/MANIFEST.MF\r\n     0 Thu Sep 20 16:47:10 EDT 2018 com/\r\n     0 Thu Sep 20 16:47:10 EDT 2018 com/google/\r\n     0 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/\r\n     0 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/\r\n     0 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/it/\r\n 19805 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsImplTest.class\r\n  4099 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/ProjectInfoTest.class\r\n 46519 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/it/ITDnsTest.class\r\n  8991 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/SerializationTest.class\r\n  4908 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/RecordSetTest.class\r\n  3820 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsExceptionTest.class\r\n  7528 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/ChangeRequestInfoTest.class\r\n  2639 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest.class\r\n   879 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest$5.class\r\n  3088 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsBatchResultTest.class\r\n  5755 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/ZoneInfoTest.class\r\n 28870 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsBatchTest.class\r\n   672 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest$3.class\r\n   605 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsImplTest$1.class\r\n   672 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest$1.class\r\n   879 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest$6.class\r\n   672 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest$4.class\r\n 15648 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/ZoneTest.class\r\n  8405 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/ChangeRequestTest.class\r\n  1207 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsOptionsTest.class\r\n  6212 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/DnsTest.class\r\n   672 Thu Sep 20 16:47:10 EDT 2018 com/google/cloud/dns/OptionTest$2.class\r\n     0 Thu Sep 20 16:47:10 EDT 2018 META-INF/maven/\r\n     0 Thu Sep 20 16:47:10 EDT 2018 META-INF/maven/com.google.cloud/\r\n     0 Thu Sep 20 16:47:10 EDT 2018 META-INF/maven/com.google.cloud/google-cloud-dns/\r\n  2486 Thu Sep 20 13:30:42 EDT 2018 META-INF/maven/com.google.cloud/google-cloud-dns/pom.xml\r\n   131 Thu Sep 20 16:47:10 EDT 2018 META-INF/maven/com.google.cloud/google-cloud-dns/pom.properties\r\n   246 Thu Sep 20 16:47:10 EDT 2018 META-INF/INDEX.LIST\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3726",
        "number": 3726,
        "title": "PubSub publisher creates threads every few seconds",
        "labels": [],
        "state": "closed",
        "body": "```\r\n\tprivate val projectId = ServiceOptions.getDefaultProjectId\r\n\r\n\tprivate val testTopicName = ProjectTopicName.of(projectId, TEST_TOPIC_NAME)\r\n\tprivate val publisher = Publisher.newBuilder(testTopicName).build()\r\n```\r\nNot sure if it is a bug or some configurations issues but I've created a simple publisher like above and see constantly increasing threads (\"Gax-N\")  every 5-10 seconds. After half of the day, I found 700 threads doing nothing for a few publishers.\r\n\r\nIs something wrong?\r\n\r\nI'm using v1.45.0 (actually I also checked 1.35 too).\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3722",
        "number": 3722,
        "title": "Node-pool response always claims a node-pool has a single accelerator, even when it really has more.",
        "labels": [
            "api: container",
            "type: question"
        ],
        "state": "open",
        "body": "Given a node-pool like this (output from gcloud):\r\n\r\n```yaml\r\nautoscaling:\r\n  enabled: true\r\n  maxNodeCount: 1\r\nconfig:\r\n  accelerators:\r\n  - acceleratorCount: '2'\r\n    acceleratorType: nvidia-tesla-p100\r\n  diskSizeGb: 200\r\n  diskType: pd-standard\r\n  imageType: COS\r\n  labels:\r\n    consumer: batch\r\n  machineType: custom-32-212992\r\n  minCpuPlatform: Automatic\r\n  oauthScopes:\r\n  - [... lots of scopes ... ]\r\n  preemptible: true\r\n  serviceAccount: default\r\ninstanceGroupUrls:\r\n- https://www.googleapis.com/compute/v1/projects/....\r\nmanagement: {}\r\nname: mul-seq2seq-large\r\nstatus: RUNNING\r\nversion: 1.10.7-gke.2\r\n```\r\n(scopes and instanceGroupUris shortened for brevity)\r\n\r\nthen I expect:\r\n```java\r\nNodePool nodepool = clusterManagerClient.getNodePool(projectId, zone, clusterName, \"mul-seq2seq-large\");\r\nSystem.out.println(nodepool.getConfig().getAcceleratorsCount());\r\n```\r\nto return 2 (as there are 2 gpus attached), but the API actually answers 1 ! Calling nodepool.getConfig().getAcceleratorsList() also gives you a list of a single entry with the name of the gpu chosen. I have not tried to have different gpus on a node (if it might have merged them somehow).\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3721",
        "number": 3721,
        "title": "Node-pool always have 1 accelerator in the API-call, while it really has 2.",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3720",
        "number": 3720,
        "title": "PubSub creating lots of thread",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using PubSub with java\r\n\r\n### Actual behabiour\r\nWhen i start application (it contains subscriber code) It creates a lot of thread, so after start within few times server will closed\r\n\r\n### My code for subscriber\r\nProjectSubscriptionName subName = ProjectSubscriptionName.of(CommonUtils.GCLOUD_PROJECT_ID,\r\nSUBSCRIPTION_ID);\r\n\r\n\t\tMessageReceiver receiver = new MessageReceiver() {\r\n\t\t\t@Override\r\n\t\t\tpublic void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n\t\t\t\tString messageString = message.getData().toStringUtf8();\r\n\t\t\t\tSystem.out.println(\"message received : \" + message.getMessageId());\r\n\t\t\t\tconsumer.ack();\r\n\r\n\t\t\t}\r\n\t\t};\r\n\r\n\t\tSubscriber subscriber = null;\r\n\t\ttry {\r\n\t\t\tExecutorProvider executorProvider = InstantiatingExecutorProvider.newBuilder().setExecutorThreadCount(1)\r\n\t\t\t\t\t.build();\r\n\t\t\tsubscriber = Subscriber.newBuilder(subName, receiver)\r\n\t\t\t\t\t.setCredentialsProvider(FixedCredentialsProvider.create(credentials))\r\n\t\t\t\t\t.setExecutorProvider(executorProvider).build();\r\n\r\n\t\t\tsubscriber.startAsync();\r\n\t\t} catch (Exception e) {\r\n\t\t\terrorLog.push(e);\r\n\t\t}"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3716",
        "number": 3716,
        "title": "Bump protobuf to 3.6.1",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "E.g.\r\n\r\n`<protobuf.version>3.6.0</protobuf.version>`\r\n\r\nto\r\n\r\n`<protobuf.version>3.6.1</protobuf.version>`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3715",
        "number": 3715,
        "title": "Document purpose of test-jar and testlib dependencies",
        "labels": [
            "status: in progress",
            "type: docs"
        ],
        "state": "closed",
        "body": "These aren't standard in Maven and aren't obvious from the code, at least to me. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3712",
        "number": 3712,
        "title": "Setup and fix Java 11 tests",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": "Java 11 is an LTS version scheduled for GA 2018-09-25.\r\n\r\nAlso, we need to fix the build on Java 11."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3711",
        "number": 3711,
        "title": "Setup synth scripts for generating clients",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": "This will enable us to automate the regeneration process outside of the release process."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3708",
        "number": 3708,
        "title": "Don't include multiple versions of same API in BOM",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "There are many cases of this. E.g.\r\n\r\n```\r\n      <dependency>\r\n        <groupId>com.google.api.grpc</groupId>\r\n        <artifactId>proto-google-cloud-tasks-v2beta2</artifactId>\r\n        <version>0.27.1-SNAPSHOT</version><!-- {x-version-update:proto-google-cloud-tasks-v2beta2:current} -->\r\n      </dependency>\r\n      <dependency>\r\n        <groupId>com.google.api.grpc</groupId>\r\n        <artifactId>grpc-google-cloud-tasks-v2beta2</artifactId>\r\n        <version>0.27.1-SNAPSHOT</version><!-- {x-version-update:grpc-google-cloud-tasks-v2beta2:current} -->\r\n      </dependency>\r\n      <dependency>\r\n        <groupId>com.google.api.grpc</groupId>\r\n        <artifactId>proto-google-cloud-tasks-v2beta3</artifactId>\r\n        <version>0.27.1-SNAPSHOT</version><!-- {x-version-update:proto-google-cloud-tasks-v2beta2:current} -->\r\n      </dependency>\r\n      <dependency>\r\n        <groupId>com.google.api.grpc</groupId>\r\n        <artifactId>grpc-google-cloud-tasks-v2beta3</artifactId>\r\n        <version>0.27.1-SNAPSHOT</version><!-- {x-version-update:grpc-google-cloud-tasks-v2beta2:current} -->\r\n      </dependency>\r\n```\r\n\r\nDo we really want proto-google-cloud-tasks-v2beta2 and proto-google-cloud-tasks-v2beta3? Shouldn't we just pick the latest?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3707",
        "number": 3707,
        "title": "test-jar in google-cloud-bom",
        "labels": [
            "status: in progress",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "The BOM contains many dependencies like this one:\r\n\r\n```\r\n      <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-storage</artifactId>\r\n        <version>1.44.1-SNAPSHOT</version><!-- {x-version-update:google-cloud-storage:current} -->\r\n        <type>test-jar</type>\r\n      </dependency>\r\n```\r\n\r\nIs this really something we want in the BOM?  I can't imagine clients should be depending on our tests. Can we take these out?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3701",
        "number": 3701,
        "title": "DialogFlow performance",
        "labels": [
            "api: dialogflow",
            "performance",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "Hi, I am trying to build a service that detects intents from multiple Dialogflow projects, so I have to create a SessionClient object every time my service is invoked [like in this example:]( https://github.com/GoogleCloudPlatform/java-docs-samples/blob/master/dialogflow/cloud-client/src/main/java/com/example/dialogflow/DetectIntentTexts.java). This operation is very time consuming (elaboration time is close to 2 seconds), but I noticed that if I re-use the same SessionClient for detecting 2 different intents, the second request is way much faster than the first (less than 500ms). My question is: is there a way to store the authentication data (e.g using Redis), so that I can speed up the detectIntent call at every invocation? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3693",
        "number": 3693,
        "title": "*~*~*~ Channel ManagedChannelImpl{logId=1, target=logging.googleapis.com:443} was not shutdown properly!!! ~*~*~*",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "I got this error message when starting up java application and I use library of **'google-cloud-logging-logback', version 0.62.0-alpha.**\r\n\r\n```\r\n*~*~*~ Channel ManagedChannelImpl{logId=1, target=logging.googleapis.com:443} was not shutdown properly!!! ~*~*~*\r\n    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.\r\n```\r\n\r\nFor log, i did add appender in **logback.xml** follow\r\n\r\n```xml\r\n<appender name=\"CLOUD\" class=\"com.google.cloud.logging.logback.LoggingAppender\">\r\n    <!-- Optional : filter logs at or above a level -->\r\n    <filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\">\r\n      <level>INFO</level>\r\n    </filter>\r\n    <log>application.log</log> <!-- Optional : default java.log -->\r\n    <enhancer>com.example.enhancers.TestLoggingEnhancer</enhancer> <!-- Optional -->\r\n    <enhancer>com.example.enhancers.AnotherEnhancer</enhancer> <!-- Optional -->\r\n    <flushLevel>WARN</flushLevel> <!-- Optional : default ERROR -->\r\n  </appender>\r\n```\r\nif no appender in **logbak.xml**, there is no error message\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3687",
        "number": 3687,
        "title": "Publisher.shutdown should return promptly",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "Current implementation waits for all messages to either succeed or fail before returning.\r\n\r\nThis will change the behavior of `shutdown`. So we should wait for `awaitTermination` to bake in for a while before doing this."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3683",
        "number": 3683,
        "title": "Possibly cycle in the dependency tree",
        "labels": [
            "dependencies",
            "type: process"
        ],
        "state": "open",
        "body": "Still investigating so this may be a false report, and if it's not it's probably not google-cloud-java's fault but I'm investigating a possible cycle in the dependency tree that starts like this:\r\n\r\n```\r\ncom.google.cloud:google-cloud-logging-logback:0.59.0-alpha / ch.qos.logback:logback-classic:1.2.3 / org.codehaus.groovy:groovy-all:2.4.0 / com.thoughtworks.xstream:xstream:1.4.7 / dom4j:dom4j:1.6.1 / jaxen:jaxen:1.1-beta-6 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 / dom4j:dom4j:1.5.2 / jaxen:jaxen:1.1-beta-4 /\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3682",
        "number": 3682,
        "title": "Can I use this library to access firestore as a firebase auth user? ",
        "labels": [
            "api: firestore",
            "type: question"
        ],
        "state": "closed",
        "body": "It appears google-auth-library-java supports 3LO so what is the blocker that prevents google-cloud-java being used in user environments (desktop, not mobile)?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3680",
        "number": 3680,
        "title": "Does google-cloud-contrib belong in the google-cloud-java BOM?",
        "labels": [
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "```\r\n      <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-contrib</artifactId>\r\n        <version>0.62.1-alpha-SNAPSHOT</version><!-- {x-version-update:google-cloud-contrib:current} -->\r\n      </dependency>\r\n```\r\n\r\n1. This is itself a BOM (type pom) and has no jar.\r\n2. Presumably it's contributed code? What's actually in here? Is this something we support?\r\n3. This is pre-release alpha code.\r\n4. If this should be included, I think it still needs to have its type set to pom for this to work. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3678",
        "number": 3678,
        "title": "Getting broken pipe exception when storage upload starts",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "We are trying to upload some blob to cloud storage and most of the cases it works, but sometimes we get Broken pipe exception. \r\n\r\nHere is the full stack trace:\r\n\r\n```\r\ncom.google.cloud.storage.StorageException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe (Write failed)\r\nat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220)\r\nat com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:292)\r\nat com.google.cloud.storage.StorageImpl.create(StorageImpl.java:148)\r\nat com.google.cloud.storage.Bucket.create(Bucket.java:937)\r\nat org.sonatype.nexus.blobstore.gcloud.internal.GoogleCloudBlobStore.lambda$0(GoogleCloudBlobStore.java:158)\r\nat org.sonatype.nexus.blobstore.gcloud.internal.GoogleCloudBlobStore.createInternal(GoogleCloudBlobStore.java:402)\r\nat org.sonatype.nexus.blobstore.gcloud.internal.GoogleCloudBlobStore.create(GoogleCloudBlobStore.java:155)\r\nat org.sonatype.nexus.common.stateguard.MethodInvocationAction.run(MethodInvocationAction.java:39)\r\nat org.sonatype.nexus.common.stateguard.StateGuard$GuardImpl.run(StateGuard.java:270)\r\nat org.sonatype.nexus.common.stateguard.GuardedInterceptor.invoke(GuardedInterceptor.java:53)\r\nat org.sonatype.nexus.repository.storage.StorageFacetImpl.createTempBlob(StorageFacetImpl.java:215)\r\nat org.sonatype.nexus.repository.storage.StorageFacetImpl.createTempBlob(StorageFacetImpl.java:228)\r\nat org.sonatype.nexus.repository.maven.internal.MavenFacetImpl.put(MavenFacetImpl.java:200)\r\nat org.sonatype.nexus.repository.maven.internal.hosted.HostedHandler.doPut(HostedHandler.java:92)\r\nat org.sonatype.nexus.repository.maven.internal.hosted.HostedHandler.handle(HostedHandler.java:64)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.storage.UnitOfWorkHandler.handle(UnitOfWorkHandler.java:39)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.view.handlers.ContentHeadersHandler.handle(ContentHeadersHandler.java:44)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.maven.internal.VersionPolicyHandler.handle(VersionPolicyHandler.java:61)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.http.PartialFetchHandler.handle(PartialFetchHandler.java:59)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.view.handlers.ConditionalRequestHandler.handle(ConditionalRequestHandler.java:72)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.assetdownloadcount.internal.AssetDownloadCountContributedHandler.handle(AssetDownloadCountContributedHandler.java:53)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat com.sonatype.nexus.clm.internal.QuarantineContributedHandler.handle(QuarantineContributedHandler.java:69)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.view.handlers.HandlerContributor.handle(HandlerContributor.java:67)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.view.handlers.ExceptionHandler.handle(ExceptionHandler.java:44)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.security.SecurityHandler.handle(SecurityHandler.java:52)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.view.handlers.TimingHandler.handle(TimingHandler.java:46)\r\nat org.sonatype.nexus.repository.view.Context.proceed(Context.java:80)\r\nat org.sonatype.nexus.repository.view.Context.start(Context.java:114)\r\nat org.sonatype.nexus.repository.view.Router.dispatch(Router.java:64)\r\nat org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:52)\r\nat org.sonatype.nexus.repository.view.ConfigurableViewFacet.dispatch(ConfigurableViewFacet.java:43)\r\nat org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.dispatchAndSend(ViewServlet.java:210)\r\nat org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.doService(ViewServlet.java:172)\r\nat org.sonatype.nexus.repository.httpbridge.internal.ViewServlet.service(ViewServlet.java:126)\r\nat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\nat com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:286)\r\nat com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:276)\r\nat com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:181)\r\nat com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)\r\nat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)\r\nat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118)\r\nat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\r\nat org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\r\nat org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\r\nat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\r\nat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\r\nat org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\r\nat org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\r\nat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\r\nat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\r\nat org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\r\nat org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\r\nat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\r\nat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\r\nat org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)\r\nat org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85)\r\nat org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)\r\nat org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)\r\nat org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)\r\nat org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)\r\nat org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)\r\nat org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101)\r\nat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat org.sonatype.nexus.repository.httpbridge.internal.ExhaustRequestFilter.doFilter(ExhaustRequestFilter.java:80)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:108)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:68)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat org.sonatype.nexus.internal.web.HeaderPatternFilter.doFilter(HeaderPatternFilter.java:98)\r\nat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\nat com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104)\r\nat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:135)\r\nat org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73)\r\nat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\r\nat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\r\nat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\r\nat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\r\nat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\r\nat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\r\nat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\r\nat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)\r\nat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\r\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\nat com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175)\r\nat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\r\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\r\nat org.eclipse.jetty.server.Server.handle(Server.java:531)\r\nat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)\r\nat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\r\nat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)\r\nat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)\r\nat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\r\nat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\r\nat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\r\nat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)\r\nat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)\r\nat java.lang.Thread.run(Thread.java:748)\r\nCaused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe (Write failed)\r\nat sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1551)\r\nat sun.security.ssl.SSLSocketImpl.checkWrite(SSLSocketImpl.java:1563)\r\nat sun.security.ssl.AppOutputStream.write(AppOutputStream.java:71)\r\nat org.apache.http.impl.io.AbstractSessionOutputBuffer.flushBuffer(AbstractSessionOutputBuffer.java:160)\r\nat org.apache.http.impl.io.AbstractSessionOutputBuffer.write(AbstractSessionOutputBuffer.java:182)\r\nat org.apache.http.impl.io.ChunkedOutputStream.flushCache(ChunkedOutputStream.java:109)\r\nat org.apache.http.impl.io.ChunkedOutputStream.finish(ChunkedOutputStream.java:141)\r\nat org.apache.http.impl.io.ChunkedOutputStream.close(ChunkedOutputStream.java:202)\r\nat org.apache.http.impl.entity.EntitySerializer.serialize(EntitySerializer.java:119)\r\nat org.apache.http.impl.AbstractHttpClientConnection.sendRequestEntity(AbstractHttpClientConnection.java:266)\r\nat org.apache.http.impl.conn.ManagedClientConnectionImpl.sendRequestEntity(ManagedClientConnectionImpl.java:214)\r\nat org.apache.http.protocol.HttpRequestExecutor.doSendRequest(HttpRequestExecutor.java:238)\r\nat org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:123)\r\nat org.apache.http.impl.client.DefaultRequestDirector.tryExecute(DefaultRequestDirector.java:684)\r\nat org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:486)\r\nat org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835)\r\nat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\r\nat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)\r\nat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\r\nat com.google.api.client.http.apache.ApacheHttpRequest.execute(ApacheHttpRequest.java:65)\r\nat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\nat com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequestWithoutGZip(MediaHttpUploader.java:545)\r\nat com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequest(MediaHttpUploader.java:562)\r\nat com.google.api.client.googleapis.media.MediaHttpUploader.directUpload(MediaHttpUploader.java:360)\r\nat com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:334)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\nat com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:289)\r\n```\r\n\r\nMaybe it is related to the following issue: GoogleCloudPlatform/google-cloud-java#3410\r\n\r\nAny idea how to solve it?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3668",
        "number": 3668,
        "title": "Exception in thread \"main\" java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured",
        "labels": [],
        "state": "closed",
        "body": "I am trying to use grpc java to connect to a service.\r\n\r\nJava Version: 1.8\r\nGradle dependencies: \r\n```\r\ndependencies {\r\n\r\n    //GRPC\r\n    compile 'io.grpc:grpc-netty:1.1.2'\r\n    compile 'io.grpc:grpc-protobuf:1.1.2'\r\n    compile 'io.grpc:grpc-stub:1.1.2'\r\n    compile 'io.netty:netty-tcnative-boringssl-static:1.1.33.Fork26'\r\n```\r\n\r\nFull Error log:\r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:159)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:136)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:124)\r\n\tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:94)\r\n\tat com.ibm.watson.sentimentanalysis.fe.service.pipeline.customization.TestGrpcTrain.getSslContext(TestGrpcTrain.java:158)\r\n\tat com.ibm.watson.sentimentanalysis.fe.service.pipeline.customization.TestGrpcTrain.main(TestGrpcTrain.java:143)\r\n```\r\nat this line in my java grpc client code:\r\n\r\n```\r\npublic static SslContext getSslContext(File certFile) throws SSLException {\r\n        return GrpcSslContexts.forClient()\r\n                .trustManager(certFile)\r\n                .build();\r\n    }\r\n```\r\n\r\nHere's my gradle dependency tree:\r\nhttps://gist.github.com/tripathysa/7966ddb1e3c6751c19e7b9777a5a0419\r\n\r\nTried the troubleshooting guide: Used the same combination of \r\n\r\ngrpc-netty version | netty-handler version | netty-tcnative-boringssl-static version as mentioned here:\r\nhttps://github.com/grpc/grpc-java/blob/master/SECURITY.md#troubleshooting\r\n\r\nBut still getting the error. Any help would be appreciated.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3666",
        "number": 3666,
        "title": "Spanner client lib read-only context via TransactionManager",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hello, we were using the new explicit rollback and commit control via the TransactionManager but noticed only TransactionContext is provided. Is there a way to get a read-only context that doesn't lock the tables? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3665",
        "number": 3665,
        "title": "No route found : google dialogflow api ",
        "labels": [
            "api: dialogflow",
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "hey , when i am trying out google dialogue flow java example libraries , i am getting below issue . Ay pointers?\r\n\r\nCaused by: io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: dialogflow.googleapis.com/2607:f8b0:4002:c06:0:0:0:5f:443"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3663",
        "number": 3663,
        "title": "exception:  \"java.lang.NoSuchMethodError: com.google.api.services.bigquery.model.JobStatistics2.getTotalPartitionsProcessed()Ljava/lang/Long;",
        "labels": [
            "api: bigquery",
            "dependencies",
            "triage me"
        ],
        "state": "closed",
        "body": "When I tried to create a query from an sql command this excption is thrown \r\n```\r\nexception:  \"java.lang.NoSuchMethodError: com.google.api.services.bigquery.model.JobStatistics2.getTotalPartitionsProcessed()Ljava/lang/Long;\r\n\tat com.google.cloud.bigquery.JobStatistics$QueryStatistics$Builder.<init>(JobStatistics.java:432)\r\n\tat com.google.cloud.bigquery.JobStatistics$QueryStatistics$Builder.<init>(JobStatistics.java:399)\r\n\tat com.google.cloud.bigquery.JobStatistics$QueryStatistics.fromPb(JobStatistics.java:745)\r\n\tat com.google.cloud.bigquery.JobStatistics.fromPb(JobStatistics.java:856)\r\n\tat com.google.cloud.bigquery.JobInfo$BuilderImpl.<init>(JobInfo.java:180)\r\n\tat com.google.cloud.bigquery.Job.fromPb(Job.java:463)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:210)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:187)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:661)`\r\n```\r\n```\r\nBigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\nString query = \"SELECT session_id_hash FROM `\" + PROJECT_ID + \".metadata.session_info`\";\r\nQueryJobConfiguration queryConfig = QueryJobConfiguration.newBuilder(query).build();\r\n for (FieldValueList row : bigquery.query(queryConfig).iterateAll()){  // the line that throws this exception \r\n\t            for (FieldValue val : row) {\r\n               }\r\n       } \r\n\r\n\r\n```\r\nthe dependency tree looks like this:\r\n\r\n```\r\nmaven-dependency-plugin:3.0.1:tree (default-cli) @ pipelines-java ---\r\n[INFO] dataflow-stream-ingestion-test:pipelines-java:jar:0.1-SNAPSHOT\r\n[INFO] +- org.apache.beam:beam-sdks-java-core:jar:2.6.0:compile\r\n[INFO] |  +- org.xerial.snappy:snappy-java:jar:1.1.4:compile\r\n[INFO] |  \\- org.tukaani:xz:jar:1.5:compile\r\n[INFO] +- org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.6.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:jar:2.6.0:compile\r\n[INFO] |  |  +- com.google.cloud.bigdataoss:gcsio:jar:1.4.5:compile\r\n[INFO] |  |  \\- com.google.apis:google-api-services-cloudresourcemanager:jar:v1-rev477-1.23.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-protobuf:jar:2.6.0:compile\r\n[INFO] |  +- io.grpc:grpc-core:jar:1.2.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-context:jar:1.2.0:compile\r\n[INFO] |  |  \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n[INFO] |  +- com.google.api:gax-grpc:jar:0.20.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-grpc:jar:1.2.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-pubsub:jar:v1-rev382-1.23.0:compile\r\n[INFO] |  +- com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.cloud.bigdataoss:util:jar:1.4.5:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-java6:jar:1.20.0:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-jackson2:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.oauth-client:google-oauth-client-java6:jar:1.20.0:compile\r\n[INFO] |  +- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.4.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.http-client:google-http-client-jackson:jar:1.20.0:compile\r\n[INFO] |  +- io.grpc:grpc-auth:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-netty:jar:1.2.0:compile\r\n[INFO] |  |  +- io.netty:netty-codec-http2:jar:4.1.8.Final:compile (version selected from constraint [4.1.8.Final,4.1.8.Final])\r\n[INFO] |  |  |  \\- io.netty:netty-codec-http:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-handler-proxy:jar:4.1.8.Final:compile\r\n[INFO] |  |     \\- io.netty:netty-codec-socks:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.netty:netty-handler:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-buffer:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-common:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-transport:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-resolver:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-codec:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.grpc:grpc-stub:jar:1.2.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-spanner:jar:0.20.0b-beta:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-v1:jar:0.1.11b:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.11b:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  |  |  \\- com.google.api.grpc:proto-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  |  \\- junit:junit:jar:4.12:compile\r\n[INFO] |  |     \\- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0:compile\r\n[INFO] |  |  +- commons-logging:commons-logging:jar:1.2:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-appengine:jar:0.7.0:compile\r\n[INFO] |  |  +- io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0:compile\r\n[INFO] |  |  \\- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile\r\n[INFO] |  +- com.google.http-client:google-http-client:jar:1.23.0:compile\r\n[INFO] |  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO] |  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO] |  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-jackson2:jar:1.23.0:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-credentials:jar:0.7.1:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.7.1:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:jar:0.1.9:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n[INFO] |  +- io.grpc:grpc-all:jar:1.2.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-okhttp:jar:1.2.0:compile\r\n[INFO] |  |  |  +- com.squareup.okhttp:okhttp:jar:2.5.0:compile\r\n[INFO] |  |  |  \\- com.squareup.okio:okio:jar:1.6.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf-nano:jar:1.2.0:compile\r\n[INFO] |  |     \\- com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\r\n[INFO] |  \\- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26:compile\r\n[INFO] +- org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.6.0:compile\r\n[INFO] |  +- org.apache.beam:beam-model-pipeline:jar:2.6.0:compile\r\n[INFO] |  +- org.apache.beam:beam-runners-core-construction-java:jar:2.6.0:compile\r\n[INFO] |  |  \\- org.apache.beam:beam-model-job-management:jar:2.6.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-dataflow:jar:v1b3-rev221-1.23.0:compile\r\n[INFO] |  \\- com.google.apis:google-api-services-clouddebugger:jar:v2-rev233-1.23.0:compile\r\n[INFO] +- org.apache.beam:beam-runners-direct-java:jar:2.6.0:compile\r\n[INFO] |  \\- args4j:args4j:jar:2.33:compile\r\n[INFO] +- com.google.cloud:google-cloud-storage:jar:1.38.0:compile\r\n[INFO] |  \\- com.google.cloud:google-cloud-core-http:jar:1.38.0:compile\r\n[INFO] |     +- com.google.http-client:google-http-client-appengine:jar:1.23.0:compile\r\n[INFO] |     +- com.google.api:gax-httpjson:jar:0.46.0:compile\r\n[INFO] |     +- io.opencensus:opencensus-api:jar:0.15.0:compile\r\n[INFO] |     \\- io.opencensus:opencensus-contrib-http-util:jar:0.15.0:compile\r\n[INFO] +- com.google.api:api-common:jar:1.1.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-core:jar:1.38.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-spanner:jar:0.20.0b-beta:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.12.0:compile\r\n[INFO] +- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n[INFO] +- joda-time:joda-time:jar:2.4:compile\r\n[INFO] +- com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0:compile\r\n[INFO] |  \\- com.google.api.grpc:grpc-google-common-protos:jar:0.1.0:compile\r\n[INFO] +- com.google.apis:google-api-services-bigquery:jar:v2-rev374-1.23.0:compile\r\n[INFO] +- com.google.protobuf:protobuf-java:jar:3.4.0:compile\r\n[INFO] +- com.google.protobuf:protobuf-java-util:jar:3.3.1:compile\r\n[INFO] +- com.google.code.findbugs:jsr305:jar:3.0.2:compile\r\n[INFO] +- com.google.guava:guava:jar:26.0-jre:compile\r\n[INFO] |  +- org.checkerframework:checker-qual:jar:2.5.2:compile\r\n[INFO] |  +- com.google.errorprone:error_prone_annotations:jar:2.1.3:compile\r\n[INFO] |  +- com.google.j2objc:j2objc-annotations:jar:1.1:compile\r\n[INFO] |  \\- org.codehaus.mojo:animal-sniffer-annotations:jar:1.14:compile\r\n[INFO] +- com.google.api-client:google-api-client:jar:1.23.0:compile\r\n[INFO] |  +- com.google.oauth-client:google-oauth-client:jar:1.23.0:compile\r\n[INFO] |  \\- com.google.guava:guava-jdk5:jar:17.0:compile\r\n[INFO] +- org.json:json:jar:20160810:compile\r\n[INFO] +- com.google.code.gson:gson:jar:2.7:compile\r\n[INFO] +- org.apache.commons:commons-compress:jar:1.8.1:compile\r\n[INFO] +- org.apache.commons:commons-lang3:jar:3.8:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-core:jar:2.9.4:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.4:compile\r\n[INFO] +- com.google.cloud:google-cloud-bigquery:jar:1.35.0:compile\r\n[INFO] |  \\- com.google.auto.value:auto-value:jar:1.4:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.4:compile\r\n[INFO] +- org.apache.avro:avro:jar:1.8.2:compile\r\n[INFO] |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile\r\n[INFO] |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile\r\n[INFO] |  \\- com.thoughtworks.paranamer:paranamer:jar:2.7:compile\r\n[INFO] +- com.google.api:gax:jar:1.30.0:compile\r\n[INFO] |  \\- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO] +- com.googlecode.json-simple:json-simple:jar:1.1:compile\r\n[INFO] \\- com.google.apis:google-api-services-storage:jar:v1-rev124-1.23.0:compile\r\n```\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3655",
        "number": 3655,
        "title": "Remove use of vulnerable legacy dependency: Jackson 1.x",
        "labels": [
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "More information:\r\n- https://www.sourceclear.com/vulnerability-database/libraries/230\r\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-7489\r\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-17485\r\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-15095\r\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-7525\r\n- https://github.com/FasterXML/jackson-docs/wiki/Presentation-Jackson-2.0\r\n\r\nThere is already an alternative implementation of JsonFactory for Jackson 2.x in `com.google.api.client.json.jackson2.JacksonFactory`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3649",
        "number": 3649,
        "title": "Java 1.7 Dependency Missing on Fedora 28",
        "labels": [
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I tried installing the google-cloud-sdk-app-engine-java package on Fedora 28, but one of the dependencies are java-1.7.0-openjdk-devel which is missing because it is no longer supported. The output I have is below.\r\n\r\n```\r\n$ sudo dnf install google-cloud-sdk-app-engine-java.noarch\r\nLast metadata expiration check: 0:32:36 ago on Thu 06 Sep 2018 11:33:02 AM EDT.\r\nError: \r\n Problem: conflicting requests\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-195.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-196.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-197.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-198.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-199.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-200.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-201.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-202.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-203.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-204.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-206.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-207.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-208.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-208.0.1-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-208.0.2-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-209.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-210.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-211.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-212.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-213.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-214.0.0-1.noarch\r\n  - nothing provides java-1.7.0-openjdk-devel needed by google-cloud-sdk-app-engine-java-215.0.0-1.noarch\r\n```\r\n\r\nIs there any possibility of supporting openjdk 1.8?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3648",
        "number": 3648,
        "title": "PubSub runs into `java.lang.RuntimeException: ManagedChannel allocation site` when a new publisher is created",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "open",
        "body": "Hi!\r\n\r\nWe've currently received around 100-200 PubSub related issues when a PubSub publisher is created with the following stacktrace:\r\n```\r\nio.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue: *~*~*~ Channel ManagedChannelImpl{logId=4613, target=pubsub.googleapis.com:443} was not shutdown properly!!! ~*~*~* (ManagedChannelOrphanWrapper.java:163)\r\n    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.\r\njava.lang.RuntimeException: ManagedChannel allocation site\r\n\tat io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:103)\r\n\tat io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)\r\n\tat io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:410)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:206)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:162)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:149)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:151)\r\n\tat com.google.cloud.pubsub.v1.stub.GrpcPublisherStub.create(GrpcPublisherStub.java:161)\r\n\tat com.google.cloud.pubsub.v1.Publisher.<init>(Publisher.java:154)\r\n\tat com.google.cloud.pubsub.v1.Publisher.<init>(Publisher.java:83)\r\n\tat com.google.cloud.pubsub.v1.Publisher$Builder.build(Publisher.java:607)\r\n```\r\n\r\nWe are using PubSub library v `1.40.0`. And here is how we create publishers:\r\n```\r\nPublisher createPublisher(ProjectTopicName topicName) {\r\n        try {\r\n            Publisher publisher = Publisher.newBuilder(topicName)\r\n                                           .build();\r\n            return publisher;\r\n        } catch (IOException e) {\r\n            String errorMessage = format(\"Cannot create a publisher for topic %s\", topicName);\r\n            throw new IllegalStateException(errorMessage, e);\r\n        }\r\n    }\r\n```\r\n\r\nAny thoughts or suggestions? By the way, we are running on AppEngine Standard with Java 8. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3646",
        "number": 3646,
        "title": "PubSub subscriber closes connection but remains running when messages are not acked/nacked",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I have a suscriber which receives messages and uses the data to call an api. I had an issue with my api which left the connection hanging, and as such the subscription never acked/nacked the message. At this point, after a couple of minutes, the subscriber eventually closes its connection and the backlog begins to climb - when I patched the api to resolve the issue, the subscriber didn't process any old or new messages; however, when I restarted the application and create a new subscriber than the entire backlog is processed. \r\n\r\nI can solve the issue in my api, and add some timeout logic to my receiver to stop this from occurring in the first place - but I am more interested in figuring out how to fail gracefully in an event like this where the subscriber is hanging. I have some logic in my application which periodically polls the subscriber to check that it is in a running state and restarts (stopAsync() + create a new subscription) if not. I can easily recreate this locally by adding a long delay to my API, and when I do so I notice again that the subscriber stops receiving any messages (I also checked the netstats and saw that there were no open connections to pubsub) - yet it still claims to be in a running state. Ideally my program would be able to identify that its not running and create a new subscriber (perhaps with some backoff), such that if I remove the delay in the api it would be automatically resolved without requiring me to manually restart the application.\r\n\r\nIs there some way to detect that the subscriber is hanging? Is that the intended behavior for a subscriber when acks/nacks are delayed?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3637",
        "number": 3637,
        "title": "Bigtable RowMutation should allow passing of a Mutation",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "closed",
        "body": "While looking at [PutAdapter](https://github.com/GoogleCloudPlatform/cloud-bigtable-client/blob/master/bigtable-client-core-parent/bigtable-hbase/src/main/java/com/google/cloud/bigtable/hbase/adapters/PutAdapter.java), I realized that I'd like to create `Mutation` objects, and then later choose to create either a `RowMutation` or a `BulkMutation` depending on context.  `RowMutation` needs a construction method that takes a `Mutation` (`BulkMutation` already has this).\r\n\r\nAlso, it would be great if we could pass in a `TableName` object instead of constructing one every time."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3636",
        "number": 3636,
        "title": "BigtableTableAdminClient missing method to check if table exists",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "closed",
        "body": "BigtableTableAdminClient missing method to check if table exists"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3635",
        "number": 3635,
        "title": "BigtableDataClient is missing sync methods",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Add below sync method in BigtableDataClient.\r\n\r\n- [ ] readRow\r\n- [ ] readRows\r\n- [ ] sampleRowKeys\r\n- [ ] mutateRow\r\n- [ ] bulkMutateRows\r\n- [ ] checkAndMutateRow\r\n- [ ] readModifyWriteRow"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3634",
        "number": 3634,
        "title": "BigtableTableAdminSettings is missing credential provider options ",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "open",
        "body": "BigtableTableAdminSettings dont have option to set CredentialProvider. As of now to set credentialProvider we need to get stubSettings and set in that. Its Better to have this as setter in BigtableTableAdminSettings."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3632",
        "number": 3632,
        "title": "testLoggingHandler fails with error expected:<g[lobal]> but was:<g[ce_instance]>",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "URL https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-logging\r\n\r\n-------------------------------------------------------\r\n T E S T S\r\n-------------------------------------------------------\r\nRunning com.google.cloud.logging.it.ITLoggingTest\r\nSep 01, 2018 12:36:24 AM com.google.cloud.logging.BaseSystemTest testLoggingHandler\r\nINFO: Message\r\nSep 01, 2018 12:36:40 AM com.google.cloud.logging.BaseSystemTest testSyncLoggingHandler\r\nWARNING: Message\r\nTests run: 11, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 21.369 sec <<< FAILURE! - in com.google.cloud.logging.it.ITLoggingTest\r\ntestLoggingHandler(com.google.cloud.logging.it.ITLoggingTest)  Time elapsed: 5.036 sec  <<< FAILURE!\r\norg.junit.ComparisonFailure: expected:<g[lobal]> but was:<g[ce_instance]>\r\n\r\n\r\nResults :\r\n\r\nFailed tests: \r\n  ITLoggingTest>BaseSystemTest.testLoggingHandler:315 expected:<g[lobal]> but was:<g[ce_instance]>\r\n\r\nTests run: 11, Failures: 1, Errors: 0, Skipped: 0\r\n\r\n[INFO] \r\n[INFO] --- maven-failsafe-plugin:2.19.1:verify (default) @ google-cloud-logging ---\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 44.709 s\r\n[INFO] Finished at: 2018-09-01T00:36:44+00:00\r\n[INFO] Final Memory: 31M/86M\r\n[INFO] ------------------------------------------------------------------------"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3629",
        "number": 3629,
        "title": "How to access/set 'beta' properties on a resource",
        "labels": [
            "api: compute",
            "type: feature request"
        ],
        "state": "open",
        "body": "I'm attempting to use the instance group manager API but hit a snag: the properties I want to use are in the 'beta' section. Notably it's the health check.\r\n\r\nhttps://cloud.google.com/sdk/gcloud/reference/compute/instance-groups/managed/create\r\nhttps://cloud.google.com/sdk/gcloud/reference/beta/compute/instance-groups/managed/create\r\n\r\nIs there any way to get access to this via the client currently (0.60.0-alpha)? Or do things need to get regenerated?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3627",
        "number": 3627,
        "title": "Error adding google-cloud-storage to new project",
        "labels": [
            "android",
            "type: question"
        ],
        "state": "closed",
        "body": "Adding \r\n`implementation 'com.google.cloud:google-cloud-storage:1.42.0'`\r\n\r\nto an empty Android Studio project compiles ok, but when pressing play I get the next error:\r\n\r\n> More than one file was found with OS independent path 'META-INF/DEPENDENCIES'\r\n\r\nI'm I missing anything here?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3626",
        "number": 3626,
        "title": "Not able to download the file GCS",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I have established connection with GCS but i recieve this error when  i try to download an object.\r\n\r\n\r\njava.io.FileNotFoundException: C:\\Users\\hemantp\\Downloads (Access is denied)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat com.trial.cloudstorage.HelloAppEngine.doGet(HelloAppEngine.java:60)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n\tat com.google.appengine.tools.development.ResponseRewriterFilter.doFilter(ResponseRewriterFilter.java:134)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.HeaderVerificationFilter.doFilter(HeaderVerificationFilter.java:34)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:63)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.jetty9.StaticFileFilter.doFilter(StaticFileFilter.java:123)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectRequest(DevAppServerModulesFilter.java:366)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectModuleRequest(DevAppServerModulesFilter.java:349)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doFilter(DevAppServerModulesFilter.java:116)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.DevAppServerRequestLogFilter.doFilter(DevAppServerRequestLogFilter.java:44)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:524)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n\tat com.google.appengine.tools.development.jetty9.DevAppEngineWebAppContext.doScope(DevAppEngineWebAppContext.java:94)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat com.google.appengine.tools.development.jetty9.JettyContainerService$ApiProxyHandler.handle(JettyContainerService.java:601)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:534)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\r\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3621",
        "number": 3621,
        "title": "Creating ML versions fails while using a correct SCIKIT trained model",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "I created a trained  scikit trained model and it works fine locally. However, when I create a new version in my model, it throws the below error:\r\nIn google console:-\r\nCommand:\r\ngcloud ml-engine versions create $VERSION_NAME       --model $MODEL_NAME --origin $MODEL_DIR       --runtime-version=1.9 --framework $FRAMEWORK \r\n      --python-version=3.5\r\n\r\nERROR:\r\nCreating version (this might take a few minutes)......failed.\r\nERROR: (gcloud.ml-engine.versions.create) Bad model detected with error:  \"Failed to load model: Invalid model type detected: builtins.int. Please make sure the model file is an exported sklearn model or pipeline. (Error code: 0)\"\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3618",
        "number": 3618,
        "title": "DNS system test is failing",
        "labels": [
            "api: dns",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "See https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/11146 for sample failure log\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3617",
        "number": 3617,
        "title": "Notification ITSystem test is failing",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "See https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/11152 for sample failure."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3616",
        "number": 3616,
        "title": "How to specify Spanner connect timeout?",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "If the client has some kind of network issue connecting to Spanner, it seems to hang indefinitely. Is there a way to specify the timeout? I don't see anything in `SpannerOptions`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3615",
        "number": 3615,
        "title": "Java Logging 'com.google.cloud.logging.LoggingHandlerTest' fails",
        "labels": [
            "api: logging",
            "priority: p2"
        ],
        "state": "closed",
        "body": "URL: https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-logging\r\n\r\nRunning com.google.cloud.logging.LoggingHandlerTest\r\nTests run: 15, Failures: 11, Errors: 0, Skipped: 0, Time elapsed: 0.273 sec <<< FAILURE! - in com.google.cloud.logging.LoggingHandlerTest\r\n\r\nPlease refer attached logs for further details.\r\n[JavaLoggingTestFail.docx](https://github.com/GoogleCloudPlatform/google-cloud-java/files/2330431/JavaLoggingTestFail.docx)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3614",
        "number": 3614,
        "title": "Can not get Error from Error Reporting from Java App running on GKE ( google kubernetes engine )",
        "labels": [],
        "state": "closed",
        "body": "in case of Java App Engine, if exception occur from Java App, i can get error from GCP Error reporting automatically like this\r\n\r\nBut in case of Java App on GKE, i can see error log on Stack Driver but there is no error on GCP Error Reporting"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3613",
        "number": 3613,
        "title": "Guava 19/20 convergence error in google-cloud-core",
        "labels": [
            "dependencies",
            "type: process"
        ],
        "state": "open",
        "body": "GAX's guava is upgraded at head but not in latest 1.30.0 release. We need a new release of GAX.\r\n\r\nWe also need to upgrade protobuf-java-util to Guava 20 and push a new release. \r\n\r\nand GAX's com.google.auth:google-auth-library-oauth2-http should go to 0.11.0\r\n\r\n```\r\nDependency convergence error for com.google.guava:guava:20.0 paths to dependency are:\r\n+-com.google.cloud:zero-pom-test:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-core:1.41.0\r\n    +-com.google.guava:guava:20.0\r\nand\r\n+-com.google.cloud:zero-pom-test:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-core:1.41.0\r\n    +-com.google.api:api-common:1.7.0\r\n      +-com.google.guava:guava:19.0\r\nand\r\n+-com.google.cloud:zero-pom-test:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-core:1.41.0\r\n    +-com.google.api:gax:1.30.0\r\n      +-com.google.guava:guava:20.0\r\nand\r\n+-com.google.cloud:zero-pom-test:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-core:1.41.0\r\n    +-com.google.api:gax:1.30.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.10.0\r\n        +-com.google.guava:guava:19.0\r\nand\r\n+-com.google.cloud:zero-pom-test:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-core:1.41.0\r\n    +-com.google.protobuf:protobuf-java-util:3.6.1\r\n      +-com.google.guava:guava:19.0\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3609",
        "number": 3609,
        "title": "Default location should be configurable at BigQueryOptions",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "open",
        "body": "\"When sending requests, the location must be specified for jobs whose location not \"US\" or \"EU\"\".\r\n\r\nThis requires a lot of annoying boilerplate, when the app uses a single location, which isn't US/EU. Namely for Tokyo now a ```JobId``` has to be provided to every call, which can be easily forgotten, hence breaking the app.\r\n\r\nJust like ```projectId``` can be configured at ```BigQueryOptions``` and will be used later automatically, this should be also possible for ```location```.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/4c3e3d137dfc57e6557bc49767251153dae00dab/google-cloud-clients/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/JobId.java#L54-L61\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3607",
        "number": 3607,
        "title": "Could not resolve dependencies for project com.google.api.grpc:grpc-google-cloud-asset-v1beta1:jar:0.24.1-SNAPSHOT",
        "labels": [],
        "state": "closed",
        "body": "At head, I ran `mvn dependency:tree` and it failed like so. I'm not sure whether this matters or not, but I thought I'd log it in case it does. \r\n\r\n```\r\n[ERROR] Failed to execute goal on project grpc-google-cloud-asset-v1beta1: Could not resolve dependencies for project com.google.api.grpc:grpc-google-cloud-asset-v1beta1:jar:0.24.1-SNAPSHOT: Could not find artifact com.google.api.grpc:proto-google-cloud-asset-v1beta1:jar:0.24.1-SNAPSHOT -> [Help 1]\r\n[ERROR] \r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3605",
        "number": 3605,
        "title": "Upgrade com.google.auth:google-auth-library-oauth2-http to 0.11.0",
        "labels": [
            "priority: p1",
            "type: process"
        ],
        "state": "closed",
        "body": "This will fix this convergence issue by upgrading com.google.http-client:google-http-client to 1.24.1\r\n\r\n```\r\n+-com.google.cloud:zero-pom-test:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-storage:1.41.0\r\n    +-com.google.cloud:google-cloud-core-http:1.41.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.10.0\r\n        +-com.google.http-client:google-http-client:1.19.0\r\nand\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3604",
        "number": 3604,
        "title": "Compute API v1: xxxResourceName.parse throws ValidationException",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Currently all `parse()` methods in `xxxResourceName` classes expect that input string will be formatted like `projects/{project}/...`, but data returned from APIs contains URL prefixes like `https://www.googleapis.com/compute/v1/projects/...` and as result parsing fails with `ValidationException`.\r\n\r\n### Example\r\nReceive instance details where:\r\n```\r\ninstance.zone = https://www.googleapis.com/compute/v1/projects/project-123/zones/europe-west3-c\r\n```\r\n\r\nThen when trying to parse it with `ProjectZoneName.parse(instance.zone)` will cause the following exception:\r\n\r\n```\r\nProjectZoneName.parse: formattedString not in valid format: Parameter \"https://www.googleapis.com/compute/v1/projects/project-123/zones/europe-west3-c\" must be in the form \"projects/{project=*}/zones/{zone=*}\"\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3603",
        "number": 3603,
        "title": "bump logback appender to beta",
        "labels": [
            "api: logging",
            "priority: p2",
            "status: blocked",
            "type: process"
        ],
        "state": "open",
        "body": "should prob gated by #3478 "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3602",
        "number": 3602,
        "title": "Transition ownership of google-cloud-java to Yoshi team",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3601",
        "number": 3601,
        "title": "Project build error: Non-resolvable import POM: Could not find artifact com.google.cloud:google-cloud-bom:pom:0.59.0-alpha in central (https://repo.maven.apache.org/maven2)",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "I am beginner to JAVA and Maven. I want to use google speech to text and some other google APIs for my project in eclipse IDE and i have been trying to add a dependency in pom.xml file as follows\r\n\r\n`<dependencyManagement>\r\n    <dependencies>\r\n      <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-bom</artifactId>\r\n        <version>0.59.0-alpha</version>\r\n        <type>pom</type>\r\n        <scope>import</scope>\r\n      </dependency>\r\n    </dependencies>\r\n  </dependencyManagement>`\r\n\r\nBut, the IDE is flashing error in pom.xml file as \"Project build error: Non-resolvable import POM: Could not find artifact com.google.cloud:google-cloud-bom:pom:0.59.0-alpha in central (https://repo.maven.apache.org/maven2)\"\r\n\r\nI am following the instructions posted on this page : https://github.com/GoogleCloudPlatform/google-cloud-java\r\n\r\nI have no idea how to fix this dependency error, any help would be appreciated"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3600",
        "number": 3600,
        "title": "java.lang.RuntimeException: Failed to construct instance from factory method DataflowRunner#fromOptions(interface org.apache.beam.sdk.opti ons.PipelineOptions)",
        "labels": [
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "When i update beam.version to 2.5.0 i get this error.\r\n```\r\njava.lang.RuntimeException: Failed to construct instance from factory method DataflowRunner#fromOptions(interface org.apache.beam.sdk.opti\r\nons.PipelineOptions)\r\n        at org.apache.beam.sdk.util.InstanceBuilder.buildFromMethod(InstanceBuilder.java:233)\r\n        at org.apache.beam.sdk.util.InstanceBuilder.build(InstanceBuilder.java:162)\r\n        at org.apache.beam.sdk.PipelineRunner.fromOptions(PipelineRunner.java:55)\r\n        at org.apache.beam.sdk.Pipeline.create(Pipeline.java:150)\r\n        at com.dataflow.stream.ingestion.dataFlowPipeline.main(dataFlowPipeline.java:684)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:282)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.reflect.InvocationTargetException\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.apache.beam.sdk.util.InstanceBuilder.buildFromMethod(InstanceBuilder.java:222)\r\n        ... 10 more\r\nCaused by: java.lang.NoSuchMethodError: com.google.api.client.googleapis.services.json.AbstractGoogleJsonClient$Builder.setBatchPath(Ljava/lang/String;)Lcom/google/api/client/googleapis/services/AbstractGoogleClient$Builder;\r\n        at com.google.api.services.dataflow.Dataflow$Builder.setBatchPath(Dataflow.java:5723)\r\n        at com.google.api.services.dataflow.Dataflow$Builder.<init>(Dataflow.java:5702)\r\n        at org.apache.beam.runners.dataflow.util.DataflowTransport.newDataflowClient(DataflowTransport.java:77)\r\n        at org.apache.beam.runners.dataflow.options.DataflowPipelineDebugOptions$DataflowClientFactory.create(DataflowPipelineDebugOptions\r\n.java:123)\r\n        at org.apache.beam.runners.dataflow.options.DataflowPipelineDebugOptions$DataflowClientFactory.create(DataflowPipelineDebugOptions\r\n.java:120)\r\n        at org.apache.beam.sdk.options.ProxyInvocationHandler.returnDefaultHelper(ProxyInvocationHandler.java:592)\r\n        at org.apache.beam.sdk.options.ProxyInvocationHandler.getDefault(ProxyInvocationHandler.java:533)\r\n        at org.apache.beam.sdk.options.ProxyInvocationHandler.invoke(ProxyInvocationHandler.java:155)\r\n        at com.sun.proxy.$Proxy37.getDataflowClient(Unknown Source)\r\n        at org.apache.beam.runners.dataflow.DataflowClient.create(DataflowClient.java:43)\r\n        at org.apache.beam.runners.dataflow.DataflowRunner.<init>(DataflowRunner.java:328)\r\n        at org.apache.beam.runners.dataflow.DataflowRunner.fromOptions(DataflowRunner.java:323)\r\n        at org.apache.beam.runners.dataflow.DataflowRunner.fromOptions(DataflowRunner.java:323)\r\n        ... 15 more\r\n```\r\n\r\n\r\n\r\nhere is my dependency tree:\r\n```\r\n- org.apache.beam:beam-sdks-java-core:jar:2.5.0:compile\r\n[INFO] |  +- com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile\r\n[INFO] |  \\- org.xerial.snappy:snappy-java:jar:1.1.4:compile\r\n[INFO] +- org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:jar:2.4.0:compile\r\n[INFO] |  |  +- com.google.cloud.bigdataoss:gcsio:jar:1.4.5:compile\r\n[INFO] |  |  \\- com.google.apis:google-api-services-cloudresourcemanager:jar:v1-rev6-1.22.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-protobuf:jar:2.4.0:compile\r\n[INFO] |  +- io.grpc:grpc-core:jar:1.2.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-context:jar:1.2.0:compile\r\n[INFO] |  |  \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n[INFO] |  +- com.google.api:gax-grpc:jar:0.20.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-grpc:jar:1.2.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-pubsub:jar:v1-rev10-1.22.0:compile\r\n[INFO] |  +- com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.cloud.bigdataoss:util:jar:1.4.5:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-java6:jar:1.20.0:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-jackson2:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.oauth-client:google-oauth-client-java6:jar:1.20.0:compile\r\n[INFO] |  +- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.4.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.http-client:google-http-client-jackson:jar:1.20.0:compile\r\n[INFO] |  +- io.grpc:grpc-auth:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-netty:jar:1.2.0:compile\r\n[INFO] |  |  +- io.netty:netty-codec-http2:jar:4.1.8.Final:compile (version selected from constraint [4.1.8.Final,4.1.8.Final])\r\n[INFO] |  |  |  \\- io.netty:netty-codec-http:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-handler-proxy:jar:4.1.8.Final:compile\r\n[INFO] |  |     \\- io.netty:netty-codec-socks:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.netty:netty-handler:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-buffer:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-common:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-transport:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-resolver:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-codec:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.grpc:grpc-stub:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-all:jar:1.2.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-okhttp:jar:1.2.0:compile\r\n[INFO] |  |  |  +- com.squareup.okhttp:okhttp:jar:2.5.0:compile\r\n[INFO] |  |  |  \\- com.squareup.okio:okio:jar:1.6.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf-nano:jar:1.2.0:compile\r\n[INFO] |  |     \\- com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-spanner:jar:0.20.0b-beta:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-v1:jar:0.1.11b:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.11b:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  |  |  \\- com.google.api.grpc:proto-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  |  \\- junit:junit:jar:4.12:compile\r\n[INFO] |  |     \\- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0:compile\r\n[INFO] |  |  +- commons-logging:commons-logging:jar:1.2:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-appengine:jar:0.7.0:compile\r\n[INFO] |  |  +- io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0:compile\r\n[INFO] |  |  \\- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile\r\n[INFO] |  +- com.google.http-client:google-http-client:jar:1.22.0:compile\r\n[INFO] |  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO] |  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO] |  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-jackson2:jar:1.22.0:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-credentials:jar:0.7.1:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.7.1:compile\r\n[INFO] |  +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:jar:0.1.9:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n[INFO] +- org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-dataflow:jar:v1b3-rev221-1.22.0:compile\r\n[INFO] |  \\- com.google.apis:google-api-services-clouddebugger:jar:v2-rev8-1.22.0:compile\r\n[INFO] +- org.apache.beam:beam-runners-direct-java:jar:2.6.0:compile\r\n[INFO] |  +- org.apache.beam:beam-model-pipeline:jar:2.6.0:compile\r\n[INFO] |  \\- args4j:args4j:jar:2.33:compile\r\n[INFO] +- com.google.cloud:google-cloud-storage:jar:1.38.0:compile\r\n[INFO] |  \\- com.google.cloud:google-cloud-core-http:jar:1.38.0:compile\r\n[INFO] |     +- com.google.http-client:google-http-client-appengine:jar:1.23.0:compile\r\n[INFO] |     +- com.google.api:gax-httpjson:jar:0.46.0:compile\r\n[INFO] |     +- io.opencensus:opencensus-api:jar:0.15.0:compile\r\n[INFO] |     \\- io.opencensus:opencensus-contrib-http-util:jar:0.15.0:compile\r\n[INFO] +- com.google.api:api-common:jar:1.6.0:compile\r\n[INFO] +- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n[INFO] +- joda-time:joda-time:jar:2.4:compile\r\n[INFO] +- com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0:compile\r\n[INFO] |  \\- com.google.api.grpc:grpc-google-common-protos:jar:0.1.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-bigquery:jar:1.35.0:compile\r\n[INFO] |  \\- com.google.auto.value:auto-value:jar:1.4:compile\r\n[INFO] +- com.google.apis:google-api-services-bigquery:jar:v2-rev355-1.22.0:compile\r\n[INFO] +- com.google.protobuf:protobuf-java:jar:3.4.0:compile\r\n[INFO] +- com.google.protobuf:protobuf-java-util:jar:3.3.1:compile\r\n[INFO] +- com.google.code.findbugs:jsr305:jar:3.0.2:compile\r\n[INFO] +- com.google.guava:guava:jar:26.0-jre:compile\r\n[INFO] |  +- org.checkerframework:checker-qual:jar:2.5.2:compile\r\n[INFO] |  +- com.google.errorprone:error_prone_annotations:jar:2.1.3:compile\r\n[INFO] |  +- com.google.j2objc:j2objc-annotations:jar:1.1:compile\r\n[INFO] |  \\- org.codehaus.mojo:animal-sniffer-annotations:jar:1.14:compile\r\n[INFO] +- com.google.api-client:google-api-client:jar:1.22.0:compile\r\n[INFO] |  +- com.google.oauth-client:google-oauth-client:jar:1.22.0:compile\r\n[INFO] |  \\- com.google.guava:guava-jdk5:jar:17.0:compile\r\n[INFO] +- org.json:json:jar:20160810:compile\r\n[INFO] +- com.google.code.gson:gson:jar:2.7:compile\r\n[INFO] +- org.apache.commons:commons-compress:jar:1.8.1:compile\r\n[INFO] +- org.apache.commons:commons-lang3:jar:3.8:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-core:jar:2.9.4:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.4:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.4:compile\r\n[INFO] +- org.apache.avro:avro:jar:1.8.2:compile\r\n[INFO] |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile\r\n[INFO] |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile\r\n[INFO] |  +- com.thoughtworks.paranamer:paranamer:jar:2.7:compile\r\n[INFO] |  \\- org.tukaani:xz:jar:1.5:compile\r\n[INFO] +- com.google.api:gax:jar:1.30.0:compile\r\n[INFO] |  \\- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO] +- com.google.cloud:google-cloud-core:jar:1.38.0:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.12.0:compile\r\n[INFO] +- com.googlecode.json-simple:json-simple:jar:1.1:compile\r\n[INFO] \\- com.google.apis:google-api-services-storage:jar:v1-rev97-1.22.0:compile```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3595",
        "number": 3595,
        "title": "utilities/generate_api errors",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "open",
        "body": "`TypeError: sequence item 0: expected str instance, bytes found`\r\n\r\nCommenting out `dump_version` can temporarily fix the problem.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3594",
        "number": 3594,
        "title": "Java Storage test fails with 403 Forbidden error message.",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "URL: https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-storage\r\n\r\nSteps:\r\n1 . cd google-cloud-java/google-cloud-clients/google-cloud-storage\r\n2. Set JSON key file path to GOOGLE_APPLICATION_CREDENTIALS\r\n3. mvn verify\r\n\r\nRESULT:\r\n-------------------------------------------------------\r\n T E S T S\r\n-------------------------------------------------------\r\nRunning com.google.cloud.storage.it.ITStorageTest\r\ncaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: \r\n403 Forbidden\r\n{\r\n  \"code\" : 403,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"message\" : \"Permission denied on Cloud KMS key. Please ensure that your Cloud Storage service account  has been authorized to use this key.\",\r\n    \"reason\" : \"forbidden\"\r\n  } ],\r\n  \"message\" : \"Permission denied on Cloud KMS key. Please ensure that your Cloud Storage service account  has been authorized to use this key.\"\r\n}\r\n\r\nResults :\r\nFailed tests: \r\n  ITStorageTest.testGetServiceAccount:1923 expected:<[gcloud-devel]@gs-project-accounts...> but was:<[service-725184503843]@gs-project-accounts...>\r\nTests in error: \r\n  ITStorageTest.testCreateBlobWithDefaultKmsKeyName:276 \u00bb Storage Permission den...\r\n  ITStorageTest.testCreateBlobWithKmsKeyName:243 \u00bb Storage Permission denied on ...\r\n  ITStorageTest.testGetBlobKmsKeyNameField:378 \u00bb Storage Permission denied on Cl...\r\n  ITStorageTest.testListBlobsKmsKeySelectedFields:482 \u00bb Storage Permission denie...\r\n  ITStorageTest.testRotateFromCustomerEncryptionToKmsKey:987 \u00bb Storage Permissio...\r\n\r\nTests run: 76, Failures: 1, Errors: 5, Skipped: 0\r\n\r\nPlease refer attached doc for command output\r\n[JavaStorageFailures.docx](https://github.com/GoogleCloudPlatform/google-cloud-java/files/2312076/JavaStorageFailures.docx)\r\n\r\nIt looks like the test is using some default service account and not using the service account set as part of GOOGLE_APPLICATION_CREDENTIALS"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3593",
        "number": 3593,
        "title": "Cloud Container Analysis is beta. Should it be alpha?",
        "labels": [
            "api: container",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "The service it depends on is alpha: https://cloud.google.com/container-registry/docs/container-analysis"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3592",
        "number": 3592,
        "title": "asset: give README a proper doc link",
        "labels": [
            "api: cloudasset",
            "status: blocked",
            "type: docs"
        ],
        "state": "closed",
        "body": "when one becomes available."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3590",
        "number": 3590,
        "title": "Overloads for flattened ByteString method args",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be nice if flattened RPC calls had overloads that accepted standard Java types (i.e. a Java `byte[]` and/or `ByteBuffer`) instead of always requiring a protobuf `ByteString`.  The latter ends up leaking an implementation detail to callers.\r\n\r\nAs an example, in Cloud KMS we currently have:\r\n```\r\nString textRaw = \"The quick brown fox jumps over the lazy dog!\";\r\nbyte[] textBytes = textRaw.getBytes(StandardCharsets.UTF_8);\r\nEncryptResponse encryptResp = client.encrypt(keyPath, ByteString.copyFrom(textBytes));\r\n```\r\n\r\nIt would be nice if the final line could be\r\n```\r\nEncryptResponse encryptResp = client.encrypt(keyPath, textBytes);\r\n```\r\nor\r\n```\r\nEncryptResponse encryptResp = client.encrypt(keyPath, ByteBuffer.wrap(textBytes));\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3589",
        "number": 3589,
        "title": "com.google.cloud.bigquery.QueryParameterValue classToType should support standard Java date/time classes.",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "open",
        "body": "Please consider adding standard java date, datetime and time classes to the classToType method so that they can be used with \"of\" generic:\r\n  /** Creates a {@code QueryParameterValue} object with the given value and type. */\r\n  public static <T> QueryParameterValue of(T value, Class<T> type) {\r\n    return of(value, classToType(type));\r\n  }\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3587",
        "number": 3587,
        "title": " WriteChannel of google storage client increases memory usage and gives memory leak",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi Everyone,\r\n\r\nI am using google cloud storage client library to store files in google cloud storage.\r\nI am using the below code for that:\r\n\r\n```\r\nWriteChannel writer = null;\r\nReadableByteChannel input=null;\r\ntry {\r\n    int bufferSize = Integer.getInteger(\"buffer.size\", 1024 * 1024);\t\r\n    writer = storageClient.writer(blobInfo);\r\n    //the fileInputStream from the file\r\n    input = Channels.newChannel(fileInputStream);\r\n\t\t\t\r\n    ByteBuffer buffer = ByteBuffer.allocateDirect(bufferSize);\r\n\t\t\t\r\n    writer.setChunkSize(5*bufferSize);\t\t\r\n    while (input.read(buffer) != -1) {\r\n\tbuffer.flip();\r\n\twriter.write(buffer);\r\n\tbuffer.compact();\r\n    }\r\n}\r\n\r\nIOUtils.closeQuietly(fileInputStream);\t\r\nIOUtils.closeQuietly(writer);\r\nIOUtils.closeQuietly(input);\r\n\r\n```\r\n\r\nAs the document suggested for big file should use the WriteChannel writer from the storage client.\r\nBut after using this code when i do the memory analysis , Its increasing up after each request .\r\nAll ways i tried mentioned in the google cloud storage documents.I am not understanding why the code is not channeling and its allocating memory  with each request and memory is not getting released , which soon  gives memory leak error.\r\n\r\nKindly help and guide me if i am doing something wrong.\r\n\r\nThanks in advance.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3586",
        "number": 3586,
        "title": "Make Cloud Storage client retry on backend error",
        "labels": [
            "api: storage",
            "priority: p2",
            "status: blocked",
            "type: bug"
        ],
        "state": "closed",
        "body": "We're operating at scale on GCS and are regularly experiencing transient [HTTP 410 status codes](https://cloud.google.com/storage/docs/json_api/v1/status-codes#410_Gone) when accessing Cloud storage. Those 410 status codes returned by Cloud storage are bogus though, as they are effectively just hiding an internal backend error on GCS, which is reflected in the error details:\r\n\r\n```\r\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: \r\n410 Gone { \"code\" : 503, \"errors\" : [ { \"domain\" : \"global\", \"message\" : \"Backend Error\", \"reason\" : \"backendError\" } ], \"message\" : \"Backend Error\" }\r\n```\r\n\r\nThe google-cloud-storage client does not treat the 410 status code as retryable, understandibly so. It should be retrying on backend errors, though, which are typically exposed with status code 500 or 503. **I'm suggesting to treat backend errors in the client [in the same way as it treats internal errors](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-storage/src/main/java/com/google/cloud/storage/StorageException.java#L45), namely match on `reason == backendError` independently of HTTP status code.**\r\n\r\nNote that we're not the first ones to experience this, and the client should be resilient against these transient GCS errors.\r\n- https://stackoverflow.com/questions/33056415/uploading-files-into-google-cloud-storage-500-backend-error\r\n- https://stackoverflow.com/questions/35125891/google-cloud-dataflow-jobs-failing-inaccessible-jars-410-gone-errors\r\n- https://stackoverflow.com/questions/41215541/dataflow-jobs-fail-after-a-few-410-errors-while-writing-to-gcs"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3585",
        "number": 3585,
        "title": "Failed to unpack response from 'any' field on v1beta2.ClusterControllerClient.createClusterAsync",
        "labels": [
            "api: dataproc",
            "priority: p2",
            "status: blocked",
            "type: bug"
        ],
        "state": "closed",
        "body": "[`ClusterControllerClient.createClusterAsync`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-dataproc/src/main/java/com/google/cloud/dataproc/v1beta2/ClusterControllerClient.java) throws the following exception when it successfully created a cluster. \r\n\r\n```\r\njava.util.concurrent.ExecutionException: com.google.api.gax.rpc.UnknownException: java.lang.IllegalStateException: Failed to unpack object from 'any' field. Expected com.google.cloud.dataproc.v1beta2.Cluster, found type.googleapis.com/google.cloud.dataproc.v1.Cluster\r\n        at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:502)\r\n        at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:481)\r\n        at com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:83)\r\n        at com.google.common.util.concurrent.ForwardingFuture.get(ForwardingFuture.java:62)\r\n        at com.google.api.gax.longrunning.OperationFutureImpl.get(OperationFutureImpl.java:127)\r\n        at App.main(App.java:41)\r\nCaused by: com.google.api.gax.rpc.UnknownException: java.lang.IllegalStateException: Failed to unpack object from 'any' field. Expected com.google.cloud.dataproc.v1beta2.Cluster, found type.googleapis.com/google.cloud.dataproc.v1.Cluster\r\n        at com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:117)\r\n        at com.google.api.gax.grpc.ProtoOperationTransformers$ResponseTransformer.apply(ProtoOperationTransformers.java:69)\r\n        at com.google.api.gax.grpc.ProtoOperationTransformers$ResponseTransformer.apply(ProtoOperationTransformers.java:46)\r\n        at com.google.api.core.ApiFutures$GaxFunctionToGuavaFunction.apply(ApiFutures.java:204)\r\n        at com.google.common.util.concurrent.AbstractTransformFuture$TransformFuture.doTransform(AbstractTransformFuture.java:249)\r\n        at com.google.common.util.concurrent.AbstractTransformFuture$TransformFuture.doTransform(AbstractTransformFuture.java:239)\r\n        at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\r\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)\r\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:973)\r\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:821)\r\n        at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:663)\r\n        at com.google.api.gax.retrying.BasicRetryingFuture.handleAttempt(BasicRetryingFuture.java:159)\r\n        at com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.handle(CallbackChainRetryingFuture.java:134)\r\n        at com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.run(CallbackChainRetryingFuture.java:114)\r\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)\r\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:973)\r\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:821)\r\n        at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:663)\r\n        at com.google.common.util.concurrent.AbstractTransformFuture$TransformFuture.setResult(AbstractTransformFuture.java:255)\r\n        at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:177)\r\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)\r\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:973)\r\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:821)\r\n        at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:663)\r\n        at com.google.api.gax.retrying.BasicRetryingFuture.handleAttempt(BasicRetryingFuture.java:159)\r\n        at com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.handle(CallbackChainRetryingFuture.java:134)\r\n        at com.google.api.gax.retrying.CallbackChainRetryingFuture$AttemptCompletionListener.run(CallbackChainRetryingFuture.java:114)\r\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)\r\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:973)\r\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:821)\r\n        at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:663)\r\n        at com.google.api.core.AbstractApiFuture$InternalSettableFuture.set(AbstractApiFuture.java:90)\r\n        at com.google.api.core.AbstractApiFuture.set(AbstractApiFuture.java:73)\r\n        at com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onSuccess(GrpcExceptionCallable.java:88)\r\n        at com.google.api.core.ApiFutures$1.onSuccess(ApiFutures.java:73)\r\n        at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1374)\r\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)\r\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:973)\r\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:821)\r\n        at com.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:663)\r\n        at io.grpc.stub.ClientCalls$GrpcFuture.set(ClientCalls.java:488)\r\n        at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:466)\r\n        at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n        at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n        at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684)\r\n        at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n        at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n        at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:403)\r\n        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\r\n        at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\r\n        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n        at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalStateException: Failed to unpack object from 'any' field. Expected com.google.cloud.dataproc.v1beta2.Cluster, found type.googleapis.com/google.cloud.dataproc.v1.Cluster\r\n        at com.google.api.gax.grpc.ProtoOperationTransformers$AnyTransformer.apply(ProtoOperationTransformers.java:131)\r\n        at com.google.api.gax.grpc.ProtoOperationTransformers$ResponseTransformer.apply(ProtoOperationTransformers.java:67)\r\n        ... 62 more\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3583",
        "number": 3583,
        "title": "Datastore Entity.Builder.Set don't accept nulls",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI've ran into this problem a while a go and although it is not a bug it does make the API harder to use.\r\n\r\nThe problem: `set` don't take null values\r\nThe solution: Use `setNull` or `set` and set a Value.Null (something like that) \r\nThe solution's problem: This require the api client to manually check if a value is null in order to call the proper `set` method.\r\n\r\nHere is a sample code\r\n```\r\npublic void put(BatchExecution obj) {\r\n    Key key = keyFactory.newKey(obj.getId());           \r\n    FullEntity<Key> incBEEntity = Entity.newBuilder(key)  \r\n        .set(BatchExecution.ID, obj.getId())\r\n        .set(BatchExecution.NAME, obj.getName())\r\n        .set(BatchExecution.CREATETIME, obj.getCreateTime())\r\n        .set(BatchExecution.ELAPSEDTIME, obj.getElapsedTime()) //I break the code because elapesedTime was never set in the object\r\n        .set(BatchExecution.STATUS, obj.getStatus().name())\r\n        .build();\r\n    datastore.put(incBEEntity);\r\n  }\r\n```\r\n\r\nThis looks very weird to me since when you call  `set` on a null value eventually the stack call throws an exception on a method called `CheckNull`. So, since a check is eventually made down the stack, why not move this null check to the overloaded `set` methods and if it yields true the method will redirect the request to the `setNull` method. Having two different `set` looks like unnecessary exposure of API innards work. If the API handles lets say a String differently than a Null, it's the API's problem to deal with that, not the client. This concern can be seen in the overload of the `set` method. The API need to treat a String differently from a TimeStamp (obviously), but this is not exposed to the client, it`s all the same `set` method.\r\n\r\nIn sum, my request is: Is it possible to have `set` accepting null values instead of having the client  manually check if an object is null and calling  the appropriate method?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3582",
        "number": 3582,
        "title": "Datastore - Inconsistent behavior of transactions between Datastore and Firestore in Datastore Mode",
        "labels": [
            "api: datastore",
            "api: firestore",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "I'm seeing inconsistency in transactions behavior between **Cloud Datastore** and **Cloud Firestore running in Datastore mode**. The sample code below runs fine when working with Cloud Datastore, but fails when working with Cloud Firestore running in Datastore mode. \r\n\r\n```java \r\nimport com.google.cloud.datastore.Datastore;\r\nimport com.google.cloud.datastore.DatastoreOptions;\r\nimport com.google.cloud.datastore.FullEntity;\r\nimport com.google.cloud.datastore.IncompleteKey;\r\nimport com.google.cloud.datastore.Transaction;\r\n\r\npublic class TransactionTest {\r\n\r\n  public static void main(String[] args) {\r\n    //change it to a project ID that has plain old Datastore and then try again \r\n    //with a different project that has Firestore running in Datastore mode. \r\n    final String projectId = \"xxx-xxx\";\r\n    Datastore datastore = DatastoreOptions.newBuilder().setProjectId(projectId).build()\r\n        .getService();\r\n    IncompleteKey incompleteKey = datastore.newKeyFactory().setKind(\"TransactionTest\").newKey();\r\n    FullEntity<IncompleteKey> fullEntity = FullEntity.newBuilder().setKey(incompleteKey)\r\n        .set(\"name\", \"Bob\").build();\r\n    com.google.cloud.datastore.Entity entity = datastore.add(fullEntity);\r\n\r\n    Transaction t1 = datastore.newTransaction();\r\n    try {\r\n      com.google.cloud.datastore.Entity entity2 = t1.get(entity.getKey());\r\n      update(entity, datastore);\r\n      t1.commit();\r\n      System.out.println(\"t1 is committed successfully\");\r\n    } finally {\r\n      if (t1.isActive()) {\r\n        t1.rollback();\r\n      }\r\n    }\r\n\r\n  }\r\n\r\n  private static void update(com.google.cloud.datastore.Entity entity, Datastore datastore) {\r\n    Transaction t2 = datastore.newTransaction();\r\n    try {\r\n      t2.update(entity);\r\n      t2.commit();\r\n      System.out.println(\"t2 is committed successfully\");\r\n    } finally {\r\n      if (t2.isActive()) {\r\n        t2.rollback();\r\n      }\r\n    }\r\n  }\r\n\r\n}\r\n\r\n\r\n```\r\n\r\nRunning this code against good old Datastore completes normally and I get the below printed to the console: \r\n\r\n```\r\nt2 is committed successfully\r\nt1 is committed successfully\r\n```\r\n\r\nHowever, running this against a different project_id, which has Firestore running in Datastore mode, produces the below exception, after running for about a minute: \r\n\r\n```\r\nException in thread \"main\" com.google.cloud.datastore.DatastoreException: The referenced transaction has expired or is no longer valid.\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.translate(HttpDatastoreRpc.java:129)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.translate(HttpDatastoreRpc.java:114)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.rollback(HttpDatastoreRpc.java:173)\r\n\tat com.google.cloud.datastore.DatastoreImpl$6.call(DatastoreImpl.java:530)\r\n\tat com.google.cloud.datastore.DatastoreImpl$6.call(DatastoreImpl.java:527)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.datastore.DatastoreImpl.rollback(DatastoreImpl.java:527)\r\n\tat com.google.cloud.datastore.DatastoreImpl.rollbackTransaction(DatastoreImpl.java:522)\r\n\tat com.google.cloud.datastore.TransactionImpl.rollback(TransactionImpl.java:120)\r\n\tat com.jmethods.catatumbo.TransactionTest.main(TransactionTest.java:30)\r\nCaused by: com.google.datastore.v1.client.DatastoreException: The referenced transaction has expired or is no longer valid., code=INVALID_ARGUMENT\r\n\tat com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:226)\r\n\tat com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:275)\r\n\tat com.google.datastore.v1.client.RemoteRpc.call(RemoteRpc.java:186)\r\n\tat com.google.datastore.v1.client.Datastore.rollback(Datastore.java:111)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.rollback(HttpDatastoreRpc.java:171)\r\n\t... 9 more\r\n\r\n```\r\n\r\nAny idea why this difference? Which one is behaving correctly, Datastore or Firestore in Datastore mode? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3580",
        "number": 3580,
        "title": "Cannot call public methods in com.google.cloud.firestore.UpdateBuilder via reflection",
        "labels": [
            "api: firestore",
            "type: feature request"
        ],
        "state": "open",
        "body": "The com.google.cloud.firestore.Transaction and WriteBatch classes are\r\npublic but they extend a package-private abstract class\r\nUpdateBuilder. The public methods inherited from\r\nUpdateBuilder cannot be invoked via the Java reflection API due to\r\nlong-standing bugs such as JDK-4283544.\r\n\r\nThis is a serious problem for alternative JVM languages which use\r\nreflection to discover Java methods. For example, Clojure uses\r\nreflection in its compiler, and it cannot invoke these methods at all.\r\n\r\nI know at least UpdateBuilder is affected. There may be other\r\ninstances of this pattern that I haven't found.\r\n\r\n**Possible Solution**\r\nFor this specific case, making UpdateBuilder public will fix the\r\nproblem. This should have no impact on other code. The class will\r\nstill not be instantiable because it is also abstract.\r\n\r\nIf there are other package-private classes extended by public API\r\nclasses, they would also need to be declared public.\r\n\r\nVersion: google-cloud-firestore-0.52.0-beta\r\nJava: Oracle JDK 1.8.0_152"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3579",
        "number": 3579,
        "title": "Duplicate definitions of dependency in the pom.xml file is causing the failure while running bigtable test.",
        "labels": [
            "api: bigtable",
            "dependencies",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-bigtable/pom.xml#L44\r\n\r\nDuplicate definitions of dependency in the pom.xml file is causing the failure. (<artifactId>grpc-google-cloud-bigtable-admin-v2</artifactId>)\r\n\r\n$ mvn verify -am -pl google-cloud-bigtable -Dbigtable.env=prod -Dbigtable.table=projects/PROJECT_ID/instances/INSTANCE_ID/tables/my-table\r\n\r\n[INFO] Scanning for projects...\r\n[ERROR] [ERROR] Some problems were encountered while processing the POMs:\r\n[WARNING] 'dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: com.google.api.grpc:grpc-google-cloud-bigtable-admin-v2:jar -> duplicate declaration of version (?) @ line 73, column 17\r\n[ERROR] Non-resolvable import POM: Could not find artifact com.google.cloud:google-cloud-bom:pom:0.58.1-alpha-SNAPSHOT @ com.google.cloud:google-cloud-clients:0.58.1-alpha-SNAPSHOT, /home/suhasm/google-cloud-java/google-cloud-clients/pom.xml, line 174, column 19\r\n[ERROR] 'dependencies.dependency.version' for com.google.cloud:google-cloud-core:jar is missing. @ line 21, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.cloud:google-cloud-core-grpc:jar is missing. @ line 25, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.api.grpc:proto-google-cloud-bigtable-v2:jar is missing. @ line 29, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.api.grpc:grpc-google-cloud-bigtable-v2:jar is missing. @ line 33, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.api.grpc:proto-google-cloud-bigtable-admin-v2:jar is missing. @ line 38, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.api.grpc:grpc-google-cloud-bigtable-admin-v2:jar is missing. @ line 73, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.cloud:google-cloud-core:test-jar is missing. @ line 67, column 17\r\n[ERROR] 'dependencies.dependency.version' for com.google.api:gax-grpc:jar:testlib is missing. @ line 93, column 17\r\n @ \r\n[ERROR] The build could not read 1 project -> [Help 1]\r\n[ERROR]   \r\n[ERROR]   The project com.google.cloud:google-cloud-bigtable:0.58.1-alpha-SNAPSHOT (/home/suhasm/google-cloud-java/google-cloud-clients/google-cloud-bigtable/pom.xml) has 9 errors\r\n[ERROR]     Non-resolvable import POM: Could not find artifact com.google.cloud:google-cloud-bom:pom:0.58.1-alpha-SNAPSHOT @ com.google.cloud:google-cloud-clients:0.58.1-alpha-SNAPSHOT, /home/suhasm/google-cloud-java/google-cloud-clients/pom.xml, line 174, column 19 -> [Help 2]\r\n[ERROR]     'dependencies.dependency.version' for com.google.cloud:google-cloud-core:jar is missing. @ line 21, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.cloud:google-cloud-core-grpc:jar is missing. @ line 25, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.api.grpc:proto-google-cloud-bigtable-v2:jar is missing. @ line 29, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.api.grpc:grpc-google-cloud-bigtable-v2:jar is missing. @ line 33, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.api.grpc:proto-google-cloud-bigtable-admin-v2:jar is missing. @ line 38, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.api.grpc:grpc-google-cloud-bigtable-admin-v2:jar is missing. @ line 73, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.cloud:google-cloud-core:test-jar is missing. @ line 67, column 17\r\n[ERROR]     'dependencies.dependency.version' for com.google.api:gax-grpc:jar:testlib is missing. @ line 93, column 17\r\n[ERROR] \r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR] \r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException\r\n[ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/UnresolvableModelException\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3573",
        "number": 3573,
        "title": "Bad credentials file causes Pub/Sub topic creation to hang",
        "labels": [
            "api: pubsub",
            "auth",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "See: https://github.com/spring-cloud/spring-cloud-gcp/issues/962.\r\nI suspect that the root cause is in the client library.\r\n\r\nNote that when the same credentials file is used to publish a message to a topic, an appropriate exception is thrown saying `java.io.IOException: Error getting access token for service account` and `401 Unauthorized`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3572",
        "number": 3572,
        "title": "textTospeech grpc throws error (both v1 and v1beta1) ",
        "labels": [],
        "state": "closed",
        "body": "I am trying to use gRPC with google text to speech API. It failed with following error( both v1 and v1beta1). Any help?\r\n\r\nRPC target method can't be resolved.12\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3567",
        "number": 3567,
        "title": "Pubsub acks are unsuccessful",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "open",
        "body": "When I use the streaming pull subscriber through the `MessageReceiver` interface, it seems acks usually expire, and even if they don't expire, the number of backlogged messages never changes (num_undelivered_messages in Stackdriver). This only seems to happen if messages take a while to be processed, i.e., more than a few minutes.\r\n\r\nIt's strange that acks are expired in the first place because I do see that the client is sending modify ack deadline requests (mod_ack_deadline_message_operation_count in Stackdriver). The subscription itself has an ack deadline of 10 minutes so these messages are processed well within the deadline.\r\n\r\nEven when acks are successful (i.e., non-expired), num_undelivered_messages is unaffected in Stackdriver. I do see the previously acked messages being redelivered as well.\r\n\r\nAnother thing I noticed that even though the client is performing streaming pulls, in Stackdriver I see metric data coming in for `pull_ack_message_operation_count` but none for `streaming_pull_ack_message_operation_count`. Similarly I see results for `mod_ack_deadline_message_operation_count` but not for `streaming_pull_mod_ack_deadline_message_operation_count`. Is this expected?\r\n\r\nI am using version 1.37.1 of the google-cloud-pubsub library. I have uploaded my code here: https://gist.github.com/stetra/d757fed41cb67d4a73dd7487ca4d452e\r\n\r\nThe following Stackdriver graphs show that successful acks are apparently happening, yet the backlog is not decreasing.\r\n![acks](https://user-images.githubusercontent.com/35081873/44225145-80c2db00-a141-11e8-970a-d503163269bf.png)\r\n![num_undelivered_messages](https://user-images.githubusercontent.com/35081873/44225144-80c2db00-a141-11e8-8619-7d485869ef23.png)\r\n![modacks](https://user-images.githubusercontent.com/35081873/44225143-80c2db00-a141-11e8-8dc2-9effe00daf8d.png)\r\n\r\nIn summary, these are my questions:\r\n\r\n1. Despite successful acks occurring, why is the number of unacknowledged messages not decreasing?\r\n\r\n2. Why are expired acks occurring in the first place?\r\n\r\n3. Why is the client performing streaming pulls with non-streaming acks and modacks?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3559",
        "number": 3559,
        "title": "Stackdriver LoggingAppender is missing container_name and namespace_id fields on MonitoredResource",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I added the 0.57.0-alpha `LoggingAppender` to my logback config in a GKE service, however I noticed that the fields `container_name` and `namespace_id` are missing.  This is important, because in the GKE UI, when clicking on \"Container logs\" for a given container, the filter is pre-populated with these fields (`resource.labels.container_name`, etc), and therefor no logs will show up unless those are populated.\r\n\r\nIt looks like `MonitoredResourceUtil` from google-cloud-logging just needs to be enhanced to pick up these fields if running in GKE."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3556",
        "number": 3556,
        "title": "Inconsistent Connection with Firestore when using Java Google App Engine",
        "labels": [],
        "state": "closed",
        "body": "Hello,\r\n\r\nI am having issues with connecting to firestore in a consistent manner. Accessing firestore sometimes is successful but also fails with the following error.\r\n\r\n> java.util.concurrent.ExecutionException: com.google.api.gax.rpc.UnavailableException: io.grpc.StatusRuntimeException: UNAVAILABLE: Credentials failed to obtain metadata at com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:500) at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:479) at com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:76) at com.google.common.util.concurrent.ForwardingFuture.get(ForwardingFuture.java:62) at com.friendzonellc.match.Matching.match(Matching.java:136) at com.friendzonellc.match.Matching.doGet(Matching.java:104) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772) at \r\n...\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: Credentials failed to obtain metadata at com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:69) at com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72) at com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60) at com.google.api.gax.grpc.GrpcExceptionServerStreamingCallable$ExceptionResponseObserver.onErrorImpl(GrpcExceptionServerStreamingCallable.java:105) at com.google.api.gax.rpc.StateCheckingResponseObserver.onError(StateCheckingResponseObserver.java:86) at com.google.api.gax.grpc.GrpcDirectStreamController$ResponseObserverAdapter.onClose(GrpcDirectStreamController.java:127) at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41) at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684) at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41) at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:391) at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475) at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478)\r\n\r\nI am currently authenticating under a static initializer within a class extending the HttpServlet class. \r\n\r\n```\r\nstatic {\r\ntry {\r\n      serviceAccount = new FileInputStream(\"WEB-INF/admin-sdk-key.json\");\r\n      options  = new FirebaseOptions.Builder()\r\n                                    .setCredentials(GoogleCredentials.fromStream(serviceAccount))\r\n                                    .setDatabaseUrl(\"${OUR_DATABASE_URL}\")\r\n                                    .build();\r\n      FirebaseApp.initializeApp(options);\r\n\r\n      db = FirestoreClient.getFirestore();\r\n    }\r\ncatch (Exception e) {\r\n      StringWriter sw = new StringWriter();\r\n      PrintWriter pw = new PrintWriter(sw);\r\n      e.printStackTrace(pw);\r\n      log.info(sw.toString());\r\n    }\r\n}\r\n```\r\nThe class accepts a get request which proceeds to call another function that requires access to the Firestore.\r\n\r\nThis is the code that I am using to obtain a Document Snapshot. \r\n\r\n```\r\nDocumentReference userRef = userCollection.document(userid);\r\n    ApiFuture<DocumentSnapshot> userSnap = userRef.get();\r\n    DocumentSnapshot userDocumentSnap = userSnap.get();\r\n    Map<String,Object> userDocument = userDocumentSnap.getData();\r\n```\r\n\r\nWhenever this fails, it raises an error when calling get on the ApiFuture<DocumentSnapshot> object. \r\n\r\nThe following dependencies I am using at the moment in my pom.xml is the following:\r\n\r\n```\r\n<dependency>\r\n<groupId>com.google.appengine</groupId>\r\n<artifactId>appengine-api-1.0-sdk</artifactId>\r\n<version>1.9.64</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud</artifactId>\r\n      <version>0.47.0-alpha</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>com.google.firebase</groupId>\r\n      <artifactId>firebase-admin</artifactId>\r\n      <version>6.3.0</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>javax.servlet</groupId>\r\n      <artifactId>javax.servlet-api</artifactId>\r\n      <version>3.1.0</version>\r\n      <type>jar</type>\r\n      <scope>provided</scope>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>jstl</groupId>\r\n      <artifactId>jstl</artifactId>\r\n      <version>1.2</version>\r\n    </dependency>\r\n```\r\n\r\nAny suggestions would be much appreciated. Thank you!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3551",
        "number": 3551,
        "title": "Add ability to disable Cloud logging when running in Development sandbox",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "open",
        "body": "When running the application in development box, I get below error:\r\n```\r\n[INFO] 06:12:12,243 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [com.google.cloud.logging.logback.LoggingAppender]\r\n[INFO] 06:12:12,249 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [CLOUD]\r\n[INFO] 06:12:13,325 |-ERROR in ch.qos.logback.core.joran.spi.Interpreter@6:13 - RuntimeException in Action for tag [appender] java.lang.NullPointerException\r\n[INFO] \tat java.lang.NullPointerException\r\n[INFO] \tat \tat com.google.cloud.MetadataConfig.getZone(MetadataConfig.java:46)\r\n[INFO] \tat \tat com.google.cloud.logging.MonitoredResourceUtil.getValue(MonitoredResourceUtil.java:154)\r\n[INFO] \tat \tat com.google.cloud.logging.MonitoredResourceUtil.getResource(MonitoredResourceUtil.java:111)\r\n[INFO] \tat \tat com.google.cloud.logging.logback.LoggingAppender.getMonitoredResource(LoggingAppender.java:134)\r\n[INFO] \tat \tat com.google.cloud.logging.logback.LoggingAppender.start(LoggingAppender.java:180)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.action.AppenderAction.end(AppenderAction.java:90)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.spi.Interpreter.callEndAction(Interpreter.java:309)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.spi.Interpreter.endElement(Interpreter.java:193)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.spi.Interpreter.endElement(Interpreter.java:179)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.spi.EventPlayer.play(EventPlayer.java:62)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.GenericConfigurator.doConfigure(GenericConfigurator.java:165)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.GenericConfigurator.doConfigure(GenericConfigurator.java:152)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.GenericConfigurator.doConfigure(GenericConfigurator.java:110)\r\n[INFO] \tat \tat ch.qos.logback.core.joran.GenericConfigurator.doConfigure(GenericConfigurator.java:53)\r\n[INFO] \tat \tat ch.qos.logback.classic.util.ContextInitializer.configureByResource(ContextInitializer.java:75)\r\n[INFO] \tat \tat ch.qos.logback.classic.util.ContextInitializer.autoConfig(ContextInitializer.java:150)\r\n[INFO] \tat \tat org.slf4j.impl.StaticLoggerBinder.init(StaticLoggerBinder.java:84)\r\n[INFO] \tat \tat org.slf4j.impl.StaticLoggerBinder.<clinit>(StaticLoggerBinder.java:55)\r\n[INFO] \tat \tat org.slf4j.LoggerFactory.bind(LoggerFactory.java:150)\r\n[INFO] \tat \tat org.slf4j.LoggerFactory.performInitialization(LoggerFactory.java:124)\r\n[INFO] \tat \tat org.slf4j.LoggerFactory.getILoggerFactory(LoggerFactory.java:412)\r\n[INFO] \tat \tat ch.qos.logback.classic.util.StatusViaSLF4JLoggerFactory.addStatus(StatusViaSLF4JLoggerFactory.java:32)\r\n[INFO] \tat \tat ch.qos.logback.classic.util.StatusViaSLF4JLoggerFactory.addInfo(StatusViaSLF4JLoggerFactory.java:20)\r\n[INFO] \tat \tat ch.qos.logback.classic.servlet.LogbackServletContainerInitializer.onStartup(LogbackServletContainerInitializer.java:32)\r\n```\r\n\r\nAt this point, I'm not really sure what should be the fix for this, but, IMHO, the library should be intelligent enough to back-off when not running in Cloud environment. Environment based logback configuration might not be possible under every circumstance."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3545",
        "number": 3545,
        "title": "Java code for PartnerDTSClient, ManagedTransferRun and TableContext",
        "labels": [
            "api: bigquery",
            "needs more info",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "I'm looking for the equivalent java code for the 3 classes:  PartnerDTSClient, ManagedTransferRun and TableContext which are being used in the python library here: https://github.com/mtai/bq-dts-partner-sdk/blob/master/bq_dts/base_connector.py\r\nfor moving data from GCS to BQ using the DTS api. I have the following 2 dependencies and it doesn't seem to have code to fulfill the functionality of those classes:\r\n            com.google.cloud /  google-cloud-bigquerydatatransfer  /  0.55.1-beta</version>\r\n         com.google.cloud   /  google-cloud-pubsub  /  1.37.1\r\nPlease let me know what am I missing"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3543",
        "number": 3543,
        "title": "Wrong Android detection",
        "labels": [
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "When library is used in Intellij Plugin, it detects Android plugin for Intellij IDEA as Android.\r\n![image](https://user-images.githubusercontent.com/6931331/43894198-08d82076-9bda-11e8-8239-6b59101d4aaa.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3540",
        "number": 3540,
        "title": "META-INF/services/ files are incorrect in shaded google-cloud-nio jar",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: process"
        ],
        "state": "open",
        "body": "The `google-cloud-nio-0.56.0-alpha-shaded.jar` doesn't correctly update the services files for shaded dependencies.  \r\nSpecifically the two files \r\n`META-INF/services/org.threeten.bp.zone.TzdbZoneRulesProvider`\r\nand \r\n`META-INF/services/com.fasterxml.jackson.core.JsonFactory` should probably be updated to point to the shaded version of those classes instead."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3537",
        "number": 3537,
        "title": "Move BOM usage up to the front",
        "labels": [
            "type: docs",
            "type: process"
        ],
        "state": "closed",
        "body": "Currently BOM info is towards the bottom of the doc and easily missed.\r\n\r\nIt should be on the top, either in the quickstart, or immediately after that. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3536",
        "number": 3536,
        "title": "Pubsub Subscriber initialization crashes JVM on Alpine Linux with libc6-compat",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "open",
        "body": "Pubsub Subscriber initialization crashes JVM on Alpine Linux with libc6-compat. Here is the stacktrace from hs_err crash log:\r\n```\r\nStack: [0x00007fad5f2d8000,0x00007fad5f3d8aa8],  sp=0x00007fad5f3d2668,  free space=1001k\r\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\r\nC  0x0000000000025426\r\nC  [libio_grpc_netty_shaded_netty_tcnative_linux_x86_64646374909380874916.so+0x29585]  JNI_OnLoad_netty_tcnative+0x55\r\nC  [libjava.so+0xda62]  Java_java_lang_ClassLoader_00024NativeLibrary_load+0xf2\r\n\r\nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\r\nj  java.lang.ClassLoader$NativeLibrary.load(Ljava/lang/String;Z)V+0\r\nj  java.lang.ClassLoader.loadLibrary0(Ljava/lang/Class;Ljava/io/File;)Z+328\r\nj  java.lang.ClassLoader.loadLibrary(Ljava/lang/Class;Ljava/lang/String;Z)V+48\r\nj  java.lang.Runtime.load0(Ljava/lang/Class;Ljava/lang/String;)V+57\r\nj  java.lang.System.load(Ljava/lang/String;)V+7\r\nj  io.grpc.netty.shaded.io.netty.util.internal.NativeLibraryUtil.loadLibrary(Ljava/lang/String;Z)V+5\r\nv  ~StubRoutines::call_stub\r\nJ 1656  sun.reflect.NativeMethodAccessorImpl.invoke0(Ljava/lang/reflect/Method;Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; (0 bytes) @ 0x00007fad4ec3aa37 [0x00007fad4ec3a9c0+0x77]\r\nJ 1655 C1 sun.reflect.NativeMethodAccessorImpl.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; (104 bytes) @ 0x00007fad4ec42554 [0x00007fad4ec41380+0x11d4]\r\nJ 587 C1 sun.reflect.DelegatingMethodAccessorImpl.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; (10 bytes) @ 0x00007fad4e8cfe0c [0x00007fad4e8cfd00+0x10c]\r\nJ 586 C1 java.lang.reflect.Method.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object; (62 bytes) @ 0x00007fad4e8d05dc [0x00007fad4e8d01e0+0x3fc]\r\nj  io.grpc.netty.shaded.io.netty.util.internal.NativeLibraryLoader$1.run()Ljava/lang/Object;+53\r\nv  ~StubRoutines::call_stub\r\nJ 697  java.security.AccessController.doPrivileged(Ljava/security/PrivilegedAction;)Ljava/lang/Object; (0 bytes) @ 0x00007fad4e9597cf [0x00007fad4e959780+0x4f]\r\nj  io.grpc.netty.shaded.io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(Ljava/lang/Class;Ljava/lang/String;Z)V+10\r\nj  io.grpc.netty.shaded.io.netty.util.internal.NativeLibraryLoader.loadLibrary(Ljava/lang/ClassLoader;Ljava/lang/String;Z)V+15\r\nj  io.grpc.netty.shaded.io.netty.util.internal.NativeLibraryLoader.load(Ljava/lang/String;Ljava/lang/ClassLoader;)V+402\r\nj  io.grpc.netty.shaded.io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(Ljava/lang/ClassLoader;[Ljava/lang/String;)V+33\r\nj  io.grpc.netty.shaded.io.netty.handler.ssl.OpenSsl.loadTcNative()V+173\r\nj  io.grpc.netty.shaded.io.netty.handler.ssl.OpenSsl.<clinit>()V+152\r\nv  ~StubRoutines::call_stub\r\nj  io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.defaultSslProvider()Lio/grpc/netty/shaded/io/netty/handler/ssl/SslProvider;+0\r\nj  io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.configure(Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContextBuilder;)Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContextBuilder;+1\r\nj  io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.forClient()Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContextBuilder;+3\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$NettyTranspo\r\nrtFactory;Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContext;)V+23\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$NettyTranspo\r\nrtFactory;Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContext;Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$1;)V+3\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$TransportCreationParamsFilterFactory;Ljava/lang/Class;Ljava/u\r\ntil/Map;Lio/grpc/netty/shaded/io/grpc/netty/NegotiationType;Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContext;Lio/grpc/netty/shaded/io/netty/channel/EventLoopGroup;IIIJJZLio/grpc/internal/TransportTra\r\ncer;)V+45\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder.buildTransportFactory()Lio/grpc/internal/ClientTransportFactory;+59\r\nj  io.grpc.internal.AbstractManagedChannelImplBuilder.build()Lio/grpc/ManagedChannel;+10\r\nj  com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel()Lio/grpc/ManagedChannel;+261\r\nj  com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel()Lcom/google/api/gax/rpc/TransportChannel;+19\r\nj  com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel()Lcom/google/api/gax/rpc/TransportChannel;+52\r\nj  com.google.cloud.pubsub.v1.Subscriber.doStart()V+25\r\nj  com.google.api.core.AbstractApiService$InnerService.doStart()V+4\r\nj  com.google.common.util.concurrent.AbstractService.startAsync()Lcom/google/common/util/concurrent/Service;+33\r\nj  com.google.api.core.AbstractApiService.startAsync()Lcom/google/api/core/ApiService;+4\r\nj  com.google.cloud.pubsub.v1.Subscriber.startAsync()Lcom/google/api/core/ApiService;+1\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3535",
        "number": 3535,
        "title": "FirestoreOptions not loading projectid from credentials correctly",
        "labels": [
            "api: firestore",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "I recently migrated from an older version (0.45) where I configured firestore using the FirebaseOptions, e.g.\r\n```java\r\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(_firebaseCredentialsPath));\r\nFirebaseOptions options = new FirebaseOptions.Builder()\r\n            .setCredentials(credentials)\r\n            .build();\r\n FirebaseApp.initializeApp(options);\r\n _database = FirestoreClient.getFirestore();\r\n```\r\nThis works. I migrated to the new way of doing things with FirestoreOptions (0.56.0).  I got warnings to change the configuration.  So the resulting code is now: \r\n\r\n```java\r\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(_firebaseCredentialsPath));\r\nFirestoreOptions fireStoreOptions =\r\n            FirestoreOptions.newBuilder().setTimestampsInSnapshotsEnabled(true)\r\n                    .setCredentials(credentials)\r\n                    .build();\r\n_database = fireStoreOptions.getService();\r\n```\r\nHowever, this code fails.  It requires that the projectId field be set using .setProjectId(\"...\"). In my case it defaulted to another project in cloud that did not have firestore enabled. Perhaps the default project in cloud? It's unclear. This seems like a bug. The project id is not available from the credentials API, even though it is there. Why is the projectid being ignored / not set from credentials correctly?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3534",
        "number": 3534,
        "title": "expose HttpRequest.setInterceptor to allow for throttled uploads",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We have a multi-threaded uploader which transfers large files from local disk to GCS.  The uploader is co-located with our low-latency app. inside the JVM.  To control latency, we must throttle the uploader.   Our best workaround involves resorting to reflection in order to install `HttpRequest` interceptor which effectively wraps `HttpContent` with a throttled `OutputStream`; e.g.,\r\n\r\n```\r\nObject storageRpc = FieldUtils.getField(storage.getClass(), \"storageRpc\", true).get(storage);\r\nObject serviceStorage = FieldUtils.getField(storageRpc.getClass(), \"storage\", true).get(storageRpc);\r\nObject requestFactory = FieldUtils.getField(serviceStorage.getClass(), \"requestFactory\", true).get(serviceStorage);\r\nField initializerField = FieldUtils.getField(requestFactory.getClass(), \"initializer\", true);\r\nObject initializer = initializerField.get(requestFactory);\r\ninitializerField.set(requestFactory, new InterceptingHttpRequestInitializer((HttpRequestInitializer) initializer));\r\n``` "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3533",
        "number": 3533,
        "title": "ServiceOptions.getDefaultProjectId incorrectly defaults to GCE metadata before service account",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "When running on a GCE host, [`ServiceOptions.getDefaultProjectId()`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L332) incorrectly returns the project id from the GCE metadata server instead of defaulting to the project ID specified in the JSON credentials file pointed by the `GOOGLE_APPLICATION_CREDENTIALS` environment variable.\r\n\r\nThis seems to be due to [`getAppEngineProjectId()`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L339) returning a project id even when running outside GAE, causing `getDefaultProjectId()` to not call `getServiceAccountProjectId()`.\r\n\r\nThis seems to have been introduced in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3413 and resulted in the behavior changing from `google-cloud-core` `1.3.0` to `1.4.0`.\r\n\r\nDocumentation: \r\n* https://github.com/GoogleCloudPlatform/google-cloud-java#specifying-a-project-id\r\n* https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L321\r\n\r\nRepro: https://github.com/danielnorberg/google-cloud-java-default-project-bug-repro"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3532",
        "number": 3532,
        "title": "error when initilizing Page<Blob> blobs",
        "labels": [
            "api: storage",
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Upon listing Blob inside the storage, I encounter this error:\r\n\r\njava.lang.NoSuchMethodError: com.google.api.services.storage.Storage$Objects$List.setUserProject(Ljava/lang/String;)Lcom/google/api/services/storage/Storage$Objects$List`\r\n\r\nthe error points at this line.\r\n\r\n``Page<Bucket> buckets = storage.list(BucketListOption.pageSize(100),\r\n    `BucketListOption.prefix(prefix));`\r\n\r\n\r\nmy dependency tree looks like this:\r\n\r\n```\r\nmaven-dependency-plugin:3.0.1:tree (default-cli) @ pipelines-java ---\r\n[INFO] dataflow-stream-ingestion-test:pipelines-java:jar:0.1-SNAPSHOT\r\n[INFO] +- org.apache.beam:beam-sdks-java-core:jar:2.2.0:compile\r\n[INFO] |  \\- org.xerial.snappy:snappy-java:jar:1.1.4:compile\r\n[INFO] +- org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.2.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:jar:2.2.0:compile\r\n[INFO] |  |  +- com.google.cloud.bigdataoss:gcsio:jar:1.4.5:compile\r\n[INFO] |  |  \\- com.google.apis:google-api-services-cloudresourcemanager:jar:v1-rev6-1.22.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-protobuf:jar:2.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-core:jar:1.2.0:compile\r\n[INFO] |  |  +- com.google.errorprone:error_prone_annotations:jar:2.0.11:compile\r\n[INFO] |  |  +- io.grpc:grpc-context:jar:1.2.0:compile\r\n[INFO] |  |  \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n[INFO] |  +- com.google.api:gax-grpc:jar:0.20.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-grpc:jar:1.2.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-pubsub:jar:v1-rev10-1.22.0:compile\r\n[INFO] |  +- com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.cloud.bigdataoss:util:jar:1.4.5:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-java6:jar:1.20.0:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-jackson2:jar:1.20.0:compile\r\n[INFO] |  |  +- com.google.oauth-client:google-oauth-client:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.oauth-client:google-oauth-client-java6:jar:1.20.0:compile\r\n[INFO] |  +- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.4.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.http-client:google-http-client-jackson:jar:1.20.0:compile\r\n[INFO] |  +- io.grpc:grpc-auth:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-netty:jar:1.2.0:compile\r\n[INFO] |  |  +- io.netty:netty-codec-http2:jar:4.1.8.Final:compile (version selected from constraint [4.1.8.Final,4.1.8.Final])\r\n[INFO] |  |  |  \\- io.netty:netty-codec-http:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-handler-proxy:jar:4.1.8.Final:compile\r\n[INFO] |  |     \\- io.netty:netty-codec-socks:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.netty:netty-handler:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-buffer:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-common:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-transport:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-resolver:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-codec:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.grpc:grpc-stub:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-all:jar:1.2.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-okhttp:jar:1.2.0:compile\r\n[INFO] |  |  |  +- com.squareup.okhttp:okhttp:jar:2.5.0:compile\r\n[INFO] |  |  |  \\- com.squareup.okio:okio:jar:1.6.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf-nano:jar:1.2.0:compile\r\n[INFO] |  |     \\- com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-spanner:jar:0.20.0-beta:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  \\- com.google.api.grpc:grpc-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  |     \\- com.google.api.grpc:proto-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0-pre3:compile\r\n[INFO] |  |  +- commons-logging:commons-logging:jar:1.2:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-appengine:jar:0.7.0:compile\r\n[INFO] |  |  \\- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile\r\n[INFO] |  +- com.google.api-client:google-api-client:jar:1.22.0:compile\r\n[INFO] |  +- com.google.http-client:google-http-client:jar:1.22.0:compile\r\n[INFO] |  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO] |  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO] |  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-jackson2:jar:1.22.0:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-credentials:jar:0.7.1:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.7.1:compile\r\n[INFO] |  +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:jar:0.1.9:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n[INFO] +- org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.2.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-common-runner-api:jar:2.2.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-dataflow:jar:v1b3-rev213-1.22.0:compile\r\n[INFO] |  \\- com.google.apis:google-api-services-clouddebugger:jar:v2-rev8-1.22.0:compile\r\n[INFO] +- org.apache.beam:beam-runners-direct-java:jar:2.5.0:compile\r\n[INFO] |  +- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n[INFO] |  +- junit:junit:jar:4.12:compile\r\n[INFO] |  \\- args4j:args4j:jar:2.33:compile\r\n[INFO] +- com.google.cloud:google-cloud-storage:jar:1.38.0:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-appengine:jar:0.7.0:compile\r\n[INFO] |  \\- com.google.cloud:google-cloud-core-http:jar:1.38.0:compile\r\n[INFO] |     +- com.google.http-client:google-http-client-appengine:jar:1.23.0:compile\r\n[INFO] |     +- com.google.api:gax-httpjson:jar:0.46.0:compile\r\n[INFO] |     +- io.opencensus:opencensus-api:jar:0.15.0:compile\r\n[INFO] |     \\- io.opencensus:opencensus-contrib-http-util:jar:0.15.0:compile\r\n[INFO] +- com.google.api:api-common:jar:1.6.0:compile\r\n[INFO] +- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n[INFO] +- joda-time:joda-time:jar:2.4:compile\r\n[INFO] +- com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0:compile\r\n[INFO] |  \\- com.google.api.grpc:grpc-google-common-protos:jar:0.1.0:compile\r\n[INFO] +- com.google.apis:google-api-services-bigquery:jar:v2-rev355-1.22.0:compile\r\n[INFO] +- com.google.protobuf:protobuf-java:jar:3.4.0:compile\r\n[INFO] +- com.google.protobuf:protobuf-java-util:jar:3.3.1:compile\r\n[INFO] +- com.google.code.findbugs:jsr305:jar:3.0.2:compile\r\n[INFO] +- com.google.guava:guava:jar:20.0:compile\r\n[INFO] +- org.json:json:jar:20160810:compile\r\n[INFO] +- com.google.code.gson:gson:jar:2.7:compile\r\n[INFO] +- org.apache.commons:commons-compress:jar:1.8.1:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-core:jar:2.8.8:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-databind:jar:2.8.8:compile\r\n[INFO] +- com.google.cloud:google-cloud-bigquery:jar:1.35.0:compile\r\n[INFO] |  \\- com.google.auto.value:auto-value:jar:1.4:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-annotations:jar:2.8.8:compile\r\n[INFO] +- org.apache.avro:avro:jar:1.8.2:compile\r\n[INFO] |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile\r\n[INFO] |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile\r\n[INFO] |  +- com.thoughtworks.paranamer:paranamer:jar:2.7:compile\r\n[INFO] |  \\- org.tukaani:xz:jar:1.5:compile\r\n[INFO] +- com.google.api:gax:jar:1.30.0:compile\r\n[INFO] |  \\- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO] +- com.google.cloud:google-cloud-core:jar:1.38.0:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.12.0:compile\r\n[INFO] \\- com.google.apis:google-api-services-storage:jar:v1-rev97-1.22.0:compile\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3531",
        "number": 3531,
        "title": "resumable uploads do not implement keep-alive correctly",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "We have implemented a multi-threaded storage uploader which uses `BlobWriteChannel` per thread to upload a chunk of a local file.  (Once all chunks are uploaded, `compose` operation completes the transfer.)  Despite `keep-alive` being enabled, (http) connections are not re-used, requiring a rather expensive TLS handshake on _every_ subsequent (file) upload.\r\n\r\nThe problem lies in the current implementation of resumable uploads.  Each intermediate `PUT` request (corresponding to a chunk being uploaded), except the last one, will result in `308` response code (see [1]) and consequently `HttpResponse.disconnect` (see [2]).\r\n\r\nThus, the corresponding connection is closed, effectively requiring a new handshake for each intermediate chunk in the subsequent upload.\r\n\r\n[1] https://cloud.google.com/storage/docs/json_api/v1/how-tos/resumable-upload\r\n[2] https://github.com/google/google-http-java-client/blob/release-1.24.1/google-http-client/src/main/java/com/google/api/client/http/HttpRequest.java#L1074\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3526",
        "number": 3526,
        "title": "google-cloud-bom has  extra > in google-cloud-tasks version",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "```    \r\n     <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-tasks</artifactId>\r\n        <version>>0.56.0-beta</version><!-- {x-version-update:google-cloud-tasks:current} -->\r\n      </dependency>\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3525",
        "number": 3525,
        "title": "Errors received in OCR requests to Cloud Vision through Java library",
        "labels": [
            "api: vision",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "Lot of our requests to Google Vision service are being failing with below error response from Google Vision service:\r\n\"We can not access the URL currently. Please download the content and pass it in.\"\r\n\r\nThe images are accessible publicly.\r\nSome samples:\r\nhttps://media.cheggcdn.com/media%2Fcb6%2Fcb6cd4d5-9514-44b2-bc13-fbe2a7ba075b%2FphpfPVqJT.png\r\nhttps://media.cheggcdn.com/media%2Fc0f%2Fc0f3d013-9c10-4a93-b04b-290a9b3e1b15%2FphpZrrY0q.png\r\nhttps://media.cheggcdn.com/media%2F260%2F260698fa-d72c-40b0-b30c-860607d06d06%2FphpdTycEW.png\r\n\r\nIf we retry the same images after some time, the OCR works fine. So the issue is very intermittent but is happening for almost 30 requests out of 50.\r\n\r\nWe are using the following libraries:\r\n```\r\n  'com.google.api-client:google-api-client:1.22.0',\r\n  'com.google.http-client:google-http-client:1.22.0',\r\n  'com.google.apis:google-api-services-vision:v1-rev369-1.22.0',\r\n  'com.google.apis:google-api-services-oauth2:v2-rev133-1.23.0',\r\n  'com.google.http-client:google-http-client-jackson2:1.23.0',\r\n  'com.google.oauth-client:google-oauth-client:1.23.0'\r\n```\r\n\r\nWe pass the image URL in the Vision request.\r\n```\r\nnew AnnotateImageRequest()\r\n            .setImage(new Image().setSource(new ImageSource().set(\"imageUri\", document.getImage())))\r\n            .setFeatures(ImmutableList.of(new Feature().setType(GoogleVision.FEATURE_TEXT_DETECTION)))\r\n```\r\nCan someone please help us in resolving it. \r\n\r\nI also found https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-vision which shows below artifact to be used:\r\ncompile 'com.google.cloud:google-cloud-vision:1.38.0'\r\n\r\nNot sure why are there two kinds of artifacts for Cloud Vision library.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3518",
        "number": 3518,
        "title": "Publish batch operation for pub sub",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "We have an api which wraps pub sub, we accept messages one at a time, do some light processing and put them on pub sub. Are clients are slow because they need to wait  one round trip before sending the next. It would be better if they could send us a large batch and in the api we put them all on to pubsub as a batch. \r\n\r\nThe java api hides pub subs batch write message behind a queuing / buffering layer. While this is nice for some use-cases it would be good if there was a simple way to publish a batch of messages to pub sub atomically. If we were to accept a batch from our client and pass them to the java api it could get split across two batches, and a partial write could occur"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3517",
        "number": 3517,
        "title": "[BigQuery] Schema autodetection does not seem to work when loading JSON data via the Java API",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "When trying to import a JSON file into BigQuery from GCS using schema autodetection via\r\n\r\n```java\r\nLoadJobConfiguration.builder(table, path)\r\n      .setAutodetect(true)\r\n      .setIgnoreUnknownValues(false)\r\n      .setMaxBadRecords(0)\r\n      .setFormatOptions(FormatOptions.json())\r\n      .setCreateDisposition(CreateDisposition.CREATE_IF_NEEDED)\r\n      .setWriteDisposition(WriteDisposition.WRITE_TRUNCATE)\r\n      .build()\r\n```\r\n\r\nI receive the error \"Schema has no fields\". I would expect the schema to be autodetected (see also https://cloud.google.com/bigquery/docs/schema-detect).\r\n\r\nTested using version 1.37.1 of google-cloud-bigquery.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3515",
        "number": 3515,
        "title": "pubsub: expire old processing time measurements",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "The pubsub client currently measures time between reception and ack of messages (processing time) in a percentile distribution. The 99%th value of this percentile distribution is used as the ack deadline for messages. This has the the positive effect of reducing the amount of modacks (used to send the ack deadline); a single modack with the right time for a message is better than many modacks with an incorrect arbitrarily low time.\r\n\r\nUnfortunately, since we use the 99%th value, we effectively always take the ceiling (excluding extreme outliers - the remaining 1%). Furthermore, since we don't expire data, a very small amount of high values at some point in time will dominate any low values thereafter until the total number of data points is so high as to push the high values into the 1%.\r\n\r\nA simple solution to this downside is to expire recordings after a period of time. I think that 6 hours is a good starting place for how much data to hold on to."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3514",
        "number": 3514,
        "title": "Firestore client stops functioning after 100 snapshot listeners are registered",
        "labels": [
            "api: firestore",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "I've run into an issue with my application where all requests (get/set/update/queries) and listeners stop functioning after the 100th one is added (the first 100 listeners still function, all ones added after just sit idle and never receive any events). If I had to guess what could be causing the issue, I'd guess that there is probably a saturated threadpool somewhere. I tried to look around in the source for that but I couldn't find what I was looking for. \r\n\r\nEdit: After doing some more investigating, it seems that all requests (get, set, update, query, etc)block after that 100th listener is added."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3511",
        "number": 3511,
        "title": "java.lang.AbstractMethodError: io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.getScheduledExecutorService()Ljava/util/concurrent/ScheduledExecutorService;",
        "labels": [
            "api: pubsub",
            "dependencies",
            "grpc",
            "type: question"
        ],
        "state": "closed",
        "body": "I encountered the following stacktrace after I included `\"com.google.cloud\" % \"google-cloud-pubsub\" % \"1.37.1\"` in my project:\r\n\r\n```\r\nCaused by: java.lang.NoSuchMethodError: io.grpc.okhttp.OkHttpChannelProvider.isAndroid()Z\r\n\tat io.grpc.okhttp.OkHttpChannelProvider.priority(OkHttpChannelProvider.java:47) ~[grpc-okhttp-1.0.1.jar:1.0.1]\r\n\tat io.grpc.ManagedChannelProvider$1.getPriority(ManagedChannelProvider.java:49) ~[grpc-core-1.13.1.jar:1.13.1]\r\n\tat io.grpc.ManagedChannelProvider$1.getPriority(ManagedChannelProvider.java:41) ~[grpc-core-1.13.1.jar:1.13.1]\r\n\tat io.grpc.ServiceProviders$1.compare(ServiceProviders.java:78) ~[grpc-core-1.13.1.jar:1.13.1]\r\n\tat java.util.Collections$ReverseComparator2.compare(Collections.java:5178) ~[na:1.8.0_131]\r\n\tat java.util.TimSort.countRunAndMakeAscending(TimSort.java:360) ~[na:1.8.0_131]\r\n\tat java.util.TimSort.sort(TimSort.java:220) ~[na:1.8.0_131]\r\n\tat java.util.Arrays.sort(Arrays.java:1512) ~[na:1.8.0_131]\r\n\tat java.util.ArrayList.sort(ArrayList.java:1454) ~[na:1.8.0_131]\r\n\tat java.util.Collections.sort(Collections.java:175) ~[na:1.8.0_131]\r\n```\r\n\r\nI then thought that the `grpc-okhttp` perhaps needed an upgrade, since it did not match the version of `grpc-core`, but upgrading resulted in another stacktrace:\r\n```\r\nCaused by: java.lang.AbstractMethodError: io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.getScheduledExecutorService()Ljava/util/concurrent/ScheduledExecutorService;\r\n\tat io.grpc.internal.CallCredentialsApplyingTransportFactory.getScheduledExecutorService(CallCredentialsApplyingTransportFactory.java:54) ~[grpc-core-1.13.1.jar:1.13.1]\r\n\tat io.grpc.internal.ManagedChannelImpl.<init>(ManagedChannelImpl.java:576) ~[grpc-core-1.13.1.jar:1.13.1]\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:410) ~[grpc-core-1.13.1.jar:1.13.1]\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:206) ~[gax-grpc-1.29.0.jar:1.29.0]\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:157) ~[gax-grpc-1.29.0.jar:1.29.0]\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:149) ~[gax-grpc-1.29.0.jar:1.29.0]\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:151) ~[gax-1.29.0.jar:1.29.0]\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:116) ~[gax-1.29.0.jar:1.29.0]\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:127) ~[google-cloud-logging-1.37.1.jar:1.37.1]\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:64) ~[google-cloud-logging-1.37.1.jar:1.37.1]\r\n```\r\n\r\nThe dependencies in `build.sbt` currently look like this:\r\n```\r\nlibraryDependencies ++= Seq(\r\n  \"com.google.cloud\" % \"google-cloud-core\" % \"1.37.1\",\r\n  jdbc,\r\n  cache,\r\n  ws,\r\n  evolutions,\r\n  \"mysql\" % \"mysql-connector-java\" % \"5.1.28\",\r\n  \"com.google.cloud.sql\" % \"mysql-socket-factory\" % \"1.0.2\",\r\n  \"com.roundeights\" %% \"hasher\" % \"1.2.0\",\r\n  \"io.intercom\" % \"intercom-java\" % \"2.3.3\",\r\n  \"com.mixpanel\" % \"mixpanel-java\" % \"1.4.2\",\r\n  \"eu.inn\" %% \"fluentd-scala\" % \"0.1.13\",\r\n  \"com.typesafe.play\" %% \"anorm\" % \"2.4.0\",\r\n  \"com.google.firebase\" % \"firebase-admin\" % \"4.0.3\",\r\n  \"org.specs2\" %% \"specs2-core\" % \"3.6.2\" % \"test\",\r\n  \"us.raudi.pushraven\" % \"Pushraven\" % \"1.0.2\",\r\n  \"com.google.cloud\" % \"google-cloud-speech\" % \"0.20.1-alpha\",\r\n  \"com.google.auth\" % \"google-auth-library-oauth2-http\" % \"0.6.0\",\r\n  \"com.google.cloud\" % \"google-cloud-logging\" % \"1.37.1\",\r\n  \"com.google.guava\" % \"guava\" % \"25.1-jre\",\r\n  \"com.github.rishabh9\" %% \"mdc-propagation-dispatcher\" % \"0.0.5\",\r\n  \"com.github.nscala-time\" %% \"nscala-time\" % \"2.18.0\",\r\n  \"com.google.cloud\" % \"google-cloud-datastore\" % \"1.14.0\",\r\n  \"com.github.davidmoten\" % \"geo\" % \"0.7.1\",\r\n  \"com.danielasfregola\" %% \"twitter4s\" % \"3.0\",\r\n  \"com.google.cloud\" % \"google-cloud-pubsub\" % \"1.37.1\"\r\n)\r\n\r\nlibraryDependencies += specs2 % Test\r\n```\r\n\r\nAny idea what might be wrong?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3510",
        "number": 3510,
        "title": "How do I log in Flexible Environment Java, bundling by request?",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "open",
        "body": "I understand that this can be [done using Logback](https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-contrib/google-cloud-logging-logback) but will appreciate an example that captures  the trace ID in  a Servlet filter then sets a `ThreadLocal `(perhaps using `TraceLoggingEnhancer.setCurrentTraceId(String id)` . (Does this automatically propagate to spunoff threads like `InheritableThreadLocal`?) \r\n\r\nThis approach was recommended in a message from the runtime team that was passed to me.\r\n\r\nGood documentation would be a modification of the [Hello World app](https://cloud.google.com/java/getting-started/hello-world) to illustrate this.\r\n\r\nI appreciate that the above looks simple to those at Google who are involved, but outsiders have  less information on this and a simple example  will speed up our work many-fold."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3509",
        "number": 3509,
        "title": "null returned when calling field.getMode()",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\nwhen calling ` field.getMode()` in the com.google.cloud.bigquery.Field, I got null returned when I creating field by \r\n```java\r\npublic static Field of(String name, LegacySQLTypeName type, Field... subFields) {\r\n    return newBuilder(name, type, subFields).build();\r\n  }\r\n``` \r\nwhich only set the name and type, do you think this should set the default mode of `nullable` when not specified a mode"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3508",
        "number": 3508,
        "title": "Can't find the library for the Pubsub class",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, I'm trying to replicate the functionality in java similar to the google-dts repo here (which is written in python): https://github.com/mtai/bq-dts-partner-sdk  to be able to listen to pub-sub messages from DTS and send a response. However I can't find the code required in  <artifactId>google-cloud-bigquerydatatransfer</artifactId> library. Searching a little bit I found this library: https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html, however couldn't find the pom to download it. Please let me know what am I missing."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3505",
        "number": 3505,
        "title": "google cloud big query does not have badRecords field for LoadJobStatistics",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It is in the generated model classes, this field would be nice"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3503",
        "number": 3503,
        "title": "cannot import PubSub classes used in documentation",
        "labels": [],
        "state": "closed",
        "body": "Using the latest version, `1.37.1`, I cannot import certain pubsub classes, only the ones listed here: https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html\r\n\r\nI am calling the Java methods from Clojure. I tried all the `1.x.y` packages and they all show the same behavior.\r\n\r\nIn all of the documentation of how to use the library, other Classes are needed/used, like `Topic`. Example: trying to list the topics requires both `Topic`, `ListTopicsRequest` and `ListTopicsPagedResponse`, none of which I can import: https://cloud.google.com/pubsub/docs/admin#pubsub-list-topics-java\r\n\r\nA few other examples of classes I can't import are `PubsubMessage` and `ReceivedMessage`, both used in the most basic Publisher flow documented here: https://cloud.google.com/pubsub/docs/publisher\r\n\r\nBehavior:\r\n`(import '[com.google.cloud.pubsub.v1 Topic])` throws this exception:\r\n```\r\n1. Unhandled java.lang.ClassNotFoundException\r\n   com.google.cloud.pubsub.v1.Topic\r\n\r\n       URLClassLoader.java:  381  java.net.URLClassLoader/findClass\r\n   DynamicClassLoader.java:   69  clojure.lang.DynamicClassLoader/findClass\r\n          ClassLoader.java:  424  java.lang.ClassLoader/loadClass\r\n   DynamicClassLoader.java:   77  clojure.lang.DynamicClassLoader/loadClass\r\n          ClassLoader.java:  357  java.lang.ClassLoader/loadClass\r\n                Class.java:   -2  java.lang.Class/forName0\r\n                Class.java:  348  java.lang.Class/forName\r\n                   RT.java: 2204  clojure.lang.RT/classForName\r\n                   RT.java: 2217  clojure.lang.RT/classForNameNonLoading\r\n                      REPL:   54  user/eval13999\r\n                      REPL:   54  user/eval13999\r\n             Compiler.java: 7062  clojure.lang.Compiler/eval\r\n             Compiler.java: 7052  clojure.lang.Compiler/eval\r\n             Compiler.java: 7025  clojure.lang.Compiler/eval\r\n                  core.clj: 3211  clojure.core/eval\r\n                  core.clj: 3207  clojure.core/eval\r\n                  main.clj:  243  clojure.main/repl/read-eval-print/fn\r\n                  main.clj:  243  clojure.main/repl/read-eval-print\r\n                  main.clj:  261  clojure.main/repl/fn\r\n                  main.clj:  261  clojure.main/repl\r\n                  main.clj:  177  clojure.main/repl\r\n               RestFn.java: 1523  clojure.lang.RestFn/invoke\r\n    interruptible_eval.clj:   87  clojure.tools.nrepl.middleware.interruptible-eval/evaluate/fn\r\n                  AFn.java:  152  clojure.lang.AFn/applyToHelper\r\n                  AFn.java:  144  clojure.lang.AFn/applyTo\r\n                  core.clj:  657  clojure.core/apply\r\n                  core.clj: 1970  clojure.core/with-bindings*\r\n                  core.clj: 1970  clojure.core/with-bindings*\r\n               RestFn.java:  425  clojure.lang.RestFn/invoke\r\n    interruptible_eval.clj:   85  clojure.tools.nrepl.middleware.interruptible-eval/evaluate\r\n    interruptible_eval.clj:   55  clojure.tools.nrepl.middleware.interruptible-eval/evaluate\r\n    interruptible_eval.clj:  222  clojure.tools.nrepl.middleware.interruptible-eval/interruptible-eval/fn/fn\r\n    interruptible_eval.clj:  190  clojure.tools.nrepl.middleware.interruptible-eval/run-next/fn\r\n                  AFn.java:   22  clojure.lang.AFn/run\r\n   ThreadPoolExecutor.java: 1142  java.util.concurrent.ThreadPoolExecutor/runWorker\r\n   ThreadPoolExecutor.java:  617  java.util.concurrent.ThreadPoolExecutor$Worker/run\r\n               Thread.java:  745  java.lang.Thread/run\r\n```\r\n\r\nI am able to import TopicAdminClient, and the other classes listed just on this page: https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html\r\n```\r\nuser> (import '[com.google.cloud.pubsub.v1 TopicAdminClient])\r\ncom.google.cloud.pubsub.v1.TopicAdminClient\r\n```\r\n\r\nMy `java -version`:\r\n```\r\njava version \"1.8.0_171\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_171-b11)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode)\r\n```\r\nmy `:dependencies` in project.clj:\r\n```\r\n                 [[camel-snake-kebab \"0.2.5\" :exclusions [org.clojure/clojure]]\r\n                 [ch.qos.logback/logback-classic \"1.2.3\" :scope \"provided\"]\r\n                 [clj-json \"0.5.3\"]\r\n                 [com.amazonaws/aws-java-sdk \"1.9.34\" :exclusions [joda-time]]\r\n                 [com.climate/claypoole \"1.1.1\"]\r\n                 [com.google.cloud/google-cloud-datastore \"1.37.1\"]\r\n                 [com.google.cloud/google-cloud-pubsub \"1.37.1\"]\r\n                 [com.google.cloud/google-cloud-storage \"1.37.1\"]\r\n                 [com.googlecode.concurrentlinkedhashmap/concurrentlinkedhashmap-lru \"1.3.1\"]\r\n                 [commons-codec \"1.5\"]\r\n                 [io.grpc/grpc-protobuf \"1.0.1\"]\r\n                 [metosin/spec-tools \"0.2.0\"]\r\n                 [org.clojure/clojure \"1.9.0-beta2\"]\r\n                 ;; required for spec-tools, not actually used\r\n                 [org.clojure/clojurescript \"1.9.518\"]\r\n                 [org.clojure/core.async \"0.3.443\"]\r\n                 [org.clojure/data.json \"0.2.5\"]\r\n                 [org.clojure/test.check \"0.9.0\" :scope \"test\"]\r\n                 [org.clojure/tools.logging \"0.3.1\"]\r\n                 [org.slf4j/slf4j-api \"1.7.25\"]\r\n                 [prismatic/plumbing \"0.5.4\"]\r\n                 [prismatic/schema \"1.1.7\"]\r\n                 [ring \"1.4.0\"]]\r\n```\r\n\r\nI've searched around for other folks having this issue but can't seem to find anything. Is there anything obvious I'm missing? Thanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3502",
        "number": 3502,
        "title": "Speech is taking a long time to respond",
        "labels": [
            "api: speech",
            "performance",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "The customer is using a sip client called peers to redirect stream from a VoIP call to speech API but the customer is seeing a latency of approximately 8 seconds before they can receive the first response from the server. This is their [code](https://github.com/absin1/peersNew/blob/master/peers-demo/src/main/java/net/sourceforge/peers/demo/StreamSoundManager1.java). The method `writeData(byte[] buffer, int offset, int length)` is a callback function to receiving data from the VoIP call and in this method the customer constructs a `streamingRecognizeRequest` from the bytes received and sends the request to the server. The customer also mentioned that they already checked that bytes from VoIP has no latency. \r\n\r\nMore discussions from [3188](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/3188#issuecomment-406766162)\r\n\r\ncc/ @absin1 "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3500",
        "number": 3500,
        "title": "bring back polling pull",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "streaming pull, while very fast, has the problem that very long running messages (> 30min) might duplicate."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3496",
        "number": 3496,
        "title": "Update google.auth.version to 0.10.0",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "There were some critical enhancements in the `google-auth-library-oauth2-http` library.  Please upgrade from 0.9.1 to 0.10.0."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3492",
        "number": 3492,
        "title": "Could not initialize class com.google.cloud.bigquery.datatransfer.v1.stub.GrpcDataTransferServiceStub",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm trying to use BQ Data transfer client just to list supported data sources as an example but I'm seeing this error:\r\n\"java.lang.NoClassDefFoundError: Could not initialize class com.google.cloud.bigquery.datatransfer.v1.stub.GrpcDataTransferServiceStub\"\r\nThis is my pom:\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-bigquerydatatransfer</artifactId>\r\n            <version>0.55.1-beta</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.protobuf</groupId>\r\n            <artifactId>protobuf-java</artifactId>\r\n            <version>3.1.0</version>\r\n        </dependency>\r\n\r\nThis is the sample code:\r\n```java\r\n        Credentials credentials = GoogleCredentials\r\n                .fromStream(new FileInputStream(credsFile));\r\n//        googleCloudStorage = StorageOptions.newBuilder().setCredentials(credentials)\r\n//                .setProjectId(projectId).build().getService();\r\n\r\n        DataTransferServiceSettings transferServiceSettings = DataTransferServiceSettings.newBuilder()\r\n                .setCredentialsProvider(FixedCredentialsProvider.create(credentials))\r\n                .build();\r\n        // Instantiate a client. If you don't specify credentials when constructing a client, the\r\n        // client library will look for credentials in the environment, such as the\r\n        // GOOGLE_APPLICATION_CREDENTIALS environment variable.\r\n        try (DataTransferServiceClient client = DataTransferServiceClient.create(transferServiceSettings)) {\r\n            // Request the list of available data sources.\r\n            String parent = String.format(\"projects/%s\", projectId);\r\n            ListDataSourcesRequest request =\r\n                    ListDataSourcesRequest.newBuilder()\r\n                            .setParent(parent)\r\n                            .build();\r\n            ListDataSourcesPagedResponse response = client.listDataSources(request);\r\n```\r\nIt throws error at the line where dts client is initialized: \r\nDataTransferServiceClient.create(transferServiceSettings)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3488",
        "number": 3488,
        "title": "Getting `com.google.common.util.concurrent.MoreExecutors.directExecutor` for using BigQuery",
        "labels": [
            "api: bigquery",
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi all.\r\n\r\nI am getting `java.lang.NoSuchMethodError: com.google.common.util.concurrent.MoreExecutors.directExecutor`for a line:\r\n\r\n```java\r\nTableDataWriteChannel writer = bigQuery.writer(writeChannelConfiguration);\r\n````\r\n\r\nHere is the part of stacktrace:\r\n```\r\njava.lang.NoSuchMethodError: com.google.common.util.concurrent.MoreExecutors.directExecutor()Ljava/util/concurrent/Executor;\r\n\tat com.google.api.gax.retrying.BasicRetryingFuture.<init>(BasicRetryingFuture.java:77)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.createFuture(DirectRetryingExecutor.java:73)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:73)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.bigquery.TableDataWriteChannel.open(TableDataWriteChannel.java:76)\r\n\tat com.google.cloud.bigquery.TableDataWriteChannel.<init>(TableDataWriteChannel.java:41)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.writer(BigQueryImpl.java:729)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.writer(BigQueryImpl.java:720)\r\n```\r\n\r\nI have investigated this error and it seems that this is usually caused by the old version of guava leaking into the dependency. However, it does not seem to be the case here. Below are snippets of `pom.xml` and the result of `mvn dependency:tree`:\r\n\r\npom.xml -->\r\n```\r\n\r\n <dependencyManagement>\r\n   <dependencies>\r\n     <dependency>\r\n       <groupId>com.amazonaws</groupId>\r\n       <artifactId>aws-java-sdk-bom</artifactId>\r\n       <version>1.11.320</version>\r\n       <type>pom</type>\r\n       <scope>import</scope>\r\n     </dependency>\r\n       <dependency>\r\n           <groupId>com.google.guava</groupId>\r\n           <artifactId>guava</artifactId>\r\n           <version>25.0-jre</version>\r\n       </dependency>\r\n   </dependencies>\r\n </dependencyManagement>\r\n <dependencies>\r\n     <dependency>\r\n       <groupId>org.apache.httpcomponents</groupId>\r\n       <artifactId>httpclient</artifactId>\r\n       <version>4.5.4</version>\r\n     </dependency>\r\n   <dependency>\r\n       <groupId>org.apache.spark</groupId>\r\n       <artifactId>spark-streaming_2.11</artifactId>\r\n       <version>2.2.0</version>\r\n   </dependency>\r\n   \r\n   <dependency>\r\n       <groupId>org.json</groupId>\r\n       <artifactId>json</artifactId>\r\n       <version>20160810</version>\r\n   </dependency>\r\n   <dependency>\r\n     <groupId>com.amazonaws</groupId>\r\n     <artifactId>aws-java-sdk-s3</artifactId>\r\n   </dependency>\r\n   <dependency>\r\n     <groupId>com.amazonaws</groupId>\r\n     <artifactId>aws-java-sdk-lambda</artifactId>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.amazonaws</groupId>\r\n       <artifactId>aws-java-sdk-kms</artifactId>\r\n   </dependency>\r\n   <dependency>\r\n     <groupId>org.apache.commons</groupId>\r\n     <artifactId>commons-lang3</artifactId>\r\n     <version>3.5</version>\r\n   </dependency>\r\n   <dependency>\r\n     <groupId>junit</groupId>\r\n     <artifactId>junit</artifactId>\r\n     <version>3.8.1</version>\r\n     <scope>test</scope>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>org.apache.spark</groupId>\r\n       <artifactId>spark-core_2.11</artifactId>\r\n       <version>2.2.0</version>\r\n       <scope>provided</scope>\r\n       <exclusions>\r\n           <exclusion> <!-- exclude an old version of Guava -->\r\n               <groupId>com.google.guava</groupId>\r\n               <artifactId>guava-jdk5</artifactId>\r\n           </exclusion>\r\n           <exclusion> <!-- exclude an old version of Guava -->\r\n               <groupId>com.google.guava</groupId>\r\n               <artifactId>guava</artifactId>\r\n           </exclusion>\r\n       </exclusions>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>org.scala-lang</groupId>\r\n       <artifactId>scala-library</artifactId>\r\n       <version>2.11.8</version>\r\n       <scope>provided</scope>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>org.apache.spark</groupId>\r\n       <artifactId>spark-sql_2.11</artifactId>\r\n       <version>2.2.0</version>\r\n       <scope>provided</scope>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.fasterxml.jackson.dataformat</groupId>\r\n       <artifactId>jackson-dataformat-csv</artifactId>\r\n       <version>2.6.5</version>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.hubspot.jinjava</groupId>\r\n       <artifactId>jinjava</artifactId>\r\n       <version>2.3.4</version>\r\n       <exclusions>\r\n           <exclusion> <!-- exclude an old version of Guava -->\r\n               <groupId>com.google.guava</groupId>\r\n               <artifactId>guava-jdk5</artifactId>\r\n           </exclusion>\r\n           <exclusion> <!-- exclude an old version of Guava -->\r\n               <groupId>com.google.guava</groupId>\r\n               <artifactId>guava</artifactId>\r\n           </exclusion>\r\n       </exclusions>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.fasterxml.jackson.dataformat</groupId>\r\n       <artifactId>jackson-dataformat-yaml</artifactId>\r\n       <version>2.6.5</version>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.fasterxml.jackson.core</groupId>\r\n       <artifactId>jackson-databind</artifactId>\r\n       <version>2.6.5</version>\r\n   </dependency>\r\n   \r\n\r\n     <dependency>\r\n         <groupId>com.google.guava</groupId>\r\n         <artifactId>guava</artifactId>\r\n         <version>25.0-jre</version>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.google.cloud</groupId>\r\n         <artifactId>google-cloud-bigquery</artifactId>\r\n         <version>1.36.0</version>\r\n     </dependency>\r\n     \r\n     <dependency>\r\n         <groupId>com.google.apis</groupId>\r\n         <artifactId>google-api-services-pubsub</artifactId>\r\n         <version>v1-rev395-1.23.0</version>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.google.cloud</groupId>\r\n         <artifactId>google-cloud-storage</artifactId>\r\n         <version>1.36.0</version>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.google.api-client</groupId>\r\n         <artifactId>google-api-client</artifactId>\r\n         <version>1.23.0</version>\r\n         <exclusions>\r\n             <exclusion> <!-- exclude an old version of Guava -->\r\n                 <groupId>com.google.guava</groupId>\r\n                 <artifactId>guava-jdk5</artifactId>\r\n             </exclusion>\r\n             <exclusion> <!-- exclude an old version of Guava -->\r\n                 <groupId>com.google.guava</groupId>\r\n                 <artifactId>guava</artifactId>\r\n             </exclusion>\r\n         </exclusions>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.google.cloud</groupId>\r\n         <artifactId>google-cloud-pubsub</artifactId>\r\n         <version>1.36.0</version>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.google.api</groupId>\r\n         <artifactId>gax</artifactId>\r\n         <version>1.29.0</version>\r\n         <exclusions>\r\n             <exclusion> <!-- exclude an old version of Guava -->\r\n                 <groupId>com.google.guava</groupId>\r\n                 <artifactId>guava-jdk5</artifactId>\r\n             </exclusion>\r\n             <exclusion> <!-- exclude an old version of Guava -->\r\n                 <groupId>com.google.guava</groupId>\r\n                 <artifactId>guava</artifactId>\r\n             </exclusion>\r\n         </exclusions>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.google.api</groupId>\r\n         <artifactId>gax-grpc</artifactId>\r\n         <version>1.29.0</version>\r\n         <scope>test</scope>\r\n         <exclusions>\r\n             <exclusion> <!-- exclude an old version of Guava -->\r\n                 <groupId>com.google.guava</groupId>\r\n                 <artifactId>guava-jdk5</artifactId>\r\n             </exclusion>\r\n             <exclusion> <!-- exclude an old version of Guava -->\r\n                 <groupId>com.google.guava</groupId>\r\n                 <artifactId>guava</artifactId>\r\n             </exclusion>\r\n         </exclusions>\r\n     </dependency>\r\n    \r\n     <dependency>\r\n         <groupId>com.amazonaws</groupId>\r\n         <artifactId>aws-java-sdk-redshift</artifactId>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.amazon.redshift</groupId>\r\n         <artifactId>redshift-jdbc42</artifactId>\r\n         <version>1.2.1.1001</version>\r\n     </dependency>\r\n     <dependency>\r\n        <groupId>org.postgresql</groupId>\r\n        <artifactId>postgresql</artifactId>\r\n        <version>42.1.1</version>\r\n     </dependency>\r\n   <dependency>\r\n       <groupId>postgresql</groupId>\r\n       <artifactId>postgresql</artifactId>\r\n       <version>9.1-901-1.jdbc4</version>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.auth0</groupId>\r\n       <artifactId>java-jwt</artifactId>\r\n       <version>3.1.0</version>\r\n   </dependency>\r\n   <dependency>\r\n       <groupId>com.jcraft</groupId>\r\n       <artifactId>jsch</artifactId>\r\n       <version>0.1.54</version>\r\n   </dependency>\r\n     <dependency>\r\n         <groupId>com.microsoft.azure</groupId>\r\n         <artifactId>adal4j</artifactId>\r\n         <version>1.1.3</version>\r\n     </dependency>\r\n     <dependency>\r\n         <groupId>com.crealytics</groupId>\r\n         <artifactId>spark-excel_2.11</artifactId>\r\n         <version>0.9.15</version>\r\n     </dependency>\r\n </dependencies>\r\n <build>\r\n   <plugins>\r\n       <plugin>\r\n         <groupId>org.apache.maven.plugins</groupId>\r\n         <artifactId>maven-compiler-plugin</artifactId>\r\n         <version>3.3</version>\r\n         <configuration>\r\n              <source>1.8</source>\r\n              <target>1.8</target>\r\n           </configuration>\r\n       </plugin>\r\n       <plugin>\r\n   <groupId>org.apache.maven.plugins</groupId>\r\n   <artifactId>maven-shade-plugin</artifactId>\r\n   <version>2.3</version>\r\n   <executions>\r\n     <execution>\r\n       <phase>package</phase>\r\n       <goals>\r\n         <goal>shade</goal>\r\n       </goals>\r\n       <configuration>\r\n         <transformers>\r\n             <transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/>\r\n         </transformers>\r\n         <filters>\r\n           <filter>\r\n             <artifact>*:*</artifact>\r\n             <excludes>\r\n                <exclude>META-INF/*.SF</exclude>\r\n                <exclude>META-INF/*.DSA</exclude>\r\n                <exclude>META-INF/*.RSA</exclude>\r\n                <exclude>junit:junit</exclude>\r\n                <exclude>org.apache.maven:lib:tests</exclude>\r\n            </excludes>\r\n           </filter>\r\n        </filters>\r\n       </configuration>\r\n     </execution>\r\n   </executions>\r\n </plugin>\r\n   </plugins>\r\n </build>\r\n</project>\r\n```\r\n`mvn dependency:tree` --> \r\n```\r\n[INFO] +- org.apache.httpcomponents:httpclient:jar:4.5.4:compile\r\n[INFO] |  +- org.apache.httpcomponents:httpcore:jar:4.4.7:compile\r\n[INFO] |  +- commons-logging:commons-logging:jar:1.2:compile\r\n[INFO] |  \\- commons-codec:commons-codec:jar:1.10:compile\r\n[INFO] +- org.apache.spark:spark-streaming_2.11:jar:2.2.0:compile\r\n[INFO] |  +- org.apache.spark:spark-tags_2.11:jar:2.2.0:compile\r\n[INFO] |  \\- org.spark-project.spark:unused:jar:1.0.0:compile\r\n[INFO] +- org.json:json:jar:20160810:compile\r\n[INFO] +- com.amazonaws:aws-java-sdk-s3:jar:1.11.320:compile\r\n[INFO] |  +- com.amazonaws:aws-java-sdk-core:jar:1.11.320:compile\r\n[INFO] |  |  +- software.amazon.ion:ion-java:jar:1.0.2:compile\r\n[INFO] |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.6.7:compile\r\n[INFO] |  |  \\- joda-time:joda-time:jar:2.8.1:compile\r\n[INFO] |  \\- com.amazonaws:jmespath-java:jar:1.11.320:compile\r\n[INFO] +- com.amazonaws:aws-java-sdk-lambda:jar:1.11.320:compile\r\n[INFO] +- com.amazonaws:aws-java-sdk-kms:jar:1.11.320:compile\r\n[INFO] +- org.apache.commons:commons-lang3:jar:3.5:compile\r\n[INFO] +- junit:junit:jar:3.8.1:test\r\n[INFO] +- org.apache.spark:spark-core_2.11:jar:2.2.0:provided\r\n[INFO] |  +- org.apache.avro:avro:jar:1.7.7:provided\r\n[INFO] |  |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile\r\n[INFO] |  |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile\r\n[INFO] |  |  +- com.thoughtworks.paranamer:paranamer:jar:2.3:provided\r\n[INFO] |  |  \\- org.apache.commons:commons-compress:jar:1.4.1:provided\r\n[INFO] |  |     \\- org.tukaani:xz:jar:1.0:provided\r\n[INFO] |  +- org.apache.avro:avro-mapred:jar:hadoop2:1.7.7:provided\r\n[INFO] |  |  +- org.apache.avro:avro-ipc:jar:1.7.7:provided\r\n[INFO] |  |  \\- org.apache.avro:avro-ipc:jar:tests:1.7.7:provided\r\n[INFO] |  +- com.twitter:chill_2.11:jar:0.8.0:provided\r\n[INFO] |  |  \\- com.esotericsoftware:kryo-shaded:jar:3.0.3:provided\r\n[INFO] |  |     \\- com.esotericsoftware:minlog:jar:1.3.0:provided\r\n[INFO] |  +- com.twitter:chill-java:jar:0.8.0:provided\r\n[INFO] |  +- org.apache.xbean:xbean-asm5-shaded:jar:4.4:provided\r\n[INFO] |  +- org.apache.hadoop:hadoop-client:jar:2.6.5:provided\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-common:jar:2.6.5:provided\r\n[INFO] |  |  |  +- commons-cli:commons-cli:jar:1.2:provided\r\n[INFO] |  |  |  +- xmlenc:xmlenc:jar:0.52:provided\r\n[INFO] |  |  |  +- commons-httpclient:commons-httpclient:jar:3.1:provided\r\n[INFO] |  |  |  +- commons-collections:commons-collections:jar:3.2.2:provided\r\n[INFO] |  |  |  +- commons-lang:commons-lang:jar:2.6:provided\r\n[INFO] |  |  |  +- commons-configuration:commons-configuration:jar:1.6:provided\r\n[INFO] |  |  |  |  +- commons-digester:commons-digester:jar:1.8:provided\r\n[INFO] |  |  |  |  \\- commons-beanutils:commons-beanutils-core:jar:1.8.0:provided\r\n[INFO] |  |  |  +- org.apache.hadoop:hadoop-auth:jar:2.6.5:provided\r\n[INFO] |  |  |  |  \\- org.apache.directory.server:apacheds-kerberos-codec:jar:2.0.0-M15:provided\r\n[INFO] |  |  |  |     +- org.apache.directory.server:apacheds-i18n:jar:2.0.0-M15:provided\r\n[INFO] |  |  |  |     +- org.apache.directory.api:api-asn1-api:jar:1.0.0-M20:provided\r\n[INFO] |  |  |  |     \\- org.apache.directory.api:api-util:jar:1.0.0-M20:provided\r\n[INFO] |  |  |  +- org.apache.curator:curator-client:jar:2.6.0:provided\r\n[INFO] |  |  |  \\- org.htrace:htrace-core:jar:3.0.4:provided\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-hdfs:jar:2.6.5:provided\r\n[INFO] |  |  |  +- org.mortbay.jetty:jetty-util:jar:6.1.26:compile\r\n[INFO] |  |  |  \\- xerces:xercesImpl:jar:2.9.1:provided\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.6.5:provided\r\n[INFO] |  |  |  +- org.apache.hadoop:hadoop-mapreduce-client-common:jar:2.6.5:provided\r\n[INFO] |  |  |  |  +- org.apache.hadoop:hadoop-yarn-client:jar:2.6.5:provided\r\n[INFO] |  |  |  |  \\- org.apache.hadoop:hadoop-yarn-server-common:jar:2.6.5:provided\r\n[INFO] |  |  |  \\- org.apache.hadoop:hadoop-mapreduce-client-shuffle:jar:2.6.5:provided\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-yarn-api:jar:2.6.5:provided\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.6.5:provided\r\n[INFO] |  |  |  \\- org.apache.hadoop:hadoop-yarn-common:jar:2.6.5:provided\r\n[INFO] |  |  |     +- javax.xml.bind:jaxb-api:jar:2.2.2:provided\r\n[INFO] |  |  |     +- org.codehaus.jackson:jackson-jaxrs:jar:1.9.13:provided\r\n[INFO] |  |  |     \\- org.codehaus.jackson:jackson-xc:jar:1.9.13:provided\r\n[INFO] |  |  +- org.apache.hadoop:hadoop-mapreduce-client-jobclient:jar:2.6.5:provided\r\n[INFO] |  |  \\- org.apache.hadoop:hadoop-annotations:jar:2.6.5:provided\r\n[INFO] |  +- org.apache.spark:spark-launcher_2.11:jar:2.2.0:provided\r\n[INFO] |  +- org.apache.spark:spark-network-common_2.11:jar:2.2.0:provided\r\n[INFO] |  |  \\- org.fusesource.leveldbjni:leveldbjni-all:jar:1.8:provided\r\n[INFO] |  +- org.apache.spark:spark-network-shuffle_2.11:jar:2.2.0:provided\r\n[INFO] |  +- org.apache.spark:spark-unsafe_2.11:jar:2.2.0:provided\r\n[INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.9.3:provided\r\n[INFO] |  |  +- javax.activation:activation:jar:1.1.1:compile\r\n[INFO] |  |  +- mx4j:mx4j:jar:3.0.2:provided\r\n[INFO] |  |  +- javax.mail:mail:jar:1.4.7:compile\r\n[INFO] |  |  \\- com.jamesmurty.utils:java-xmlbuilder:jar:1.0:provided\r\n[INFO] |  |     \\- net.iharder:base64:jar:2.3.8:provided\r\n[INFO] |  +- org.apache.curator:curator-recipes:jar:2.6.0:provided\r\n[INFO] |  |  +- org.apache.curator:curator-framework:jar:2.6.0:provided\r\n[INFO] |  |  \\- org.apache.zookeeper:zookeeper:jar:3.4.6:provided\r\n[INFO] |  +- javax.servlet:javax.servlet-api:jar:3.1.0:compile\r\n[INFO] |  +- org.apache.commons:commons-math3:jar:3.4.1:provided\r\n[INFO] |  +- com.google.code.findbugs:jsr305:jar:1.3.9:compile\r\n[INFO] |  +- org.slf4j:slf4j-api:jar:1.7.16:compile\r\n[INFO] |  +- org.slf4j:jul-to-slf4j:jar:1.7.16:provided\r\n[INFO] |  +- org.slf4j:jcl-over-slf4j:jar:1.7.16:provided\r\n[INFO] |  +- log4j:log4j:jar:1.2.17:compile\r\n[INFO] |  +- org.slf4j:slf4j-log4j12:jar:1.7.16:provided\r\n[INFO] |  +- com.ning:compress-lzf:jar:1.0.3:provided\r\n[INFO] |  +- org.xerial.snappy:snappy-java:jar:1.1.2.6:provided\r\n[INFO] |  +- net.jpountz.lz4:lz4:jar:1.3.0:provided\r\n[INFO] |  +- org.roaringbitmap:RoaringBitmap:jar:0.5.11:provided\r\n[INFO] |  +- commons-net:commons-net:jar:2.2:provided\r\n[INFO] |  +- org.json4s:json4s-jackson_2.11:jar:3.2.11:provided\r\n[INFO] |  |  \\- org.json4s:json4s-core_2.11:jar:3.2.11:provided\r\n[INFO] |  |     +- org.json4s:json4s-ast_2.11:jar:3.2.11:provided\r\n[INFO] |  |     \\- org.scala-lang:scalap:jar:2.11.0:provided\r\n[INFO] |  |        \\- org.scala-lang:scala-compiler:jar:2.11.0:provided\r\n[INFO] |  |           \\- org.scala-lang.modules:scala-parser-combinators_2.11:jar:1.0.1:provided\r\n[INFO] |  +- org.glassfish.jersey.core:jersey-client:jar:2.22.2:provided\r\n[INFO] |  |  +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:provided\r\n[INFO] |  |  +- org.glassfish.hk2:hk2-api:jar:2.4.0-b34:provided\r\n[INFO] |  |  |  +- org.glassfish.hk2:hk2-utils:jar:2.4.0-b34:provided\r\n[INFO] |  |  |  \\- org.glassfish.hk2.external:aopalliance-repackaged:jar:2.4.0-b34:provided\r\n[INFO] |  |  +- org.glassfish.hk2.external:javax.inject:jar:2.4.0-b34:provided\r\n[INFO] |  |  \\- org.glassfish.hk2:hk2-locator:jar:2.4.0-b34:provided\r\n[INFO] |  +- org.glassfish.jersey.core:jersey-common:jar:2.22.2:provided\r\n[INFO] |  |  +- javax.annotation:javax.annotation-api:jar:1.2:provided\r\n[INFO] |  |  +- org.glassfish.jersey.bundles.repackaged:jersey-guava:jar:2.22.2:provided\r\n[INFO] |  |  \\- org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:provided\r\n[INFO] |  +- org.glassfish.jersey.core:jersey-server:jar:2.22.2:provided\r\n[INFO] |  |  +- org.glassfish.jersey.media:jersey-media-jaxb:jar:2.22.2:provided\r\n[INFO] |  |  \\- javax.validation:validation-api:jar:1.1.0.Final:provided\r\n[INFO] |  +- org.glassfish.jersey.containers:jersey-container-servlet:jar:2.22.2:provided\r\n[INFO] |  +- org.glassfish.jersey.containers:jersey-container-servlet-core:jar:2.22.2:provided\r\n[INFO] |  +- io.netty:netty-all:jar:4.0.43.Final:provided\r\n[INFO] |  +- io.netty:netty:jar:3.9.9.Final:provided\r\n[INFO] |  +- com.clearspring.analytics:stream:jar:2.7.0:provided\r\n[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:provided\r\n[INFO] |  +- io.dropwizard.metrics:metrics-jvm:jar:3.1.2:provided\r\n[INFO] |  +- io.dropwizard.metrics:metrics-json:jar:3.1.2:provided\r\n[INFO] |  +- io.dropwizard.metrics:metrics-graphite:jar:3.1.2:provided\r\n[INFO] |  +- com.fasterxml.jackson.module:jackson-module-scala_2.11:jar:2.6.5:provided\r\n[INFO] |  |  +- org.scala-lang:scala-reflect:jar:2.11.7:provided\r\n[INFO] |  |  \\- com.fasterxml.jackson.module:jackson-module-paranamer:jar:2.6.5:provided\r\n[INFO] |  +- org.apache.ivy:ivy:jar:2.4.0:provided\r\n[INFO] |  +- oro:oro:jar:2.0.8:provided\r\n[INFO] |  +- net.razorvine:pyrolite:jar:4.13:provided\r\n[INFO] |  +- net.sf.py4j:py4j:jar:0.10.4:provided\r\n[INFO] |  \\- org.apache.commons:commons-crypto:jar:1.0.0:provided\r\n[INFO] +- org.scala-lang:scala-library:jar:2.11.8:provided\r\n[INFO] +- org.apache.spark:spark-sql_2.11:jar:2.2.0:provided\r\n[INFO] |  +- com.univocity:univocity-parsers:jar:2.2.1:provided\r\n[INFO] |  +- org.apache.spark:spark-sketch_2.11:jar:2.2.0:provided\r\n[INFO] |  +- org.apache.spark:spark-catalyst_2.11:jar:2.2.0:provided\r\n[INFO] |  |  +- org.codehaus.janino:janino:jar:3.0.0:provided\r\n[INFO] |  |  +- org.codehaus.janino:commons-compiler:jar:3.0.0:provided\r\n[INFO] |  |  \\- org.antlr:antlr4-runtime:jar:4.5.3:provided\r\n[INFO] |  +- org.apache.parquet:parquet-column:jar:1.8.2:provided\r\n[INFO] |  |  +- org.apache.parquet:parquet-common:jar:1.8.2:provided\r\n[INFO] |  |  \\- org.apache.parquet:parquet-encoding:jar:1.8.2:provided\r\n[INFO] |  \\- org.apache.parquet:parquet-hadoop:jar:1.8.2:provided\r\n[INFO] |     +- org.apache.parquet:parquet-format:jar:2.3.1:provided\r\n[INFO] |     \\- org.apache.parquet:parquet-jackson:jar:1.8.2:provided\r\n[INFO] +- com.fasterxml.jackson.dataformat:jackson-dataformat-csv:jar:2.6.5:compile\r\n[INFO] |  \\- com.fasterxml.jackson.core:jackson-core:jar:2.6.5:compile\r\n[INFO] +- com.hubspot.jinjava:jinjava:jar:2.3.4:compile\r\n[INFO] |  +- org.javassist:javassist:jar:3.18.2-GA:compile\r\n[INFO] |  +- org.jsoup:jsoup:jar:1.8.1:compile\r\n[INFO] |  \\- com.google.code.findbugs:annotations:jar:3.0.0:compile\r\n[INFO] +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.6.5:compile\r\n[INFO] |  \\- org.yaml:snakeyaml:jar:1.15:compile\r\n[INFO] +- com.fasterxml.jackson.core:jackson-databind:jar:2.6.5:compile\r\n[INFO] |  \\- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.0:compile\r\n[INFO] +- some_project_1:jar:1.0.2:compile\r\n[INFO] |  +- com.google.oauth-client:google-oauth-client-jetty:jar:1.22.0:compile\r\n[INFO] |  |  +- com.google.oauth-client:google-oauth-client-java6:jar:1.22.0:compile\r\n[INFO] |  |  \\- org.mortbay.jetty:jetty:jar:6.1.26:compile\r\n[INFO] |  |     \\- org.mortbay.jetty:servlet-api:jar:2.5-20081211:compile\r\n[INFO] |  \\- com.google.apis:google-api-services-sheets:jar:v4-rev18-1.22.0:compile\r\n[INFO] +- com.google.guava:guava:jar:25.0-jre:compile\r\n[INFO] |  +- org.checkerframework:checker-compat-qual:jar:2.0.0:compile\r\n[INFO] |  +- com.google.errorprone:error_prone_annotations:jar:2.1.3:compile\r\n[INFO] |  +- com.google.j2objc:j2objc-annotations:jar:1.1:compile\r\n[INFO] |  \\- org.codehaus.mojo:animal-sniffer-annotations:jar:1.14:compile\r\n[INFO] +- com.google.cloud:google-cloud-bigquery:jar:1.36.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core:jar:1.36.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client:jar:1.23.0:compile\r\n[INFO] |  |  +- com.google.protobuf:protobuf-java-util:jar:3.6.0:compile\r\n[INFO] |  |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.12.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-http:jar:1.36.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-appengine:jar:1.23.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-jackson:jar:1.23.0:compile\r\n[INFO] |  |  +- com.google.api:gax-httpjson:jar:0.46.0:compile\r\n[INFO] |  |  +- io.opencensus:opencensus-api:jar:0.12.3:compile\r\n[INFO] |  |  \\- io.opencensus:opencensus-contrib-http-util:jar:0.12.3:compile\r\n[INFO] |  +- com.google.auto.value:auto-value:jar:1.4:compile\r\n[INFO] |  \\- com.google.apis:google-api-services-bigquery:jar:v2-rev383-1.23.0:compile\r\n[INFO] +- com.google.apis:google-api-services-pubsub:jar:v1-rev395-1.23.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-storage:jar:1.36.0:compile\r\n[INFO] |  \\- com.google.apis:google-api-services-storage:jar:v1-rev131-1.23.0:compile\r\n[INFO] +- com.google.api-client:google-api-client:jar:1.23.0:compile\r\n[INFO] |  +- com.google.oauth-client:google-oauth-client:jar:1.23.0:compile\r\n[INFO] |  \\- com.google.http-client:google-http-client-jackson2:jar:1.23.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-pubsub:jar:1.36.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-grpc:jar:1.36.0:compile\r\n[INFO] |  |  +- com.google.protobuf:protobuf-java:jar:3.6.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-context:jar:1.13.1:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:1.18.0:compile\r\n[INFO] |  +- com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:1.18.0:compile\r\n[INFO] |  +- io.grpc:grpc-netty-shaded:jar:1.13.1:compile\r\n[INFO] |  |  \\- io.grpc:grpc-core:jar:1.13.1:compile (version selected from constraint [1.13.1,1.13.1])\r\n[INFO] |  |     \\- io.opencensus:opencensus-contrib-grpc-metrics:jar:0.12.3:compile\r\n[INFO] |  +- io.grpc:grpc-stub:jar:1.13.1:compile\r\n[INFO] |  \\- io.grpc:grpc-auth:jar:1.13.1:compile\r\n[INFO] +- com.google.api:gax:jar:1.29.0:compile\r\n[INFO] |  +- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.9.1:compile\r\n[INFO] |  \\- com.google.api:api-common:jar:1.6.0:compile\r\n[INFO] +- com.google.api:gax-grpc:jar:1.29.0:test\r\n[INFO] |  +- io.grpc:grpc-protobuf:jar:1.10.1:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf-lite:jar:1.10.1:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-credentials:jar:0.9.1:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-common-protos:jar:1.0.0:compile\r\n[INFO] +- some_project_2:jar:1.0.7:compile\r\n[INFO] |  +- some_project_3:jar:1.0.7:compile\r\n[INFO] |  |  \\- com.google.apis:google-api-services-sqladmin:jar:v1beta4-rev25-1.22.0:compile\r\n[INFO] |  +- org.apache.commons:commons-text:jar:1.1:compile\r\n[INFO] |  \\- mysql:mysql-connector-java:jar:5.1.38:compile\r\n[INFO] +- some_project_4:jar:1.0.7:compile\r\n[INFO] +- com.amazonaws:aws-java-sdk-redshift:jar:1.11.320:compile\r\n[INFO] +- com.amazon.redshift:redshift-jdbc42:jar:1.2.1.1001:compile\r\n[INFO] +- org.postgresql:postgresql:jar:42.1.1:compile\r\n[INFO] +- postgresql:postgresql:jar:9.1-901-1.jdbc4:compile\r\n[INFO] +- com.auth0:java-jwt:jar:3.1.0:compile\r\n[INFO] |  \\- org.bouncycastle:bcprov-jdk15on:jar:1.55:compile\r\n[INFO] +- com.jcraft:jsch:jar:0.1.54:compile\r\n[INFO] +- com.microsoft.azure:adal4j:jar:1.1.3:compile\r\n[INFO] |  +- com.nimbusds:oauth2-oidc-sdk:jar:4.5:compile\r\n[INFO] |  |  +- net.jcip:jcip-annotations:jar:1.0:compile\r\n[INFO] |  |  +- net.minidev:json-smart:jar:1.1.1:compile\r\n[INFO] |  |  +- com.nimbusds:lang-tag:jar:1.4:compile\r\n[INFO] |  |  \\- com.nimbusds:nimbus-jose-jwt:jar:3.1.2:compile\r\n[INFO] |  \\- com.google.code.gson:gson:jar:2.2.4:compile\r\n[INFO] \\- com.crealytics:spark-excel_2.11:jar:0.9.15:compile\r\n[INFO]    +- org.apache.poi:poi-ooxml:jar:3.17:compile\r\n[INFO]    |  +- org.apache.poi:poi:jar:3.17:compile\r\n[INFO]    |  |  \\- org.apache.commons:commons-collections4:jar:4.1:compile\r\n[INFO]    |  +- org.apache.poi:poi-ooxml-schemas:jar:3.17:compile\r\n[INFO]    |  |  \\- org.apache.xmlbeans:xmlbeans:jar:2.6.0:compile\r\n[INFO]    |  |     \\- stax:stax-api:jar:1.0.1:compile\r\n[INFO]    |  \\- com.github.virtuald:curvesapi:jar:1.04:compile\r\n[INFO]    +- com.norbitltd:spoiwo_2.11:jar:1.2.0:compile\r\n[INFO]    |  +- org.scala-lang.modules:scala-xml_2.11:jar:1.0.6:compile\r\n[INFO]    |  \\- org.joda:joda-convert:jar:1.8.1:compile\r\n[INFO]    \\- com.monitorjbl:xlsx-streamer:jar:1.2.1:compile\r\n[INFO]       +- com.rackspace.apache:xerces2-xsd11:jar:2.11.1:compile\r\n[INFO]       |  +- com.rackspace.eclipse.webtools.sourceediting:org.eclipse.wst.xml.xpath2.processor:jar:2.1.100:compile\r\n[INFO]       |  |  +- edu.princeton.cup:java-cup:jar:10k:compile\r\n[INFO]       |  |  \\- com.ibm.icu:icu4j:jar:4.6:compile\r\n[INFO]       |  \\- xml-resolver:xml-resolver:jar:1.2:compile\r\n[INFO]       \\- xml-apis:xml-apis:jar:1.4.01:compile\r\n```\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3482",
        "number": 3482,
        "title": "Remove last usages of Joda",
        "labels": [
            "dependencies",
            "type: process"
        ],
        "state": "open",
        "body": "Migrate usages to threetenbp to remove any possibility of conflicts with other versions of Joda."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3480",
        "number": 3480,
        "title": "Upgrade opencensus",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "0.15.0 is current"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3479",
        "number": 3479,
        "title": "Pub/Sub access to message ack id in the subscribe use case",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "When pulling messages, we get `ReceivedMessage` that contains the ack id that can then be used to ack multiple messages at once using the `ModifyAckDeadlineRequest`.\r\n\r\nHowever, on the subscribe side all we get is `PubsubMessage` and `AckReplyConsumer`, without access to the ack id of the message. So, this means that we cannot ack messages in batch.\r\n\r\n@garrettjonesgoogle "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3478",
        "number": 3478,
        "title": "LoggingAppender failure",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using [com.google.cloud.logging.logback.LoggingAppender](https://cloud.google.com/logging/docs/setup/java) to send logs to Stackdriver. I have configured the logger in `logback.xml`. Earlier today, [Stackdriver had an outage](https://status.cloud.google.com/incident/google-stackdriver/18008), and the throughput of my service stopped. Turns out the logger was unable to write logs due to the outage:\r\n\r\n```\r\nJul 17, 2018 9:06:01 AM com.google.common.util.concurrent.AbstractFuture executeListener\r\nSEVERE: RuntimeException while executing runnable CallbackListener{com.google.api.core.ApiFutures$1@6781a500} with executor MoreExecutors.directExecutor()\r\njava.lang.RuntimeException: com.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: UNAVAILABLE: 502:Bad Gateway\r\nat com.google.cloud.logging.LoggingImpl$7.onFailure(LoggingImpl.java:578)\r\n```\r\n\r\nSo threads became blocked on logging:\r\n```\r\n\"Gax-8\" #33 daemon prio=5 os_prio=0 tid=0x00005588b0db1800 nid=0x1d72 in Object.wait() [0x00007f7d2cee0000]\r\n   java.lang.Thread.State: WAITING (on object monitor)\r\n    at java.lang.Object.wait(Native Method)\r\n    at java.lang.Object.wait(Object.java:502)\r\n    at com.google.api.gax.batching.BlockingSemaphore.acquire(BlockingSemaphore.java:61)\r\n    - locked <0x00000000ee827400> (a com.google.api.gax.batching.BlockingSemaphore)\r\n    at com.google.api.gax.batching.FlowController.reserve(FlowController.java:197)\r\n    at com.google.api.gax.batching.BatchingFlowController.reserve(BatchingFlowController.java:58)\r\n    at com.google.api.gax.batching.ThresholdBatcher.add(ThresholdBatcher.java:166)\r\n    at com.google.api.gax.rpc.BatchingCallable.futureCall(BatchingCallable.java:73)\r\n    at com.google.api.gax.rpc.UnaryCallable$1.futureCall(UnaryCallable.java:126)\r\n    at com.google.api.gax.rpc.UnaryCallable.futureCall(UnaryCallable.java:87)\r\n    at com.google.cloud.logging.spi.v2.GrpcLoggingRpc.write(GrpcLoggingRpc.java:223)\r\n    at com.google.cloud.logging.LoggingImpl.writeAsync(LoggingImpl.java:593)\r\n    at com.google.cloud.logging.LoggingImpl.writeLogEntries(LoggingImpl.java:559)\r\n    at com.google.cloud.logging.LoggingImpl.write(LoggingImpl.java:522)\r\n    at com.google.cloud.logging.logback.LoggingAppender.append(LoggingAppender.java:201)\r\n    at com.google.cloud.logging.logback.LoggingAppender.append(LoggingAppender.java:63)\r\n    at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84)\r\n    at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51)\r\n    at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270)\r\n    at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257)\r\n    at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421)\r\n    at ch.qos.logback.classic.Logger.filterAndLog_1(Logger.java:398)\r\n    at ch.qos.logback.classic.Logger.debug(Logger.java:486)\r\n```\r\n\r\nHowever, it's been many hours since the outage was resolved, yet my service has still not recovered. I would expect the logger to finish writing the pending log events, and service throughput would resume. Any ideas on why this is happening? I have attached the thread stack traces: [threads.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/2203644/threads.txt)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3476",
        "number": 3476,
        "title": "RetrySetting problem with google storage java api",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nI am trying to understand how my application runs if it goes out of internet. However I am facing a behavior that I am sure that is not correct.\r\n\r\nI am setting the RetrySettings to \"1\" when creating the Storage client (google-cloud-storage, version 1.36.0) of google storage, however, the library perform always 10 attempts and then it blocks without returning to the client. \r\n\r\nThis is how I am creating the client.\r\n```java\r\nstorage = StorageOptions.newBuilder()\r\n      .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(credentialsPath)))\r\n      .setRetrySettings(RetrySettings.newBuilder().setMaxAttempts(1).build())\r\n      .build()\r\n      .getService();\r\n```\r\n\r\nThen, if I try to perform any request (e.g.: delete or upload an object to a bucket) without an internet connection, I am getting this output 10 repeated times:\r\n\r\n```\r\njul 17, 2018 5:03:04 PM com.google.api.client.http.HttpRequest execute\r\nWARNING: exception thrown while executing request\r\njava.net.UnknownHostException: accounts.google.com\r\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\r\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\r\n\tat java.net.Socket.connect(Socket.java:589)\r\n\tat sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673)\r\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:175)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:463)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:558)\r\n\tat sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)\r\n\tat sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1334)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1309)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:259)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:383)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161)\r\n\tat com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96)\r\n\tat com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:161)\r\n\tat com.google.cloud.http.CensusHttpModule$CensusHttpRequestInitializer.initialize(CensusHttpModule.java:120)\r\n\tat com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.delete(HttpStorageRpc.java:519)\r\n\tat com.google.cloud.storage.StorageImpl$13.call(StorageImpl.java:388)\r\n\tat com.google.cloud.storage.StorageImpl$13.call(StorageImpl.java:385)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.storage.StorageImpl.delete(StorageImpl.java:385)\r\n\tat com.google.cloud.storage.StorageImpl.delete(StorageImpl.java:377)\r\n```\r\n\r\nAfter seeing 10 times this output the request do not returns, not even if I turn on my internet connection. It seems it stay blocked.\r\n\r\nCan someone help me on this or point me in the right direction.\r\n\r\nThanks in advance,\r\nRegards"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3475",
        "number": 3475,
        "title": "Setting userProject from NIO FileSystemProvider",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm happy to see that [requester-pays support was just added](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/3221)!\r\n\r\nafaict, I can't set the `userProject` in a `CloudStorageFileSystemProvider` that gets instantiated via the Java NIO `FileSystemProvider` machinery, which uses `Class.newInstance()` to invoke the nullary constructor:\r\n\r\n```java\r\nimport java.net.URI;\r\nimport java.nio.file.Paths;\r\nimport java.nio.file.Files;\r\nFiles.newDirectoryStream(Paths.get(new URI(\"gs://<bucket>\")))\r\n```\r\n\r\nthrows:\r\n```\r\ncom.google.cloud.storage.StorageException: Bucket is requester pays bucket but no user project provided.\r\n  at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220)\r\n  at com.google.cloud.storage.spi.v1.HttpStorageRpc.list(HttpStorageRpc.java:347)\r\n  at com.google.cloud.storage.StorageImpl$8.call(StorageImpl.java:299)\r\n  \u2026\r\n```\r\n\r\nIs there a way to set the user-project, other than as a ctor param?\r\n- an environment variable would seem easiest\r\n  - afaict there's no standard mechanism for doing that across GCS libraries in various languages\r\n  - perhaps it's still ok to add one here\r\n- a setter would help a bit\r\n  - I'll be mainly using it from [hammerlab/path-utils](https://github.com/hammerlab/path-utils), where I (unfortunately) have code to [reach into the `installedProviders` and modify the providers for a given URI scheme](https://github.com/hammerlab/path-utils/blob/1.5.0/src/main/scala/org/hammerlab/paths/FileSystems.scala#L128-L145)\r\n  - a setter would at least save me from a second reflection hack to reach "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3470",
        "number": 3470,
        "title": "NoSuchMethod Error in gax core",
        "labels": [
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Here is my pom file\r\n\r\n\t<dependencies>\r\n\t\t<!-- Compile/runtime dependencies -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.appengine</groupId>\r\n\t\t\t<artifactId>appengine-api-1.0-sdk</artifactId>\r\n\t\t\t<version>1.9.49</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.apis</groupId>\r\n\t\t\t<artifactId>google-api-services-pagespeedonline</artifactId>\r\n\t\t\t<version>v2-rev13-1.22.0</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>javax.servlet</groupId>\r\n\t\t\t<artifactId>servlet-api</artifactId>\r\n\t\t\t<version>3.0-alpha-1</version>\r\n\t\t\t<scope>provided</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>jstl</groupId>\r\n\t\t\t<artifactId>jstl</artifactId>\r\n\t\t\t<version>1.2</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.googlecode.objectify</groupId>\r\n\t\t\t<artifactId>objectify</artifactId>\r\n\t\t\t<version>5.1.14</version>\r\n\t\t</dependency>\r\n\r\n\r\n\t\t<!-- Cloud SQL Library dependency-->\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.apis</groupId>\r\n\t\t\t<artifactId>google-api-services-sqladmin</artifactId>\r\n\t\t\t<version>v1beta4-rev50-1.23.0</version>\r\n\t\t</dependency>\r\n\r\n\t\t<!-- Cloud SQL JDBC Library dependency-->\r\n\t\t<dependency> <!-- Only used locally -->\r\n\t\t\t<groupId>mysql</groupId>\r\n\t\t\t<artifactId>mysql-connector-java</artifactId>\r\n\t\t\t<version>5.1.42</version>  <!-- v5.x.x is for production, v6.x.x EAP X DevAPI -->\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud.sql</groupId>\r\n\t\t\t<!-- If using MySQL 6.x driver, use mysql-socket-factory-connector-j-6 instead -->\r\n\t\t\t<artifactId>mysql-socket-factory</artifactId>\r\n\t\t\t<version>1.0.5</version>\r\n\t\t</dependency>\r\n\r\n\t\t<!-- Restlet dependencies -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.restlet.jee</groupId>\r\n\t\t\t<artifactId>org.restlet</artifactId>\r\n\t\t\t<version>${restlet.target.version}</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.restlet.jee</groupId>\r\n\t\t\t<artifactId>org.restlet.ext.json</artifactId>\r\n\t\t\t<version>${restlet.target.version}</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.restlet.jee</groupId>\r\n\t\t\t<artifactId>org.restlet.ext.servlet</artifactId>\r\n\t\t\t<version>${restlet.target.version}</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.restlet.jee</groupId>\r\n\t\t\t<artifactId>org.restlet.ext.fileupload</artifactId>\r\n\t\t\t<version>${restlet.target.version}</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.restlet.jee</groupId>\r\n\t\t\t<artifactId>org.restlet.ext.xml</artifactId>\r\n\t\t\t<version>${restlet.target.version}</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.restlet.osgi</groupId>\r\n\t\t\t<artifactId>org.restlet.ext.swagger</artifactId>\r\n\t\t\t<version>${restlet.target.version}</version>\r\n\t\t\t<exclusions>\r\n\t\t\t\t<!-- exclude transitive dependency (version 0.8.7) -->\r\n\t\t\t\t<!-- because is not available in Central and 0.8.11 is -->\r\n\t\t\t\t<exclusion>\r\n\t\t\t\t\t<groupId>org.raml</groupId>\r\n\t\t\t\t\t<artifactId>raml-parser</artifactId>\r\n\t\t\t\t</exclusion>\r\n\t\t\t</exclusions>\r\n\t\t</dependency>\r\n\t\t<!-- explicitly define dependency to version 0.8.11 -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.raml</groupId>\r\n\t\t\t<artifactId>raml-parser</artifactId>\r\n\t\t\t<version>0.8.11</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>joda-time</groupId>\r\n\t\t\t<artifactId>joda-time</artifactId>\r\n\t\t\t<version>2.9.7</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.code.gson</groupId>\r\n\t\t\t<artifactId>gson</artifactId>\r\n\t\t\t<version>2.8.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.guava</groupId>\r\n\t\t\t<artifactId>guava</artifactId>\r\n\t\t\t<version>18.0</version>\r\n\t\t</dependency>\r\n\r\n\t\t<!-- Test Dependencies -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>junit</groupId>\r\n\t\t\t<artifactId>junit</artifactId>\r\n\t\t\t<version>4.12</version>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.mockito</groupId>\r\n\t\t\t<artifactId>mockito-all</artifactId>\r\n\t\t\t<version>2.0.2-beta</version>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.appengine</groupId>\r\n\t\t\t<artifactId>appengine-testing</artifactId>\r\n\t\t\t<version>${appengine.target.version}</version>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.appengine</groupId>\r\n\t\t\t<artifactId>appengine-api-stubs</artifactId>\r\n\t\t\t<version>${appengine.target.version}</version>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-storage</artifactId>\r\n\t\t\t<version>1.4.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.endpoints</groupId>\r\n\t\t\t<artifactId>endpoints-framework-tools</artifactId>\r\n\t\t\t<version>2.0.3</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.endpoints</groupId>\r\n\t\t\t<artifactId>endpoints-management-control-appengine</artifactId>\r\n\t\t\t<version>1.0.2</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.endpoints</groupId>\r\n\t\t\t<artifactId>endpoints-framework-auth</artifactId>\r\n\t\t\t<version>1.0.2</version>\r\n\t\t</dependency>\r\n\t</dependencies>`\r\n\r\nProject was working earlier in the day, suddenly is returning an internal server error:\r\n\r\n`Caused by: java.lang.NoSuchMethodError: com.google.api.gax.core.GaxProperties.getLibraryVersion(Ljava/lang/Class;)Ljava/lang/String;\r\nat com.google.cloud.ServiceOptions.getLibraryVersion(ServiceOptions.java:614)\r\n\tat com.google.cloud.ServiceOptions.getApplicationName(ServiceOptions.java:577)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.<init>(HttpStorageRpc.java:94)\r\n\tat com.google.cloud.storage.StorageOptions$DefaultStorageRpcFactory.create(StorageOptions.java:53)\r\n\tat com.google.cloud.storage.StorageOptions$DefaultStorageRpcFactory.create(StorageOptions.java:47)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:506)\r\n\tat com.google.cloud.storage.StorageOptions.getStorageRpcV1(StorageOptions.java:121)\r\n\tat com.google.cloud.storage.StorageImpl.<init>(StorageImpl.java:98)\r\n\tat com.google.cloud.storage.StorageOptions$DefaultStorageFactory.create(StorageOptions.java:43)\r\n\tat com.google.cloud.storage.StorageOptions$DefaultStorageFactory.create(StorageOptions.java:37)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:493)`\r\n\r\nWas something deprecated? Not really sure what the issue could be."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3466",
        "number": 3466,
        "title": "Unable to set destinationDefaultAcl for copied objects",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "GCS client library doesn't support ACL properties when performing a copy/rewrite operation.\r\n\r\n```java\r\nStorage.CopyRequest copyRequest = Storage.CopyRequest.newBuilder()\r\n         .setSource(sourceBucketName, sourcePath)\r\n         .setTarget(BlobId.of(destinationBucketName, destinationPath),\r\n                   BlobTargetOption.predefinedAcl(PredefinedAcl.PUBLIC_READ))\r\n         .build();\r\n         storage.copy(copyRequest).getResult();\r\n```\r\n\r\nIssue is predefinedAcl isn't being set in rewrite request.\r\nRef: [HttpStorageRpc.java#L797](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-storage/src/main/java/com/google/cloud/storage/spi/v1/HttpStorageRpc.java#L797)\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3461",
        "number": 3461,
        "title": "javadoc_test CI build does not run mvn javadoc target ",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/8882?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link should have failed on making the javadoc (https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3459 fixes the javadoc error)\r\n\r\nWe should ensure that the CI build for javadoc_test does indeed run the javadoc target and throw an exception if there's an error.\r\n\r\nThis is an annoying issue for when google-cloud-java is being released, and the javadoc target is actually run."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3458",
        "number": 3458,
        "title": "FirestoreOptions .setCredentials() seems to be ignored",
        "labels": [
            "api: firestore",
            "auth",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I recently upgraded Firestore from version 0.51.0-beta to 0.52.0-beta, which allows overriding of various options. My instantiation broke and now throws this exception:\r\n`\r\ncom.google.cloud.firestore.FirestoreException: java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.\r\n`\r\n\r\n My previous service instantiation code looked like this:\r\n```java\r\nGoogleCredentials creds = getServiceAccountCredentialsFromFile();\r\nFirestore firestore = new DefaultFirestoreFactory()\r\n    .create(\r\n        FirestoreOptions.newBuilder()\r\n            .setCredentials(creds)\r\n            .setProjectId(projectId)\r\n            .build());\r\n```\r\n\r\nAfter upgrading this config no longer works; I have to do something like this:\r\n```java\r\nFirestore firestore = new DefaultFirestoreFactory()\r\n    .create(\r\n        FirestoreOptions.newBuilder()\r\n            .setCredentialsProvider(FixedCredentialsProvider.create(creds))\r\n            .setProjectId(projectId)\r\n            .build());\r\n```\r\n\r\nI have also tried this:\r\n```java\r\nFirestore firestore = new DefaultFirestoreFactory()\r\n    .create(\r\n        FirestoreOptions.newBuilder()\r\n            .setCredentials(creds)\r\n            .setProjectId(config.getString(\"firestore.projectId\"))\r\n            .setCredentialsProvider(FirestoreOptions.getDefaultCredentialsProviderBuilder().build())\r\n            .build());\r\n```\r\n\r\nbut this also did not work.\r\n\r\nIs it expected that `setCredentials()` is effectively ignored?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3455",
        "number": 3455,
        "title": "Netty crashes when LoggingAppender is configured in logback.xml",
        "labels": [
            "api: logging",
            "dependencies",
            "priority: p2",
            "type: bug"
        ],
        "state": "open",
        "body": "I am trying to use [com.google.cloud.logging.logback.LoggingAppender](https://cloud.google.com/logging/docs/setup/java) to send logs to Stackdriver. However, when I add the appender to `logback.xml`, Netty crashes upon initialization. It's strange that this only occurs when the appender is configured in logback.xml. If I instead manually instantiate the logger within application code, logging works and Netty doesn't crash. Please let me know how I can help resolve this.\r\n\r\nI have created an example repo at https://github.com/stetra/minrepro\r\n\r\nTo reproduce (you might need to set `GOOGLE_APPLICATION_CREDENTIALS`):\r\n\r\n    1. git clone https://github.com/stetra/minrepro.git && cd minrepro\r\n    2. mvn clean compile assembly:single\r\n    3. java -jar ./target/minrepro-1.0-SNAPSHOT-jar-with-dependencies.jar \r\n\r\nlogback.xml:\r\n\r\n    <configuration>\r\n        <!-- Crash goes away if next two lines are commented out -->\r\n        <appender name=\"CLOUD\" class=\"com.google.cloud.logging.logback.LoggingAppender\">\r\n        </appender>\r\n    </configuration>\r\n\r\nCrash output:\r\n\r\n```\r\n#\r\n# A fatal error has been detected by the Java Runtime Environment:\r\n#\r\n#  SIGSEGV (0xb) at pc=0x00007f7ef7c2ce90, pid=11025, tid=0x00007f7f42061700\r\n#\r\n# JRE version: OpenJDK Runtime Environment (8.0_171-b11) (build 1.8.0_171-8u171-b11-1~deb9u1-b11)\r\n# Java VM: OpenJDK 64-Bit Server VM (25.171-b11 mixed mode linux-amd64 compressed oops)\r\n# Problematic frame:\r\n# C  0x00007f7ef7c2ce90\r\n#\r\n# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n#\r\n# An error report file with more information is saved as:\r\n# /home/steven/minrepro2/minrepro/hs_err_pid11025.log\r\n#\r\n# If you would like to submit a bug report, please visit:\r\n#   http://bugreport.java.com/bugreport/crash.jsp\r\n#\r\nAborted\r\n```\r\n\r\nFull crash log: [hs_err_pid11025.log](https://github.com/GoogleCloudPlatform/google-cloud-java/files/2186581/hs_err_pid11025.log)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3448",
        "number": 3448,
        "title": "Figure out permission settings for requester pays bucket integration tests",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "`testCantCreateWithoutUserProject`, `testCantReadWithoutUserProject`, `testCantCopyWithoutUserProject` and `testFileExistsRequesterPaysNoUserProject` (https://github.com/GoogleCloudPlatform/google-cloud-java/blob/92b87dc9dd28fdaa523ecca0dfce02514a2c7297/google-cloud-clients/google-cloud-contrib/google-cloud-nio/src/test/java/com/google/cloud/storage/contrib/nio/it/ITGcsNio.java) are failing because the testing project has `resourcemanager.projects.createBillingAssignment` permission. Currently ignoring these tests."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3443",
        "number": 3443,
        "title": "Please upgrade grpc 1.13.1",
        "labels": [
            "dependencies",
            "priority: p2"
        ],
        "state": "closed",
        "body": "grpc 1.13.1 was released in June 20.  Please upgrade to the latest."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3442",
        "number": 3442,
        "title": "Google Cloud JAVA SDK alternative for gsutil parallel_composite_upload_threshold",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "Team,\r\n\r\nIs there any Google Cloud JAVA SDK alternative for gsutil parallel_composite_upload_threshold option? \r\n\r\nRegards,\r\nTanmay"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3437",
        "number": 3437,
        "title": "Bigtable integration tests are failing consistently",
        "labels": [
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/8457?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3436",
        "number": 3436,
        "title": "Add support to Dataproc workflows",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Dataproc has a new workflow implementation (https://cloud.google.com/dataproc/docs/reference/rpc/google.cloud.dataproc.v1beta2#google.cloud.dataproc.v1beta2.WorkflowTemplateService). Is it possible to add a Java client for it?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3432",
        "number": 3432,
        "title": "Writing to a bucket should be possible without 'storage.buckets.get'",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I wish to have a service account be able to write, read, read metadata and read history of objects in a pre-defined and existing bucket. It does not need to be able to do anything about the bucket, itself.\r\n\r\nFrom the [Cloud Storage IAM Roles](https://cloud.google.com/storage/docs/access-control/iam-roles) page..\r\n\r\n|Role|Description|Permissions|\r\n|---|---|---|\r\n|`roles/storage.objectAdmin`|Full control over objects, including listing, creating, viewing, and deleting objects. Does not grant permission to read or edit bucket metadata.|`storage.objects.*`|\r\n|`roles/storage.admin`|Full control of buckets and objects.|`storage.buckets.*`, `storage.objects.*`|\r\n\r\n..it seems `roles/storage.objectAdmin` would be the role for this.\r\n\r\nIf I run the (below) code with it, I get the error:\r\n\r\n>... does not have `storage.buckets.get` access to <bucket-name>.\r\n\r\nAdding the \"Storage Admin\" or \"Storage Legacy Bucket Reader\" role makes things work.\r\n\r\nThe possible bug is that I find the reality and the documentation to be at odds. It may be that this is the same thing as google-cloud-ruby has had (and fixed) in their [#1588](https://github.com/GoogleCloudPlatform/google-cloud-ruby/issues/1588). Their it was fixed in a way that allows accessing a bucket without bucket-level rights.\r\n\r\nScala code:\r\n\r\n```\r\nval sto: Storage = StorageOptions.getDefaultInstance.getService()\r\nval bucket: Bucket = sto.get(bucketName)\r\nbucket.create(\"abc\", \"ABC!\".getBytes(UTF_8) )\r\n```\r\n\r\nUsing `google-cloud-storage` client version 1.31.0"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3431",
        "number": 3431,
        "title": "Report slow zipping to maven",
        "labels": [
            "dependencies",
            "triage me"
        ],
        "state": "closed",
        "body": "In the BOM I find this comment: \r\n\r\n           <!--\r\n              maven-source-plugin-3.0.0 exhibits the zipping behavior on ubuntu that was seen in\r\n              maven-jar-plugin with version < 2.5 (https://issues.apache.org/jira/browse/MJAR-188).\r\n              Until that is fixed we should stick to 2.4.\r\n            -->\r\n\r\nCould someone who understands it report this upstream to Maven so it can be worked on and tracked? This may not be on their radar. \r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3430",
        "number": 3430,
        "title": "Dialogflow Error: Permission Denied",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "I have created a Dialogflow agent with some intents. However, when I try to integrate it into my java backend, it seems to be accessing the wrong application default credentials.\r\n\r\nI can confirm that it is verifying authentication is successful because the console logs the correct project ID (weather-checker-50074) when I run this code:\r\n\r\n\r\n      \r\n        // Set the session name using the sessionId (UUID) and projectID (my-project-id)\r\n       try (SessionsClient sessionsClient = SessionsClient.create()) { \r\n        SessionName session = SessionName.of(projectId, sessionId);\r\n        System.out.println(\"Session Path: \" + session.toString());\r\n\r\nAnd it works fine for even this piece of code: \r\n\r\n\r\n          // Build the query with the TextInput\r\n          Builder textInput = TextInput.newBuilder().setText(text).setLanguageCode(languageCode);\r\n          System.out.println(\"Passed text input stage\");\r\n          QueryInput queryInput = QueryInput.newBuilder().setText(textInput).build();\r\n          System.out.println(\"Passed query input stage\");\r\n\r\nHowever, when I try to get the response back from dialogflow, I get an error. Here is the code for getting the response back from Dialogflow.\r\n\r\n          DetectIntentResponse response = sessionsClient.detectIntent(session, queryInput);\r\n          System.out.println(\"Detected Intent\");\r\n\r\n> ERROR [stderr] (default task-108) com.google.api.gax.rpc.PermissionDeniedException: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Dialogflow API has not been used in project 764086051850 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/dialogflow.googleapis.com/overview?project=764086051850 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\r\n\r\nThe weird thing is, my project number is not 764086051850. So it seems like it's not accessing the correct credentials. I have tried the solution given in the link below but it still doesn't seem to work. Any help would be appreciated. Thanks!\r\n\r\n(https://stackoverflow.com/questions/50563803/cant-access-correct-application-default-credentials-for-dialogflow-app)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3429",
        "number": 3429,
        "title": "Timestamp.of(java.util.Date) fails for pre-epoch dates not truncated to seconds",
        "labels": [
            "api: core",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "com.google.cloud.Timestamp.of(Date) fails with IllegalArgumentException if the given date is before epoch and not truncated to seconds, in the concrete example, one millisecond before epoch was used.\r\n\r\ngoogle-cloud-core version: 1.35.0\r\n\r\nStacktrace fragment:\r\n```\r\njava.lang.IllegalArgumentException: timestamp out of range: 0, -1000000\r\n\r\n\tat com.google.common.base.Preconditions.checkArgument(Preconditions.java:356)\r\n\tat com.google.cloud.Timestamp.ofTimeMicroseconds(Timestamp.java:84)\r\n\tat com.google.cloud.Timestamp.of(Timestamp.java:95)\r\n```\r\n\r\nUnit test (the variant with seconds and nanos succeeds, the variant with Date fails for the same instant in time):\r\n\r\n```java\r\npackage com.outfit7.gcloud;\r\n\r\nimport java.time.Instant;\r\nimport java.util.Date;\r\n\r\nimport org.assertj.core.api.Assertions;\r\nimport org.junit.jupiter.api.Test;\r\n\r\nimport com.google.cloud.Timestamp;\r\n\r\nclass TimestampTest {\r\n\r\n   private static final long EPOCH_MILLIS = 0L;\r\n   private static final long EPOCH_MILLIS_MINUS_ONE = EPOCH_MILLIS - 1;\r\n\r\n   @Test\r\n   void ofTimeSecondsAndNanos_preEpoch() {\r\n\r\n       // given (one second backwards, 999 millis forward, effectively one millisecond before epoch)\r\n       long seconds = -1;\r\n       int nanos = 999 * 1000000;\r\n\r\n       // when\r\n       Timestamp timestamp = Timestamp.ofTimeSecondsAndNanos(seconds, nanos);\r\n\r\n       // then\r\n       Assertions.assertThat(timestamp.toDate().getTime()).isEqualTo(EPOCH_MILLIS_MINUS_ONE);\r\n   }\r\n\r\n   @Test\r\n   void ofJavaUtilDate_preEpoch() {\r\n\r\n       // given\r\n       Date epochMinusMillisecond = Date.from(Instant.ofEpochMilli(EPOCH_MILLIS_MINUS_ONE));\r\n\r\n       // when\r\n       Timestamp timestamp = Timestamp.of(epochMinusMillisecond);\r\n\r\n       // then\r\n       Assertions.assertThat(timestamp.toDate().getTime()).isEqualTo(EPOCH_MILLIS_MINUS_ONE);\r\n   }\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3427",
        "number": 3427,
        "title": "Enable TLS 1.2 for Java 7 builds",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "https://tonyyan.wordpress.com/2015/07/17/enabled-tls-1-2-and-tls-1-1-on-java-7/"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3426",
        "number": 3426,
        "title": "Drop support for Java 7",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "Clients won't be able to fetch dependencies from Maven due to Java 7 not supporting TLS 1.2 by default \r\n[Sample failed CI build](https://ci.appveyor.com/project/googlejavacloud/google-cloud-java-v0gf7/build/3082), note the \"Received fatal alert: protocol_version\" message:\r\n```\r\n[ERROR] Failed to execute goal on project proto-google-cloud-bigquerydatatransfer-v1:\r\n Could not resolve dependencies for project com.google.api.grpc:proto-google-cloud-bigquerydatatransfer-v1:jar:0.18.1-SNAPSHOT:\r\n Failed to collect dependencies at com.google.api.grpc:proto-google-common-protos:jar:1.12.0:\r\n Failed to read artifact descriptor for com.google.api.grpc:proto-google-common-protos:jar:1.12.0:\r\n Could not transfer artifact com.google.api.grpc:proto-google-common-protos:pom:1.12.0 from/to central (https://repo.maven.apache.org/maven2):\r\n Received fatal alert: protocol_version -> [Help 1]\r\n```\r\n\r\nThis will continue to break any CI builds that use Java 7, e.g. in google-cloud-java.\r\n\r\nThis can be mitigated by https://github.com/GoogleCloudPlatform/google-cloud-java/issues/3427, which will solve the dependency fetch issue, but still leaves open concerns that we are supported an outdated, potentially insecure version of Java.\r\n\r\nJava 7 doesn't have public security updates any more, and it has been deprecated by Oracle."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3425",
        "number": 3425,
        "title": "[BigQuery] There are no column descriptions provided for table",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "When trying to import a CSV file into BigQuery from GCS using\r\n```\r\nLoadJobConfiguration.builder(table, path)\r\n      .setAutodetect(true)\r\n      .setIgnoreUnknownValues(false)\r\n      .setMaxBadRecords(0)\r\n      .setFormatOptions(FormatOptions.csv())\r\n      .setCreateDisposition(CreateDisposition.CREATE_IF_NEEDED)\r\n      .setWriteDisposition(WriteDisposition.WRITE_TRUNCATE)\r\n      .build()\r\n```\r\nI get the error \"There are no column descriptions provided for table [table_name]\". Loading the same file via the BigQuery web UI using the same options works fine. The CSV file is available at https://storage.googleapis.com/miraisolutions/public/macbeth.csv"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3424",
        "number": 3424,
        "title": "Type: Bug Not Streaming Null Values",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Bigquery insertAll operation is checking for a field in the inserted Row which is not present in the schema. I have set setIgnoreUnknownValues to true and also set setSkipInvalidRows to true.\r\n\r\nHere is the exception Trace, \r\n```java\r\njava.lang.NullPointerException: null value in entry: xyz=null\r\n    at com.google.common.collect.CollectPreconditions.checkEntryNotNull(CollectPreconditions.java:33) ~[bqstream.jar:?]\r\n    at com.google.common.collect.RegularImmutableMap.fromEntryArray(RegularImmutableMap.java:69) ~[bqstream.jar:?]\r\n    at com.google.common.collect.RegularImmutableMap.fromEntries(RegularImmutableMap.java:46) ~[bqstream.jar:?]\r\n    at com.google.common.collect.ImmutableMap.copyOf(ImmutableMap.java:354) ~[bqstream.jar:?]\r\n    at com.google.common.collect.ImmutableMap.copyOf(ImmutableMap.java:327) ~[bqstream.jar:?]\r\n    at com.google.cloud.bigquery.InsertAllRequest$RowToInsert.<init>(InsertAllRequest.java:81) ~[bqstream.jar:?]\r\n    at com.google.cloud.bigquery.InsertAllRequest$RowToInsert.of(InsertAllRequest.java:141) ~[bqstream.jar:?]\r\n    at com.XXXXXXXXXX.bqstream.data.Data.lambda$getData$0(Data.java:46) ~[bqstream.jar:?]\r\n    at java.util.ArrayList.forEach(Unknown Source) ~[?:1.8.0_141]\r\n    at com.XXXXXXXXXX.bqstream.data.Data.getData(Data.java:34) [bqstream.jar:?]\r\n    at com.XXXXXXXXXX.bqstream.BatchProcessor.apply(BatchProcessor.java:22) [bqstream.jar:?]\r\n    at com.XXXXXXXXXX.mdaolib.controller.BatchOutHandler.run(BatchOutHandler.java:35) [bqstream.jar:?]\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:1.8.0_141]\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:1.8.0_141]\r\n    at java.lang.Thread.run(Unknown Source) [?:1.8.0_141]\r\n```\r\n\r\nAfter looking at the code for InsertAll, it seems like some Preconditons call is performed on the row to be inserted. But why is the same performed on a data not provided in the Schema."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3420",
        "number": 3420,
        "title": "Fix url in pom.xml for each google-cloud-client",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "Change `<url>` in pom.xml for each client in `google-cloud-clients/` to `.../google-cloud-clients/google-cloud-xxx`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3417",
        "number": 3417,
        "title": "Includes the .proto files in generated jars",
        "labels": [
            "type: feature request"
        ],
        "state": "open",
        "body": "Right now the proto-google-cloud-xxx dependencies (eg [dialogflow](https://search.maven.org/#artifactdetails%7Ccom.google.api.grpc%7Cproto-google-cloud-dialogflow-v2%7C0.18.0%7Cjar) ) only include the generated source files. This makes impossible to import the source protos in your protos in an easy way.\r\n\r\nFor instance, the workaround for using [protobuf-maven-plugin](https://www.xolstice.org/protobuf-maven-plugin/index.html) is to add this repository as a submodule and configure the plugin to lookup the proto files.\r\n\r\nAdding the protos would make working with the libraries easier. Also, this is done for [other Google artifacts](http://search.maven.org/#artifactdetails%7Ccom.google.protobuf%7Cprotobuf-java%7C3.1.0%7Cbundle). "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3416",
        "number": 3416,
        "title": "Any plans to setup as a Bazel workspace?",
        "labels": [
            "type: feature request"
        ],
        "state": "open",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3414",
        "number": 3414,
        "title": "[PubSub][Question] DEADLINE_EXCEEDED after 60s for sending acks/modacks",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "We've recently added a new feature which involves a new topic and subscriptions using google-cloud-pubsub version 1.35.0.\r\n\r\nHowever, we noticed warning logs for `DEADLINE_EXCEEDED` over a number of days all stating a 60 second deadline like the following:\r\n\r\n```\r\n3549577 [Gax-11] WARN c.g.c.p.v.StreamingSubscriberConnection - failed to send operationsio.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 59999669883ns at\r\nio.grpc.Status.asRuntimeException(Status.java:526) at\r\nio.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:419) at\r\nio.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41) at\r\nio.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684) at\r\nio.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41) at\r\nio.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:391) at\r\nio.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475) at\r\nio.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63) at\r\nio.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557) at\r\nio.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478) at\r\nio.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590) at\r\nio.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at\r\nio.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at\r\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at\r\njava.util.concurrent.FutureTask.run(FutureTask.java:266) at\r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at\r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at\r\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at\r\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at\r\njava.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nWe had set a 300 second Ack Deadline on topic creation but investigating the code reveals instead a default of 60 seconds is used since [pubsub: re-implement periodic deadline adjustment](https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2639). However, that deadline should have adjusted and we use the default Max Ack Extension setting so would expect a larger deadline than 60 seconds.\r\n\r\nFurther investigation led to discovering that the unary calls to send the acks/modacks also has a deadline of 60 seconds and it appears that the stacktrace is produced by the logging StreamObserver used during this step.\r\n\r\nCould someone confirm whether these stacktraces actually relate to the the sending of ack/modacks timing-out?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3412",
        "number": 3412,
        "title": "Question: Kotlin Interopability",
        "labels": [
            "android",
            "type: feature request"
        ],
        "state": "open",
        "body": "It would be great to have this library follow the [Kotlin Interoperability Guide](https://android.github.io/kotlin-guides/interop.html). \r\n\r\nI would love to submit a PR to fix any of these interoperability issues in this library, in the downstream [gapic-generator](https://github.com/googleapis/gapic-generator), and also in the [apiary client](https://github.com/google/google-api-java-client). \r\n\r\nOf course maintaining Backwards Compatibility will be key, and if there's a situation where breaking BC is required, we'll handle those case-by-case.\r\n\r\nThoughts?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3410",
        "number": 3410,
        "title": "Problems uploading files to Cloud Storage: com.google.cloud.storage.StorageException: Error writing request body to server",
        "labels": [
            "api: storage",
            "priority: p1",
            "type: question"
        ],
        "state": "closed",
        "body": "We randomly get the exception stated below when uploading files to Cloud Storage. The file size does not seem to be the relevant factor - the files where we see the problems are in the range between 25MB and 22GB. \r\n\r\n```\r\ncom.google.cloud.storage.StorageException: Error writing request body to server\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.write(HttpStorageRpc.java:704)\r\n\tat com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:51)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:47)\r\n\tat com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:122)\r\n\tat com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:149)\r\n\tat java.nio.channels.Channels.writeFullyImpl(Channels.java:78)\r\n\tat java.nio.channels.Channels.writeFully(Channels.java:101)\r\n\tat java.nio.channels.Channels.access$000(Channels.java:61)\r\n\tat java.nio.channels.Channels$1.write(Channels.java:174)\r\n\tat smarter.ecommerce.commons.io.DelegatingOutputStream.write(DelegatingOutputStream.java:27)\r\n\tat org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:1793)\r\n\tat org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:1769)\r\n\tat org.apache.commons.io.IOUtils.copy(IOUtils.java:1744)\r\n        .......\r\n        Caused by: java.io.IOException: Error writing request body to server\r\n\tat sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.checkError(HttpURLConnection.java:3518)\r\n\tat sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.write(HttpURLConnection.java:3501)\r\n\tat com.google.api.client.util.ByteStreams.copy(ByteStreams.java:55)\r\n\tat com.google.api.client.util.IOUtils.copy(IOUtils.java:94)\r\n\tat com.google.api.client.http.AbstractInputStreamContent.writeTo(AbstractInputStreamContent.java:72)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:80)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.write(HttpStorageRpc.java:685)\r\n\t... 85 more\r\n```\r\n\r\nWe already had a look at the integrated retry handling and it looks like that exceptions of this kind are not retried when sending a chunk to Cloud Storage. Unfortunately it's very hard to reproduce with a test. But the problem occurs randomly, but frequently (multiple times a day)!\r\n\r\nThis might be related: https://stackoverflow.com/questions/50019241/google-cloud-storage-throwing-error-for-multiple-large-file-uploads-concurrently\r\n\r\nThe code that we are using is pretty much the same as stated in the linked stackoverflow article. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3405",
        "number": 3405,
        "title": "User reports it takes 5 seconds to start gRPC connection for Cloud Spanner",
        "labels": [
            "api: spanner",
            "performance",
            "type: question"
        ],
        "state": "open",
        "body": "https://stackoverflow.com/questions/50861577/spring-boot-gcp-data-spanner-latency-issues\r\n\r\nThe user here is using the cloud spanner client lib and reports that it takes him 5 seconds to start the connection to Cloud Spanner and then he is getting slow performance out of each query and read operation. There is sample code in there as well."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3402",
        "number": 3402,
        "title": "StorageException: 404 Not Found",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "We make use of Google's JAVA client library to create storage client using which we get a particular blob by: storageClient.get(blobId).\r\n\r\nWe are facing an issue - calling the above method intermittently leads to \"StorageException: 404 Not Found\". Even when the objects exists and can be seen from console.\r\n\r\nBelow is the stack-trace: \r\n```\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT **Caused by: com.google.cloud.storage.StorageException: 404 Not Found**\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT No such object: <our object name - we would not want to disclose>\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:588) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.StorageImpl$16.call(StorageImpl.java:464) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.StorageImpl$16.call(StorageImpl.java:461) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89) ~[gax-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.RetryHelper.run(RetryHelper.java:74) ~[google-cloud-core-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51) ~[google-cloud-core-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:461) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.Blob.getContent(Blob.java:455) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.sap.hcp.osaas.cfbroker.utils.GCPUtils.getBlob(GCPUtils.java:60) ~[classes/:?]\r\n\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \t... 89 more\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT **Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found**\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT No such object: <our object name we would not want to disclose>\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065) ~[google-http-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380) ~[google-api-client-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6189) ~[google-api-services-storage-v1-rev114-1.23.0.jar!/:?]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:584) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.StorageImpl$16.call(StorageImpl.java:464) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.StorageImpl$16.call(StorageImpl.java:461) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89) ~[gax-1.23.0.jar!/:1.23.0]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.RetryHelper.run(RetryHelper.java:74) ~[google-cloud-core-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51) ~[google-cloud-core-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:461) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n   2018-06-25T15:25:38.58+0530 [APP/PROC/WEB/1] OUT \tat **com.google.cloud.storage.Blob.getContent**(Blob.java:455) ~[google-cloud-storage-1.24.1.jar!/:1.24.1]\r\n```\r\n\r\nCan there be anything that we might be missing? or is it an issue on the library side?\r\n\r\nThanks,\r\nSwati Jain"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3400",
        "number": 3400,
        "title": "[google-cloud-java][Text-to-Speech][Android] want to use api key",
        "labels": [
            "android",
            "api: texttospeech",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I use the [Text-to-Speech Java Library](https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-texttospeech) on my Android app. \r\nI want to use google cloud api-key to use the Text-to-Speech Java Library.\r\n\r\nOn my android. If I did the following code, it got the error message.\r\n```\r\ntry (TextToSpeechClient textToSpeechClient = TextToSpeechClient.create()) { \r\n}\r\n\r\n/* \r\nerror message\r\njava.io.IOException: The Application Default Credentials are not available. \r\nThey are available if running in Google Compute Engine. \r\nOtherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials.\r\nSee https://developers.google.com/accounts/docs/application-default-credentials for more information.\r\n*/\r\n```\r\nSo I read the [Authentication API Keys document](https://cloud.google.com/docs/authentication/api-keys) and found API-Key not support Text-to-Speech, so I can't use api-key to Text-to-Speech Java Library.\r\n\r\nIf I want to use Text-to-Speech by API-Key or Text-to-Speech Java Library on Android. How can I do it ?\r\n\r\nThe following code is my command line and execute on mac and It work fine and can get the \"audioContent\". I think I can use http method by java. Is there any other way ?\r\n```\r\nCurl -H \"X-Goog-Api-Key: API_KEY\" \\\r\n  -H \"Content-Type: application/json; charset=utf-8\" \\\r\n  --data \"{\r\n    'input':{\r\n      'text':'Hello I am david, Nice to meet you'\r\n    },\r\n    'voice':{\r\n      'languageCode':'en-gb',\r\n      'name':'en-GB-Standard-A',\r\n      'ssmlGender':'FEMALE'\r\n    },\r\n    'audioConfig':{\r\n      'audioEncoding':'MP3'\r\n    }\r\n  }\" \"https://texttospeech.googleapis.com/v1beta1/text:synthesize\"\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3397",
        "number": 3397,
        "title": "Bigquery list projects",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I would like have new feature of listing projects. \r\nThe old bigquery library support to list projects, any reason the new library does not support that?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3396",
        "number": 3396,
        "title": "Unknow topic of \"_deleted-topic_\" in the list",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "when listing all the topics, the topic of \"_deleted-topic_\" is returned on the list, which is  not created by user, and cause issue to parsing the topic\r\n`com.google.api.pathtemplate.ValidationException: ProjectTopicName.parse: formattedString not in valid format: Parameter \"_deleted-topic_\" must be in the form \"projects/{project=*}/topics/{topic=*}\"\r\n\tat com.google.api.pathtemplate.PathTemplate.validatedMatch(PathTemplate.java:454)\r\n\tat com.google.pubsub.v1.ProjectTopicName.parse(ProjectTopicName.java:78)`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3393",
        "number": 3393,
        "title": "can't import the com.google.api.services.bigquery.Bigquery",
        "labels": [
            "api: bigquery",
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "when I ready to export data from BQ  to GCS, there always have errors that \r\ncan't import the com.google.api.services.bigquery.Bigquery;\r\ncom.google.api.services.bigquery.model.Job;"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3390",
        "number": 3390,
        "title": "Java docs for Google Cloud Java clients for older versions are not accessible",
        "labels": [
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Recently, changes were done to migrate the Java doc page for Google Cloud client libraries. The latest version of the client libraries' API details can be found at https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html However earlier we could just play with the version on the URL and get the API reference for a particular version like https://googlecloudplatform.github.io/google-cloud-java/0.46.0/apidocs/index.html but now we can't do that anymore. Whatever version we give, it is redirecting to the latest version's page. I think developers should still be able to view the API reference material for the older versions as well."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3386",
        "number": 3386,
        "title": "`ServiceOptions.java`: Extract projectId from credentials when provided via .setCredentials`",
        "labels": [
            "api: core",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Handwritten clients that use `ServiceOptions`:\r\n\r\nwhen `.setCredentials` is used, the project id is not extracted from the service account.\r\nThis behavior is different when  service account credentials are supplied via `GOOGLE_APPLICATION_CREDENTIALS` env var (project id is extracted)\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L465\r\n\r\nSimilar issue for BigQuery:\r\nhttps://github.com/GoogleCloudPlatform/java-docs-samples/issues/936"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3385",
        "number": 3385,
        "title": "How to use google application credentials json file with 12factor app on heroku or elsewhere?",
        "labels": [
            "api: core",
            "auth",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "We like to stick to the [12factor best practices](https://12factor.net/config) of using environment variables for any credentials.   Using Heroku, we don't want to commit this file to our repo, but we can't include the whole file as an env variable.  \r\n\r\nIs there an option using this SDK that allows us to authenticate with only the necessary values from the provided json file, set only as environment variables?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3384",
        "number": 3384,
        "title": "Decouple non-dependent client libraries",
        "labels": [
            "type: process"
        ],
        "state": "open",
        "body": "Releasing one Java client triggers releasing all client libraries in this github repo. This makes for  unnecessary hassle when it comes to refreshing a single client.\r\n\r\nAlso, because the entire maven project needs to be built at once, CircleCI is running out of memory during the CI build: https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/7773?utm_campaign=build-failed&utm_content=failing-command&utm_medium=email#tests/containers/0/actions/103\r\n\r\n```\r\n#!/bin/bash -eo pipefail\r\n./utilities/verify_single_it.sh google-cloud-clients/google-cloud-compute\r\n\r\n...\r\n[INFO] --- maven-install-plugin:2.4:install (default-install) @ google-cloud-appenginejava8 ---\r\n[INFO] Installing /home/circleci/googleapis/google-cloud-testing/google-cloud-appenginejava8/target/google-cloud-appenginejava8-0.52.0-alpha.war to /home/circleci/.m2/repository/com/google/cloud/google-cloud-appenginejava8/0.52.0-alpha/google-cloud-appenginejava8-0.52.0-alpha.war\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO] \r\n...\r\n[INFO] Google Cloud Examples 0.52.0-alpha ................. SUCCESS [  2.672 s]\r\n[INFO] Google Cloud Testing 0.52.0-alpha .................. SUCCESS [  0.004 s]\r\n[INFO] google-cloud-managedtest 0.52.0-alpha .............. SUCCESS [  0.329 s]\r\n[INFO] google-cloud-appengineflexcompat 0.52.0-alpha ...... SUCCESS [  4.320 s]\r\n[INFO] google-cloud-appengineflexcustom 0.52.0-alpha ...... SUCCESS [  2.215 s]\r\n[INFO] google-cloud-appengineflexjava 0.52.0-alpha ........ SUCCESS [  2.209 s]\r\n[INFO] google-cloud-appenginejava8 0.52.0-alpha ........... FAILURE [  5.085 s]\r\n[INFO] Google Cloud Util 0.52.0-alpha ..................... SKIPPED\r\n[INFO] Google Cloud Java Compatibility Checker 0.52.0-alpha SKIPPED\r\n[INFO] Google Cloud Java 0.0.1-SNAPSHOT ................... SKIPPED\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 02:22 min\r\n[INFO] Finished at: 2018-06-14T21:50:58Z\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-install-plugin:2.4:install (default-install) on project google-cloud-appenginejava8: Failed to install artifact com.google.cloud:google-cloud-appenginejava8:war:0.52.0-alpha: Cannot allocate memory -> [Help 1]\r\n[ERROR] \r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR] \r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n[ERROR] \r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <goals> -rf :google-cloud-appenginejava8\r\n./utilities/verify_single_it.sh: line 19:    68 Killed                  mvn -B install -DskipTests\r\nExited with code 137\r\n\r\nHint: Exit code 137 typically means the process is killed because it was running out of memory\r\nHint: Check if you can optimize the memory usage in your app\r\nHint: Max memory usage of this container is 4286214144\r\n according to /sys/fs/cgroup/memory/memory.max_usage_in_bytes\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3383",
        "number": 3383,
        "title": "Pub/Sub `StreamingPull` receives many duplicates when there is a backlog",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "status: blocked",
            "type: question"
        ],
        "state": "closed",
        "body": "The Pub/Sub `StreamingPull` API gives many duplicates when the messages are small and there is a backlog. This is a difference from `Pull`, which does not exhibit this behavior. After a while, more than 50% of messages can be duplicates. This makes it very hard to process a backlog. @kir-titievsky [suggested](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2465#issuecomment-397417225) that I create a new issue when I described it in #2465.\r\n\r\nI created two test programs to replicate this issue:\r\n\r\n1. [CloudPubSub.java](https://github.com/yonran/pubsubfallingbehindbug/blob/master/src/main/java/io/github/yonran/pubsubfallingbehindbug/CloudPubSub.java) uses the [Asynchronous Pull (`MessageReceiver`) Java API](https://cloud.google.com/pubsub/docs/pull#asynchronous-pull) to receive messages and write to a file of JSONs. Optionally, you can also use my [custom `google-cloud-java` branch](https://github.com/yonran/google-cloud-java/tree/pubsub-log-message-ids) in which I instrumented `MessageDispatcher.java` to log the message IDs that are acked.\r\n    * [MyProducer.java](https://github.com/yonran/pubsubfallingbehindbug/blob/master/src/main/java/io/github/yonran/pubsubfallingbehindbug/MyProducer.java) publishes a backlog of messages (e.g. `--initial-publish-messages=10000`) and then publishes a stream of messages (default `--publish-period=400` means 2.5 messages/second)\r\n    * [LogMessagesReceiver.java](https://github.com/yonran/pubsubfallingbehindbug/blob/master/src/main/java/io/github/yonran/pubsubfallingbehindbug/LogMessagesReceiver.java) sleeps a fixed duration per message (default `--message-processing-time=5000`ms), then throttles acking to `--period=333` which means 3 messages/second, and then acks the message. Note that it should make progress since its `--period` is less than the publisher\u2019s `--publish-period`, but it doesn\u2019t because of the duplicate messages.\r\n    * [CloudPubSub.java](https://github.com/yonran/pubsubfallingbehindbug/blob/master/src/main/java/io/github/yonran/pubsubfallingbehindbug/CloudPubSub.java) has the `FlowControlSettings`. By default, `--concurrent-messages=20` means that 20 receivers sleep in parallel. Since 5000 < 333*20 = 6660, there are enough concurrent threads that a 5000ms sleep does not reduce the subscriber throughput below the desired 3 messages per second.\r\n    * Result: After an hour or two, there are many duplicate message ids, as indicated by running `jq < /tmp/inv-log-cloudpubsub-pub2.5-sub3.jsons  --slurp '[.[] | .messageId] | {unique: sort|unique|length, total: length} | .duplicates = .total - .unique'`\r\n    * Stackdriver metrics show that the backlog is growing even through the consumer (3 messages/second) is faster than the producer (2.5 messages/second).<br><img alt=\"undelivered and oldest acknowledged\" src=\"https://user-images.githubusercontent.com/483060/41439921-84bc2b44-6fe1-11e8-8a6d-2a245cc5d6dc.png\" width=426>\r\n2. [RawPubSub.java](https://github.com/yonran/pubsubfallingbehindbug/blob/master/src/main/java/io/github/yonran/pubsubfallingbehindbug/RawPubSub.java) uses the same low-level GRPC `StreamingPull` API as the high-level `MessageReceiver` API does. Like `CloudPubSub.java`, it logs the message ids to stdout and to a file of JSONs.\r\n    * In the publisher thread, [MyProducer.java](https://github.com/yonran/pubsubfallingbehindbug/blob/master/src/main/java/io/github/yonran/pubsubfallingbehindbug/MyProducer.java) publishes a backlog of messages (e.g. `--initial-publish-messages=10000`) and then publishes a stream of messages (default `--publish-period=400` means 2.5 messages/second)\r\n    * [`onError` is implemented](https://github.com/yonran/pubsubfallingbehindbug/blob/80e9d18081db5c9de9e7572dbec87f7af066508b/src/main/java/io/github/yonran/pubsubfallingbehindbug/RawPubSub.java#L235) on the ack StreamObserver so that we can detect acks that failed. I have not seen any failures.\r\n    * The [receiver thread](https://github.com/yonran/pubsubfallingbehindbug/blob/80e9d18081db5c9de9e7572dbec87f7af066508b/src/main/java/io/github/yonran/pubsubfallingbehindbug/RawPubSub.java#L276-L455) calls `request(1)` to get one message at a time, queues them up, and processes them with similar timing as `CloudPubSub.java` (i.e., waits 5 seconds per message and then throttles acks to 3 messages per second). It also calls modack to extend deadlines.\r\n    * Result: After an hour or two, there are many duplicate message ids, as indicated by running `jq < /tmp/inv-log-grpc-pub2.5-sub3.jsons  --slurp '[.[] | .messageId] | {unique: sort|unique|length, total: length} | .duplicates = .total - .unique'`\r\n    * Message IDs are logged to stdout [at the time they are received](https://github.com/yonran/pubsubfallingbehindbug/blob/80e9d18081db5c9de9e7572dbec87f7af066508b/src/main/java/io/github/yonran/pubsubfallingbehindbug/RawPubSub.java#L198) and [at the time they are acked](https://github.com/yonran/pubsubfallingbehindbug/blob/80e9d18081db5c9de9e7572dbec87f7af066508b/src/main/java/io/github/yonran/pubsubfallingbehindbug/RawPubSub.java#L382). By checking the log, we can see that the client acks messages within the subscription\u2019s ackDeadlineSeconds (10s default), and the server sent duplicates regardless.\r\n3. The [pubsub-0.21.1-beta branch](https://github.com/yonran/pubsubfallingbehindbug/tree/pubsub-0.21.1-beta) of CloudPubSub.java uses the same `MessageReceiver` Java API, but at version 0.21.1-beta which still used `Pull` instead of `StreamingPull`. It does not give a significant number of duplicates.\r\n\r\nI opened a support ticket for this, Case 15877623, 2018-05-21: Pub/Sub subscriber receives duplicated MessageIds and never catches up. On 2018-05-29, the representative said this is a [known issue](https://cloud.google.com/pubsub/docs/pull#dealing-with-large-backlogs-of-small-messages) with `StreamingPull`, but there is no ETA for fixing it and that I should poll the [PubSub release notes](https://cloud.google.com/pubsub/docs/release-notes) for updates."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3381",
        "number": 3381,
        "title": "Increase Java memory for Circle CI build",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/7773?utm_campaign=build-failed&utm_content=failing-command&utm_medium=email#tests/containers/0/actions/103"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3378",
        "number": 3378,
        "title": "Ignore failing deprecated Compute IT test methods",
        "labels": [
            "api: compute",
            "priority: p2"
        ],
        "state": "closed",
        "body": "CircleCI failure log: https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/7756?utm_campaign=build-failed&utm_content=failing-command&utm_medium=email#tests/containers/0/actions/103\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3377",
        "number": 3377,
        "title": "Update README for Compute",
        "labels": [
            "api: compute",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Fix links on https://cloud.google.com/compute/docs/api/libraries#google_apis_java_client_library.\r\n\r\nUpdate google-cloud-compute/README.rst with correct links.\r\n\r\nRegenerate the gh_pages branch, and ensure that https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients/apidocs/index.html?com/google/cloud/compute/v1/package-summary.html returns a 200."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3373",
        "number": 3373,
        "title": "Upgrade to latest grpc",
        "labels": [
            "dependencies",
            "grpc",
            "priority: p2"
        ],
        "state": "closed",
        "body": "We currently depend on 1.10.1, but 1.12.0 is available now."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3372",
        "number": 3372,
        "title": "Unable to set credentials explicitly for GC Natural Language API",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "The library for Google Cloud Natural Language library allows only to set credentials via the environment variable. Is there a way to set this in code or even if it is an environment variable, is there a way to set it without using gcloud?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3371",
        "number": 3371,
        "title": "datastore.run can't be used without ReadOptions",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "open",
        "body": "I want to be able to call `run` without specifying any ReadOptions: `Option(datastore.run[Entity](query)`. If I don't pass in any ReadOptions, I get this error: \r\n```\r\nambiguous reference to overloaded definition, both \r\nmethod run in trait Datastore of type (\r\nx$1: com.google.cloud.datastore.Query[com.google.cloud.datastore.Entity], \r\nx$2: com.google.cloud.datastore.ReadOption*)com.google.cloud.datastore.QueryResults[com.google.cloud.datastore.Entity]\r\nand  \r\nmethod run in trait DatastoreReader of type (\r\nx$1: com.google.cloud.datastore.Query[com.google.cloud.datastore.Entity])\r\ncom.google.cloud.datastore.QueryResults[com.google.cloud.datastore.Entity]\r\nmatch argument types (com.google.cloud.datastore.EntityQuery)\r\n```\r\n\r\n...because `run` is defined both on the `Datastore` interface and the `DatastoreReader` interface, which `Datastore` inherits from.\r\n\r\nWhat's worse, the *only* ReadOption is `EventualConsistency`. So it's currently impossible for me to call `datastore.run` and enforce strong consistency.\r\n\r\nIn case it matters, I'm calling `datastore.run` from a Scala application."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3370",
        "number": 3370,
        "title": "Transitive dependency conflict - com.google.api:api-common",
        "labels": [
            "api: spanner",
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "For `com.google.cloud:google-cloud-spanner` versions `0.51.0-beta` and `0.50.0-beta` there is a conflict in transitive dependencies - it depends on both versions `1.6.0` and `1.5.0` of library `com.google.api:api-common`.\r\n\r\nHere's the `gradle dependencyInsight` for more details : \r\n```\r\ncom.google.api:api-common:1.6.0 (conflict resolution)\r\n+--- com.google.api:gax:1.27.0\r\n|    +--- com.google.cloud:google-cloud-core:1.33.0\r\n|    |    +--- com.google.cloud:google-cloud-spanner:0.51.0-beta\r\n|    |    |    \\--- compileClasspath\r\n|    |    \\--- com.google.cloud:google-cloud-core-grpc:1.33.0\r\n|    |         \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n|    \\--- com.google.api:gax-grpc:1.27.0\r\n|         +--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n|         \\--- com.google.cloud:google-cloud-core-grpc:1.33.0 (*)\r\n+--- com.google.api:gax-grpc:1.27.0 (*)\r\n+--- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:0.16.0\r\n|    +--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n|    \\--- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:0.16.0\r\n|         \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n+--- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:0.16.0\r\n|    +--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n|    \\--- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:0.16.0\r\n|         \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n+--- com.google.api.grpc:proto-google-cloud-spanner-v1:0.16.0\r\n|    +--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n|    \\--- com.google.api.grpc:grpc-google-cloud-spanner-v1:0.16.0\r\n|         \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n\\--- com.google.cloud:google-cloud-core:1.33.0 (*)\r\n\r\ncom.google.api:api-common:1.5.0 -> 1.6.0\r\n\\--- com.google.api.grpc:proto-google-iam-v1:0.12.0\r\n     +--- com.google.cloud:google-cloud-core:1.33.0\r\n     |    +--- com.google.cloud:google-cloud-spanner:0.51.0-beta\r\n     |    |    \\--- compileClasspath\r\n     |    \\--- com.google.cloud:google-cloud-core-grpc:1.33.0\r\n     |         \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n     +--- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:0.16.0\r\n     |    +--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n     |    \\--- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:0.16.0\r\n     |         \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n     \\--- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:0.16.0\r\n          +--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n          \\--- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:0.16.0\r\n               \\--- com.google.cloud:google-cloud-spanner:0.51.0-beta (*)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3369",
        "number": 3369,
        "title": "SSL error",
        "labels": [
            "triage me"
        ],
        "state": "closed",
        "body": "Hi Google Cloud team,\r\nTried the BigQuery code sample from here:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/3ebebd0b12c12d6a1c70db54c7f416ea0e70c2a1/google-cloud-examples/src/main/java/com/google/cloud/examples/bigquery/snippets/InsertDataAndQueryTable.java \r\nI've set up the GOOGLE_APPLICATION_CREDENTIALS point to the key per instruction from here: https://cloud.google.com/bigquery/docs/reference/libraries \r\nAnd got following error:\r\n```\r\nJun 12, 2018 2:57:41 PM com.google.api.client.http.HttpRequest execute\r\nWARNING: exception thrown while executing request\r\njavax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\r\n\tat java.base/sun.security.ssl.Alerts.getSSLException(Alerts.java:198)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1974)\r\n\tat java.base/sun.security.ssl.Handshaker.fatalSE(Handshaker.java:345)\r\n\tat java.base/sun.security.ssl.Handshaker.fatalSE(Handshaker.java:339)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.checkServerCerts(ClientHandshaker.java:1968)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1777)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:264)\r\n\tat java.base/sun.security.ssl.Handshaker.processLoop(Handshaker.java:1098)\r\n\tat java.base/sun.security.ssl.Handshaker.processRecord(Handshaker.java:1026)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.processInputRecord(SSLSocketImpl.java:1137)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1074)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1402)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1429)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1413)\r\n\tat java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:567)\r\n\tat java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185)\r\n\tat java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1356)\r\n\tat java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1331)\r\n\tat java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:241)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135)\r\n\tat com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96)\r\n\tat com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:161)\r\n\tat com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.create(HttpBigQueryRpc.java:144)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:152)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:149)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:149)\r\n\tat InsertDataAndQueryTable.main(InsertDataAndQueryTable.java:40)\r\nCaused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\r\n\tat java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:385)\r\n\tat java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:290)\r\n\tat java.base/sun.security.validator.Validator.validate(Validator.java:264)\r\n\tat java.base/sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:343)\r\n\tat java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:226)\r\n\tat java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:133)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.checkServerCerts(ClientHandshaker.java:1947)\r\n\t... 35 more\r\nCaused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\r\n\tat java.base/sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141)\r\n\tat java.base/sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126)\r\n\tat java.base/java.security.cert.CertPathBuilder.build(CertPathBuilder.java:297)\r\n\tat java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:380)\r\n\t... 41 more\r\n\r\nJun 12, 2018 2:57:42 PM com.google.api.client.http.HttpRequest execute\r\nWARNING: exception thrown while executing request\r\njavax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\r\n\tat java.base/sun.security.ssl.Alerts.getSSLException(Alerts.java:198)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1974)\r\n\tat java.base/sun.security.ssl.Handshaker.fatalSE(Handshaker.java:345)\r\n\tat java.base/sun.security.ssl.Handshaker.fatalSE(Handshaker.java:339)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.checkServerCerts(ClientHandshaker.java:1968)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1777)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:264)\r\n\tat java.base/sun.security.ssl.Handshaker.processLoop(Handshaker.java:1098)\r\n\tat java.base/sun.security.ssl.Handshaker.processRecord(Handshaker.java:1026)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.processInputRecord(SSLSocketImpl.java:1137)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1074)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1402)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1429)\r\n\tat java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1413)\r\n\tat java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:567)\r\n\tat java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185)\r\n\tat java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1356)\r\n\tat java.base/sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1331)\r\n\tat java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:241)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135)\r\n\tat com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96)\r\n\tat com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:161)\r\n\tat com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.create(HttpBigQueryRpc.java:144)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:152)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:149)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:149)\r\n\tat InsertDataAndQueryTable.main(InsertDataAndQueryTable.java:40)\r\nCaused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\r\n\tat java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:385)\r\n\tat java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:290)\r\n\tat java.base/sun.security.validator.Validator.validate(Validator.java:264)\r\n\tat java.base/sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:343)\r\n\tat java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:226)\r\n\tat java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:133)\r\n\tat java.base/sun.security.ssl.ClientHandshaker.checkServerCerts(ClientHandshaker.java:1947)\r\n\t... 35 more\r\nCaused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\r\n\tat java.base/sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141)\r\n\tat java.base/sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126)\r\n\tat java.base/java.security.cert.CertPathBuilder.build(CertPathBuilder.java:297)\r\n\tat java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:380)\r\n\t... 41 more\r\n```\r\nlibrary version:\r\n```\r\n <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-bigquery</artifactId>\r\n            <version>1.31.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-core</artifactId>\r\n            <version>1.33.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.api</groupId>\r\n            <artifactId>gax</artifactId>\r\n            <version>1.27.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.api</groupId>\r\n            <artifactId>gax-grpc</artifactId>\r\n            <version>1.27.0</version>\r\n        </dependency>\r\n```\r\nI still can use bq to access the BigQuery.\r\nCould you please help to advise how to resolve this error?\r\nThanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3368",
        "number": 3368,
        "title": "`IntentsClient.listIntents(...)` in the google-cloud-dialogflow library does not retrieve the training phases of an Intent",
        "labels": [
            "api: dialogflow",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "When using the following method: \r\n`com.google.cloud.dialogflow.v2.IntentsClient#listIntents(com.google.cloud.dialogflow.v2.ProjectAgentName)`, the training phrases are not being returned to the client. \r\n\r\nLocally tested with 0.51.0-alpha"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3367",
        "number": 3367,
        "title": "[IoT] IoT client got Internal error HTTP/2. Received Rst Stream.",
        "labels": [
            "api: cloudiot",
            "priority: p2",
            "status: blocked",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nWhen I use the client library for IoT, I got a HTTP/2 internal error with message, \"Received Rst Stream\".\r\nIn here, I used listDevicesCallable() , but also got a same error for simpler call, listDevices().\r\nDoes anyone has an insight for this error?\r\n\r\nThank you.\r\n\r\n### Java version\r\n1.10\r\n\r\n### API Version\r\n0.51-beta (also tried 0.48-beta and 0.50-beta)\r\n\r\n### Stacktrace\r\n```\r\njava.util.concurrent.ExecutionException: com.google.api.gax.rpc.InternalException: io.grpc.StatusRuntimeException: INTERNAL: HTTP/2 error code: INTERNAL_ERROR\r\nReceived Rst Stream\r\n\tat com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:526)\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:507)\r\n\tat com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:83)\r\n       ....\r\nCaused by: com.google.api.gax.rpc.InternalException: io.grpc.StatusRuntimeException: INTERNAL: HTTP/2 error code: INTERNAL_ERROR\r\nReceived Rst Stream\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:67)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:95)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:61)\r\n\tat com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1349)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1024)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:711)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:492)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:467)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684)\r\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\r\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:391)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:471)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:553)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:474)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:591)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t... 1 more\r\nCaused by: io.grpc.StatusRuntimeException: INTERNAL: HTTP/2 error code: INTERNAL_ERROR\r\nReceived Rst Stream\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 22 more\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3363",
        "number": 3363,
        "title": "Dependency issues with PubSub and beam-sdks-java-io-google-cloud-platform",
        "labels": [
            "api: pubsub",
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I have just introduced Beam libraries along with the GCP I/O (for the PubsubIO unbounded source) jar into my existing project which has Bigtable and PubSub.\r\n\r\nMy pom dependencies look like this \r\n\r\n```\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-pubsub</artifactId>\r\n      <version>0.34.0-beta</version>\r\n    </dependency>\r\n\r\n    <dependency>\r\n      <groupId>com.google.cloud.bigtable</groupId>\r\n      <artifactId>bigtable-hbase-1.x</artifactId>\r\n      <version>1.0.0-pre3</version>\r\n    </dependency>\r\n\r\n    <dependency>\r\n      <groupId>org.apache.beam</groupId>\r\n      <artifactId>beam-runners-flink_2.11</artifactId>\r\n      <version>2.4.0</version>\r\n    </dependency>\r\n\r\n    <dependency>\r\n      <groupId>org.apache.beam</groupId>\r\n      <artifactId>beam-sdks-java-core</artifactId>\r\n      <version>2.4.0</version>\r\n    </dependency>\r\n\r\n    <dependency>\r\n      <groupId>org.apache.beam</groupId>\r\n      <artifactId>beam-sdks-java-io-google-cloud-platform</artifactId>\r\n      <version>2.4.0</version>\r\n    </dependency>\r\n\r\n```\r\nThe beam-sdks-java-io-google-cloud-platform dependencies seem to cause a conflict, and maven does not even resolve the dependencies correctly due to conflicting versions. The error message is\r\n\r\n```\r\nCould not resolve version conflict among [com.google.cloud:google-cloud-pubsub:jar:0.34.0-beta -> com.google.cloud:google-cloud-core-grpc:jar:1.16.0 -> io.grpc:grpc-protobuf:jar:1.9.0 -> io.grpc:grpc-core:jar:1.9.0,\r\n com.google.cloud:google-cloud-pubsub:jar:0.34.0-beta -> io.grpc:grpc-netty:jar:1.9.0 -> io.grpc:grpc-core:jar:[1.9.0,\r\n1.9.0],\r\n com.google.cloud:google-cloud-pubsub:jar:0.34.0-beta -> io.grpc:grpc-stub:jar:1.9.0 -> io.grpc:grpc-core:jar:1.9.0,\r\n com.google.cloud:google-cloud-pubsub:jar:0.34.0-beta -> io.grpc:grpc-auth:jar:1.9.0 -> io.grpc:grpc-core:jar:[1.9.0,\r\n1.9.0],\r\n com.google.cloud.bigtable:bigtable-hbase-1.x:jar:1.0.0-pre3 -> com.google.cloud.bigtable:bigtable-hbase:jar:1.0.0-pre3 -> io.grpc:grpc-core:jar:1.5.0,\r\n org.apache.beam:beam-runners-flink_2.11:jar:2.4.0 -> org.apache.beam:beam-runners-core-java:jar:2.4.0 -> org.apache.beam:beam-model-fn-execution:jar:2.4.0 -> io.grpc:grpc-core:jar:1.2.0,\r\n org.apache.beam:beam-runners-flink_2.11:jar:2.4.0 -> org.apache.beam:beam-runners-core-construction-java:jar:2.4.0 -> org.apache.beam:beam-model-job-management:jar:2.4.0 -> io.grpc:grpc-core:jar:1.2.0,\r\n org.apache.beam:beam-runners-flink_2.11:jar:2.4.0 -> org.apache.beam:beam-runners-core-construction-java:jar:2.4.0 -> io.grpc:grpc-core:jar:1.2.0,\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> io.grpc:grpc-core:jar:1.2.0,\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,\r\n1.2.0],\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-okhttp:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,\r\n1.2.0],\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-protobuf-lite:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0,\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> io.grpc:grpc-all:jar:1.2.0 -> io.grpc:grpc-protobuf-nano:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0,\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3 -> io.grpc:grpc-core:jar:1.5.0,\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -> io.grpc:grpc-core:jar:1.7.0,\r\n org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -> io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0 -> io.grpc:grpc-core:jar:1.6.1]\r\n```\r\nI have tried juggling around with lower/other versions of the PubSub/Bigtable libraries, but that just leads to more, different errors. Is there any way to resolve this? \r\n\r\nI have looked at shading with relocation for the \"beam-sdks-java-io-google-cloud-platform\" jar but without success. There are related tickets like https://github.com/apache/beam/pull/4727 and the umbrella #2555 , but the latter has been moved to the backlog. Any solutions?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3356",
        "number": 3356,
        "title": "[BigQuery] FieldValue.getTimestampValue returns incorrect microseconds",
        "labels": [
            ":rotating_light:",
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "open",
        "body": "I have a BigQuery table with a timestamp column where some values are '9999-12-31 23:59:59.999 UTC' (no microseconds; i.e. `TIMESTAMP_TO_USEC` of that timestamp gives 253402300799999000). Retrieving such a timestamp using the Java BigQuery API (via `FieldValue.getTimestampValue`) results in 253402300799999008 being returned, i.e. with an additional 8 microseconds. I haven't seen this for other timestamp values yet."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3355",
        "number": 3355,
        "title": "Add dependency management section for Gradle in README",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "In the Quickstart section of the README file, need steps similar to the Maven instructions."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3350",
        "number": 3350,
        "title": "Programmatically Consumable Metadata about clients",
        "labels": [
            "type: feature request"
        ],
        "state": "open",
        "body": "Cloud Tools for Java has been maintaining a JSON file with info about the client libraries that we can consume in our products:\r\n\r\nhttps://github.com/GoogleCloudPlatform/appengine-plugins-core/blob/master/src/main/resources/com/google/cloud/tools/libraries/libraries.json\r\n\r\nWe also have Java code for consuming and validating this file.\r\n\r\nAny interest in moving this into google-cloud-java so everyone can use it and it stays in sync with releases? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3349",
        "number": 3349,
        "title": "Compute: diskTypes.aggregateList retruns region scope instead of zone scope",
        "labels": [],
        "state": "closed",
        "body": "```\r\ntestAggregatedListDiskTypes(com.google.cloud.compute.deprecated.it.ITComputeTest)  Time elapsed: 0.155 sec  <<< ERROR!\r\njava.lang.IllegalArgumentException: https://www.googleapis.com/compute/v1/projects/gcloud-devel/regions/us-central1/diskTypes/local-ssd is not a valid disk type URL\r\n\tat com.google.cloud.compute.deprecated.DiskTypeId.fromUrl(DiskTypeId.java:149)\r\n\tat com.google.cloud.compute.deprecated.DiskType.fromPb(DiskType.java:234)\r\n\tat com.google.cloud.compute.deprecated.ComputeImpl$5.apply(ComputeImpl.java:542)\r\n\tat com.google.cloud.compute.deprecated.ComputeImpl$5.apply(ComputeImpl.java:539)\r\n\tat com.google.common.collect.Iterators$7.transform(Iterators.java:750)\r\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:47)\r\n\tat com.google.cloud.PageImpl$PageIterator.computeNext(PageImpl.java:72)\r\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:145)\r\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:140)\r\n\tat com.google.cloud.compute.deprecated.it.ITComputeTest.testAggregatedListDiskTypes(ITComputeTest.java:206)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\ntestAggregatedListDiskTypesWithFilter(com.google.cloud.compute.deprecated.it.ITComputeTest)  Time elapsed: 0.164 sec  <<< ERROR!\r\njava.lang.IllegalArgumentException: https://www.googleapis.com/compute/v1/projects/gcloud-devel/regions/us-central1/diskTypes/pd-ssd is not a valid disk type URL\r\n\tat com.google.cloud.compute.deprecated.DiskTypeId.fromUrl(DiskTypeId.java:149)\r\n\tat com.google.cloud.compute.deprecated.DiskType.fromPb(DiskType.java:234)\r\n\tat com.google.cloud.compute.deprecated.ComputeImpl$5.apply(ComputeImpl.java:542)\r\n\tat com.google.cloud.compute.deprecated.ComputeImpl$5.apply(ComputeImpl.java:539)\r\n\tat com.google.common.collect.Iterators$7.transform(Iterators.java:750)\r\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:47)\r\n\tat com.google.cloud.PageImpl$PageIterator.computeNext(PageImpl.java:72)\r\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:145)\r\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:140)\r\n\tat com.google.cloud.compute.deprecated.it.ITComputeTest.testAggregatedListDiskTypesWithFilter(ITComputeTest.java:223)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nThose two tests fail because diskTypes.aggregateList returns diskTypeIds in the form \r\n```\r\nprojects/{project}/regions/{region}/diskTypes/{diskType}\r\n```\r\ninstead of the expected\r\n```\r\nprojects/{project}/zones/{zone}/diskTypes/{diskType}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3345",
        "number": 3345,
        "title": "Document in javadoc that certain BigQuery methods do not interact with streaming buffer",
        "labels": [
            "api: bigquery",
            "priority: p2"
        ],
        "state": "closed",
        "body": "So issues like https://github.com/GoogleCloudPlatform/google-cloud-java/issues/3344 can be immediately be avoided by users.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3344",
        "number": 3344,
        "title": "[BigQuery] Streaming insert drops records?",
        "labels": [
            ":rotating_light:",
            "api: bigquery",
            "priority: p2",
            "status: blocked",
            "type: bug"
        ],
        "state": "open",
        "body": "I'm facing an issue with BigQuery streaming inserts (`Table.insert(...)`, specifically `insert(Iterable<InsertAllRequest.RowToInsert> rows, boolean skipInvalidRows, boolean ignoreUnknownValues)` with `skipInvalidRows = false` and `ignoreUnknownValues = false`) where (sometimes) records don't seem to be available after one or more insert requests. The `InsertAllRequest`s complete successfully, i.e. no exceptions are thrown and no errors are reported (`InsertAllResponse.hasErrors` returns `false`). I checked availability of streamed data in the BigQuery Web UI and using the `Table.list(...)` API. According to https://cloud.google.com/bigquery/streaming-data-into-bigquery I would expect streamed data to be available for query a few seconds after insertion. In cases where some records were missing after the initial check, I tried again after 10s, 30s, 60s, 1h, ... but to no avail. So it looks like the records have been dropped for some reason.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3343",
        "number": 3343,
        "title": "ResourceExhaustedException ",
        "labels": [
            "api: monitoring",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nI am reading a pubsub subscription queue length and publish rate continuously using a Timer. But I am getting this exception time to time. \r\n\r\n> Exception in thread \"Timer-0\" com.google.api.gax.rpc.ResourceExhaustedException: io.grpc.StatusRuntimeException: RESOURCE_EXHAUSTED: The query rate is too high. at com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:57) at com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72) at com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60) at com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:95) at com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:61) at com.google.common.util.concurrent.Futures$4.run(Futures.java:1123) at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435) at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900) at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811) at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675) at io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:492) at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:467) at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41) at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684) at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41) at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:392) at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475) at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590) at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: io.grpc.StatusRuntimeException: RESOURCE_EXHAUSTED: The query rate is too high. at io.grpc.Status.asRuntimeException(Status.java:526) ... 19 more\r\n\r\n\r\n my code is as follows.\r\n```\r\n   final MetricServiceClient client = MetricServiceClient.create();\r\n            ProjectName name = ProjectName.of(projectId);    \r\n             long startMillis = System.currentTimeMillis() - ((60 * 1) * 1000);\r\n             TimeInterval interval = TimeInterval.newBuilder()\r\n                .setStartTime(Timestamps.fromMillis(startMillis))\r\n                .setEndTime(Timestamps.fromMillis(System.currentTimeMillis()))\r\n                .build(); \r\n\r\n\r\n\r\n        Aggregation aggregation = Aggregation.newBuilder()\r\n                .setAlignmentPeriod(Duration.newBuilder().setSeconds(300).build())\r\n                .setPerSeriesAligner(Aggregation.Aligner.ALIGN_MEAN)\r\n                .build();\r\n\r\n        ListTimeSeriesRequest.Builder requestBuilder1 = ListTimeSeriesRequest.newBuilder()\r\n                .setName(name.toString())\r\n                .setFilter(filter1)\r\n                .setInterval(interval);\r\n        ListTimeSeriesRequest request1 = requestBuilder1.build();\r\n        MetricServiceClient.ListTimeSeriesPagedResponse response1 = client.listTimeSeries(request1);\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3336",
        "number": 3336,
        "title": "Document how to add custom outbound headers",
        "labels": [
            "type: docs"
        ],
        "state": "open",
        "body": "This issue came up a number of times already, where users need to add custom headers when using w/ their own proxy server for outbound calls.  Should document how to do this for both HTTP and gRPC  clients."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3334",
        "number": 3334,
        "title": "Pubsub: Invalid resource name given",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "When I try to follow the example code as given [here](https://cloud.google.com/pubsub/docs/publisher): \r\n\r\n(NOTE: I altered the hardcoded strings here to match the ones I need)\r\n-------\r\n```\r\nProjectTopicName topicName = ProjectTopicName.of(\"my-project-id\", \"my-topic-id\");\r\nPublisher publisher = null;\r\nList<ApiFuture<String>> messageIdFutures = new ArrayList<>();\r\n\r\ntry {\r\n  // Create a publisher instance with default settings bound to the topic\r\n  publisher = Publisher.newBuilder(topicName).build();\r\n\r\n  List<String> messages = Arrays.asList(\"first message\", \"second message\");\r\n\r\n  // schedule publishing one message at a time : messages get automatically batched\r\n  for (String message : messages) {\r\n    ByteString data = ByteString.copyFromUtf8(message);\r\n    PubsubMessage pubsubMessage = PubsubMessage.newBuilder().setData(data).build();\r\n\r\n    // Once published, returns a server-assigned message id (unique within the topic)\r\n    ApiFuture<String> messageIdFuture = publisher.publish(pubsubMessage);\r\n    messageIdFutures.add(messageIdFuture);\r\n  }\r\n} finally {\r\n  // wait on any pending publish requests.\r\n  List<String> messageIds = ApiFutures.allAsList(messageIdFutures).get();\r\n\r\n  for (String messageId : messageIds) {\r\n    System.out.println(\"published with message ID: \" + messageId);\r\n  }\r\n\r\n  if (publisher != null) {\r\n    // When finished with the publisher, shutdown to free up resources.\r\n    publisher.shutdown();\r\n  }\r\n}\r\n``` \r\n\r\n\r\nIt raises an exception on:\r\n\r\n`ApiFutures.allAsList(messageIdFutures).get();`\r\n\r\nException:\r\n```\r\njava.util.concurrent.ExecutionException: com.google.api.gax.rpc.InvalidArgumentException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Invalid resource name given (name=testResource) Refer to https://cloud.google.com/pubsub/overview#names for more information.\r\n```\r\n\r\nWhen I publish a message through the web console, it works as intended and my code (based on the example subscriber code) can read it out correctly.\r\n\r\nMy resource name matches with what I see in the console though:\r\n\r\n```\r\nprojects/testProject-2013370/topics/testResource\r\n```\r\n\r\n### Project info:\r\nJava version: 1.8.0_131\r\nPubsub dependency:   'com.google.cloud:google-cloud-pubsub:1.31.0'\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3333",
        "number": 3333,
        "title": "Pubsub exception refers to faulty URL",
        "labels": [
            "api: pubsub",
            "priority: p2"
        ],
        "state": "closed",
        "body": "When I try to use ApiFutures.allAsList(messageIDFutures).get() it raises an exception when the resource name is wrong:\r\n\r\n```\r\njava.util.concurrent.ExecutionException: com.google.api.gax.rpc.InvalidArgumentException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Invalid resource name given (name=testresource). Refer to https://cloud.google.com/pubsub/overview#names for more information.\r\n```\r\n\r\nHowever, the URL: https://cloud.google.com/pubsub/overview#names is of no help, as it just points to: https://cloud.google.com/pubsub/docs/overview#names which has no \"Overview#names\" and thus is of little help in resolving this issue. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3331",
        "number": 3331,
        "title": "Logging - no public API to create SourceLocation.Builder",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It appears there is no public API to create a new `com.google.cloud.logging.SourceLocation.Builder` object, thus I am unable to append this metadata to the log entries. \r\n\r\nExpected API would be to have a public `com.google.cloud.logging.SourceLocation.newBuilder()` function, but this is not there."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3329",
        "number": 3329,
        "title": "Update library dependencies to avoid sbt eviction warnings",
        "labels": [
            "dependencies",
            "type: feature request"
        ],
        "state": "open",
        "body": "Using the latest `0.49.0-alpha` version results in the following warning using sbt.\r\n\r\n```sbt\r\nsbt:projectname> clean\r\n[success] Total time: 0 s, completed 31.05.2018 22:50:18\r\nsbt:projectname> compile\r\n[info] Updating ...\r\n[info] Done updating.\r\n[warn] Found version conflict(s) in library dependencies; some are suspected to be binary incompatible:\r\n[warn] \t* com.google.auth:google-auth-library-credentials:0.9.1 is selected over 0.9.0\r\n[warn] \t    +- com.google.auth:google-auth-library-oauth2-http:0.9.1 (depends on 0.9.1)\r\n[warn] \t    +- com.google.api:gax-grpc:1.25.0                     (depends on 0.9.1)\r\n[warn] \t    +- com.google.cloud:google-cloud-core-grpc:1.31.0     (depends on 0.9.1)\r\n[warn] \t    +- io.grpc:grpc-auth:1.10.1                           (depends on 0.9.0)\r\n[warn] \t* com.google.code.findbugs:jsr305:3.0.1 is selected over {1.3.9, 3.0.0}\r\n[warn] \t    +- io.grpc:grpc-core:1.10.1                           (depends on 3.0.0)\r\n[warn] \t    +- com.google.api:gax-grpc:1.25.0                     (depends on 3.0.0)\r\n[warn] \t    +- com.google.api:gax:1.25.0                          (depends on 1.3.9)\r\n[warn] \t    +- com.google.http-client:google-http-client:1.23.0   (depends on 1.3.9)\r\n[warn] \t    +- com.google.api:api-common:1.5.0                    (depends on 1.3.9)\r\n[warn] \t    +- com.google.cloud:google-cloud-core:1.31.0          (depends on 1.3.9)\r\n[warn] \t* com.google.guava:guava:20.0 is selected over 19.0\r\n[warn] \t    +- com.google.api:gax:1.25.0                          (depends on 20.0)\r\n[warn] \t    +- com.google.api:gax-grpc:1.25.0                     (depends on 20.0)\r\n[warn] \t    +- com.google.cloud:google-cloud-core-grpc:1.31.0     (depends on 20.0)\r\n[warn] \t    +- com.google.cloud:google-cloud-core:1.31.0          (depends on 20.0)\r\n[warn] \t    +- com.google.auth:google-auth-library-oauth2-http:0.9.1 (depends on 19.0)\r\n[warn] \t    +- io.grpc:grpc-core:1.10.1                           (depends on 19.0)\r\n[warn] \t    +- io.opencensus:opencensus-api:0.11.0                (depends on 19.0)\r\n[warn] \t    +- com.google.protobuf:protobuf-java-util:3.5.1       (depends on 19.0)\r\n[warn] \t    +- io.grpc:grpc-protobuf:1.10.1                       (depends on 19.0)\r\n[warn] \t    +- io.grpc:grpc-protobuf-lite:1.10.1                  (depends on 19.0)\r\n[warn] \t    +- com.google.api:api-common:1.5.0                    (depends on 19.0)\r\n[warn] Run 'evicted' to see detailed eviction warnings\r\n[info] Compiling 51 Scala sources to /Users/tobscore/pathToProject/target/scala-2.12/classes ...\r\n[info] Done compiling.\r\n[success] Total time: 4 s, completed 31.05.2018 22:50:25\r\n```\r\nAdding the following line to any project's `build.sbt`, will cause the above warnings.\r\n```sbt\r\nlibraryDependencies += \"com.google.cloud\" % \"google-cloud-speech\" % \"0.49.0-alpha\"\r\n```\r\nI also tested this in a bare project with no other dependencies but this one."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3326",
        "number": 3326,
        "title": "Pubsub.Publisher: Failed to submit a listener notification task. Event loop shut down?",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm Receiving the following exception:  Failed to submit a listener notification task. Event loop shut down?\r\n\r\n```\r\nclass: io.grpc.netty.shaded.io.netty.util.concurrent.DefaultPromise\t\r\nexception:\t\r\n{\t\r\n         exception_class:\t java.lang.UnsupportedOperationException\t\r\n         stacktrace: \tjava.lang.UnsupportedOperationException\r\n         \t\t\t\tat io.grpc.netty.shaded.io.netty.util.internal.shaded.org.jctools.queues.BaseMpscLinkedArrayQueue.iterator(BaseMpscLinkedArrayQueue.java:201)\r\n\t\t\t\t\t\tat java.util.AbstractCollection.remove(AbstractCollection.java:282)\r\n\t\t\t\t\t\tat io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.removeTask(SingleThreadEventExecutor.java:339)\r\n\t\t\t\t\t\tat io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:747)\r\n\t\t\t\t\t\tat io.grpc.netty.shaded.io.netty.util.concurrent.DefaultPromise.safeExecute(DefaultPromise.java:760)\r\n\t\t\t\t\t\tat io.grpc.netty.shaded.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:428)\r\n\t\t\t\t\t\tat io.grpc.netty.shaded.io.netty.util.concurrent.DefaultPromise.cancel(DefaultPromise.java:315)\r\n\t\t\t\t\t\tat io.grpc.netty.shaded.io.netty.util.concurrent.ScheduledFutureTask.cancel(ScheduledFutureTask.java:151)\r\n\t\t\t\t\t\tat io.grpc.internal.ClientCallImpl.removeContextListenerAndCancelDeadlineFuture(ClientCallImpl.java:335)\r\n\t\t\t\t\t\tat io.grpc.internal.ClientCallImpl.access$1000(ClientCallImpl.java:63)\r\n\t\t\t\t\t\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:559)\r\n\t\t\t\t\t\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478)\r\n\t\t\t\t\t\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590)\r\n\t\t\t\t\t\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\t\t\t\t\t\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\t\t\t\t\t\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\t\t\t\t\t\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\t\t\t\t\t\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\t\t\t\t\t\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\t\t\t\t\t\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\t\t\t\t\t\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t\t\t\t\t\tat java.lang.Thread.run(Thread.java:748)\t\r\n\r\n }\t\r\nfile:\t DefaultPromise.java\t\r\nlevel:\t ERROR\t\r\nline_number:\t 762\t\r\nlogger_name:\t io.grpc.netty.shaded.io.netty.util.concurrent.DefaultPromise.rejectedExecution\t\r\nmessage:\t Failed to submit a listener notification task. Event loop shut down?\t\r\n```\r\n\r\n\r\nhere's how i configure publisher and how I publish:\r\n\r\n```\r\nfinal Publisher publisher = Publisher.newBuilder(topicName)\r\n        .setChannelProvider(TopicAdminSettings.defaultTransportChannelProvider())\r\n        .setCredentialsProvider(credentialsProvider) // loading cred. from file\r\n        .build();\r\n\r\n```\r\n\r\nThis is how i publish: I'm receiving batches contains maximum of 2 messages so publishing whenever new messages comes\r\n\r\n```\r\ntry {\r\n\r\n      for (final String message : messages) {\r\n        final ByteString data = ByteString.copyFromUtf8(message);\r\n\r\n        final PubsubMessage pubsubMessage = PubsubMessage.newBuilder()\r\n            .setData(data)\r\n            .build();\r\n        final ApiFuture<String> messageIdFuture = publisher.publish(pubsubMessage);\r\n        messageIdFutures.add(messageIdFuture);\r\n      }\r\n\r\n    } finally {\r\n      final List<String> messageIds = ApiFutures.allAsList(messageIdFutures).get();\r\n\r\n      for (final String messageId : messageIds) {\r\n        LOG.info(MessageFormat.format(\"published with message ID: {0}\", messageId));\r\n      }\r\n      if (publisher != null) {\r\n        publisher.shutdown();\r\n      }\r\n      return messageIds;\r\n    }\r\n```\r\nI don't know why I'm receiving above exception.\r\n\r\nSo I think it's related to concurrency issue I added the following to control concurrency but not sure if this will help me solving it or not.\r\n```\r\nfinal Publisher publisher = Publisher.newBuilder(topicName)\r\n        .setChannelProvider(transportChannelProvider)\r\n        .setCredentialsProvider(credentialsProvider)\r\n        .setExecutorProvider(InstantiatingExecutorProvider.newBuilder()\r\n        .setExecutorThreadCount(1).build())\r\n        .build();\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3325",
        "number": 3325,
        "title": "google-cloud-logging LogEntry is missing a \"spanId\" field.",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm writing a LoggingEnhancer for OpenCensus (https://github.com/census-instrumentation/opencensus-java/pull/1212).  I noticed that the Stackdriver LogEntry has a \"spanId\" field in https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry, but the google-cloud-logging LogEntry class does not ([LogEntry.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-logging/src/main/java/com/google/cloud/logging/LogEntry.java)).  Should both LogEntry data structures have a \"spanId\"?  If so, I can make a pull request to add the field.\r\n\r\n/cc @g-easy "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3321",
        "number": 3321,
        "title": "BigQuery insertAll always retries operation",
        "labels": [
            ":rotating_light:",
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi. First time reporter here.\r\nI wanted to report a small but perhaps inconvenient bug in BigQuery, specifically regarding streaming inserts using an `InsertAllRequest`. It seems for some reason unknown to me that inserts are retried using the client's `RetrySettings` whenever row ids are supplied for deduplication.\r\nWhen the current implementation always attempts a retry (which I discovered during these odd retry errors) due to the fact that `Lists.transform()` is strictly lazy.\r\nAnyhow the fix is minor and I corrected it on my branch but I'm unsure how to write the necessary tests in order to validate my claim. My commit is here: https://github.com/neuromantik33/google-cloud-java/commit/984b5bb41cfb1ec0ef7cea27a0bc38d8adde5051, and after proper review I can submit a pull request.\r\n\r\nThanks in advance for any feedback."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3319",
        "number": 3319,
        "title": "Please support HTTPS proxies and self-signed certificates",
        "labels": [],
        "state": "closed",
        "body": "When these libraries try to connect to googleapis.com through HTTPS proxies, they use to validate the server's certificate a cacerts file embedded in google-client-api-x.y.z.jar itself. \r\n\r\nThe file is src/main/resources/com/google/api/client/googleapis/google.jks. Because this file is packaged in the same jar as the client code, it's not possible to override it or inject the CA's certificates to make the client recognize the proxy's certificates.\r\n\r\nAs a result, these libraries cannot be used behind a proxy when a plain HTTP proxy is not an option.\r\n\r\nPlease provide a way to instruct these client libraries to either use the standard Java cacerts file or a way to provide extra certificates to be added to the list of valid CAs at run time."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3316",
        "number": 3316,
        "title": "longRunningRecognizeAsync return SpeechRecognitionResult  whit Alternatives different from first have word list empty",
        "labels": [
            "api: speech",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "```\r\n// after  longRunningRecognizeAsync \r\n// with setMaxAlternatives to 6\r\nfor ( SpeechRecognitionAlternative alt :  result.getAlternativesList()) {\r\n    alt.getConfidence(); // is ok full\r\n    alt.getTranscript(); // is ok full\r\n      \tfor ( WordInfo word : alt.getWordsList() ) { // NOT ok word list is empty after first ..     \r\n\t\t//speechRecognitionAlternative\r\n\t\tParolaTrascrizione parola = new ParolaTrascrizione(word);\r\n\t\tlistParole.add(parola);\r\n\t}\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3315",
        "number": 3315,
        "title": "Firestore should accept Protobuf and Firestore Value(s)",
        "labels": [
            "api: firestore",
            "type: feature request"
        ],
        "state": "open",
        "body": "Currently, the Firestore SDK provides the following interfaces for `set(`/`update(`/etc, w.r.t. write batches and writing in general (parameters irrelevant to this ticket omitted):\r\n\r\n- Add via Java: `set(..., Map<String, Object> fields, ...)`\r\n- Add via POJO: `set(..., Object pojo, ...)`\r\n\r\nThese are great for a lot of use cases. But, those underlying methods immediately serialize everything to `com.google.firestore.v1beta1.Value` objects.\r\n\r\nIf your application would like more control over the `Value`(s) selected during serialization, why can't you provide your object via `set(..., Map<String, com.google.firestore.v1beta1.Value>)`?\r\n\r\nI'd like to request that such an interface be added. Or, another way to do it would be to accept Protobuf's regular `Value` well-known-type. However, it seems as though it reflects a subset of Firestore's types (i.e. `setNumberValue` where Firestore has `setDoubleValue`, `setIntegerValue`, etc) so I understand why that particular type wrapper was not used.\r\n\r\nThank you in advance"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3314",
        "number": 3314,
        "title": "GoogleCredentials Deprecated but is still used as an example for authentication",
        "labels": [],
        "state": "closed",
        "body": "Hi Admin,\r\n\r\nGoogleCredentials has already been deprecated but is still being used as an example in the Authentication using OAuth2. Would like to use the more updated version. Hope there will be some update. Thanks! :)\r\n\r\nIf you already have an OAuth2 access token, you can use it to authenticate (notice that in this case, the access token will not be automatically refreshed):\r\n```\r\nStorage storage = StorageOptions.newBuilder()\r\n    .setCredentials(new GoogleCredentials(new AccessToken(accessToken, expirationTime)))\r\n    .build()\r\n    .getService();\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3312",
        "number": 3312,
        "title": "Compute integration tests are failing",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/6716?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\n```\r\n-------------------------------------------------------\r\n T E S T S\r\n-------------------------------------------------------\r\nRunning com.google.cloud.compute.deprecated.it.ITComputeTest\r\nTests run: 58, Failures: 0, Errors: 2, Skipped: 4, Time elapsed: 679.408 sec <<< FAILURE! - in com.google.cloud.compute.deprecated.it.ITComputeTest\r\ntestAggregatedListDiskTypes(com.google.cloud.compute.deprecated.it.ITComputeTest)  Time elapsed: 0.184 sec  <<< ERROR!\r\njava.lang.IllegalArgumentException: https://www.googleapis.com/compute/v1/projects/gcloud-devel/regions/us-central1/diskTypes/local-ssd is not a valid disk type URL\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3309",
        "number": 3309,
        "title": "Likely Copypasta on https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-websecurityscanner",
        "labels": [
            ":rotating_light:",
            "triage me"
        ],
        "state": "closed",
        "body": "You will need a Google Developers Console project **with the Text-to-Speech API** enabled. Follow these instructions to get your project set up. You will also need to set up the local development environment by installing the Google Cloud SDK and running the following commands in command line: gcloud auth login and gcloud config set project [YOUR PROJECT ID].\r\n\r\nDoes cloud security scanner really require the Text-To-Speech API? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3308",
        "number": 3308,
        "title": "PubSub subscription messages are not getting acknowledged properly",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I am new to google cloud, first tried with available code snippets. Able to read from subscription successfully, after that messages are not getting cleared off from subscription, there is no change in depth of subscription when I monitored on stack driver.\r\n```\r\nMessageReceiver receiver = new MessageReceiver() {\r\n    @Override\r\n    public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n        System.out.println(\"Received message: \" + message.getData().toStringUtf8());\r\n        consumer.ack();\r\n    }\r\n};\r\n\r\nSubscriber subscriber = null;\t\t\r\n\r\ntry {\r\n    FlowControlSettings flowControlSettings = FlowControlSettings.newBuilder()\r\n       .setMaxOutstandingElementCount(10_000L)\r\n       .setMaxOutstandingRequestBytes(1_000_000_000L).build();\r\n\r\n    subscriber = Subscriber.newBuilder(subscription, receiver)\r\n        .setFlowControlSettings(flowControlSettings)\r\n        .setCredentialsProvider(credentialsProvider()).build();\t\t\r\n\r\n    subscriber.addListener(new Subscriber.Listener() {\r\n        @Override\r\n\tpublic void failed(Subscriber.State from, Throwable failure) {\r\n\t// Handle failure. This is called when the Subscriber\r\n\t// encountered a fatal error and is shutting down.\r\n\t    System.err.println(failure);\r\n\t }\r\n    }, MoreExecutors.directExecutor());"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3305",
        "number": 3305,
        "title": "EnvironmentSessionName defaults to draft",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "What is the current default value to EnvironmentSessionName? How can i default to Draft? \r\n\r\nIt doesnt seem to be possible at the moment to fallback to draft and i cant find any documentation around that."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3302",
        "number": 3302,
        "title": "Only the first of several US phone numbers in the same input gets de-identified",
        "labels": [
            "api: dlp",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm sending an input string with several phone numbers to the DLP service, and it seems like only the first occurrence gets de-identified. My input looks like this: `\"My phone number is 408.867.5309 or 650.867.5309\"`. My config is:\r\n\r\n- Using all available InfoTypes. PHONE_NUMBER is definitely in there.\r\n- The string gets set as one single Row in a Table which is added to a ContentItem.\r\n\r\nThe request code looks like this:\r\n\r\n```\r\n                DeidentifyContentRequest request =\r\n                        DeidentifyContentRequest.newBuilder()\r\n                                .setParent(ProjectName.of(projectId).toString())\r\n                                .setDeidentifyConfig(deidentifyConfig)\r\n                                .setInspectConfig(inspectConfig)\r\n                                .setItem(contentItem)\r\n                                .build();\r\n```\r\n\r\nOnly the first occurrence of the phone number in the input string above gets de-identified. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3300",
        "number": 3300,
        "title": "RFE: provide a method that adds all InfoTypes without having to specify them",
        "labels": [
            "api: dlp",
            "type: feature request"
        ],
        "state": "open",
        "body": "It would be great if the Java API for DLP de-identification/redaction had a way of specifying that the client wants to use all available `InfoType` variants without having to first retrieve all available InfoTypes, and then explicitly set them. Something like this would be nice:\r\n```\r\n        InspectConfig inspectConfig = InspectConfig.newBuilder().addAllInfoTypes().build();\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3295",
        "number": 3295,
        "title": "Include project ID in validation failure",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This code from com.google.cloud.datastore.Validator recently triggered in a user project:\r\n\r\n```\r\n  static String validateDatabase(String projectId) {\r\n    checkArgument(!Strings.isNullOrEmpty(projectId), \"projectId can't be empty or null\");\r\n    checkArgument(PROJECT_ID_PATTERN.matcher(projectId).matches(),\r\n        \"projectId must match the following pattern: \" + PROJECT_ID_PATTERN.pattern());\r\n    return projectId;\r\n  }\r\n```\r\n\r\nIt's a little harder to debug the user error than I'd like because the actual project ID does not appear in the exception message. Something like this would be nice:\r\n\r\n```\r\n    checkArgument(PROJECT_ID_PATTERN.matcher(projectId).matches(),\r\n        \"projectId \" + projectId + \" does not match the required pattern: \" + PROJECT_ID_PATTERN.pattern());\r\n```\r\n\r\nHere's the actual trace:\r\n\r\n\r\n```\r\ncom.googlecode.objectify.SaveException: Error saving app.Car@53a45906: java.lang.IllegalArgumentException: projectId must match the following pattern: ([a-z\\d\\-]{1,100}~)?([a-z\\d][a-z\\d\\-\\.]{0,99}:)?([a-z\\d][a-z\\d\\-]{0,99})\r\n\tat com.googlecode.objectify.impl.EntityMetadata.save(EntityMetadata.java:117)\r\n\tat com.googlecode.objectify.impl.WriteEngine.save(WriteEngine.java:69)\r\n\tat com.googlecode.objectify.impl.SaverImpl.entities(SaverImpl.java:60)\r\n\tat com.googlecode.objectify.impl.SaverImpl.entity(SaverImpl.java:35)\r\n\tat app.HelloAppEngine.doGet(HelloAppEngine.java:23)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n\tat com.googlecode.objectify.ObjectifyFilter.doFilter(ObjectifyFilter.java:48)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.ResponseRewriterFilter.doFilter(ResponseRewriterFilter.java:134)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.HeaderVerificationFilter.doFilter(HeaderVerificationFilter.java:34)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:63)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.jetty9.StaticFileFilter.doFilter(StaticFileFilter.java:123)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectRequest(DevAppServerModulesFilter.java:366)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectModuleRequest(DevAppServerModulesFilter.java:349)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doFilter(DevAppServerModulesFilter.java:116)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.DevAppServerRequestLogFilter.doFilter(DevAppServerRequestLogFilter.java:44)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:524)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n\tat com.google.appengine.tools.development.jetty9.DevAppEngineWebAppContext.doScope(DevAppEngineWebAppContext.java:94)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat com.google.appengine.tools.development.jetty9.JettyContainerService$ApiProxyHandler.handle(JettyContainerService.java:597)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:534)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\r\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: \r\njava.lang.IllegalArgumentException: projectId must match the following pattern: ([a-z\\d\\-]{1,100}~)?([a-z\\d][a-z\\d\\-\\.]{0,99}:)?([a-z\\d][a-z\\d\\-]{0,99})\r\n\tat com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\r\n\tat com.google.cloud.datastore.Validator.validateDatabase(Validator.java:42)\r\n\tat com.google.cloud.datastore.BaseKey$Builder.<init>(BaseKey.java:58)\r\n\tat com.google.cloud.datastore.KeyFactory.<init>(KeyFactory.java:35)\r\n\tat com.google.cloud.datastore.DatastoreHelper.newKeyFactory(DatastoreHelper.java:58)\r\n\tat com.google.cloud.datastore.DatastoreImpl.newKeyFactory(DatastoreImpl.java:466)\r\n\tat com.googlecode.objectify.impl.Keys.createRawIncomplete(Keys.java:179)\r\n\tat com.googlecode.objectify.impl.KeyMetadata.getIncompleteKey(KeyMetadata.java:184)\r\n\tat com.googlecode.objectify.impl.KeyMetadata.setKey(KeyMetadata.java:153)\r\n\tat com.googlecode.objectify.impl.KeyPopulator.save(KeyPopulator.java:29)\r\n\tat com.googlecode.objectify.impl.translate.ClassPopulator.save(ClassPopulator.java:156)\r\n\tat com.googlecode.objectify.impl.translate.ClassTranslator.saveSafe(ClassTranslator.java:131)\r\n\tat com.googlecode.objectify.impl.translate.NullSafeTranslator.save(NullSafeTranslator.java:31)\r\n\tat com.googlecode.objectify.impl.EntityMetadata.save(EntityMetadata.java:113)\r\n\tat com.googlecode.objectify.impl.WriteEngine.save(WriteEngine.java:69)\r\n\tat com.googlecode.objectify.impl.SaverImpl.entities(SaverImpl.java:60)\r\n\tat com.googlecode.objectify.impl.SaverImpl.entity(SaverImpl.java:35)\r\n\tat app.HelloAppEngine.doGet(HelloAppEngine.java:23)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n\tat com.googlecode.objectify.ObjectifyFilter.doFilter(ObjectifyFilter.java:48)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.ResponseRewriterFilter.doFilter(ResponseRewriterFilter.java:134)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.HeaderVerificationFilter.doFilter(HeaderVerificationFilter.java:34)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:63)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.jetty9.StaticFileFilter.doFilter(StaticFileFilter.java:123)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectRequest(DevAppServerModulesFilter.java:366)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectModuleRequest(DevAppServerModulesFilter.java:349)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doFilter(DevAppServerModulesFilter.java:116)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.appengine.tools.development.DevAppServerRequestLogFilter.doFilter(DevAppServerRequestLogFilter.java:44)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:524)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n\tat com.google.appengine.tools.development.jetty9.DevAppEngineWebAppContext.doScope(DevAppEngineWebAppContext.java:94)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat com.google.appengine.tools.development.jetty9.JettyContainerService$ApiProxyHandler.handle(JettyContainerService.java:597)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:534)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\r\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3293",
        "number": 3293,
        "title": "Generated javadoc missing for most of the dlp v2 api",
        "labels": [
            "api: dlp",
            "type: docs",
            "type: process"
        ],
        "state": "closed",
        "body": "https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients/apidocs/com/google/cloud/dlp/v2/package-summary.html\r\n\r\nThis page has only a couple methods, but is missing content for many parts of the api - deidentifyContent, inspectContent, redactImage, etc."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3292",
        "number": 3292,
        "title": "redirect JavaDocs",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "Not very old javadoc links such as https://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/com/google/cloud/bigquery/package-summary.html are now 404.\r\n\r\nhttps://googlecloudplatform.github.io/google-cloud-java/latest should redirect to https://googlecloudplatform.github.io/google-cloud-java/google-cloud-clients\r\n\r\nObReference: https://www.w3.org/Provider/Style/URI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3291",
        "number": 3291,
        "title": "Exception while writing to stackdriver",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "Version for stackdriver in build.gradle:\r\n\r\n`compile 'com.google.cloud:google-cloud-logging:1.7.0'`\r\n\r\nHi our logging calls to stackdriver in our service is facing this exception since morning:\r\n\r\ncom.google.api.gax.batching.FlowController$FlowControlRuntimeException: The maximum number of batch bytes: 10485760 have been reached.\r\n\r\n\tat com.google.api.gax.batching.FlowController$FlowControlRuntimeException.fromFlowControlException(FlowController.java:55)\r\n\tat com.google.api.gax.rpc.BatchingCallable.futureCall(BatchingCallable.java:77)\r\n\tat com.google.api.gax.rpc.EntryPointUnaryCallable.futureCall(EntryPointUnaryCallable.java:70)\r\n\tat com.google.api.gax.rpc.UnaryCallable.futureCall(UnaryCallable.java:89)\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.write(GrpcLoggingRpc.java:199)\r\n\tat com.google.cloud.logging.LoggingImpl.writeAsync(LoggingImpl.java:591)\r\n\tat com.google.cloud.logging.LoggingImpl.writeLogEntries(LoggingImpl.java:558)\r\n\tat com.google.cloud.logging.LoggingImpl.write(LoggingImpl.java:521)\r\n\tat com.google.cloud.pubsub.v1.MessageDispatcher$2.run(MessageDispatcher.java:412)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n\r\nThe exception happens on `write` method on the the `Logging` type.\r\n\r\nAny pointers to resolve this would be helpful"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3289",
        "number": 3289,
        "title": "Google Cloud Javadoc reference page doesn't work anymore",
        "labels": [],
        "state": "closed",
        "body": "The API reference (Javadoc) site for Google Cloud doesn't work anymore. I have seen it working yesterday. And the link to access the site is http://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/index.html"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3284",
        "number": 3284,
        "title": "In troubleshooting guide, add link to compat checker",
        "labels": [
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/TROUBLESHOOTING.md#alpn-is-not-configured-properly needs to point people to https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-util/google-cloud-compat-checker , because it's much easier to have a tool tell you what's not compatible than to have to look through the whole list of possible incompatibilities to figure it out.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3283",
        "number": 3283,
        "title": "[BigQuery] TableId.setProjectId ignored if non-null value exists",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "As per the title, calling [setProjectId](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/TableId.java#L113) to an existing tableId instance is ignored if the existing projectId is not null.\r\n\r\nSuggested changing this to:\r\n```java\r\n  TableId setProjectId(String projectId) {\r\n    Preconditions.checkArgument(!Strings.isNullOrEmpty(projectId), \"ErrorMSG\");\r\n    return TableId.of(projectId, getDataset(), getTable());\r\n  }\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3280",
        "number": 3280,
        "title": "TraceLoggingEnhancer sets trace ID in the wrong field",
        "labels": [
            "api: logging",
            "type: bug"
        ],
        "state": "closed",
        "body": "The trace ID of a log entry is being set [in the wrong field](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-clients/google-cloud-logging/src/main/java/com/google/cloud/logging/TraceLoggingEnhancer.java#L61) (label).\r\n\r\nIn order for the log entries to be linked to the trace, the `TraceLoggingEnhancer` needs to look something like [this](https://github.com/spring-cloud/spring-cloud-gcp/pull/683/files#diff-808bd3f7c7330cf558cdec7c5f754906).\r\n1) Use `setTrace()`, not `setLabel()`\r\n2) Use a `project/myProjectId/traces/myTraceId` format."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3279",
        "number": 3279,
        "title": "google-cloud-datastore Java library exposes too little of the information in query results",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "In particular, this makes it impossible to implement a more efficient implementation of counting query results, as that requires the values from the skipped_results and more_results fields.\r\n\r\nSee https://groups.google.com/forum/#!topic/gcd-discuss/wH8lVOA-a8Y for an in-depth discussion of what's needed from query results to implement that.\r\n\r\nGenerally, skipped_results, more_results and snapshot_version should be available in QueryResults\r\n(https://github.com/googleapis/googleapis/blob/master/google/datastore/v1/query.proto#L261)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3277",
        "number": 3277,
        "title": "Exception in thread \"grpc-default-executor-1\" java.lang.IllegalArgumentException : Jetty ALPN/NPN has not been properly configured.         at io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSsl Contexts.java:153)",
        "labels": [],
        "state": "closed",
        "body": "May 16, 2018 11:43:39 AM com.example.flexible.speak.TranscribeSocket onWebSocket\r\nText\r\nINFO: Got sampleRate: 48000\r\nMay 16, 2018 11:43:39 AM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@117866a] Created with target speech.googleapis.com:443\r\n\r\nException in thread \"grpc-default-executor-1\" java.lang.IllegalArgumentException\r\n: Jetty ALPN/NPN has not been properly configured.\r\n        at io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSsl\r\nContexts.java:153)\r\n        at io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:130)\r\n        at io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:119)\r\n        at io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:90)\r\n        at io.grpc.netty.NettyChannelBuilder.createProtocolNegotiator(NettyChann\r\nelBuilder.java:265)\r\n        at io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.newClientTran\r\nsport(NettyChannelBuilder.java:324)\r\n        at io.grpc.internal.CallCredentialsApplyingTransportFactory.newClientTra\r\nnsport(CallCredentialsApplyingTransportFactory.java:62)\r\n        at io.grpc.internal.TransportSet.startNewTransport(TransportSet.java:215\r\n)\r\n        at io.grpc.internal.TransportSet.obtainActiveTransport(TransportSet.java\r\n:192)\r\n        at io.grpc.internal.ManagedChannelImpl$3.getTransport(ManagedChannelImpl\r\n.java:651)\r\n        at io.grpc.internal.ManagedChannelImpl$3.getTransport(ManagedChannelImpl\r\n.java:592)\r\n        at io.grpc.DummyLoadBalancerFactory$DummyLoadBalancer$1.get(DummyLoadBal\r\nancerFactory.java:135)\r\n        at io.grpc.internal.DelayedClientTransport$2.run(DelayedClientTransport.\r\njava:262)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.\r\njava:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor\r\n.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3276",
        "number": 3276,
        "title": "datastore emulator sometimes crashes, which causes test flakyness",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "We're using bazel to build our software. At the Ci we noticed test flakyness. When I run the tests localy like:\r\n\r\n    bazel test --runs_per_test=10000 //src/java/com/example/foo:FooTest\r\n\r\nI get about 5 failures that look like this:\r\n\r\n```\r\nSEVERE: Exception while executing runnable io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@74287ea3\r\ncom.google.cloud.datastore.DatastoreException: I/O error\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.translate(HttpDatastoreRpc.java:129)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.translate(HttpDatastoreRpc.java:114)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.runQuery(HttpDatastoreRpc.java:182)\r\n\tat com.google.cloud.datastore.DatastoreImpl$1.call(DatastoreImpl.java:178)\r\n\tat com.google.cloud.datastore.DatastoreImpl$1.call(DatastoreImpl.java:174)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.datastore.DatastoreImpl.runQuery(DatastoreImpl.java:173)\r\n\tat com.google.cloud.datastore.QueryResultsImpl.sendRequest(QueryResultsImpl.java:73)\r\n\tat com.google.cloud.datastore.QueryResultsImpl.<init>(QueryResultsImpl.java:57)\r\n\tat com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:167)\r\n\tat com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:158)\r\n\tat com.cloudrobotics.map.MapService.deleteOccupancyGrid(MapService.java:519)\r\n\tat com.cloudrobotics.map.MapService.deleteLayer(MapService.java:252)\r\n\tat com.cloudrobotics.map.MapService.deleteLayer(MapService.java:272)\r\n\tat com.cloudrobotics.map.v1alpha1.MapServiceGrpc$MethodHandlers.invoke(MapServiceGrpc.java:1755)\r\n\tat io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:171)\r\n\tat io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:272)\r\n\tat io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:653)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializeReentrantCallsDirectExecutor.execute(SerializeReentrantCallsDirectExecutor.java:49)\r\n\tat io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener.halfClosed(ServerImpl.java:664)\r\n\tat io.grpc.inprocess.InProcessTransport$InProcessStream$InProcessClientStream.halfClose(InProcessTransport.java:621)\r\n\tat io.grpc.internal.ClientCallImpl.halfClose(ClientCallImpl.java:422)\r\n\tat io.grpc.ForwardingClientCall.halfClose(ForwardingClientCall.java:47)\r\n\tat io.grpc.ForwardingClientCall.halfClose(ForwardingClientCall.java:47)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:271)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:177)\r\n\tat io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:119)\r\n\tat com.cloudrobotics.map.v1alpha1.MapServiceGrpc$MapServiceBlockingStub.deleteLayer(MapServiceGrpc.java:1371)\r\n\tat com.cloudrobotics.map.MapServiceTest.testGetOccupancyGrid_afterDeleteLayer_throwsNotFound(MapServiceTest.java:472)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\r\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\r\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\r\n\tat com.google.testing.junit.runner.internal.junit4.CancellableRequestFactory$CancellableRunner.run(CancellableRequestFactory.java:89)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:160)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:138)\r\n\tat com.google.testing.junit.runner.junit4.JUnit4Runner.run(JUnit4Runner.java:112)\r\n\tat com.google.testing.junit.runner.BazelTestRunner.runTestsInSuite(BazelTestRunner.java:144)\r\n\tat com.google.testing.junit.runner.BazelTestRunner.main(BazelTestRunner.java:82)\r\nCaused by: com.google.datastore.v1.client.DatastoreException: I/O error, code=UNAVAILABLE\r\n\tat com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:226)\r\n\tat com.google.datastore.v1.client.RemoteRpc.call(RemoteRpc.java:195)\r\n\tat com.google.datastore.v1.client.Datastore.runQuery(Datastore.java:119)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.runQuery(HttpDatastoreRpc.java:180)\r\n\t... 57 more\r\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\r\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\r\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\r\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\r\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\r\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\r\n\tat java.net.Socket.connect(Socket.java:589)\r\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:175)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:463)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:558)\r\n\tat sun.net.www.http.HttpClient.<init>(HttpClient.java:242)\r\n\tat sun.net.www.http.HttpClient.New(HttpClient.java:339)\r\n\tat sun.net.www.http.HttpClient.New(HttpClient.java:357)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138)\r\n\tat sun.net.www.protocol.http.HttpURLConnection$6.run(HttpURLConnection.java:1022)\r\n\tat sun.net.www.protocol.http.HttpURLConnection$6.run(HttpURLConnection.java:1020)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.security.AccessController.doPrivilegedWithCombiner(AccessController.java:782)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1019)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.access$100(HttpURLConnection.java:91)\r\n\tat sun.net.www.protocol.http.HttpURLConnection$8.run(HttpURLConnection.java:1283)\r\n\tat sun.net.www.protocol.http.HttpURLConnection$8.run(HttpURLConnection.java:1281)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.security.AccessController.doPrivilegedWithCombiner(AccessController.java:782)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1280)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.datastore.v1.client.RemoteRpc.call(RemoteRpc.java:183)\r\n\t... 59 more\r\n```\r\n\r\nRight now we're using a helper like this to mitigate it a bit\r\nhttps://gist.github.com/ensonic/a1b64be415f537b59bcc951883b29596\r\nbut of course this won't help tests where datastore looses connection in the middle of the test."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3275",
        "number": 3275,
        "title": "Failed to deploy - FileNotFoundException",
        "labels": [
            "auth",
            "running on app engine",
            "type: question"
        ],
        "state": "closed",
        "body": "## Expected\r\nJAR deployment to AppEngine instance for Kotlin app.\r\n\r\n## Actual\r\nDuring deployment to my AppEngine instance I am receiving the following **FileNotFoundException**. This error is not logical because the same built **JAR** runs the app successfully via IntelliJ prior to the deploy attempt.\r\n\r\nHere is the Kotlin app file hierarchy which runs as expected both as an IntelliJ Application and JAR configuration. The \"missing\" directory/file is **firebase/carpecoin-service-firebase-adminsdk-cyl9p-4b18763dbc.json** which is nested under the **main** directory. The hierarchy was not altered after creating and building my JAR.\r\n\r\n**App Hiearchy**\r\n![screen shot 2018-05-15 at 11 06 43 pm](https://user-images.githubusercontent.com/3938076/40099483-0b74d550-5895-11e8-8c31-61e6961f4a39.png)\r\n\r\n**Build Config**\r\n![screen shot 2018-05-15 at 11 35 24 pm](https://user-images.githubusercontent.com/3938076/40100470-db82ca42-5898-11e8-9a12-dfaea673e0b2.png)\r\n\r\n## Error\r\n```Exception in thread \"main\" java.io.FileNotFoundException: src/main/firebase/carpecoin-service-firebase-adminsdk-cyl9p-4b18763dbc.json (No such file or directory)\r\n\tat java.io.FileInputStream.open0(Native Method)\r\n\tat java.io.FileInputStream.open(FileInputStream.java:195)\r\n\tat java.io.FileInputStream.<init>(FileInputStream.java:138)\r\n\tat java.io.FileInputStream.<init>(FileInputStream.java:93)\r\n\tat Coordinator.main(Coordinator.kt:12)`\r\n`Failed to deploy '[2018-05-15 23:00:21] carpe.coin_main.jar. Project: carpecoin-service. Version: auto': Deployment failed with exit code: 1```\r\n\r\n## IntelliJ Info\r\nIntelliJ IDEA 2018.1.3 (Community Edition)\r\nBuild #IC-181.4892.42, built on May 7, 2018\r\nJRE: 1.8.0_152-release-1136-b38 x86_64\r\nJVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o\r\nMac OS X 10.10.5\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3271",
        "number": 3271,
        "title": "Bigquery Datatransfer and Redis use GRPC but set language level to 1.7",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3270",
        "number": 3270,
        "title": "google-cloud-redis docs point to https://cloud.google.com/ ",
        "labels": [],
        "state": "closed",
        "body": "should be more specific; maybe https://cloud.google.com/memorystore/"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3268",
        "number": 3268,
        "title": "Open repo to GoogleCloudPlatform members",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": "so we can push branches. It's annoying having to fork all the time. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3267",
        "number": 3267,
        "title": "Background task always pops up on app engine task",
        "labels": [],
        "state": "closed",
        "body": "This happens even if there are no long running Cloud SDK related background tasks;\r\n\r\n![image](https://user-images.githubusercontent.com/1735744/40024576-bd0ca36e-579c-11e8-8ed3-e0e3ee0feb6c.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3265",
        "number": 3265,
        "title": "Links from README to specific client directories 404",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3263",
        "number": 3263,
        "title": "Unit test firestore: Mocking DocumentReference and CollectionReference",
        "labels": [
            "api: firestore",
            "priority: p2",
            "status: blocked",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We are trying to test classes with dependencies on firestore and we found we cannot mock these classes because their constructors are internal. Is it possible if the following methods return interfaces instead of classes: \r\n\r\nval collectionReference:CollectionReference = db.collection(collectionName)\r\nval document: DocumentReference = collectionReference.document(docId)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3260",
        "number": 3260,
        "title": "All README links to specific products (i.e. Datastore, Dialgoflow, etc.) are broken",
        "labels": [],
        "state": "closed",
        "body": "All README links that point to a specific product i.e. Datastore, Dialogflow, etc. are broken\r\n\r\nExample: https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-datastore"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3257",
        "number": 3257,
        "title": "Batch acknowledgement is not working in asynchronous call",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "We are having the requirement of creating a batch of messages on every one minute. \r\nOnce batch is processed and return success in response, we need to acknowledge all the messages which were present in that batch.\r\nIf batch process response is failure , we need to unacknowledged the messages.\r\n\r\nCurrent functionality given by pub/sub library: In asynchronous call, we can ack/nack message one by one, immediate after receiving.\r\n\r\nBelow is our code snippet-\r\n```java\r\nSubscriber.Builder builder = Subscriber.newBuilder(subscription, new MessageReceiver() {\r\n                @Override\r\n                public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n                    // handle incoming message, then ack/nack the received message\r\n              try {                             \r\n                       //dropping the message in a queue\r\n                      //here we are creating a batch on every one minute and ack/nack the message accordingly\r\n                                \r\n                     }\r\n```\r\nalso do we have any method to get ackId instead of MessageId in case of asynchronous call.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3256",
        "number": 3256,
        "title": "java.lang.ClassNotFoundException: org/eclipse/jetty/alpn/ALPN",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Can anyone please help me with this. Getting this exception when deploying in Jboss\r\n\r\n**Application error message:**\r\n\r\n```\r\n16:27:39,275 ERROR [org.hyperledger.fabric.sdk.Channel] (ServerService Thread Pool -- 146) Jetty ALPN/NPN has not been properly configured.: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\nat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:162) [grpc-netty-1.7.0.jar:1.7.0]\r\nat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:136) [grpc-netty-1.7.0.jar:1.7.0]\r\nat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:124) [grpc-netty-1.7.0.jar:1.7.0]\r\nat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:94) [grpc-netty-1.7.0.jar:1.7.0]\r\nat org.hyperledger.fabric.sdk.Endpoint.(Endpoint.java:143) [fabric-sdk-java-1.0.0.jar:]\r\nat org.hyperledger.fabric.sdk.Orderer.sendDeliver(Orderer.java:159) [fabric-sdk-java-1.0.0.jar:]\r\nat org.hyperledger.fabric.sdk.Channel.getLatestBlock(Channel.java:1074) [fabric-sdk-java-1.0.0.jar:]\r\nat org.hyperledger.fabric.sdk.Channel.getConfigurationBlock(Channel.java:898) [fabric-sdk-java-1.0.0.jar:]\r\nat org.hyperledger.fabric.sdk.Channel.parseConfigBlock(Channel.java:826) [fabric-sdk-java-1.0.0.jar:]\r\nat org.hyperledger.fabric.sdk.Channel.initialize(Channel.java:526) [fabric-sdk-java-1.0.0.jar:]\r\nat com.solartis.hyperledger.ejb.HyperLedgerSingleton.loadChannel(HyperLedgerSingleton.java:159) [classes:]\r\nat com.solartis.hyperledger.ejb.HyperLedgerSingleton.init(HyperLedgerSingleton.java:73) [classes:]\r\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [rt.jar:1.8.0_92]\r\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) [rt.jar:1.8.0_92]\r\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [rt.jar:1.8.0_92]\r\nat java.lang.reflect.Method.invoke(Method.java:498) [rt.jar:1.8.0_92]\r\nat org.jboss.as.ee.component.ManagedReferenceLifecycleMethodInterceptor.processInvocation(ManagedReferenceLifecycleMethodInterceptor.java:96)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.as.ee.component.ManagedReferenceFieldInjectionInterceptorFactory$ManagedReferenceFieldInjectionInterceptor.processInvocation(ManagedReferenceFieldInjectionInterceptorFactory.java:109)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.as.ee.component.ComponentInstantiatorInterceptor.processInvocation(ComponentInstantiatorInterceptor.java:76)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.as.ee.component.NamespaceContextInterceptor.processInvocation(NamespaceContextInterceptor.java:50)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.as.ejb3.tx.CMTTxInterceptor.invokeInOurTx(CMTTxInterceptor.java:278) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.as.ejb3.tx.CMTTxInterceptor.requiresNew(CMTTxInterceptor.java:352) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.as.ejb3.tx.LifecycleCMTTxInterceptor.processInvocation(LifecycleCMTTxInterceptor.java:66) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.as.ejb3.component.interceptors.CurrentInvocationContextInterceptor.processInvocation(CurrentInvocationContextInterceptor.java:41) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.invocation.ContextClassLoaderInterceptor.processInvocation(ContextClassLoaderInterceptor.java:70)\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.as.ejb3.component.singleton.StartupCountDownInterceptor.processInvocation(StartupCountDownInterceptor.java:25) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:288)\r\nat org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)\r\nat org.jboss.as.ee.component.BasicComponent.constructComponentInstance(BasicComponent.java:162)\r\nat org.jboss.as.ee.component.BasicComponent.constructComponentInstance(BasicComponent.java:135)\r\nat org.jboss.as.ee.component.BasicComponent.createInstance(BasicComponent.java:90)\r\nat org.jboss.as.ejb3.component.singleton.SingletonComponent.getComponentInstance(SingletonComponent.java:122) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.as.ejb3.component.singleton.SingletonComponent.start(SingletonComponent.java:137) [jboss-as-ejb3-7.5.9.Final-redhat-2.jar:7.5.9.Final-redhat-2]\r\nat org.jboss.as.ee.component.ComponentStartService$1.run(ComponentStartService.java:54)\r\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [rt.jar:1.8.0_92]\r\nat java.util.concurrent.FutureTask.run(FutureTask.java:266) [rt.jar:1.8.0_92]\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [rt.jar:1.8.0_92]\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [rt.jar:1.8.0_92]\r\nat java.lang.Thread.run(Thread.java:745) [rt.jar:1.8.0_92]\r\nat org.jboss.threads.JBossThread.run(JBossThread.java:122)\r\nCaused by: java.lang.ClassNotFoundException: org/eclipse/jetty/alpn/ALPN\r\nat java.lang.Class.forName0(Native Method) [rt.jar:1.8.0_92]\r\nat java.lang.Class.forName(Class.java:348) [rt.jar:1.8.0_92]\r\nat io.grpc.netty.JettyTlsUtil.isJettyAlpnConfigured(JettyTlsUtil.java:34) [grpc-netty-1.7.0.jar:1.7.0]\r\nat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:153) [grpc-netty-1.7.0.jar:1.7.0]\r\n... 52 more\r\n```\r\n\r\n**My maven dependency tree**\r\n```\r\n+- org.slf4j:slf4j-api:jar:1.7.3:compile\r\n+- com.google.protobuf:protobuf-java:jar:3.1.0:compile\r\n+- org.jboss.spec.javax.ejb:jboss-ejb-api_3.1_spec:jar:1.0.2.Final:provided\r\n+- org.jboss.spec.javax.servlet:jboss-servlet-api_3.0_spec:jar:1.0.2.Final:provided\r\n+- org.jboss.spec.javax.ws.rs:jboss-jaxrs-api_1.1_spec:jar:1.0.1.Final:provided\r\n+- com.solartis.commons:commons-questionhashmap:jar:3.3-SNAPSHOT:compile\r\n+- io.netty:netty-common:jar:4.1.14.Final:compile\r\n+- io.netty:netty-tcnative-boringssl-static:jar:2.0.5.Final:compile\r\n+- org.hyperledger.fabric-sdk-java:fabric-sdk-java:jar:1.0.0:compile\r\n+- org.apache.commons:commons-compress:jar:1.8:compile\r\n+- commons-cli:commons-cli:jar:1.4:compile\r\n+- org.bouncycastle:bcprov-jdk15on:jar:1.55:compile\r\n+- com.solartis.dataretriever:DataRetriever:jar:0.0.1-SNAPSHOT:compile\r\n| +- org.slf4j:slf4j-log4j12:jar:1.7.5:compile\r\n| | - log4j:log4j:jar:1.2.17:compile\r\n| - mysql:mysql-connector-java:jar:5.1.25:compile\r\n+- org.bouncycastle:bcpkix-jdk15on:jar:1.55:compile\r\n+- com.solartis.hyperledger:HyperLedgerIntegrationService-sd:jar:1.0:compile\r\n| +- com.solartis.commons:commons-sd:jar:1.1-SNAPSHOT:compile\r\n| +- org.glassfish.jersey.media:jersey-media-json-jackson:jar:2.0:compile\r\n| | +- org.glassfish.jersey.core:jersey-common:jar:2.0:compile\r\n| | | +- javax.annotation:javax.annotation-api:jar:1.2:compile\r\n| | | - org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:compile\r\n| | +- org.codehaus.jackson:jackson-core-asl:jar:1.9.11:compile\r\n| | +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.11:compile\r\n| | +- org.codehaus.jackson:jackson-jaxrs:jar:1.9.11:compile\r\n| | - org.codehaus.jackson:jackson-xc:jar:1.9.11:compile\r\n| +- org.glassfish.jersey.core:jersey-client:jar:2.0:compile\r\n| | +- javax.ws.rs:javax.ws.rs-api:jar:2.0:compile\r\n| | +- org.glassfish.hk2:hk2-api:jar:2.1.88:compile\r\n| | | - org.glassfish.hk2:hk2-utils:jar:2.1.88:compile\r\n| | +- org.glassfish.hk2.external:javax.inject:jar:2.1.88:compile\r\n| | - org.glassfish.hk2:hk2-locator:jar:2.1.88:compile\r\n| | +- org.glassfish.hk2.external:asm-all-repackaged:jar:2.1.88:compile\r\n| | - org.glassfish.hk2.external:cglib:jar:2.1.88:compile\r\n| +- org.glassfish.jersey.media:jersey-media-json-processing:jar:2.0:compile\r\n| | +- javax.json:javax.json-api:jar:1.0:compile\r\n| | +- org.glassfish:javax.json:jar:1.0:compile\r\n| | - org.glassfish:jsonp-jaxrs:jar:1.0:compile\r\n| - org.slf4j:slf4j-simple:jar:1.6.4:compile\r\n+- commons-codec:commons-codec:jar:1.9:compile\r\n+- com.solartis.datasaver:DataSaver:jar:0.0.1-SNAPSHOT:compile\r\n+- com.solartis.ruleUtil:gateway:jar:2.0:compile\r\n| +- com.solartis.knowledge.entity:knowledgebase-ed:jar:2.1.0-Final:compile\r\n| +- org.drools:drools-core:jar:5.5.0.Final:compile\r\n| | +- org.mvel:mvel2:jar:2.1.3.Final:compile\r\n| | - org.drools:knowledge-internal-api:jar:5.5.0.Final:compile\r\n| +- org.drools:drools-compiler:jar:5.5.0.Final:compile\r\n| | +- org.antlr:antlr-runtime:jar:3.3:compile\r\n| | +- org.antlr:antlr:jar:3.3:compile\r\n| | +- org.antlr:stringtemplate:jar:3.2.1:compile\r\n| | +- antlr:antlr:jar:2.7.7:compile\r\n| | +- org.eclipse.jdt.core.compiler:ecj:jar:3.5.1:compile\r\n| | - com.thoughtworks.xstream:xstream:jar:1.4.1:compile\r\n| | +- xmlpull:xmlpull:jar:1.1.3.1:compile\r\n| | - xpp3:xpp3_min:jar:1.1.4c:compile\r\n| +- org.jbpm:jbpm-flow-builder:jar:5.4.0.Final:compile\r\n| +- org.jbpm:jbpm-bpmn2:jar:5.4.0.Final:compile\r\n| +- org.jbpm:jbpm-flow:jar:5.4.0.Final:compile\r\n| +- org.drools:drools-decisiontables:jar:5.5.0.Final:compile\r\n| | +- org.drools:drools-templates:jar:5.5.0.Final:compile\r\n| | - net.sourceforge.jexcelapi:jxl:jar:2.6.10:compile\r\n| +- org.drools:knowledge-api:jar:5.5.0.Final:compile\r\n| +- commons-io:commons-io:jar:1.3.2:compile\r\n| +- org.apache.httpcomponents:httpclient:jar:4.0-beta1:compile\r\n| | - org.apache.httpcomponents:httpcore:jar:4.0-beta2:compile\r\n| - com.solartis.drools:drools-sd:jar:3.0:compile\r\n+- org.jboss.spec:jboss-javaee-6.0:pom:3.0.1.Final:compile\r\n| +- javax.activation:activation:jar:1.1.1:compile\r\n| +- javax.enterprise:cdi-api:jar:1.0-SP4:compile\r\n| +- javax.inject:javax.inject:jar:1:compile\r\n| +- javax.jws:jsr181-api:jar:1.0-MR1:compile\r\n| +- javax.mail:mail:jar:1.4.4:compile\r\n| +- javax.validation:validation-api:jar:1.0.0.GA:compile\r\n| +- org.hibernate.javax.persistence:hibernate-jpa-2.0-api:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.annotation:jboss-annotations-api_1.1_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.el:jboss-el-api_2.2_spec:jar:1.0.2.Final:compile\r\n| +- org.jboss.spec.javax.enterprise.deploy:jboss-jad-api_1.2_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.faces:jboss-jsf-api_2.1_spec:jar:2.0.9.Final:compile\r\n| +- org.jboss.spec.javax.interceptor:jboss-interceptors-api_1.1_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.management.j2ee:jboss-j2eemgmt-api_1.1_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.resource:jboss-connector-api_1.6_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.security.jacc:jboss-jacc-api_1.4_spec:jar:1.0.2.Final:compile\r\n| +- org.jboss.spec.javax.security.auth.message:jboss-jaspi-api_1.0_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.xml.registry:jboss-jaxr-api_1.0_spec:jar:1.0.2.Final:compile\r\n| +- org.jboss.spec.javax.jms:jboss-jms-api_1.1_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.servlet.jsp:jboss-jsp-api_2.2_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.servlet.jstl:jboss-jstl-api_1.2_spec:jar:1.0.3.Final:compile\r\n| | - xalan:xalan:jar:2.7.1.jbossorg-2:compile\r\n| | - xalan:serializer:jar:2.7.1.jbossorg-2:compile\r\n| +- org.jboss.spec.javax.transaction:jboss-transaction-api_1.1_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.xml.bind:jboss-jaxb-api_2.2_spec:jar:1.0.4.Final:compile\r\n| +- org.jboss.spec.javax.xml.rpc:jboss-jaxrpc-api_1.1_spec:jar:1.0.1.Final:compile\r\n| +- org.jboss.spec.javax.xml.soap:jboss-saaj-api_1.3_spec:jar:1.0.2.Final:compile\r\n| - org.jboss.spec.javax.xml.ws:jboss-jaxws-api_2.2_spec:jar:2.0.1.Final:compile\r\n+- org.jboss.resteasy:resteasy-jaxrs:jar:3.0-beta-3:test\r\n| +- org.jboss.resteasy:jaxrs-api:jar:3.0-beta-3:test\r\n| +- org.scannotation:scannotation:jar:1.0.3:test\r\n| | - javassist:javassist:jar:3.12.1.GA:test\r\n| +- javax.annotation:jsr250-api:jar:1.0:test\r\n| +- net.jcip:jcip-annotations:jar:1.0:test\r\n| - org.hibernate:hibernate-validator:jar:4.2.0.Final:test\r\n+- com.solartis.insconfig:insconfig-ed:jar:0.3.7-SNAPSHOT:compile\r\n| - com.google.code.gson:gson:jar:1.7.1:compile\r\n+- io.grpc:grpc-all:jar:1.7.0:compile\r\n| +- io.grpc:grpc-auth:jar:1.7.0:compile\r\n| | - com.google.auth:google-auth-library-credentials:jar:0.4.0:compile\r\n| +- io.grpc:grpc-core:jar:1.7.0:compile (version selected from constraint [1.7.0,1.7.0])\r\n| | +- com.google.errorprone:error_prone_annotations:jar:2.0.19:compile\r\n| | +- com.google.code.findbugs:jsr305:jar:3.0.0:compile\r\n| | +- com.google.instrumentation:instrumentation-api:jar:0.4.3:compile\r\n| | - io.opencensus:opencensus-api:jar:0.6.0:compile\r\n| +- io.grpc:grpc-context:jar:1.7.0:compile\r\n| +- io.grpc:grpc-netty:jar:1.7.0:compile\r\n| | +- io.netty:netty-codec-http2:jar:4.1.16.Final:compile (version selected from constraint [4.1.16.Final,4.1.16.Final])\r\n| | | +- io.netty:netty-codec-http:jar:4.1.16.Final:compile\r\n| | | | - io.netty:netty-codec:jar:4.1.16.Final:compile\r\n| | | - io.netty:netty-handler:jar:4.1.16.Final:compile\r\n| | | - io.netty:netty-buffer:jar:4.1.16.Final:compile\r\n| | - io.netty:netty-handler-proxy:jar:4.1.16.Final:compile\r\n| | +- io.netty:netty-transport:jar:4.1.16.Final:compile\r\n| | | - io.netty:netty-resolver:jar:4.1.16.Final:compile\r\n| | - io.netty:netty-codec-socks:jar:4.1.16.Final:compile\r\n| +- io.grpc:grpc-okhttp:jar:1.7.0:compile\r\n| | +- com.squareup.okhttp:okhttp:jar:2.5.0:compile\r\n| | - com.squareup.okio:okio:jar:1.6.0:compile\r\n| +- io.grpc:grpc-protobuf:jar:1.7.0:compile\r\n| | +- com.google.protobuf:protobuf-java-util:jar:3.4.0:compile\r\n| | +- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n| | - io.grpc:grpc-protobuf-lite:jar:1.7.0:compile\r\n| +- io.grpc:grpc-protobuf-nano:jar:1.7.0:compile\r\n| | - com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\r\n| - io.grpc:grpc-stub:jar:1.7.0:compile\r\n+- com.solartis.commons:commons-util:jar:1.4-SNAPSHOT:compile\r\n| +- com.sun.crypto:sun-jce:jar:1.0:compile\r\n| - org.hibernate:hibernate-core:jar:4.2.0.Final:compile\r\n| +- org.jboss.logging:jboss-logging:jar:3.1.0.GA:compile\r\n| +- dom4j:dom4j:jar:1.6.1:compile\r\n| +- org.javassist:javassist:jar:3.15.0-GA:compile\r\n| - org.hibernate.common:hibernate-commons-annotations:jar:4.0.1.Final:compile\r\n+- com.solartis.eclipse:alpn-api:jar:1.0.1:compile\r\n+- com.google.guava:guava:jar:19.0:compile\r\n- commons-httpclient:commons-httpclient:jar:3.1:compile\r\n- commons-logging:commons-logging:jar:1.0.4:compile\r\n```\r\n\r\n**My Compat checker result:**\r\n\r\n```\r\nOS details:\r\nos.detected.name: linux\r\nos.detected.arch: x86_64\r\nos.detected.classifier: linux-x86_64\r\nos.detected.release: centos\r\nos.detected.release.version: null\r\nJVM details:\r\nJava version: 1.8.0_92\r\nJava specification version: 1.8\r\nJVM bit mode: 64\r\nOpenSSL details:\r\nopen ssl is available: false\r\nALPN is supported: false\r\nChecking compatibility...\r\n[PASS] This OS + architecture is supported.\r\n[PASS] 64-bit JVM is supported.\r\n[FAIL] Open SSL is NOT available\r\nOpen SSL Unavailability cause:\r\njava.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty-tcnative-linux-x86_64, netty-tcnative-linux-x86_64-fedora, netty-tcnative]\r\nat io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:178)\r\nat io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:403)\r\nat io.netty.handler.ssl.OpenSsl.(OpenSsl.java:85)\r\nat com.google.cloud.compatchecker.GoogleCloudCompatChecker.check(GoogleCloudCompatChecker.java:58)\r\nat com.google.cloud.compatchecker.GoogleCloudCompatChecker.main(GoogleCloudCompatChecker.java:47)\r\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\nat java.lang.reflect.Method.invoke(Method.java:498)\r\nat org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:282)\r\nat java.lang.Thread.run(Thread.java:745)\r\n[FAIL] Open SSL ALPN is NOT supported\r\nResult: FAIL\r\nYour environment is not supported by Forked Tomcat Native.\r\nSee http://netty.io/wiki/forked-tomcat-native.html for details.\r\nThis means that you won't be able to use grpc-based APIs, but\r\nhttp1-based APIs should still work.\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3255",
        "number": 3255,
        "title": "File upload connections are over fixed ports and path",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "If one uses `StorageOptions.Builder#setHost` with a value such as `http://proxy.url.local:8888/somepath`, builds the storage client using this `StorageOptions`, *most* connections generated by the client use these values (scheme, host, port, path), eg when listing and deleting blobs, but the file upload connection does not:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/52b727aef88ae76984aa3c02b4d7067e198d34b7/google-cloud-storage/src/main/java/com/google/cloud/storage/spi/v1/HttpStorageRpc.java#L720\r\n\r\nI think all connections should follow the `host setting` as a hostname or as an endpoint setting."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3254",
        "number": 3254,
        "title": "Batched Requests don't honor the host setting",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "Batch endpoint always hits `www.googleapis.com` irrespective of the `host` setting on the `StorageOptions` that built the storage client.\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/52b727aef88ae76984aa3c02b4d7067e198d34b7/google-cloud-storage/src/main/java/com/google/cloud/storage/spi/v1/HttpStorageRpc.java#L191"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3252",
        "number": 3252,
        "title": "NLP example doesn't work in Cloud Shell",
        "labels": [
            "api: language",
            "auth"
        ],
        "state": "closed",
        "body": "I'm getting this error:\r\n\r\n```\r\nCaused by: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Cloud Natural Language API has not been used in project 618104708054 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/language.googleapis.com/overview?project=618104708054 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\r\n```\r\n\r\nThe project I'm using does have the API enabled. I have no idea what project `618104708054` is \u2014 that is not the project I'm using.\r\n\r\nI've tried setting the `GOOGLE_CLOUD_PROJECT` environment variable to my project ID, but I still get the same error.\r\n\r\nAny idea what might be causing this?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3250",
        "number": 3250,
        "title": "Stackdriver Trace: com.google.api.gax.rpc.NotFoundException: io.grpc.StatusRuntimeException: NOT_FOUND: Requested entity was not found.",
        "labels": [],
        "state": "closed",
        "body": "Hi there,\r\n\r\nOne of our customers got a exception when exporting via the v2 `TraceServiceClient`:\r\n\r\n```java\r\n[server] 2018-05-08 14:27:14,169 [ExportComponent.ServiceExporterThread-0] WARN  io.opencensus.trace.export.ExportComponent  - Exception thrown by the service export io.opencensus.exporter.trace.stackdriver.StackdriverTraceExporter\r\n[server] com.google.api.gax.rpc.NotFoundException: io.grpc.StatusRuntimeException: NOT_FOUND: Requested entity was not found.\r\n[server] at com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:45)\r\n[server] at com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\n[server] at com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\n[server] at com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:95)\r\n[server] at com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:61)\r\n[server] at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1341)\r\n[server] at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:398)\r\n[server] at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1025)\r\n[server] at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:866)\r\n[server] at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:711)\r\n[server] at io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:492)\r\n[server] at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:467)\r\n[server] at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n[server] at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684)\r\n[server] at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n[server] at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:392)\r\n[server] at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475)\r\n[server] at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n[server] at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557)\r\n[server] at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478)\r\n[server] at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590)\r\n[server] at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n[server] at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n[server] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n[server] at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n[server] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n[server] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n[server] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n[server] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n[server] at java.lang.Thread.run(Thread.java:745)\r\n[server] Caused by: io.grpc.StatusRuntimeException: NOT_FOUND: Requested entity was not found.\r\n[server] at io.grpc.Status.asRuntimeException(Status.java:526)\r\n[server] ... 19 more\r\n```\r\n\r\nHe tried with version `0.42.0-alpha` and `0.34.0-beta`, but got this exception in both cases. He could also see this in Stackdriver trace view in the Google Cloud Console:\r\n![image](https://user-images.githubusercontent.com/187029/39799419-70c7bfd4-5364-11e8-9a38-e18399ddf58d.png)\r\n\r\nAny idea how this happened?\r\n\r\nOriginal issue: https://github.com/census-instrumentation/opencensus-java/issues/1184"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3244",
        "number": 3244,
        "title": "Not able to run this sample project ",
        "labels": [],
        "state": "closed",
        "body": "I have created new json with new google console project but its not working. when i going to run project its giving error like \"Failed to obtain access toke com.fasterxml.jackson.core.JsonParseException:Unexpected character ('H' (code 72)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')\" and \r\n\"java.lang.NullPointerException: Attempt to invoke virtual method 'java.util.Date com.google.auth.oauth2.AccessToken.getExpirationTime()' on a null object reference\"\r\n here i have attached my json file also. Give solution for this issue\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3238",
        "number": 3238,
        "title": "Update Redis doc link when available",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3236",
        "number": 3236,
        "title": "Google DLP broken with 0.46.0-beta: Caused by: io.grpc.StatusRuntimeException: UNIMPLEMENTED: Method not found",
        "labels": [],
        "state": "closed",
        "body": "Ever since the Google DLP service went from V2Beta to GA, my production code is broken. I'm getting an exception with a message like this: \r\n\r\n`Caused by: io.grpc.StatusRuntimeException: UNIMPLEMENTED: Method not found`\r\n\r\nI'm stepping through the execution in the debugger, and I can see what looks like a URL referencing the old service:\r\n`google.privacy.dlp.v2beta1.DlpService/RedactContent`. See attached screen shot for details. My production service that uses DLP is not functional, and it's a big deal to re-deploy without DLP. What do I need to do to get this to work again? \r\n\r\n<img width=\"676\" alt=\"screen shot 2018-05-07 at 9 53 11 am\" src=\"https://user-images.githubusercontent.com/32073685/39713721-a1c0fc2e-51dc-11e8-8a75-764de29f2fd0.png\">\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3235",
        "number": 3235,
        "title": "SessionPool logging is using wrong object string to replace",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Class: `com.google.cloud.spanner.SessionPool`\r\nFunction: `PoolMaintainer.closeIdleSessions(Instant currTime)`\r\n\r\n`logger.log(Level.FINE, \"Closing session %s\", sess.getName());`\r\nShould instead be\r\n`logger.log(Level.FINE, \"Closing session {0}\", sess.getName());`\r\nto replace `{0}` with `sess.getName()`, otherwise all it's logging is `Closing session %s`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3233",
        "number": 3233,
        "title": "java.net.UnknownHostException: accounts.google.com",
        "labels": [],
        "state": "closed",
        "body": "Hi \r\n\r\nI am trying to setup a server for a firebase based project.\r\nWhen I run the sever(spring boot based sever) on my machine. I get the following issue\r\n\r\n```\r\ncom.google.api.client.http.HttpRequest execute\r\nWARNING: exception thrown while executing request\r\njava.net.UnknownHostException: accounts.google.com\r\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\r\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\r\n\tat java.net.Socket.connect(Socket.java:589)\r\n\tat sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673)\r\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:175)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:463)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:558)\r\n\tat sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)\r\n\tat sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1334)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1309)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:259)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:378)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160)\r\n\tat com.google.firebase.FirebaseApp$TokenRefresher$1.call(FirebaseApp.java:548)\r\n\tat com.google.firebase.FirebaseApp$TokenRefresher$1.call(FirebaseApp.java:544)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nSame thing happens with my firebase project url. As following\r\n`java.net.UnknownHostException: xxxxxx-xxxxx.firebaseio.com: nodename nor servname provided, or not known`\r\n\r\nNotes\r\n1. If I start another terminal windows with 'ping accounts.google.com' and 'ping xxxxxx-xxxxx.firebaseio.com' and leave them running, I constantly receive ping packets. AND during this period the project(the spring based server) also runs fine!\r\nThis is true mostly, NOT always.\r\n2. This happens only on my wifi-router, doesnt happen, on my mobile hotspot, or on my server machine.\r\n3. This is happening with my entire team.\r\n\r\nPlease note that I am not looking for complete solution here. Any help at any level is deeply appreciated. This has become a development nightmare for me and my team.\r\n\r\nTIA\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3230",
        "number": 3230,
        "title": "import com.google.pubsub.v1.ProjectTopicName cannot be resolved",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "So I am using Gradle to build the project and implicitly get your library. If you have some other dependencies with the same packages names inside, the dependency is not grabbed by Gradle. Otherwise the class is missing even from your sources here. \r\n\r\nI see \"mvn compile \" fails for pubsub ... Not expecting this kind of issues here ...\r\n\r\nPlease advise"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3228",
        "number": 3228,
        "title": "unable do junit testing of TableResult outside of package",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I am using table to result to get the result from query job and then using a FieldValueList to iterate the list of row and is working fine, However when I do the junit testing for this code , I tried the TableResultTest and getting error that TableResult() not available publicly. Is there any way I can populate the FiledValueList in TableResult and do the unit test on different package\r\n\r\n TableResult result = queryJob.getQueryResults();\r\n\r\nfor (FieldValueList row : result.iterateAll()) {\r\n}\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3227",
        "number": 3227,
        "title": "List links to other language doc pages in alphabetical order (and add link to C++)",
        "labels": [],
        "state": "closed",
        "body": "Please update drop down menu of [Java docs page(s)](https://googlecloudplatform.github.io/google-cloud-java/0.46.0/index.html)\r\n\r\n### Expected Behavior\r\n\r\n.NET, C++, Go, Java, Node.js , PHP, Python, Ruby\r\n\r\n### Actual Behavior\r\n\r\n.NET, Go, Java, Node.js, PHP, Python, Ruby\r\n\r\n![image](https://user-images.githubusercontent.com/6241635/39551793-7475a7c0-4e34-11e8-8324-230e378af87b.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3223",
        "number": 3223,
        "title": "Error: ... virtual machine instance does not have permission scopes specified.",
        "labels": [],
        "state": "closed",
        "body": "I have a relatively straight forward cloud datastore app, deployed on appengine. I'm using Objectify 6. I am getting this error when running unit tests against the local datastore, on travis-ci.\r\n\r\n`java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.`\r\n\r\nA few notes:\r\n\r\n- this works fine on my local osx and windows machine\r\n- it also works fine on a digital ocean ubuntu 16 instance\r\n- storage and query ops works fine if I don't use Objectify\r\n- it's **not** working on a ubuntu 14 instance hosted by travis (on GCE, coincidentally)\r\n\r\nI've scraped the web looking for info on the problem, and while the problem seems scarce, the answers are even more scarce. I'm not really sure if this is a google problem, a travis problem, or an objectify problem.\r\n\r\nFew questions:\r\n\r\n1. Why, when running against the **local** datastore, is it querying a remote google metadata server? Compute Engine? That's not even a service we are currently using. Edit: Actually, turns out the ubuntu 14 instance is itself running on GCE, so maybe that is the link.\r\n2. I've given the App Engine default service account all the seemingly relevant roles, to no avail. I do have 8 service accounts though - which one is correct?\r\n3. I've also made sure that on the travis instance, I am logged in through gcloud as said default service account, before running `mvn test`\r\n4. Is there a way I can debug using some curl calls to the metadata server? The error is just not very informative.\r\n\r\nAnd finally, any ideas on what I can do to fix this? Thanks.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3221",
        "number": 3221,
        "title": "Requester Pays on NIO",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "There is an option on `BlobSourceOption` and `BlobWriteOption` to specify the billing project to use when accessing a requester pays bucket, but there doesn't seem to be a way to wire that through NIO.\r\nAm I missing it ? And if not is this something that could be considered ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3220",
        "number": 3220,
        "title": "Logging to root handler doesn't work",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "We use [tomcat-runtime](https://github.com/GoogleCloudPlatform/tomcat-runtime), and our logging.properties looks like this:\r\n\r\n```\r\nhandlers = com.google.cloud.logging.LoggingHandler\r\n.level = INFO\r\n\r\ncom.google.cloud.logging.LoggingHandler.level = INFO\r\ncom.google.cloud.logging.LoggingHandler.log = gae_app.log\r\ncom.google.cloud.logging.LoggingHandler.formatter = java.util.logging.SimpleFormatter\r\njava.util.logging.SimpleFormatter.format = %3$s: %5$s%6$s\r\n\r\n.handlers = com.google.cloud.logging.LoggingHandler\r\n```\r\n\r\nAdding something like `org.apache.handlers` works, just not for the root handler."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3219",
        "number": 3219,
        "title": "Issue upgrading grpc logger",
        "labels": [],
        "state": "closed",
        "body": "Upgrading our dependencies from grpc-core-1.7 to grpc-core-1.11.0, and grpc-netty-1.7.0 to grpc-netty-shaded-1.110, we get this exception:\r\n```\r\nCaused by: java.util.ServiceConfigurationError: io.grpc.ManagedChannelProvider: Provider io.grpc.netty.NettyChannelProvider not a subtype\r\n\tat java.util.ServiceLoader.fail(ServiceLoader.java:239)\r\n\tat java.util.ServiceLoader.access$300(ServiceLoader.java:185)\r\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:376)\r\n\tat java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)\r\n\tat java.util.ServiceLoader$1.next(ServiceLoader.java:480)\r\n\tat io.grpc.ServiceProviders.loadAll(ServiceProviders.java:67)\r\n\tat io.grpc.ServiceProviders.load(ServiceProviders.java:42)\r\n\tat io.grpc.ManagedChannelProvider.<clinit>(ManagedChannelProvider.java:37)\r\n\tat io.grpc.ManagedChannelBuilder.forAddress(ManagedChannelBuilder.java:36)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:183)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:155)\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:147)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:151)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:116)\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:127)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:64)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:58)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:506)\r\n\tat com.google.cloud.logging.LoggingOptions.getLoggingRpcV2(LoggingOptions.java:134)\r\n\tat com.google.cloud.logging.LoggingImpl.<init>(LoggingImpl.java:108)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:46)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:41)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:493)\r\n\tat com.google.cloud.logging.LoggingHandler.getLogging(LoggingHandler.java:360)\r\n\tat com.google.cloud.logging.LoggingHandler.<init>(LoggingHandler.java:195)\r\n\tat com.google.cloud.logging.LoggingHandler.<init>(LoggingHandler.java:151)\r\n\tat com.google.cloud.logging.LoggingHandler.<init>(LoggingHandler.java:120)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat java.lang.Class.newInstance(Class.java:442)\r\n\tat org.apache.juli.ClassLoaderLogManager.readConfiguration(ClassLoaderLogManager.java:563)\r\n\tat org.apache.juli.ClassLoaderLogManager.readConfiguration(ClassLoaderLogManager.java:506)\r\n\tat org.apache.juli.ClassLoaderLogManager$2.run(ClassLoaderLogManager.java:403)\r\n\tat org.apache.juli.ClassLoaderLogManager$2.run(ClassLoaderLogManager.java:399)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat org.apache.juli.ClassLoaderLogManager.getClassLoaderInfo(ClassLoaderLogManager.java:399)\r\n\tat org.apache.juli.ClassLoaderLogManager.getLogger(ClassLoaderLogManager.java:230)\r\n\tat java.util.logging.LogManager.demandLogger(LogManager.java:551)\r\n\tat java.util.logging.Logger.demandLogger(Logger.java:455)\r\n\tat java.util.logging.Logger.getLogger(Logger.java:502)\r\n\tat org.apache.juli.logging.DirectJDKLog.<init>(DirectJDKLog.java:67)\r\n\tat org.apache.juli.logging.DirectJDKLog.getInstance(DirectJDKLog.java:187)\r\n\tat org.apache.juli.logging.LogFactory.getInstance(LogFactory.java:117)\r\n\tat org.apache.juli.logging.LogFactory.getLog(LogFactory.java:216)\r\n\tat org.apache.catalina.core.ContainerBase.getLogger(ContainerBase.java:360)\r\n```\r\nnetty-shaded appears to have a `io.grpc.netty.shaded.io.grpc.netty.NettyChannelProvider.`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3215",
        "number": 3215,
        "title": "Injecting google cloud credentials instead GOOGLE_APPLICATION_CREDENTIALS environment ",
        "labels": [
            "type: feature request"
        ],
        "state": "open",
        "body": "Please provide a way to inject google credentials information for the stackdriver logger by means of public method/property instead of placing a private key file on machine and refer it from the GOOGLE_APPLICATION_CREDENTIALS environment variable.\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3213",
        "number": 3213,
        "title": "ThreadManager not available on Google Cloud Java",
        "labels": [],
        "state": "closed",
        "body": "It is available in AppEngine SDK, but not on Google Cloud Java. This limits applications from being ported over to the new SDK."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3206",
        "number": 3206,
        "title": "Merge without code review allowed",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": "See https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3193 for example.\r\n\r\n\"Review has been requested on this pull request. It is not required to merge.\"\r\n\r\nI suspect the repo should be configured to require review before merge."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3205",
        "number": 3205,
        "title": "Reporting configuration should be done in <reporting> section, not in maven-site-plugin <configuration> as reportPlugins parameter.",
        "labels": [
            "priority: p2",
            "type: bug",
            "type: process"
        ],
        "state": "closed",
        "body": "While building google-cloud-bom\r\n\r\n```\r\n[WARNING] \r\n[WARNING] Some problems were encountered while building the effective model for com.google.cloud:google-cloud-core:jar:1.27.1-SNAPSHOT\r\n[WARNING] Reporting configuration should be done in <reporting> section, not in maven-site-plugin <configuration> as reportPlugins parameter.\r\n[WARNING] \r\n[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.\r\n[WARNING] \r\n[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.\r\n[WARNING] \r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3203",
        "number": 3203,
        "title": "Firestore runTransaction doesn't propagate java.lang.Error",
        "labels": [],
        "state": "closed",
        "body": "If a `Transaction.Function<T>` lambda throws an instance of `java.lang.Error`, the returned `ApiFuture<T>` doesn't trigger the listeners registered through `apiFuture.addListener(Runnable, Executor)`. \r\n\r\nI'm wrapping all `ApiFuture<T>` instances into a `Mono<T>` from project reactor, and because the listeners don't get fired on Errors my application is just hanging.\r\n\r\nAs a workaround I've had to wrap my `Transaction.Function<T>` in a try/catch block to catch `Error` and rethrow a normal `Exception`, then catch that from my reactive stream and map it to the original Error. \r\n\r\nIt would be nice to not have to do this \ud83d\ude0a "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3198",
        "number": 3198,
        "title": "com.google.cloud:google-cloud-core:jar:tests:1.27.1",
        "labels": [],
        "state": "closed",
        "body": "Locally at master I'm seeing:\r\n\r\n```\r\n[ERROR] Failed to execute goal on project google-cloud-bigtable: Could not resolve dependencies for project com.google.cloud:google-cloud-bigtable:jar:0.45.1-alpha-SNAPSHOT: Could not find artifact com.google.cloud:google-cloud-core:jar:tests:1.27.1-SNAPSHOT -> [Help 1]\r\n[ERROR] \r\n```\r\n\r\nLooks like an artifact that isn't in Maven Central yet? Can anyone suggest how I should proceed?  "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3194",
        "number": 3194,
        "title": "PubSubPublisher : High CPU usage",
        "labels": [],
        "state": "closed",
        "body": "We use PubSub in a fairly conventional way : \r\n```\r\n                                                Database X\r\n                                              /   \r\n                                             / \r\nPubsub (Topic A) --> Worker (Subscription A) \r\n                                             \\\r\n                                              \\\r\n                                                Database Y\r\n```\r\nOur infrastructure is on google cloud (and we use k8s). For a steady ~3000 messages / second, 6 pods with the following config are enough and work at around 80% CPU\r\n\r\n```\r\n  \"resources\": {\r\n    \"requests\": {\r\n      \"cpu\": \"500m\",\r\n      \"memory\": \"2Gi\"\r\n    },\r\n    \"limits\": {\r\n      \"cpu\": \"1500m\",\r\n      \"memory\": \"3Gi\"\r\n    }\r\n  }\r\n```\r\n\r\nWe would like to use the message in different ways and move towards something like : \r\n\r\n```\r\n                                                 Database X\r\n                                              /   \r\n                                             / \r\nPubsub (Topic A) --> Worker (Subscription A) -- Database Y\r\n                                             \\\r\n                                              \\\r\n                                                Pubsub (Topic B)\r\n```\r\n\r\nThe only modification we made to the code is creating a new PubSubPublisher and publishing messages to the topic. Every message from Topic A / Subscription A ends up in Topic B so we are also effectively publishing ~3000 messages / second.\r\n\r\nAfter adding that operation, CPU usage for the pods went through the roof. What 6 pods were able to handle @ 80% CPU could not be handled by 20 pods @ 100% CPU with the config noted above (we rolled the code back as the workers weren't able to keep up).\r\n\r\nThe PubSubPublisher is created with very standard settings (I believe the retry settings are the default ones) : \r\n\r\n```java\r\nprivate void startPublisher() {\r\nRetrySettings retrySettings = RetrySettings.newBuilder()\r\n    .setTotalTimeout(Duration.ofSeconds(10))\r\n    .setInitialRetryDelay(Duration.ofMillis(5))\r\n    .setRetryDelayMultiplier(2.0)\r\n    .setMaxRetryDelay(Duration.ofMillis(Long.MAX_VALUE))\r\n    .setInitialRpcTimeout(Duration.ofSeconds(10))\r\n    .setRpcTimeoutMultiplier(2)\r\n    .setMaxRpcTimeout(Duration.ofSeconds(10))\r\n    .build();\r\n\r\npublisher = Publisher.newBuilder(topic)\r\n    .setRetrySettings(retrySettings)\r\n    .setCredentialsProvider(FixedCredentialsProvider.create(\r\n            ServiceAccountCredentials.fromStream(new FileInputStream(Configurations.getGoogleCloudCredentials())))\r\n    )\r\n    .build();\r\n}\r\n```\r\n\r\nThe actual publish method is : \r\n\r\n```java\r\nprivate void publish(byte[] message) {\r\n    try {\r\n        PubsubMessage pubsubMessage = PubsubMessage.newBuilder().setData(ByteString.copyFrom(message)).build();\r\n        ApiFuture<String> future = publisher.publish(pubsubMessage);\r\n\r\n        ApiFutures.addCallback(future, new ApiFutureCallback<String>() {\r\n            @Override\r\n            public void onFailure(Throwable throwable) {\r\n                if (throwable instanceof ApiException) {\r\n                    ApiException apiException = ((ApiException) throwable);\r\n                    logger.debug(new LogEntry().setMessage(String.format(\"PubSubException : ApiException. Code %s. IsRetryable ? %s\",\r\n                            apiException.getStatusCode().getCode(),\r\n                            apiException.isRetryable())));\r\n                }\r\n                logger.warn(new LogEntry().setMessage(\"Error publishing message : \" + Helper.getStackTrace(throwable)));\r\n            }\r\n\r\n            @Override\r\n            public void onSuccess(String messageId) {\r\n\r\n            }\r\n        });\r\n    }\r\n    catch(Exception ex) {\r\n        logger.error(new LogEntry().setMessage(\"An error occured publishing a message to pubsub : \" + Helper.getStackTrace(ex)));\r\n    }\r\n}\r\n```\r\n\r\nConverting our objects to byte arrays is simple serialization : \r\n\r\n```java\r\norg.apache.commons.lang3.SerializationUtils.serialize(message);\r\n```\r\n\r\nIs such a high CPU usage to be expected ? Should queueing into Pubsub need that much processing power ? What are we doing wrong for our publishers to consume so much ?\r\n\r\nWe've seen this with different versions. We got these results with `0.39.0-beta` on a box running centos 7. We use gRPC 1.10.0 in the project."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3192",
        "number": 3192,
        "title": "Dependency convergence errors in datastore",
        "labels": [
            "type: process"
        ],
        "state": "open",
        "body": "It's not immediately obvious to me why I see this and the checks in this project's own pom.xml don't; but I definitely see this in a project that does nothing but import the datastore dependency from the google-cloud-java BOM and check dependency convergence:\r\n\r\n```\r\n[INFO] Scanning for projects...\r\n[INFO] \r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Building Dependency Tests for Google Cloud Libraries 0.0.1-SNAPSHOT\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] \r\n[INFO] --- maven-enforcer-plugin:1.4.1:enforce (enforce) @ dependencytest ---\r\n[WARNING] \r\nDependency convergence error for com.google.code.findbugs:jsr305:1.3.9 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.guava:guava:24.1-jre\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.code.findbugs:jsr305:3.0.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api:api-common:1.5.0\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api:gax:1.23.0\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.oauth-client:google-oauth-client:1.23.0\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api:gax-httpjson:0.40.0\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\n        +-com.google.code.findbugs:jsr305:3.0.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-contrib-http-util:0.11.1\r\n        +-com.google.code.findbugs:jsr305:3.0.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-com.google.code.findbugs:jsr305:3.0.0\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.protobuf:protobuf-java:3.5.1 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.protobuf:protobuf-java-util:3.5.1\r\n        +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api.grpc:proto-google-common-protos:1.9.0\r\n        +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api.grpc:proto-google-iam-v1:0.10.0\r\n        +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.api.grpc:proto-google-cloud-datastore-v1:0.10.0\r\n      +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client-protobuf:1.20.0\r\n        +-com.google.protobuf:protobuf-java:2.4.1\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.errorprone:error_prone_annotations:2.1.3 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.guava:guava:24.1-jre\r\n        +-com.google.errorprone:error_prone_annotations:2.1.3\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\n        +-com.google.errorprone:error_prone_annotations:2.2.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-contrib-http-util:0.11.1\r\n        +-com.google.errorprone:error_prone_annotations:2.2.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-com.google.errorprone:error_prone_annotations:2.1.2\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.http-client:google-http-client-jackson2:1.19.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.9.0\r\n        +-com.google.http-client:google-http-client-jackson2:1.19.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api-client:google-api-client:1.23.0\r\n        +-com.google.http-client:google-http-client-jackson2:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-jackson2:1.23.0\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.http-client:google-http-client-jackson:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-jackson:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client-jackson:1.20.0\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.api-client:google-api-client:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api-client:google-api-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.api-client:google-api-client:1.20.0\r\n\r\n[WARNING] \r\nDependency convergence error for io.opencensus:opencensus-api:0.11.1 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-contrib-http-util:0.11.1\r\n        +-io.opencensus:opencensus-api:0.11.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-io.opencensus:opencensus-api:0.11.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-io.opencensus:opencensus-contrib-grpc-metrics:0.11.0\r\n        +-io.opencensus:opencensus-api:0.11.0\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.oauth-client:google-oauth-client:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.oauth-client:google-oauth-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api-client:google-api-client:1.23.0\r\n        +-com.google.oauth-client:google-oauth-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.oauth-client:google-oauth-client:1.20.0\r\n\r\n[WARNING] \r\nDependency convergence error for io.grpc:grpc-context:1.9.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\n        +-io.grpc:grpc-context:1.9.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-io.grpc:grpc-context:1.10.1\r\n\r\n[WARNING] \r\nDependency convergence error for com.google.http-client:google-http-client:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.9.0\r\n        +-com.google.http-client:google-http-client:1.19.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.oauth-client:google-oauth-client:1.23.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-appengine:1.23.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-jackson:1.23.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api:gax-httpjson:0.40.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client-protobuf:1.20.0\r\n        +-com.google.http-client:google-http-client:1.20.0\r\n\r\n[WARNING] Rule 0: org.apache.maven.plugins.enforcer.DependencyConvergence failed with message:\r\nFailed while enforcing releasability the error(s) are [\r\nDependency convergence error for com.google.code.findbugs:jsr305:1.3.9 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.guava:guava:24.1-jre\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.code.findbugs:jsr305:3.0.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api:api-common:1.5.0\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api:gax:1.23.0\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.oauth-client:google-oauth-client:1.23.0\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api:gax-httpjson:0.40.0\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\n        +-com.google.code.findbugs:jsr305:3.0.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-contrib-http-util:0.11.1\r\n        +-com.google.code.findbugs:jsr305:3.0.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-com.google.code.findbugs:jsr305:3.0.0\r\n, \r\nDependency convergence error for com.google.protobuf:protobuf-java:3.5.1 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.protobuf:protobuf-java-util:3.5.1\r\n        +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api.grpc:proto-google-common-protos:1.9.0\r\n        +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.api.grpc:proto-google-iam-v1:0.10.0\r\n        +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.api.grpc:proto-google-cloud-datastore-v1:0.10.0\r\n      +-com.google.protobuf:protobuf-java:3.5.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client-protobuf:1.20.0\r\n        +-com.google.protobuf:protobuf-java:2.4.1\r\n, \r\nDependency convergence error for com.google.errorprone:error_prone_annotations:2.1.3 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.guava:guava:24.1-jre\r\n        +-com.google.errorprone:error_prone_annotations:2.1.3\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\n        +-com.google.errorprone:error_prone_annotations:2.2.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-contrib-http-util:0.11.1\r\n        +-com.google.errorprone:error_prone_annotations:2.2.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-com.google.errorprone:error_prone_annotations:2.1.2\r\n, \r\nDependency convergence error for com.google.http-client:google-http-client-jackson2:1.19.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.9.0\r\n        +-com.google.http-client:google-http-client-jackson2:1.19.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api-client:google-api-client:1.23.0\r\n        +-com.google.http-client:google-http-client-jackson2:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-jackson2:1.23.0\r\n, \r\nDependency convergence error for com.google.http-client:google-http-client-jackson:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-jackson:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client-jackson:1.20.0\r\n, \r\nDependency convergence error for com.google.api-client:google-api-client:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api-client:google-api-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.api-client:google-api-client:1.20.0\r\n, \r\nDependency convergence error for io.opencensus:opencensus-api:0.11.1 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-contrib-http-util:0.11.1\r\n        +-io.opencensus:opencensus-api:0.11.1\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-io.opencensus:opencensus-api:0.11.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-io.opencensus:opencensus-contrib-grpc-metrics:0.11.0\r\n        +-io.opencensus:opencensus-api:0.11.0\r\n, \r\nDependency convergence error for com.google.oauth-client:google-oauth-client:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.oauth-client:google-oauth-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api-client:google-api-client:1.23.0\r\n        +-com.google.oauth-client:google-oauth-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.oauth-client:google-oauth-client:1.20.0\r\n, \r\nDependency convergence error for io.grpc:grpc-context:1.9.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-io.opencensus:opencensus-api:0.11.1\r\n        +-io.grpc:grpc-context:1.9.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-io.grpc:grpc-core:1.10.1\r\n      +-io.grpc:grpc-context:1.10.1\r\n, \r\nDependency convergence error for com.google.http-client:google-http-client:1.23.0 paths to dependency are:\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core:1.27.0\r\n      +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.9.0\r\n        +-com.google.http-client:google-http-client:1.19.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.oauth-client:google-oauth-client:1.23.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-appengine:1.23.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.http-client:google-http-client-jackson:1.23.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud:google-cloud-core-http:1.27.0\r\n      +-com.google.api:gax-httpjson:0.40.0\r\n        +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client:1.23.0\r\nand\r\n+-com.google.cloud.tools.dependencies:dependencytest:0.0.1-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-datastore:1.27.0\r\n    +-com.google.cloud.datastore:datastore-v1-proto-client:1.6.0\r\n      +-com.google.http-client:google-http-client-protobuf:1.20.0\r\n        +-com.google.http-client:google-http-client:1.20.0\r\n]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 3.710 s\r\n[INFO] Finished at: 2018-04-25T08:04:18-04:00\r\n[INFO] Final Memory: 10M/159M\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce) on project dependencytest: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1]\r\n[ERROR] \r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR] \r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3191",
        "number": 3191,
        "title": "Unclear in docs if config can be reused and relevant classes are thread safe.",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "E.g.: Can I reuse parts spanding more requests like the response of the getServcie() and have that injected in another class? Are these classes thread safe or should a developer always create a new Translate object?\r\n\r\n```\r\n@Inject\r\nprivate Translate translate; \r\n// Somewhere else defined and injected like\r\n// Translate translate = TranslateOptions.newBuilder().setApiKey(googleApiKey).build().getService();\r\n...\r\npublic void doTranslation(){\r\n    Translation translation = translate.translate(\r\n                            \"Some text here\",\r\n                            Translate.TranslateOption.sourceLanguage(sourceLanguage),\r\n                            Translate.TranslateOption.targetLanguage(targetLanguage));\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3190",
        "number": 3190,
        "title": "Update all Maven and Gradle based library import instructions to use BOM",
        "labels": [
            "dependencies",
            "type: docs",
            "type: feature request"
        ],
        "state": "closed",
        "body": "all the specific API readme's instruct the user to directly import the versioned dependency using \r\n`<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-translate</artifactId>\r\n  <version>1.27.0</version>\r\n</dependency>`\r\n\r\nThis is setting users up for diamond dep conflicts as soon as they choose to import another library in the catalog.  \r\n\r\nInstead we should always instruct the user to use the BOM to import google-cloud-java libraries."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3188",
        "number": 3188,
        "title": "How to pass Audio from Microphone to Google Speech To Text?",
        "labels": [
            "api: speech",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I can't find any example for this functionality on the repository : \r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-speech\r\n\r\nIs it supported at all ? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3187",
        "number": 3187,
        "title": "OpenSSL exception with google-cloud-dlp 0.44.0-beta on OpenJDK 8",
        "labels": [
            "api: dlp",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm using Google DLP through the Google Cloud Java client library, and when I upgraded to the latest version, 0.44.0-beta, I started getting the CertificateException shown below. This runs fine when I run it on my Mac with the Oracle JDK 8, but when run in OpenJDK 8 in a Docker instance, I'm seeing the exception. I have to have this running on OpenJDK. I'm guessing that the certificate is signed by a CA that is unknown to OpenJDK. What's the easiest solution to this? Do I have to install a custom CA for OpenJDK? What's interesting is that the OverOps snapshot contains a call to this method:\r\n\r\n`public io.grpc.netty.shaded.io.netty.handler.ssl.util.SelfSignedCertificate(String fqdn, SecureRandom random, int bits, Date notBefore, Date notAfter)`\r\n\r\nand the `fqdn` parameter is actually set to `example.com`. The stack trace is as follows:\r\n```\r\nCertificateException: Issuer class type invalid.\r\nat sun.security.x509.X509CertInfo.setIssuer(Object)\r\nat sun.security.x509.X509CertInfo.set(String, Object)\r\nat io.grpc.netty.shaded.io.netty.handler.ssl.util.OpenJdkSelfSignedCertGenerator.generate(String, KeyPair, SecureRandom, Date, Date)\r\nat io.grpc.netty.shaded.io.netty.handler.ssl.util.SelfSignedCertificate.<init>(String, SecureRandom, int, Date, Date)\r\nat io.grpc.netty.shaded.io.netty.handler.ssl.util.SelfSignedCertificate.<init>(String, Date, Date)\r\nat io.grpc.netty.shaded.io.netty.handler.ssl.util.SelfSignedCertificate.<init>(Date, Date)\r\nat io.grpc.netty.shaded.io.netty.handler.ssl.util.SelfSignedCertificate.<init>()\r\nat io.grpc.netty.shaded.io.netty.handler.ssl.OpenSsl.<clinit>()\r\nat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.defaultSslProvider()\r\nat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.configure(SslContextBuilder)\r\nat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.forClient()\r\nat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(NettyChannelBuilder$NettyTransportFactory, SslContext)\r\nat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(NettyChannelBuilder$NettyTransportFactory, SslContext, NettyChannelBuilder$1)\r\nat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder$TransportCreationParamsFilterFactory, Class, Map, NegotiationType, SslContext, EventLoopGroup, int, int, int, long, long, boolean, TransportTracer)\r\nat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder.buildTransportFactory()\r\nat io.grpc.internal.AbstractManagedChannelImplBuilder.build()\r\nat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel()\r\nat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel()\r\nat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel()\r\nat com.google.api.gax.rpc.ClientContext.create(StubSettings)\r\nat com.google.cloud.dlp.v2beta1.stub.GrpcDlpServiceStub.create(DlpServiceStubSettings)\r\nat com.google.cloud.dlp.v2beta1.stub.DlpServiceStubSettings.createStub()\r\nat com.google.cloud.dlp.v2beta1.DlpServiceClient.<init>(DlpServiceSettings)\r\nat com.google.cloud.dlp.v2beta1.DlpServiceClient.create(DlpServiceSettings)\r\nat XXXXXXXX.redactContent(Collection, String, Likelihood, List)\r\nat XXXXXXXX.lambda$redact$0(Collection, String, Likelihood, List)\r\nat java.util.concurrent.CompletableFuture$AsyncSupply.run()\r\nat java.lang.Thread.run()\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3186",
        "number": 3186,
        "title": "Local Datastore API's",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "App Engine standard has [API's](https://cloud.google.com/appengine/docs/standard/java/tools/localunittesting#high-replication-datastore) to support unit testing in customers app's."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3182",
        "number": 3182,
        "title": "Dependency conflicts between Vision client library and Apache Beam Cloud Dataflow runner",
        "labels": [
            ":rotating_light:",
            "api: vision",
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI am creating a **Google Cloud Dataflow pipeline** that collects data (like image URLs) from a CSV and calls the **Google Cloud Vision service** using client libraries for image detection.\r\n\r\nI create a maven project with the beam libraries. Problems appear when adding the [java vision client library](https://cloud.google.com/vision/docs/libraries?hl=es#installing_the_client_library), looks like there are some dependency issues [similar to here](https://issues.apache.org/jira/browse/BEAM-2837), but I am not able to add proper exclusions to make it work.\r\n\r\n```\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-vision</artifactId>\r\n  <version>1.26.0</version>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\nThis is my POM file:\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \r\n\t~ Copyright (C) 2017 Google Inc. ~ ~ Licensed under the Apache License, Version \r\n\t2.0 (the \"License\"); you may not ~ use this file except in compliance with \r\n\tthe License. You may obtain a copy of ~ the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 \r\n\t~ ~ Unless required by applicable law or agreed to in writing, software ~ \r\n\tdistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT \r\n\t~ WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the \r\n\t~ License for the specific language governing permissions and limitations \r\n\tunder ~ the License. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n\txsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n\t<modelVersion>4.0.0</modelVersion>\r\n\r\n\t<groupId>com.sample.dataflow.cloud</groupId>\r\n\t<artifactId>test</artifactId>\r\n\t<version>0.0.1-SNAPSHOT</version>\r\n\r\n\t<packaging>jar</packaging>\r\n\r\n\t<properties>\r\n\t\t<beam.version>2.0.0</beam.version>\r\n\t\t<surefire-plugin.version>2.20</surefire-plugin.version>\r\n\t</properties>\r\n\r\n\t<repositories>\r\n\t\t<repository>\r\n\t\t\t<id>apache.snapshots</id>\r\n\t\t\t<name>Apache Development Snapshot Repository</name>\r\n\t\t\t<url>https://repository.apache.org/content/repositories/snapshots/</url>\r\n\t\t\t<releases>\r\n\t\t\t\t<enabled>false</enabled>\r\n\t\t\t</releases>\r\n\t\t\t<snapshots>\r\n\t\t\t\t<enabled>true</enabled>\r\n\t\t\t</snapshots>\r\n\t\t</repository>\r\n\t</repositories>\r\n\r\n\t<build>\r\n\t\t<plugins>\r\n\t\t\t<plugin>\r\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\r\n\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\r\n\t\t\t\t<version>3.5.1</version>\r\n\t\t\t\t<configuration>\r\n\t\t\t\t\t<source>1.7</source>\r\n\t\t\t\t\t<target>1.7</target>\r\n\t\t\t\t</configuration>\r\n\t\t\t</plugin>\r\n\r\n\t\t\t<plugin>\r\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\r\n\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\r\n\t\t\t\t<version>${surefire-plugin.version}</version>\r\n\t\t\t\t<configuration>\r\n\t\t\t\t\t<parallel>all</parallel>\r\n\t\t\t\t\t<threadCount>4</threadCount>\r\n\t\t\t\t\t<redirectTestOutputToFile>true</redirectTestOutputToFile>\r\n\t\t\t\t</configuration>\r\n\t\t\t\t<dependencies>\r\n\t\t\t\t\t<dependency>\r\n\t\t\t\t\t\t<groupId>org.apache.maven.surefire</groupId>\r\n\t\t\t\t\t\t<artifactId>surefire-junit47</artifactId>\r\n\t\t\t\t\t\t<version>${surefire-plugin.version}</version>\r\n\t\t\t\t\t</dependency>\r\n\t\t\t\t</dependencies>\r\n\t\t\t</plugin>\r\n\r\n\t\t\t<!-- Ensure that the Maven jar plugin runs before the Maven shade plugin \r\n\t\t\t\tby listing the plugin higher within the file. -->\r\n\t\t\t<plugin>\r\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\r\n\t\t\t\t<artifactId>maven-jar-plugin</artifactId>\r\n\t\t\t</plugin>\r\n\r\n\t\t\t<!-- Configures `mvn package` to produce a bundled jar (\"fat jar\") for \r\n\t\t\t\trunners that require this for job submission to a cluster. -->\r\n\t\t\t<plugin>\r\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\r\n\t\t\t\t<artifactId>maven-shade-plugin</artifactId>\r\n\t\t\t\t<version>3.0.0</version>\r\n\t\t\t\t<executions>\r\n\t\t\t\t\t<execution>\r\n\t\t\t\t\t\t<phase>package</phase>\r\n\t\t\t\t\t\t<goals>\r\n\t\t\t\t\t\t\t<goal>shade</goal>\r\n\t\t\t\t\t\t</goals>\r\n\t\t\t\t\t\t<configuration>\r\n\t\t\t\t\t\t\t<filters>\r\n\t\t\t\t\t\t\t\t<filter>\r\n\t\t\t\t\t\t\t\t\t<artifact>*:*</artifact>\r\n\t\t\t\t\t\t\t\t\t<excludes>\r\n\t\t\t\t\t\t\t\t\t\t<exclude>META-INF/LICENSE</exclude>\r\n\t\t\t\t\t\t\t\t\t\t<exclude>META-INF/*.SF</exclude>\r\n\t\t\t\t\t\t\t\t\t\t<exclude>META-INF/*.DSA</exclude>\r\n\t\t\t\t\t\t\t\t\t\t<exclude>META-INF/*.RSA</exclude>\r\n\t\t\t\t\t\t\t\t\t</excludes>\r\n\t\t\t\t\t\t\t\t</filter>\r\n\t\t\t\t\t\t\t</filters>\r\n\t\t\t\t\t\t\t<transformers>\r\n\t\t\t\t\t\t\t\t<transformer\r\n\t\t\t\t\t\t\t\t\timplementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\" />\r\n\t\t\t\t\t\t\t</transformers>\r\n\t\t\t\t\t\t</configuration>\r\n\t\t\t\t\t</execution>\r\n\t\t\t\t</executions>\r\n\t\t\t</plugin>\r\n\t\t</plugins>\r\n\t</build>\r\n\r\n\t<profiles>\r\n\t\t<profile>\r\n\t\t\t<id>direct-runner</id>\r\n\t\t\t<activation>\r\n\t\t\t\t<activeByDefault>true</activeByDefault>\r\n\t\t\t</activation>\r\n\t\t\t<!-- Makes the DirectRunner available when running a pipeline. -->\r\n\t\t\t<dependencies>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t\t\t<artifactId>beam-runners-direct-java</artifactId>\r\n\t\t\t\t\t<version>${beam.version}</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t</dependencies>\r\n\t\t</profile>\r\n\r\n\t\t<profile>\r\n\t\t\t<id>apex-runner</id>\r\n\t\t\t<!-- Makes the ApexRunner available when running a pipeline. -->\r\n\t\t\t<dependencies>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t\t\t<artifactId>beam-runners-apex</artifactId>\r\n\t\t\t\t\t<version>${beam.version}</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t\t<!-- Apex depends on httpclient version 4.3.5, project has a transitive \r\n\t\t\t\t\tdependency to httpclient 4.0.1 from google-http-client. Apex dependency version \r\n\t\t\t\t\tbeing specified explicitly so that it gets picked up. This can be removed \r\n\t\t\t\t\twhen the project no longer has a dependency on a different httpclient version. -->\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.httpcomponents</groupId>\r\n\t\t\t\t\t<artifactId>httpclient</artifactId>\r\n\t\t\t\t\t<version>4.3.5</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t\t<exclusions>\r\n\t\t\t\t\t\t<exclusion>\r\n\t\t\t\t\t\t\t<groupId>commons-codec</groupId>\r\n\t\t\t\t\t\t\t<artifactId>commons-codec</artifactId>\r\n\t\t\t\t\t\t</exclusion>\r\n\t\t\t\t\t</exclusions>\r\n\t\t\t\t</dependency>\r\n\t\t\t</dependencies>\r\n\t\t</profile>\r\n\r\n\t\t<profile>\r\n\t\t\t<id>dataflow-runner</id>\r\n\t\t\t<!-- Makes the DataflowRunner available when running a pipeline. -->\r\n\t\t\t<dependencies>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t\t\t<artifactId>beam-runners-google-cloud-dataflow-java</artifactId>\r\n\t\t\t\t\t<version>${beam.version}</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t</dependencies>\r\n\t\t</profile>\r\n\r\n\t\t<profile>\r\n\t\t\t<id>flink-runner</id>\r\n\t\t\t<!-- Makes the FlinkRunner available when running a pipeline. -->\r\n\t\t\t<dependencies>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t\t\t<artifactId>beam-runners-flink_2.10</artifactId>\r\n\t\t\t\t\t<version>${beam.version}</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t</dependencies>\r\n\t\t</profile>\r\n\r\n\t\t<profile>\r\n\t\t\t<id>spark-runner</id>\r\n\t\t\t<!-- Makes the SparkRunner available when running a pipeline. Additionally, \r\n\t\t\t\toverrides some Spark dependencies to Beam-compatible versions. -->\r\n\t\t\t<dependencies>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t\t\t<artifactId>beam-runners-spark</artifactId>\r\n\t\t\t\t\t<version>${beam.version}</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t\t\t<artifactId>beam-sdks-java-io-hadoop-file-system</artifactId>\r\n\t\t\t\t\t<version>${beam.version}</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>org.apache.spark</groupId>\r\n\t\t\t\t\t<artifactId>spark-streaming_2.10</artifactId>\r\n\t\t\t\t\t<version>1.6.2</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t\t<exclusions>\r\n\t\t\t\t\t\t<exclusion>\r\n\t\t\t\t\t\t\t<groupId>org.slf4j</groupId>\r\n\t\t\t\t\t\t\t<artifactId>jul-to-slf4j</artifactId>\r\n\t\t\t\t\t\t</exclusion>\r\n\t\t\t\t\t</exclusions>\r\n\t\t\t\t</dependency>\r\n\t\t\t\t<dependency>\r\n\t\t\t\t\t<groupId>com.fasterxml.jackson.module</groupId>\r\n\t\t\t\t\t<artifactId>jackson-module-scala_2.10</artifactId>\r\n\t\t\t\t\t<version>2.8.8</version>\r\n\t\t\t\t\t<scope>runtime</scope>\r\n\t\t\t\t</dependency>\r\n\t\t\t</dependencies>\r\n\t\t</profile>\r\n\t</profiles>\r\n\r\n\t<dependencies>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.api.grpc</groupId>\r\n\t\t\t<artifactId>grpc-google-common-protos</artifactId>\r\n\t\t\t<version>0.1.9</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.apache.beam</groupId>\r\n\t\t\t<artifactId>beam-sdks-java-io-google-cloud-platform</artifactId>\r\n\t\t\t<version>${beam.version}</version>\r\n\t\t\t<exclusions>\r\n\t\t\t\t<exclusion>\r\n\t\t\t\t\t<groupId>com.google.api.grpc</groupId>\r\n\t\t\t\t\t<artifactId>grpc-google-common-protos</artifactId>\r\n\t\t\t\t</exclusion>\r\n\t\t\t</exclusions>\r\n\t\t</dependency>\r\n\r\n\t\t<!-- Dependencies below this line are specific dependencies needed by the \r\n\t\t\texamples code. -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.api-client</groupId>\r\n\t\t\t<artifactId>google-api-client</artifactId>\r\n\t\t\t<version>1.22.0</version>\r\n\t\t\t<exclusions>\r\n\t\t\t\t<!-- Exclude an old version of guava that is being pulled in by a transitive \r\n\t\t\t\t\tdependency of google-api-client -->\r\n\t\t\t\t<exclusion>\r\n\t\t\t\t\t<groupId>com.google.guava</groupId>\r\n\t\t\t\t\t<artifactId>guava-jdk5</artifactId>\r\n\t\t\t\t</exclusion>\r\n\t\t\t</exclusions>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.apis</groupId>\r\n\t\t\t<artifactId>google-api-services-bigquery</artifactId>\r\n\t\t\t<version>v2-rev295-1.22.0</version>\r\n\t\t\t<exclusions>\r\n\t\t\t\t<!-- Exclude an old version of guava that is being pulled in by a transitive \r\n\t\t\t\t\tdependency of google-api-client -->\r\n\t\t\t\t<exclusion>\r\n\t\t\t\t\t<groupId>com.google.guava</groupId>\r\n\t\t\t\t\t<artifactId>guava-jdk5</artifactId>\r\n\t\t\t\t</exclusion>\r\n\t\t\t</exclusions>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.http-client</groupId>\r\n\t\t\t<artifactId>google-http-client</artifactId>\r\n\t\t\t<version>1.22.0</version>\r\n\t\t\t<exclusions>\r\n\t\t\t\t<!-- Exclude an old version of guava that is being pulled in by a transitive \r\n\t\t\t\t\tdependency of google-api-client -->\r\n\t\t\t\t<exclusion>\r\n\t\t\t\t\t<groupId>com.google.guava</groupId>\r\n\t\t\t\t\t<artifactId>guava-jdk5</artifactId>\r\n\t\t\t\t</exclusion>\r\n\t\t\t</exclusions>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>joda-time</groupId>\r\n\t\t\t<artifactId>joda-time</artifactId>\r\n\t\t\t<version>2.4</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.guava</groupId>\r\n\t\t\t<artifactId>guava</artifactId>\r\n\t\t\t<version>20.0</version>\r\n\t\t</dependency>\r\n\r\n\t\t<!-- Add slf4j API frontend binding with JUL backend -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.slf4j</groupId>\r\n\t\t\t<artifactId>slf4j-api</artifactId>\r\n\t\t\t<version>1.7.14</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.slf4j</groupId>\r\n\t\t\t<artifactId>slf4j-jdk14</artifactId>\r\n\t\t\t<version>1.7.14</version>\r\n\t\t\t<!-- When loaded at runtime this will wire up slf4j to the JUL backend -->\r\n\t\t\t<scope>runtime</scope>\r\n\t\t</dependency>\r\n\r\n\t\t<!-- Hamcrest and JUnit are required dependencies of PAssert, which is \r\n\t\t\tused in the main code of DebuggingWordCount example. -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.hamcrest</groupId>\r\n\t\t\t<artifactId>hamcrest-all</artifactId>\r\n\t\t\t<version>1.3</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>junit</groupId>\r\n\t\t\t<artifactId>junit</artifactId>\r\n\t\t\t<version>4.12</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-vision</artifactId>\r\n\t\t\t<version>1.26.0</version>\r\n\t\t</dependency>\r\n\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.apache.commons</groupId>\r\n\t\t\t<artifactId>commons-csv</artifactId>\r\n\t\t\t<version>RELEASE</version>\r\n\t\t</dependency>\r\n\t</dependencies>\r\n</project>\r\n\r\n\r\n\r\nAnd there are the errors (**ALL errors** disappear if I remove the **google-cloud-vision** dependency):\r\n\r\nThe project cannot be built until build path errors are resolved\tdataflow-celsa-iscrap\t\tUnknown\tJava Problem\r\nThe container 'Maven Dependencies' references non existing library '/Users/rafaelsanchez/.m2/repository/com/google/cloud/google-cloud-vision/1.26.0/google-cloud-vision-1.26.0.jar'\tdataflow-celsa-iscrap\t\tBuild path\tBuild Path Problem\r\nNo versions available for io.grpc:grpc-core:jar:[1.10.1] within specified range\r\n\r\norg.eclipse.aether.resolution.VersionRangeResolutionException: No versions available for io.grpc:grpc-core:jar:[1.10.1] within specified range\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.filterVersions(DefaultDependencyCollector.java:648)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:394)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.collectDependencies(DefaultDependencyCollector.java:254)\r\n\tat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies(DefaultRepositorySystem.java:316)\r\n\tat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve(DefaultProjectDependenciesResolver.java:172)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.resolveDependencies(DefaultProjectBuilder.java:215)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:188)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:119)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenImpl.readMavenProject(MavenImpl.java:636)\r\n\tat org.eclipse.m2e.core.internal.project.registry.DefaultMavenDependencyResolver.resolveProjectDependencies(DefaultMavenDependencyResolver.java:63)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refreshPhase2(ProjectRegistryManager.java:529)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:491)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:1)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:495)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:350)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:297)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder$BuildMethod.getProjectFacade(MavenBuilder.java:154)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder$BuildMethod$1.call(MavenBuilder.java:89)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:99)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder$BuildMethod.execute(MavenBuilder.java:86)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder.build(MavenBuilder.java:200)\r\n\tat org.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:734)\r\n\tat org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:205)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:245)\r\n\tat org.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:300)\r\n\tat org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:303)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:359)\r\n\tat org.eclipse.core.internal.events.BuildManager.build(BuildManager.java:382)\r\n\tat org.eclipse.core.internal.events.AutoBuildJob.doBuild(AutoBuildJob.java:144)\r\n\tat org.eclipse.core.internal.events.AutoBuildJob.run(AutoBuildJob.java:235)\r\n\tat org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)\r\n\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nNo versions available for io.grpc:grpc-core:jar:[1.10.1] within specified range\r\n\r\norg.eclipse.aether.resolution.VersionRangeResolutionException: No versions available for io.grpc:grpc-core:jar:[1.10.1] within specified range\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.filterVersions(DefaultDependencyCollector.java:648)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:394)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.collectDependencies(DefaultDependencyCollector.java:254)\r\n\tat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies(DefaultRepositorySystem.java:316)\r\n\tat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve(DefaultProjectDependenciesResolver.java:172)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.resolveDependencies(DefaultProjectBuilder.java:215)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:188)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:119)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenImpl.readMavenProject(MavenImpl.java:636)\r\n\tat org.eclipse.m2e.core.internal.project.registry.DefaultMavenDependencyResolver.resolveProjectDependencies(DefaultMavenDependencyResolver.java:63)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refreshPhase2(ProjectRegistryManager.java:529)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:491)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:1)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:495)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:350)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:297)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder$BuildMethod.getProjectFacade(MavenBuilder.java:154)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder$BuildMethod$1.call(MavenBuilder.java:89)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:99)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder$BuildMethod.execute(MavenBuilder.java:86)\r\n\tat org.eclipse.m2e.core.internal.builder.MavenBuilder.build(MavenBuilder.java:200)\r\n\tat org.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:734)\r\n\tat org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:205)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:245)\r\n\tat org.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:300)\r\n\tat org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:303)\r\n\tat org.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:359)\r\n\tat org.eclipse.core.internal.events.BuildManager.build(BuildManager.java:382)\r\n\tat org.eclipse.core.internal.events.AutoBuildJob.doBuild(AutoBuildJob.java:144)\r\n\tat org.eclipse.core.internal.events.AutoBuildJob.run(AutoBuildJob.java:235)\r\n\tat org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)\r\n\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.xerial.snappy:snappy-java:jar:1.1.4-M3\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.tukaani:xz:jar:1.5\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.threeten:threetenbp:jar:1.3.3\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.slf4j:slf4j-jdk14:jar:1.7.14\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.slf4j:slf4j-api:jar:1.7.14\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.hamcrest:hamcrest-core:jar:1.3\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.hamcrest:hamcrest-all:jar:1.3\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.codehaus.jackson:jackson-core-asl:jar:1.9.13\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.httpcomponents:httpcore:jar:4.0.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.httpcomponents:httpclient:jar:4.0.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.commons:commons-csv:jar:RELEASE\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.commons:commons-compress:jar:1.8.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.0.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.beam:beam-sdks-java-extensions-protobuf:jar:2.0.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:jar:2.0.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.beam:beam-sdks-java-core:jar:2.0.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.beam:beam-runners-direct-java:jar:2.0.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.avro:avro:jar:1.8.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact junit:junit:jar:4.12\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact joda-time:joda-time:jar:2.4\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-transport:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-resolver:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-handler:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-handler-proxy:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-common:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec-socks:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec-http2:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec-http:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-buffer:jar:4.1.8.Final\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-stub:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-protobuf:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-protobuf-nano:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-protobuf-lite:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-okhttp:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-netty:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-netty-shaded:jar:1.10.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-core:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-context:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-auth:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-all:jar:1.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact io.dropwizard.metrics:metrics-core:jar:3.1.2\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact commons-logging:commons-logging:jar:1.2\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact commons-codec:commons-codec:jar:1.3\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.thoughtworks.paranamer:paranamer:jar:2.7\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.squareup.okio:okio:jar:1.6.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.squareup.okhttp:okhttp:jar:2.5.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.protobuf:protobuf-java:jar:3.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.protobuf:protobuf-java-util:jar:3.2.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.oauth-client:google-oauth-client:jar:1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.oauth-client:google-oauth-client-java6:jar:1.20.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.instrumentation:instrumentation-api:jar:0.3.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.http-client:google-http-client:jar:1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.http-client:google-http-client-protobuf:jar:1.20.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.http-client:google-http-client-jackson2:jar:1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.http-client:google-http-client-jackson:jar:1.20.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.guava:guava:jar:20.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.errorprone:error_prone_annotations:jar:2.0.11\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.code.gson:gson:jar:2.7\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.code.findbugs:jsr305:jar:3.0.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud.datastore:datastore-v1-proto-client:jar:1.4.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud.bigtable:bigtable-protos:jar:0.9.6.2\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud.bigtable:bigtable-client-core:jar:0.9.6.2\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud.bigdataoss:util:jar:1.4.5\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud.bigdataoss:gcsio:jar:1.4.5\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud:google-cloud-vision:jar:1.26.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud:google-cloud-core:jar:1.26.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud:google-cloud-core-grpc:jar:1.26.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auto.value:auto-value:jar:1.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auth:google-auth-library-oauth2-http:jar:0.6.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auth:google-auth-library-credentials:jar:0.6.1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auth:google-auth-library-appengine:jar:0.6.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.appengine:appengine-api-1.0-sdk:jar:1.9.34\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.apis:google-api-services-storage:jar:v1-rev71-1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.apis:google-api-services-pubsub:jar:v1-rev10-1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.apis:google-api-services-cloudresourcemanager:jar:v1-rev6-1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.apis:google-api-services-bigquery:jar:v2-rev295-1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-iam-v1:jar:0.9.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-common-protos:jar:0.1.9\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-cloud-vision-v1p2beta1:jar:1.8.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-cloud-vision-v1p1beta1:jar:0.9.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-cloud-vision-v1:jar:1.8.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:grpc-google-pubsub-v1:jar:0.1.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:grpc-google-iam-v1:jar:0.1.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:grpc-google-common-protos:jar:0.1.9\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api:gax:jar:1.23.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api:gax-grpc:jar:1.23.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api:api-common:jar:1.0.0-rc1\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api-client:google-api-client:jar:1.22.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api-client:google-api-client-java6:jar:1.20.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api-client:google-api-client-jackson2:jar:1.20.0\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.fasterxml.jackson.core:jackson-databind:jar:2.8.8\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.fasterxml.jackson.core:jackson-core:jar:2.8.8\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\nMissing artifact com.fasterxml.jackson.core:jackson-annotations:jar:2.8.8\tpom.xml\t/dataflow-celsa-iscrap\tline 1\tMaven Dependency Problem\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3178",
        "number": 3178,
        "title": "BigQuery: Cannot list jobs when there has been an invalid job request",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "I recently ran an invalid job outside of the Java BigQuery client library, and when I try to list jobs when running the BigQuery samples tests with the Java client library, I get an error:\r\n\r\n```\r\nRunning com.google.cloud.examples.bigquery.snippets.ITBigQuerySnippets\r\nTests run: 15, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 162.203 sec <<< FAILURE! - in com.google.cloud.examples.bigquery.snippets.ITBigQuerySnippets\r\ntestJob(com.google.cloud.examples.bigquery.snippets.ITBigQuerySnippets)  Time elapsed: 1.602 sec  <<< ERROR!\r\njava.lang.IllegalArgumentException: value must be set if and only if the type is not ARRAY\r\n\tat com.google.cloud.examples.bigquery.snippets.ITBigQuerySnippets.testJob(ITBigQuerySnippets.java:273)\r\n```\r\n\r\nThis error comes from from the Java BigQuery client library when it attempts to build an invalid job ([error defined here](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/b7b3f21b784a3524f7830f34148abfd3e39677d4/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/QueryParameterValue.java#L116))\r\n\r\nThis issue is similar to one we fixed in [Python](https://github.com/GoogleCloudPlatform/google-cloud-python/issues/4246). The solution we used was to not validate Job objects as they are created from the API, which allowed invalid jobs from the API to be constructed into Job objects."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3175",
        "number": 3175,
        "title": "Publishing to pub/sub works unstable",
        "labels": [],
        "state": "closed",
        "body": "I am using exact example of publish message to pub/sub from https://cloud.google.com/pubsub/docs/publisher\r\n\r\nwith only one small modification \r\nmy loop looks like :   ` for (i in 1..1000000)` \r\nand the message has 16kb of text from Wikipedia\r\n\r\nIf loop is 1000 I see console output of ids (workds fine)\r\nbut with 10000 I already got error:\r\n\r\n```\r\nException in thread \"main\" java.util.concurrent.ExecutionException: com.google.api.gax.rpc.DeadlineExceededException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 9999958540ns\r\n\tat com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:500)\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:479)\r\n\tat com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:76)\r\n\tat com.google.common.util.concurrent.ForwardingFuture.get(ForwardingFuture.java:62)\r\n\tat TestRunKt.main(TestRun.kt:81)\r\nCaused by: com.google.api.gax.rpc.DeadlineExceededException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 9999958540ns\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:51)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:72)\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.create(GrpcApiExceptionFactory.java:60)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:95)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:61)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:492)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:467)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:391)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 9999958540ns\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 19 more\r\n\r\n```\r\n\r\nIf I decrease message size to 16 byte I can send successfully 10000 or 100 000 messages without any problems.\r\n\r\nCan you explain me the problem and help to find the solution. \r\n\r\nMy main goal is to send millions of messages with as said in spec not more then 10Mb size. \r\nThanks\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3172",
        "number": 3172,
        "title": "[Spanner] TransactionManager.close() not idempotent; API doc example is broken",
        "labels": [],
        "state": "closed",
        "body": "I am using the new `TransactionManager` API and am getting mysterious `\"rollback can only be called if the transaction is in progress\"` exceptions.\r\n\r\nI think I've tracked down the problem...\r\n\r\nThe API docs example shown with `DatabaseClient.transactionManager()` is this:\r\n```\r\n long singerId = my_singer_id;\r\n try (TransactionManager manager = dbClient.transactionManager()) {\r\n   TransactionContext txn = manager.begin();\r\n   while (true) {\r\n     String column = \"FirstName\";\r\n     Struct row = txn.readRow(\"Singers\", Key.of(singerId), Collections.singleton(column));\r\n     String name = row.getString(column);\r\n     txn.buffer(\r\n         Mutation.newUpdateBuilder(\"Singers\").set(column).to(name.toUpperCase()).build());\r\n     try {\r\n       manager.commit();\r\n       break;\r\n     } catch (AbortedException e) {\r\n       Thread.sleep(e.getRetryDelayInMillis() / 1000);\r\n       txn = manager.resetForRetry();\r\n     }\r\n   }\r\n }\r\n```\r\nHowever, this example usage is actually wrong.\r\n\r\nThe reason is that the implementation returned from `DatabaseClient.transactionManager()` is actually an `AutoClosingTransactionManager` (in `SessionPool.java`), which automatically `close()`s the transaction if `commit()` or `rollback()` is invoked. Sounds like a good idea, right?\r\n\r\nThe problem is that `AutoClosingTransactionManager.close()` is not idempotent:\r\n```\r\n    @Override\r\n    public void close() {\r\n      try {\r\n        delegate.close();\r\n      } finally {\r\n        session.close();\r\n      }\r\n    }\r\n```\r\nIf the transaction is closed twice, then the second time around the `session` is closed _again_, even though it has already been returned to the pool and possibly reassigned to another transaction. If so, this in turn causes that other transaction to fail on `commit()` with an exception `\"rollback can only be called if the transaction is in progress\"`.\r\n\r\nOne fix for this is to document that a `TransactionManager` must only be closed exactly once, and fix your API javadoc example accordingly.\r\n\r\nA much better and more robust fix would be to fix `AutoClosingTransactionManager.close()` to be idempotent. `TransactionManager` could then implement `Closeable` instead of `AutoCloseable` to denote this (if desired)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3170",
        "number": 3170,
        "title": "Stackdriver logging - setCredentials not working, getting \"PERMISSION_DENIED: The caller does not have permission\"",
        "labels": [
            "auth",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm trying to use setCredentials in LoggingBuilder, however if I supply my key.json file from code I'm getting PERMISSION_DENIED on my logging call.\r\n\r\nIf I instead populate the environment variable GOOGLE_APPLICATION_CREDENTIALS with the same /path/to/key.json it works.\r\n\r\n\r\nMy main method is:\r\n```\r\n\t\tLogging logging = LoggingOptions\r\n\t\t\t\t                  .newBuilder()\r\n\t\t\t\t                  .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(\"/path/to/key.json\")))\r\n\t\t\t\t                  .build()\r\n\t\t\t\t                  .getService();\r\n\r\n\t\tlogging.setWriteSynchronicity(Synchronicity.SYNC);\r\n\r\n\t\tlogging.setFlushSeverity(Severity.DEBUG);\r\n\r\n\t\tLogEntry entry = LogEntry\r\n\t\t\t\t                 .newBuilder(Payload.StringPayload.of(\"Hello world\"))\r\n\t\t\t\t                 .setSeverity(Severity.INFO)\r\n\t\t\t\t                 .setLogName(\"test-log\")\r\n\t\t\t\t                 .setResource(MonitoredResource\r\n\t\t\t\t\t\t                              .newBuilder(\"global\")\r\n\t\t\t\t\t\t                              .build())\r\n\t\t\t\t                 .build();\r\n\r\n\t\tlogging.write(Collections.singleton(entry)); // Throws PERMISSION_DENIED\r\n```\r\n\r\nMy only dependencies:\r\n```\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-logging</artifactId>\r\n\t\t\t<version>1.26.0</version>\r\n\t\t</dependency>\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3169",
        "number": 3169,
        "title": "[BigQuery] Allow to stream compressed data into BigQuery",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "How can I turn on compression in BigQuery's Java driver?\r\nI found here that the API supports gzip: https://cloud.google.com/bigquery/docs/api-performance\r\n\r\nI need it for my streaming inserts which have very high compression ratio:\r\nhttps://cloud.google.com/bigquery/streaming-data-into-bigquery#bigquery-stream-data-java"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3168",
        "number": 3168,
        "title": "Pub/Sub: When returnImmediatly is set to false in a PullRequest it sometimes ignores messages",
        "labels": [],
        "state": "closed",
        "body": "I use this snippet for implementing sync pulling:\r\nhttps://cloud.google.com/pubsub/docs/pull#synchronous-pull\r\n\r\nSometimes when there is a few minutes gap between messages, this snippet doesn't return `PullResponse` and hangs on the request call.\r\n\r\nI ended up doing something like this in the meantime which works perfectly but I don't like the implementation (scala):\r\n```scala\r\nFuture {\r\n        val pullRequest = PullRequest.newBuilder().setMaxMessages(1).setReturnImmediately(true)\r\n          .setSubscription(subscription.toString).build()\r\n        val pullResponse = subscriber.pullCallable().call(pullRequest)\r\n        pullResponse.getReceivedMessagesList.asScala\r\n      }.flatMap { list =>\r\n        if (list.isEmpty) {\r\n          Thread.sleep(10)\r\n          pull()\r\n        } else {\r\n          Future.successful(list.foreach(callback.invoke))\r\n        }\r\n      }\r\n``"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3167",
        "number": 3167,
        "title": "Accumulating io.grpc.netty....MpscArrayQueue objects using google-cloud-monitoring 0.40/0.41",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I'm not sure if this is a bug or not, but the behavior is strange and I'm not sure if it's me misusing a library but I have a Spring scheduled task that runs periodically on a GCE instance.\r\n\r\nWhen `google-cloud-monitoring` was added (version `0.40.0-beta` initially but later `0.41.0-beta`) we began making calls to write timeseries data.\r\n\r\nThis results in a large pile up over time of `io.grpc.netty.shaded.io.netty.util.internal.shaded.org.jctools.queues.MpscArrayQueue` objects and then eventually to an out of memory exception.\r\n\r\n<img width=\"1291\" alt=\"screen shot 2018-04-13 at 2 51 04 pm\" src=\"https://user-images.githubusercontent.com/31287795/38905263-69bd652e-4264-11e8-94c1-a9a10585feeb.png\">\r\n\r\n<img width=\"1060\" alt=\"screen shot 2018-04-13 at 2 37 22 pm\" src=\"https://user-images.githubusercontent.com/31287795/38905285-8b451fa2-4264-11e8-8ef1-0c5f5824b3f4.png\">\r\n\r\nThese objects also increase the presence/footprint of generic `java.lang.Object` instances which point to these queue objects.\r\n\r\n<img width=\"1054\" alt=\"screen shot 2018-04-17 at 5 28 59 pm\" src=\"https://user-images.githubusercontent.com/31287795/38905328-dee23834-4264-11e8-986e-74ec39c3797c.png\">\r\n\r\nWe also use Datastore in this project, but these objects do not show up if I remove the monitoring piece (even though I thought Datastore also used netty/grpc for communication.)\r\n\r\nThe relevant pom.xml is:\r\n\r\n```\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n            <exclusions>\r\n                <exclusion>\r\n                    <groupId>org.springframework.boot</groupId>\r\n                    <artifactId>spring-boot-starter-tomcat</artifactId>\r\n                </exclusion>\r\n            </exclusions>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-jetty</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter</artifactId>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.apache.thrift</groupId>\r\n            <artifactId>libthrift</artifactId>\r\n            <version>0.11.0</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-configuration-processor</artifactId>\r\n            <optional>true</optional>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.google.guava</groupId>\r\n            <artifactId>guava</artifactId>\r\n            <version>23.6-jre</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>io.netty</groupId>\r\n            <artifactId>netty-handler</artifactId>\r\n            <version>4.1.17.Final</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>io.netty</groupId>\r\n            <artifactId>netty-tcnative-boringssl-static</artifactId>\r\n            <version>2.0.7.Final</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.apache.commons</groupId>\r\n            <artifactId>commons-lang3</artifactId>\r\n            <version>3.5</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>commons-io</groupId>\r\n            <artifactId>commons-io</artifactId>\r\n            <version>2.5</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.akamai</groupId>\r\n            <artifactId>NetStorageKit</artifactId>\r\n            <version>3.6.6</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>org.jsoup</groupId>\r\n            <artifactId>jsoup</artifactId>\r\n            <version>1.11.2</version>\r\n        </dependency>\r\n\r\n        <!-- google cloud -->\r\n        <dependency>\r\n            <groupId>com.google.guava</groupId>\r\n            <artifactId>guava</artifactId>\r\n            <version>23.6-jre</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-datastore</artifactId>\r\n            <version>1.16.0</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-monitoring</artifactId>\r\n            <version>0.41.0-beta</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-logging</artifactId>\r\n            <version>1.17.0</version>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.google.apis</groupId>\r\n            <artifactId>google-api-services-cloudkms</artifactId>\r\n            <version>v1-rev26-1.23.0</version>\r\n            <exclusions>\r\n                <exclusion>\r\n                    <artifactId>guava-jdk5</artifactId>\r\n                    <groupId>com.google.guava</groupId>\r\n                </exclusion>\r\n            </exclusions>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-storage</artifactId>\r\n            <version>1.14.0</version>\r\n        </dependency>\r\n\r\n        <!-- end: google cloud -->\r\n\r\n        <!-- test dependencies -->\r\n        <dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-test</artifactId>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.12</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.mockito</groupId>\r\n            <artifactId>mockito-core</artifactId>\r\n            <version>2.15.0</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.truth</groupId>\r\n            <artifactId>truth</artifactId>\r\n            <version>0.39</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n        <!-- end test dependencies -->\r\n\r\n    </dependencies>\r\n```\r\n\r\nWe are using `java-1.8.0-openjdk.x86_64` on a Centos 7 build, deployed in GCE as a Docker container. (With `yum-plugin-ovl` installed to get around another Google monitoring issue.)\r\n\r\nThe code to write the timeseries data is:\r\n\r\n```java\r\n    /**\r\n     * Method to write a IMetricPoint to Stackdriver, does most of the driving for the class.\r\n     *\r\n     * @param metricPoint a metric type to write, defined as a constant on this class.\r\n     * @param labels a string map of metric labels\r\n     */\r\n    public void writePoint(IMetricPoint metricPoint, Map<String, String> labels) {\r\n        Metric metric = Metric.newBuilder()\r\n                .setType(String.format(\"custom.googleapis.com/%s\", metricPoint.getKey()))\r\n                .putAllLabels(labels)\r\n                .putLabels(ENVIRONMENT_LABEL, config.getEnvironment())\r\n                .build();\r\n\r\n        // Google recommends only one point per timeseries, or limiting writing more\r\n        // than one to only once a minute.\r\n        // https://cloud.google.com/monitoring/custom-metrics/creating-metrics#writing-ts\r\n        ArrayList<Point> pts = new ArrayList<>();\r\n        pts.add(metricPoint.getPoint());\r\n\r\n        MonitoredResource resource = getMonitoredResource();\r\n\r\n        // by default, a GAUGE metric.\r\n        TimeSeries timeSeries = TimeSeries.newBuilder()\r\n                .setMetric(metric)\r\n                .addAllPoints(pts)\r\n                .setResource(resource)\r\n                .build();\r\n\r\n        // We could accumulate these and just have a batch job send them, eventually.\r\n        ArrayList<TimeSeries> tsList = new ArrayList<>();\r\n        tsList.add(timeSeries);\r\n\r\n        CreateTimeSeriesRequest request = CreateTimeSeriesRequest.newBuilder()\r\n                .setName(String.format(\"projects/%s\", config.getProjectId()))\r\n                .addAllTimeSeries(tsList)\r\n                .build();\r\n\r\n        try {\r\n            MetricServiceClient client = MetricServiceClient.create();\r\n            client.createTimeSeries(request);\r\n\r\n        } catch (IOException | ApiException e) {\r\n            logError(\"Unable to write Stackdriver metric \"\r\n                    + metricPoint.getKey()\r\n                    + e.getMessage());\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Creates a resource type indicating where this metric was recorded.\r\n     *\r\n     * When deployed, a start up script should pull the GCE metadata and provide\r\n     * the zone and instance_id as environmental variables. Otherwise, we just put\r\n     * the metrics in the global zone (e.g. when running from a development box.)\r\n     *\r\n     * We cannot say our resource is a \"laptop\" but note that when we write a point out,\r\n     * we add the label \"environment\" in `writePoint` which is gotten from config and\r\n     * will read \"dev\" so we won't just have global metrics floating about we can't find\r\n     * the origin for.\r\n     *\r\n     * @return a resource\r\n     */\r\n    private MonitoredResource getMonitoredResource() {\r\n        String instanceId = this.systemConfig.getenv(SystemConfig.ENV_GCE_INSTANCE_ID).orElse(\"\");\r\n        String zone = this.systemConfig.getenv(SystemConfig.ENV_GCE_ZONE).orElse(\"\");\r\n\r\n        if (!instanceId.isEmpty() && !zone.isEmpty()) {\r\n            return MonitoredResource.newBuilder()\r\n                    .setType(GCE_RESOURCE_TYPE)\r\n                    .putLabels(INSTANCE_ID_LABEL, instanceId)\r\n                    .putLabels(ZONE_LABEL, zone)\r\n                    .build();\r\n        } else {\r\n            return MonitoredResource.newBuilder()\r\n                    .setType(GLOBAL_RESOURCE_TYPE)\r\n                    .build();\r\n        }\r\n    }\r\n\r\n```\r\n\r\nIn this case `config` is simply a Spring component that can be auto wired in with some environmental config data and `systemConfig` is just a functional wrapper around `System.getenv`.\r\n\r\nI have also called this code without the auto-wiring and I still see these objects created.\r\n\r\nAny pointers would be great, hoping this is just misuse of the library somehow."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3164",
        "number": 3164,
        "title": "IAM is not included in google-cloud-java project?",
        "labels": [
            "iam",
            "type: feature request"
        ],
        "state": "open",
        "body": "I was wondering whether google-cloud-java  includes IAM service as I found out that it is provided separated from this project based on https://developers.google.com/api-client-library/java/apis/iam/v1. I think it will be helpful for user to have centralized project for all of the services"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3157",
        "number": 3157,
        "title": "com.google.cloud.Date has no interop w/ java.util.Date",
        "labels": [
            "api: core",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It's very hard to convert c.g.c.Date to j.u.Date. Can c.g.c.Date add something similar to `toDate`, `fromDate` method?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3156",
        "number": 3156,
        "title": "Spanner: javadoc error",
        "labels": [],
        "state": "closed",
        "body": "Generating spanner javadoc throws following error. It seems a code block with `@Override` is not correctly parsed.\r\n\r\n[ERROR] .../github/google-cloud-java/google-cloud-spanner/src/main/java/com/google/cloud/spanner/DatabaseClient.java:241: error: unterminated inline tag\r\n[ERROR]    * <pre> {@code\r\n[ERROR]            ^\r\n[ERROR].../github/google-cloud-java/google-cloud-spanner/src/main/java/com/google/cloud/spanner/DatabaseClient.java:247: error: unknown tag: Override\r\n[ERROR]    *       @Override\r\n[ERROR]            ^"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3155",
        "number": 3155,
        "title": "Add circle job to generate javadocs",
        "labels": [
            "priority: p1"
        ],
        "state": "closed",
        "body": "So that we don't have releases blocked all the time by silly mistakes. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3152",
        "number": 3152,
        "title": "Pub/Sub: messages stuck in buffer, preventing proper load balancing",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "Repro:\r\n1. Publish 60 messages, with numbers 1 through 6 as message content.  Observe the total backlog for a subscription reach 60 messages and 23 bytes. \r\n2. Start an instance of a subscriber client, with a single-threaded executor and FlowControl set to 1 message per buffer (see code below).  The subscriber takes 10 second to process each message.\r\n3. Observe that the subscriber processes messages, one at a time, every 10 seconds (see log output below)\r\n4. *The bug*: Start two new instances of the same subscriber client, roughly a minute later.   Observe: *they process no messages.*  Expected behavior: the two subscribers immediately start processing messages.   \r\n5.  Stop the first subscriber client.  Observe: the next two subscriber clients start processing messages.  \r\n\r\nThe hypothesis here is that the entire backlog is stuck in the gRPC and other buffers, between the server and the client.  So the server thinks the messages are out and being processed, while the client code can't really see the messages. When new clients connect, the server does not have anything to send them. Killing the original client effectively \"nacks\" the messages in the buffer, by sending a stream close signal to the server. This allows the server to start sending messages to the other clients.\r\n\r\n```java\r\nimport com.google.api.gax.batching.FlowControlSettings;\r\nimport com.google.api.gax.core.InstantiatingExecutorProvider;\r\nimport com.google.cloud.pubsub.v1.AckReplyConsumer;\r\nimport com.google.cloud.pubsub.v1.MessageReceiver;\r\nimport com.google.cloud.pubsub.v1.Subscriber;\r\nimport com.google.pubsub.v1.ProjectSubscriptionName;\r\nimport com.google.pubsub.v1.PubsubMessage;\r\nimport org.threeten.bp.ZonedDateTime;\r\nimport org.threeten.bp.format.DateTimeFormatter;\r\n\r\nimport java.util.concurrent.TimeUnit;\r\nimport java.util.concurrent.atomic.AtomicInteger;\r\n\r\npublic class Sub{\r\n\r\n    private static AtomicInteger messageCounter = new AtomicInteger(0);\r\n    private static String appInstanceId = ZonedDateTime.now().format(DateTimeFormatter.ofPattern(\"HHmmss\"));\r\n\r\n    static class MessageHandler implements MessageReceiver {\r\n\r\n        @Override\r\n        public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n            try {\r\n                TimeUnit.SECONDS.sleep(10);\r\n                System.out.println(\r\n                        ZonedDateTime.now().format(DateTimeFormatter.ofPattern(\"HH:mm:ss\")) + \",\\t\"\r\n                        + \"App instance id\" + appInstanceId\r\n                        + \",\\tProcessing id: \" + messageCounter.incrementAndGet()\r\n                        + \",\\tmessage content:\" + message.getData().toStringUtf8()\r\n                );\r\n                consumer.ack();\r\n            }\r\n            catch (InterruptedException e){\r\n                consumer.nack();\r\n            }\r\n        }\r\n    }\r\n\r\n    /** Receive messages over a subscription. */\r\n    public static void main(String... args) throws Exception {\r\n        // set subscriber id, eg. my-sub\r\n        String projectId = args[0];\r\n        String subscriptionId = args[1];\r\n        ProjectSubscriptionName subscriptionName = ProjectSubscriptionName.of( projectId, subscriptionId);\r\n        Subscriber subscriber = null;\r\n        try {\r\n            // we create a single threaded subscriber with the most restrictive flow control setting:\r\n            subscriber =\r\n                    Subscriber.newBuilder(subscriptionName, new MessageHandler())\r\n                            .setFlowControlSettings(FlowControlSettings.newBuilder().setMaxOutstandingElementCount(1L).build())\r\n                            .setExecutorProvider(InstantiatingExecutorProvider.newBuilder().setExecutorThreadCount(1).build())\r\n                            .build();\r\n            subscriber.startAsync().awaitTerminated();\r\n        } finally {\r\n            if (subscriber != null) {\r\n                subscriber.stopAsync();\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n```xml\r\n    <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-pubsub</artifactId>\r\n        <version>0.42.1-beta</version>\r\n    </dependency>\r\n```\r\n<pre>\r\nLogs\r\n# start first client at 17:00:34\r\n17:00:47,\tApp instance id170034,\tProcessing id: 1,\tmessage content:1\r\n17:00:57,\tApp instance id170034,\tProcessing id: 2,\tmessage content:5\r\n17:01:07,\tApp instance id170034,\tProcessing id: 3,\tmessage content:9\r\n17:01:17,\tApp instance id170034,\tProcessing id: 4,\tmessage content:4\r\n17:01:27,\tApp instance id170034,\tProcessing id: 5,\tmessage content:8\r\n17:01:37,\tApp instance id170034,\tProcessing id: 6,\tmessage content:3\r\n17:01:47,\tApp instance id170034,\tProcessing id: 7,\tmessage content:7\r\n17:01:57,\tApp instance id170034,\tProcessing id: 8,\tmessage content:2\r\n17:02:07,\tApp instance id170034,\tProcessing id: 9,\tmessage content:6\r\n17:02:17,\tApp instance id170034,\tProcessing id: 10,\tmessage content:13\r\n17:02:27,\tApp instance id170034,\tProcessing id: 11,\tmessage content:17\r\n17:02:37,\tApp instance id170034,\tProcessing id: 12,\tmessage content:12\r\n17:02:47,\tApp instance id170034,\tProcessing id: 13,\tmessage content:16\r\n17:02:57,\tApp instance id170034,\tProcessing id: 14,\tmessage content:11\r\n17:03:07,\tApp instance id170034,\tProcessing id: 15,\tmessage content:15\r\n17:03:17,\tApp instance id170034,\tProcessing id: 16,\tmessage content:10\r\n17:03:27,\tApp instance id170034,\tProcessing id: 17,\tmessage content:14\r\n17:03:37,\tApp instance id170034,\tProcessing id: 18,\tmessage content:22\r\n\r\n# start second and third clients around here: they generate no logs\r\n\r\n17:03:47,\tApp instance id170034,\tProcessing id: 19,\tmessage content:26\r\n17:03:57,\tApp instance id170034,\tProcessing id: 20,\tmessage content:21\r\n17:04:07,\tApp instance id170034,\tProcessing id: 21,\tmessage content:25\r\n17:04:17,\tApp instance id170034,\tProcessing id: 22,\tmessage content:19\r\n# kill first client\r\n\r\nProcess finished with exit code 130 (interrupted by signal 2: SIGINT)\r\n# second client logs (note they start \"10 seconds\" after the first client is killed\r\n17:04:35,\tApp instance id170328,\tProcessing id: 1,\tmessage content:39\r\n17:04:45,\tApp instance id170328,\tProcessing id: 2,\tmessage content:47\r\n17:04:55,\tApp instance id170328,\tProcessing id: 3,\tmessage content:20\r\n17:05:05,\tApp instance id170328,\tProcessing id: 4,\tmessage content:40\r\n17:05:15,\tApp instance id170328,\tProcessing id: 5,\tmessage content:38\r\n17:05:25,\tApp instance id170328,\tProcessing id: 6,\tmessage content:46\r\n17:05:35,\tApp instance id170328,\tProcessing id: 7,\tmessage content:27\r\n17:05:45,\tApp instance id170328,\tProcessing id: 8,\tmessage content:42\r\n17:05:55,\tApp instance id170328,\tProcessing id: 9,\tmessage content:55\r\n17:06:05,\tApp instance id170328,\tProcessing id: 10,\tmessage content:48\r\n17:06:15,\tApp instance id170328,\tProcessing id: 11,\tmessage content:56\r\n17:06:25,\tApp instance id170328,\tProcessing id: 12,\tmessage content:54\r\n17:06:35,\tApp instance id170328,\tProcessing id: 13,\tmessage content:49\r\n17:06:45,\tApp instance id170328,\tProcessing id: 14,\tmessage content:57\r\n17:07:39,\tApp instance id170328,\tProcessing id: 15,\tmessage content:18\r\n17:07:49,\tApp instance id170328,\tProcessing id: 16,\tmessage content:23\r\n17:08:19,\tApp instance id170328,\tProcessing id: 17,\tmessage content:30\r\n17:08:29,\tApp instance id170328,\tProcessing id: 18,\tmessage content:34\r\n17:09:39,\tApp instance id170328,\tProcessing id: 19,\tmessage content:32\r\n\r\n# third client logs (note they start \"10 seconds\" after the first client is killed\r\n17:04:35,\tApp instance id170328,\tProcessing id: 1,\tmessage content:39\r\n17:04:45,\tApp instance id170328,\tProcessing id: 2,\tmessage content:47\r\n17:04:55,\tApp instance id170328,\tProcessing id: 3,\tmessage content:20\r\n17:05:05,\tApp instance id170328,\tProcessing id: 4,\tmessage content:40\r\n17:05:15,\tApp instance id170328,\tProcessing id: 5,\tmessage content:38\r\n17:05:25,\tApp instance id170328,\tProcessing id: 6,\tmessage content:46\r\n17:05:35,\tApp instance id170328,\tProcessing id: 7,\tmessage content:27\r\n17:05:45,\tApp instance id170328,\tProcessing id: 8,\tmessage content:42\r\n17:05:55,\tApp instance id170328,\tProcessing id: 9,\tmessage content:55\r\n17:06:05,\tApp instance id170328,\tProcessing id: 10,\tmessage content:48\r\n17:06:15,\tApp instance id170328,\tProcessing id: 11,\tmessage content:56\r\n17:06:25,\tApp instance id170328,\tProcessing id: 12,\tmessage content:54\r\n17:06:35,\tApp instance id170328,\tProcessing id: 13,\tmessage content:49\r\n17:06:45,\tApp instance id170328,\tProcessing id: 14,\tmessage content:57\r\n17:07:39,\tApp instance id170328,\tProcessing id: 15,\tmessage content:18\r\n17:07:49,\tApp instance id170328,\tProcessing id: 16,\tmessage content:23\r\n17:08:19,\tApp instance id170328,\tProcessing id: 17,\tmessage content:30\r\n17:08:29,\tApp instance id170328,\tProcessing id: 18,\tmessage content:34\r\n17:09:39,\tApp instance id170328,\tProcessing id: 19,\tmessage content:32\r\n</pre>"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3150",
        "number": 3150,
        "title": "Mysterious \"Repeated record added outside of an array\" error when inserting BigQuery records including Clojure/Scala Lists",
        "labels": [],
        "state": "closed",
        "body": "Oops! Pressed RET to fast. Sorry, I'm writing up a description!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3149",
        "number": 3149,
        "title": "Performance tests in pub/sub show that the publisher is using 50-100x more CPU than subscriber",
        "labels": [
            "api: pubsub",
            "performance",
            "type: question"
        ],
        "state": "closed",
        "body": "I've been running performance tests with Pub/Sub trying to find the right combination of threads, memory, buffer sizes, etc..  I'm seeing that the Publisher taking ~500% CPU versus 5-8% for the Subscriber running on the same server, simultaneously handling the same message throughput.  Does that surprise anyone?  In looking at the running threads I see that a number of them have the following stack trace in the RSA/SSHA256 JWT signing code.  I suspect that this is to a large degree the real limitation of the Publisher's performance.\r\n\r\nAnyone else seeing this?  Any recommendations on how to work around this?  Is there something I can do to the transport layer turn off these or reduce their usage?  Maybe GPRC configuration tweaks?\r\n\r\nThanks.  This is using v0.38 on a Linux box running Java 7 outside of google's cloud.  Would running on Google's computer engine instances?\r\n\r\n```\r\nBigInteger.oddModPow(BigInteger.java:2716) \r\njava.math.BigInteger.modPow(BigInteger.java:2459) \r\nsun.security.rsa.RSACore.crtCrypt(RSACore.java:183) \r\nsun.security.rsa.RSACore.rsa(RSACore.java:122) \r\nsun.security.rsa.RSASignature.engineSign(RSASignature.java:175) \r\njava.security.Signature$Delegate.engineSign(Signature.java:1207) \r\njava.security.Signature.sign(Signature.java:579) \r\ncom.google.api.client.util.SecurityUtils.sign(SecurityUtils.java:147) \r\ncom.google.api.client.json.webtoken.JsonWebSignature.signUsingRsaSha256(JsonWebSignature.java:637) \r\ncom.google.auth.oauth2.ServiceAccountJwtAccessCredentials.getJwtAccess(ServiceAccountJwtAccessCredentials.java:300) \r\ncom.google.auth.oauth2.ServiceAccountJwtAccessCredentials.getRequestMetadata(ServiceAccountJwtAccessCredentials.java:267) \r\ncom.google.auth.Credentials.blockingGetToCallback(Credentials.java:103) \r\ncom.google.auth.oauth2.ServiceAccountJwtAccessCredentials.getRequestMetadata(ServiceAccountJwtAccessCredentials.java:251) \r\nio.grpc.auth.GoogleAuthLibraryCallCredentials.applyRequestMetadata(GoogleAuthLibraryCallCredentials.java:90) \r\nio.grpc.internal.CallCredentialsApplyingTransportFactory$CallCredentialsApplyingTransport.newStream(CallCredentialsApplyingTransportFactory.java:91) \r\nio.grpc.internal.ClientCallImpl.start(ClientCallImpl.java:242) \r\nio.grpc.internal.CensusTracingModule$TracingClientInterceptor$1.start(CensusTracingModule.java:387) \r\nio.grpc.internal.CensusStatsModule$StatsClientInterceptor$1.start(CensusStatsModule.java:679) \r\nio.grpc.ForwardingClientCall.start(ForwardingClientCall.java:32) \r\ncom.google.api.gax.grpc.GrpcHeaderInterceptor$1.start(GrpcHeaderInterceptor.java:95) \r\nio.grpc.stub.ClientCalls.startCall(ClientCalls.java:293) \r\nio.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:268) \r\nio.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:177) \r\ncom.google.pubsub.v1.PublisherGrpc$PublisherFutureStub.publish(PublisherGrpc.java:538) \r\ncom.google.cloud.pubsub.v1.Publisher.publishOutstandingBatch(Publisher.java:333) \r\ncom.google.cloud.pubsub.v1.Publisher.access$000(Publisher.java:90) \r\ncom.google.cloud.pubsub.v1.Publisher$1.run(Publisher.java:255) \r\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) \r\njava.util.concurrent.FutureTask.run(FutureTask.java:266) \r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) \r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) \r\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) \r\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) \r\njava.lang.Thread.run(Thread.java:745) \r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3146",
        "number": 3146,
        "title": "Pub/Sub: Mitigate message duplication to due stuck stream-close signal",
        "labels": [],
        "state": "closed",
        "body": "As documented offline, Pub/Sub streamingPull may result in a high duplicate rate because the server terminates a streamingPull connection by sending a signal down the stream. This signal is delivered to the client after the messages already in the stream buffer are processed. As a result, the client may send acks and modifyAckDeadline's up a stream that has already been broken, leading to their loss.\r\n\r\nTo close this bug:\r\n- Agree on a mitigation strategy. Currently, it is to send acks and modifyAckDeadline's as separate requests (synchronous or streaming?)\r\n- Implement in Java.\r\n- Validate that the implementation does not lead to performance degradation or extreme delays in ack and modAck delivery to the server, which would again lead to high rate of duplication.\r\n- Reproduce in other clients. \r\n\r\nThis is GA launch blocking.  "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3145",
        "number": 3145,
        "title": "google-cloud-pubsub 0.21.0-beta: `RejectedExecutionException` when publishing new messages",
        "labels": [],
        "state": "closed",
        "body": "We're seeing exceptions from `com.google.cloud.pubsub.v1.Publisher.publish` when trying to publish many messages quickly.\r\n\r\n```\r\nCritical error in message receiver java.util.concurrent.RejectedExecutionException:\r\nTask java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3dca33bb rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7977292c[Terminated, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 11555] at \r\njava.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) at \r\njava.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533) at \r\njava.util.concurrent.Executors$DelegatedScheduledExecutorService.schedule(Executors.java:729) at \r\ncom.google.cloud.pubsub.v1.Publisher.setupDurationBasedPublishAlarm(Publisher.java:277) at \r\ncom.google.cloud.pubsub.v1.Publisher.publish(Publisher.java:229) at \r\ncom.cognite.purgatory.services.PipelineService.pushMessagesWithExplicitPipelineId(PipelineService.java:209) at \r\ncom.cognite.purgatory.services.PipelineService.notifyPipelines(PipelineService.java:174) at \r\ncom.cognite.purgatory.services.PipelineService.process(PipelineService.java:106) at \r\ncom.cognite.purgatory.handlers.PurgatoryJobHandler.handleV1(PurgatoryJobHandler.java:25) at \r\ncom.cognite.purgatory.handlers.PurgatoryJobHandler.handle(PurgatoryJobHandler.java:19) at \r\ncom.cognite.purgatory.App.lambda$setUpListener$0(App.java:94) at \r\ncom.cognite.pubsub.PubsubListener.handleMessage(PubsubListener.java:108) at \r\ncom.cognite.pubsub.PubsubListener.lambda$getMessageReceiver$0(PubsubListener.java:90) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher$2.run(MessageDispatcher.java:409) at \r\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at \r\njava.util.concurrent.FutureTask.run(FutureTask.java:266) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at \r\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at \r\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at \r\njava.lang.Thread.run(Thread.java:748)\r\n```\r\nwhich I believe comes from:\r\n```\r\nAn exception was thrown by io.grpc.netty.NettyClientHandler$3.operationComplete() java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@15477b52 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7977292c[Shutting down, pool size = 19, active threads = 0, queued tasks = 0, completed tasks = 11555] at \r\njava.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) at \r\njava.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.execute(ScheduledThreadPoolExecutor.java:622) at \r\njava.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668) at \r\nio.grpc.internal.SerializingExecutor.schedule(SerializingExecutor.java:77) at \r\nio.grpc.internal.SerializingExecutor.execute(SerializingExecutor.java:70) at \r\nio.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.onReady(ClientCallImpl.java:584) at \r\nio.grpc.internal.DelayedStream$DelayedStreamListener.onReady(DelayedStream.java:392) at \r\nio.grpc.internal.AbstractStream$TransportState.notifyIfReady(AbstractStream.java:282) at \r\nio.grpc.internal.AbstractStream$TransportState.onStreamAllocated(AbstractStream.java:225) at \r\nio.grpc.netty.NettyClientStream$TransportState.setHttp2Stream(NettyClientStream.java:232) at \r\nio.grpc.netty.NettyClientHandler$3.operationComplete(NettyClientHandler.java:469) at \r\nio.grpc.netty.NettyClientHandler$3.operationComplete(NettyClientHandler.java:457) at \r\nio.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507) at \r\nio.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481) at \r\nio.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420) at \r\nio.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) at \r\nio.netty.handler.codec.http2.Http2CodecUtil$SimpleChannelPromiseAggregator.tryPromise(Http2CodecUtil.java:389) at \r\nio.netty.handler.codec.http2.Http2CodecUtil$SimpleChannelPromiseAggregator.trySuccess(Http2CodecUtil.java:355) at \r\nio.netty.handler.codec.http2.Http2CodecUtil$SimpleChannelPromiseAggregator.trySuccess(Http2CodecUtil.java:267) at io.netty.util.internal.PromiseNotificationUtil.trySuccess(PromiseNotificationUtil.java:48) at \r\nio.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:52) at \r\nio.netty.channel.DelegatingChannelPromiseNotifier.operationComplete(DelegatingChannelPromiseNotifier.java:31) at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507) at \r\nio.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500) at \r\nio.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479) at \r\nio.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420) at \r\nio.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) at \r\nio.netty.util.internal.PromiseNotificationUtil.trySuccess(PromiseNotificationUtil.java:48) at \r\nio.netty.channel.ChannelOutboundBuffer.safeSuccess(ChannelOutboundBuffer.java:673) at \r\nio.netty.channel.ChannelOutboundBuffer.remove(ChannelOutboundBuffer.java:257) at \r\nio.netty.channel.ChannelOutboundBuffer.removeBytes(ChannelOutboundBuffer.java:337) at \r\nio.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:419) at \r\nio.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:934) at \r\nio.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:362) at \r\nio.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:901) at \r\nio.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1321) at \r\nio.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) at \r\nio.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768) at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749) at \r\nio.netty.handler.ssl.SslHandler.forceFlush(SslHandler.java:1667) at \r\nio.netty.handler.ssl.SslHandler.wrapAndFlush(SslHandler.java:735) at \r\nio.netty.handler.ssl.SslHandler.flush(SslHandler.java:712) at \r\nio.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) at \r\nio.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768) at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749) at \r\nio.netty.handler.codec.http2.Http2ConnectionHandler.flush(Http2ConnectionHandler.java:201) at \r\nio.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776) at \r\nio.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768) at \r\nio.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749) at \r\nio.netty.channel.DefaultChannelPipeline.flush(DefaultChannelPipeline.java:983) at \r\nio.netty.channel.AbstractChannel.flush(AbstractChannel.java:248) at \r\nio.grpc.netty.WriteQueue.flush(WriteQueue.java:136) at \r\nio.grpc.netty.WriteQueue.access$000(WriteQueue.java:32) at \r\nio.grpc.netty.WriteQueue$1.run(WriteQueue.java:44) at \r\nio.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) at \r\nio.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403) at \r\nio.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463) at \r\nio.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at \r\nio.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138) at \r\njava.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nIn addition, we're also seeing this one:\r\n```\r\nRuntimeException while executing runnable com.google.common.util.concurrent.Futures$4@340c6ca9 with executor MoreExecutors.directExecutor() java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@658bcc5e rejected from java.util.concurrent.ScheduledThreadPoolExecutor@61667ce5[Shutting down, pool size = 6, active threads = 1, queued tasks = 40, completed tasks = 1217] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533) at \r\njava.util.concurrent.Executors$DelegatedScheduledExecutorService.schedule(Executors.java:729) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher.setupPendingAcksAlarm(MessageDispatcher.java:426) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher.access$500(MessageDispatcher.java:55) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher$AckHandler.onSuccess(MessageDispatcher.java:223) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher$AckHandler.onSuccess(MessageDispatcher.java:172) at \r\ncom.google.common.util.concurrent.Futures$4.run(Futures.java:1135) at \r\ncom.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399) at \r\ncom.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:902) at \r\ncom.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:813) at \r\ncom.google.common.util.concurrent.AbstractFuture.set(AbstractFuture.java:655) at \r\ncom.google.common.util.concurrent.SettableFuture.set(SettableFuture.java:48) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher$1.nack(MessageDispatcher.java:400) at \r\ncom.cognite.pubsub.PubsubListener.lambda$getMessageReceiver$0(PubsubListener.java:95) at \r\ncom.google.cloud.pubsub.v1.MessageDispatcher$2.run(MessageDispatcher.java:409) at \r\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at \r\njava.util.concurrent.FutureTask.run(FutureTask.java:266) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at \r\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at \r\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at \r\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nI just realized that version `0.43.0-beta` is out, but the code dealing with executorprovider doesn't look to be changed since `0.21.0-beta`. Is the right solution here just to provide our own `ExecutorProvider` with a higher thread count?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3141",
        "number": 3141,
        "title": "Bigtable: Admin should have proto utility methods",
        "labels": [
            "api: bigtable",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "There are some complex protobuf objects.  Here are some possibilities where utilities might come in handy:\r\n\r\n- any message with \"oneof\" gets confusjng, since users set multiple values (`AppProfile`, `DropRowRangeRequest`, `ModifyColumnFamiliesRequest`)\r\n- `Instance` messages are complex\r\n- `PartialUpdateInstanceRequest` use `google.protobuf.FieldMask` which is quite confusing\r\n- `CheckConsistency` is used for for polling, so it's ideal having a utility for this kind of functionality\r\n- \"TableExists\" type functionality should use ListTables instead of GetTable, since it's less expensive.  Users should have a clear API that produces the most efficient calls."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3140",
        "number": 3140,
        "title": "should be able to change hostname of generated URL",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We are facing google storage access issue in China. We have a kind of proxy controller at our CDN (Fastly) which will serve files from google storage to avoid Chinese blockage of Google hostnames. \r\nSo I need CDN's host in resource URL instead of `storage.googleapis.com`. I checked code and found it is currently hardcoded in `StorageImpl.signUrl(...)`. So it would be good if it is possible to configure it.\r\nCurrently, URL looks like: https://storage.googleapis.com/<bucket>/<file_path>?GoogleAccessId=accessID\r\nAnd I want something like: https://my.custom.host.com/<bucket>/<file_path>?GoogleAccessId=accessID"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3137",
        "number": 3137,
        "title": "Allow adding google credentials through logback appender code or xml configuration",
        "labels": [],
        "state": "closed",
        "body": "Any reason why the only option to inject credentials to google-cloud-logging-logback is through the GOOGLE_APPLICATION_CREDENTIALS environment variable?\r\nAny option to add it to the appender configuration file or code?\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3136",
        "number": 3136,
        "title": "Fix ITStorageTest credentials",
        "labels": [
            ":rotating_light:",
            "api: storage",
            "priority: p2"
        ],
        "state": "closed",
        "body": "When a user runs `ITStorageTest.testGetServiceAccount()`, they fail with the message \r\n```\r\nITStorageTest.testGetServiceAccount:1678 expected:<[gcloud-devel]@gs-project-accounts...>\r\n  but was:<[REDACTED]@gs-project-accounts...>\r\n```\r\n\r\nDeliverables:\r\n1. Remove the `gcloud-devel` hardcoded project value from the test file. \r\n2. Project ID needs to be configurable for this test, perhaps via [GOOGLE_APPLICATION_CREDENTIALS](https://cloud.google.com/docs/authentication/production)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3135",
        "number": 3135,
        "title": "PubSub : Internal Error while creating subscription",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I keep getting this intermittently while creating subscriptions\r\n```\r\nCaused by: com.google.api.gax.rpc.InternalException: io.grpc.StatusRuntimeException: INTERNAL: A service error has occurred. Please retry your request. If the error persists, please report it. [code=e8c0]\r\nat com.google.api.gax.grpc.GrpcApiExceptionFactory.createException(GrpcApiExceptionFactory.java:88)\r\nat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:112)\r\nat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:53)\r\nat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\nat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\nat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\nat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\nat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\nat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:458)\r\nat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:433)\r\nat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\nat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\nat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\nat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n```\r\n\r\nThe code is as follows (exception handling etc omitted)\r\n\r\n```\r\nSubscriptionName sName = SubscriptionName.create(projectId, finalSubName);\r\nSubscriptionAdminClient subscriptionAdminClient = SubscriptionAdminClient.create()\r\nsubscriptionAdminClient.createSubscription(sName, topicName, PushConfig.getDefaultInstance(), 10 * 60)\r\n```\r\nI am using pull subscribers.\r\n\r\nPubSub library version in use is 0.26.0-beta . I am unable to try this with a newer version of pubsub due to dependency conflicts with the bigtable-hbase-1.x library which is used in the same application.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3134",
        "number": 3134,
        "title": "Pub/Sub Subscriber.stopAsync() is not asynchronous",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "The javadocs for `Subscriber.stopAsync()` (really from `AbstractApiService`) read:\r\n\r\n> ... this initiates a service shutdown and returns immediately.\r\n\r\nThis does not seem to be how it is implemented in Pub/Sub.  The `doStop()` calls into the `MessageDispatcher.stop()` then into the `MessageWaiter.waitNoMessages()`, etc..\r\n\r\nMaybe the method name needs to be changed or the functionality updated?  What I've had to do outside is to fork a thread that calls `stopAsync()`, dequeue messages from the receiver queues in other thread(s) so they can be nack'd in a ~spin loop, notice when the `subscriber.state()` gets to TERMINATED, and then join with the stopping thread.\r\n\r\nA simple way to test this is to receive a message, don't ack or nack it reply-consumer, and the call `stopAsync()`.\r\n\r\nMaybe I am missing a configuration option or something?  Thanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3133",
        "number": 3133,
        "title": "Publish javadocs to maven central",
        "labels": [
            "type: docs"
        ],
        "state": "closed",
        "body": "Javadocs are published to [http://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/](http://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/) but not to\r\n[http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22com.google.appengine%22%20AND%20a%3A%22appengine-api-1.0-sdk%22](http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22com.google.appengine%22%20AND%20a%3A%22appengine-api-1.0-sdk%22). Why is that? This can easily be configured by\r\n```xml\r\n<plugin>\r\n        <groupId>org.apache.maven.plugins</groupId>\r\n                        <artifactId>maven-javadoc-plugin</artifactId>\r\n                        <version>2.7</version>\r\n                        <executions>\r\n                            <execution>\r\n                                <id>attach-javadocs</id>\r\n                                <goals>\r\n                                    <goal>jar</goal>\r\n                                </goals>\r\n                            </execution>\r\n                        </executions>\r\n</plugin>\r\n```\r\nWhich it is by default if you use\r\n```xml\r\n\t<parent>\r\n\t\t<groupId>org.sonatype.oss</groupId>\r\n\t\t<artifactId>oss-parent</artifactId>\r\n\t\t<version>9</version>\r\n\t</parent>\r\n``` \r\nin the root pom. I can see that you have a \"release\" profile that should enable this. Was that profile not used during the release?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3126",
        "number": 3126,
        "title": "bigquery: allow specifying job id when calling write()",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "From #3121"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3125",
        "number": 3125,
        "title": "Remove coverage analysis from release process",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "Prefer moving coverage analysis to a nightly build or something of the like. Currently coverage analysis makes the release process take a long time.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3124",
        "number": 3124,
        "title": "Reduce size of gh-pages",
        "labels": [
            "type: process"
        ],
        "state": "open",
        "body": "Probably just retain latest/ instead of every single version every generated."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3122",
        "number": 3122,
        "title": "Bigquery com.google.api.gax.retrying.PollException",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "I have an App Engine Standard project, which is performing query jobs on BigQuery\r\n\r\nThis is the library version\r\n```\r\n<dependency>\r\n    <groupId>com.google.cloud</groupId>\r\n    <artifactId>google-cloud-bigquery</artifactId>\r\n    <version>1.24.0</version>\r\n</dependency>\r\n```\r\n\r\nThis is the code\r\n```\r\nRetryOption retryOption = RetryOption.totalTimeout(Duration.ofMillis(60000));\r\nJob waitedJob;\r\ntry {\r\n    waitedJob = job.waitFor(retryOption);\r\n} catch (InterruptedException e) {\r\n    throw new IOException(e);\r\n}\r\n```\r\n\r\nI got this error on `waitFor` method call, but I'm unable to understand the cause\r\n```\r\ncom.google.cloud.bigquery.BigQueryException: com.google.api.gax.retrying.PollException\r\n\tat com.google.cloud.bigquery.BigQueryException.translateAndThrow(BigQueryException.java:108)\r\n\tat com.google.cloud.bigquery.Job.waitForQueryResults(Job.java:337)\r\n\tat com.google.cloud.bigquery.Job.waitFor(Job.java:240)\r\n\t<stacktrace of my classes>\r\nCaused by: com.google.api.gax.retrying.PollException\r\n\tat com.google.api.gax.retrying.ExponentialPollAlgorithm.shouldRetry(ExponentialPollAlgorithm.java:68)\r\n\tat com.google.api.gax.retrying.RetryAlgorithm.shouldRetry(RetryAlgorithm.java:115)\r\n\tat com.google.api.gax.retrying.BasicRetryingFuture.handleAttempt(BasicRetryingFuture.java:151)\r\n\tat com.google.api.gax.retrying.BasicRetryingFuture.setAttemptFuture(BasicRetryingFuture.java:87)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:90)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.poll(RetryHelper.java:63)\r\n\tat com.google.cloud.bigquery.Job.waitForQueryResults(Job.java:321)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3119",
        "number": 3119,
        "title": "What would be the correct import? com.google.cloud.speech.v1 or com.google.cloud.speech.v1beta1",
        "labels": [
            "api: speech",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi All,\r\nI'm having doubt that what would be the correct import to be used in google-clould-java streaming because i found some examples which have used both **com.google.cloud.speech.v1** and **com.google.cloud.speech.v1beta1** imports. Looking forward for  to hear your valuable suggestions.\r\n\r\nThanks in advance"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3114",
        "number": 3114,
        "title": "Struct has only getStructList, no get single Struct",
        "labels": [],
        "state": "closed",
        "body": "I'm working on our GCP Spring Data integration for Spanner (https://github.com/spring-cloud/spring-cloud-gcp/tree/master/spring-cloud-gcp-data-spanner), and noticed that Struct has getter methods for singular or array for all types other than Struct. \r\n\r\nI know that STRUCTs can only be created in SQL queries and that STRUCTs are only allowed as ARRAYs of STRUCTs at the root level of the query. This lines up with only having the getStructList method, but \r\nSTRUCTs can have nested STRUCTs  singularly ( like `STRUCT<int64, STRUCT<boolean,string>>` ). How can we access that inner STRUCT in java? Would it just be getting the first element of getStructList's result?\r\n\r\nThanks!\r\n\r\n\r\n@balopat FYI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3109",
        "number": 3109,
        "title": "Severity is always set to INFO when using logging logback plugin",
        "labels": [
            ":rotating_light:",
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I use the google-cloud-logging-logback plugin and the logs are forwarded properly to the ingestion agent (fluentd). \r\nHowever, the log level seems to not be picked up and the 'severity' field always shows as 'INFO' in Stackdriver, and this for any logs no matter their original level.\r\nAny idea how to configure the logback.xml so that the severity is correctly reflected in Stackdriver Logging ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3108",
        "number": 3108,
        "title": "[BigQuery] Is there a way to specify QueryResultOptions from query()",
        "labels": [
            "api: bigquery",
            "type: docs",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Sometime after 0.32.0-beta the method of querying changed such that it is no longer obvious that there is a way to specify either `QueryResultsOption.maxWaitTime` or `QueryResultsOption.pageSize` when using `BigQuery.query`. All of the examples seem to use `BigQuery.query` but none seem to cover the case of controlling the page sizes or altering the timeouts. \r\n\r\nIs there a way to do this now?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3105",
        "number": 3105,
        "title": "gax conflict dependency",
        "labels": [],
        "state": "closed",
        "body": "Hi,\r\n\r\nI'm trying to use google cloud storage client along with apache beam/dataflow.\r\nThough I'm having some runtime dependency conflicts problems with java-gax library instanciating gcs client.\r\n```\r\nCaused by: java.lang.ClassNotFoundException: com.google.api.gax.retrying.ExceptionRetryAlgorithm\r\n    at java.net.URLClassLoader.findClass (URLClassLoader.java:381)\r\n    at java.lang.ClassLoader.loadClass (ClassLoader.java:424)\r\n    at java.lang.ClassLoader.loadClass (ClassLoader.java:357)\r\n    at java.lang.ClassLoader.defineClass1 (Native Method)\r\n    at java.lang.ClassLoader.defineClass (ClassLoader.java:760)\r\n    at java.security.SecureClassLoader.defineClass (SecureClassLoader.java:142)\r\n    at java.net.URLClassLoader.defineClass (URLClassLoader.java:467)\r\n    at java.net.URLClassLoader.access$100 (URLClassLoader.java:73)\r\n    at java.net.URLClassLoader$1.run (URLClassLoader.java:368)\r\n    at java.net.URLClassLoader$1.run (URLClassLoader.java:362)\r\n    at java.security.AccessController.doPrivileged (Native Method)\r\n    at java.net.URLClassLoader.findClass (URLClassLoader.java:361)\r\n    at java.lang.ClassLoader.loadClass (ClassLoader.java:424)\r\n    at java.lang.ClassLoader.loadClass (ClassLoader.java:357)\r\n    at com.google.cloud.BaseService.<clinit> (BaseService.java:48)\r\n    at com.google.cloud.storage.StorageOptions$DefaultStorageFactory.create (StorageOptions.java:44)\r\n    at com.google.cloud.storage.StorageOptions$DefaultStorageFactory.create (StorageOptions.java:38)\r\n    at com.google.cloud.ServiceOptions.getService (ServiceOptions.java:426)\r\n````\r\nBelow the code calling storage service\r\n```\r\nStorage storage = StorageOptions.getDefaultInstance().getService();\r\n```\r\n\r\nI've tried adding multiple versions of java-gax, excluding it from apache beam dependencies.\r\n\r\n```\r\n    <dependency>\r\n      <groupId>org.apache.beam</groupId>\r\n      <artifactId>beam-sdks-java-io-google-cloud-platform</artifactId>\r\n      <version>${beam.version}</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>com.google.api</groupId>\r\n          <artifactId>gax</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n    </dependency>\r\n....\r\n   <dependency>\r\n      <groupId>com.google.api</groupId>\r\n      <artifactId>gax</artifactId>\r\n      <version>1.21.0</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-storage</artifactId>\r\n      <version>1.24.0</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>com.google.cloud</groupId>\r\n          <artifactId>google-cloud-core</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>com.google.api</groupId>\r\n          <artifactId>gax-httpjson</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>com.google.auth</groupId>\r\n          <artifactId>google-auth-library-credentials</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n    </dependency>\r\n```\r\nBut still having those dependencies issues :(.\r\n\r\nBelow dependency tree:\r\n```\r\n[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ word-count-beam ---\r\n[INFO] org.example:word-count-beam:jar:0.1\r\n[INFO] +- org.apache.beam:beam-sdks-java-core:jar:2.4.0:compile\r\n[INFO] |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile\r\n[INFO] |  +- com.github.stephenc.findbugs:findbugs-annotations:jar:1.3.9-1:compile\r\n[INFO] |  +- com.fasterxml.jackson.core:jackson-core:jar:2.8.9:compile\r\n[INFO] |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.8.9:compile\r\n[INFO] |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.8.9:compile\r\n[INFO] |  +- org.apache.avro:avro:jar:1.8.2:compile\r\n[INFO] |  |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile\r\n[INFO] |  |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile\r\n[INFO] |  |  +- com.thoughtworks.paranamer:paranamer:jar:2.7:compile\r\n[INFO] |  |  +- org.apache.commons:commons-compress:jar:1.8.1:compile\r\n[INFO] |  |  \\- org.tukaani:xz:jar:1.5:compile\r\n[INFO] |  \\- org.xerial.snappy:snappy-java:jar:1.1.4:compile\r\n[INFO] +- org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:jar:2.4.0:compile\r\n[INFO] |  |  +- com.google.cloud.bigdataoss:gcsio:jar:1.4.5:compile\r\n[INFO] |  |  +- com.google.apis:google-api-services-cloudresourcemanager:jar:v1-rev6-1.22.0:compile\r\n[INFO] |  |  \\- com.google.apis:google-api-services-storage:jar:v1-rev71-1.22.0:compile\r\n[INFO] |  +- org.apache.beam:beam-sdks-java-extensions-protobuf:jar:2.4.0:compile\r\n[INFO] |  +- io.grpc:grpc-core:jar:1.2.0:compile\r\n[INFO] |  |  +- com.google.errorprone:error_prone_annotations:jar:2.0.11:compile\r\n[INFO] |  |  +- io.grpc:grpc-context:jar:1.2.0:compile\r\n[INFO] |  |  \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n[INFO] |  +- com.google.apis:google-api-services-bigquery:jar:v2-rev374-1.22.0:compile\r\n[INFO] |  +- com.google.api:gax-grpc:jar:0.20.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n[INFO] |  |  \\- com.google.auto.value:auto-value:jar:1.2:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-grpc:jar:1.2.0:compile\r\n[INFO] |  |  \\- com.google.protobuf:protobuf-java-util:jar:3.2.0:compile\r\n[INFO] |  |     \\- com.google.code.gson:gson:jar:2.7:compile\r\n[INFO] |  +- com.google.apis:google-api-services-pubsub:jar:v1-rev10-1.22.0:compile\r\n[INFO] |  +- com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n[INFO] |  |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.1.18:compile\r\n[INFO] |  +- com.google.cloud.bigdataoss:util:jar:1.4.5:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-java6:jar:1.20.0:compile\r\n[INFO] |  |  +- com.google.api-client:google-api-client-jackson2:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.oauth-client:google-oauth-client-java6:jar:1.20.0:compile\r\n[INFO] |  +- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.4.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n[INFO] |  |  \\- com.google.http-client:google-http-client-jackson:jar:1.20.0:compile\r\n[INFO] |  +- com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0:compile\r\n[INFO] |  |  \\- com.google.api.grpc:grpc-google-common-protos:jar:0.1.0:compile\r\n[INFO] |  +- io.grpc:grpc-auth:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-netty:jar:1.2.0:compile\r\n[INFO] |  |  +- io.netty:netty-codec-http2:jar:4.1.8.Final:compile (version selected from constraint [4.1.8.Final,4.1.8.Final])\r\n[INFO] |  |  |  \\- io.netty:netty-codec-http:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-handler-proxy:jar:4.1.8.Final:compile\r\n[INFO] |  |     \\- io.netty:netty-codec-socks:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.netty:netty-handler:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-buffer:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-common:jar:4.1.8.Final:compile\r\n[INFO] |  |  +- io.netty:netty-transport:jar:4.1.8.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-resolver:jar:4.1.8.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-codec:jar:4.1.8.Final:compile\r\n[INFO] |  +- io.grpc:grpc-stub:jar:1.2.0:compile\r\n[INFO] |  +- io.grpc:grpc-all:jar:1.2.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-okhttp:jar:1.2.0:compile\r\n[INFO] |  |  |  +- com.squareup.okhttp:okhttp:jar:2.5.0:compile\r\n[INFO] |  |  |  \\- com.squareup.okio:okio:jar:1.6.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf-nano:jar:1.2.0:compile\r\n[INFO] |  |     \\- com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core:jar:1.0.2:compile\r\n[INFO] |  |  \\- org.json:json:jar:20160810:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-spanner:jar:0.20.0b-beta:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-v1:jar:0.1.11b:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.11b:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.11:compile\r\n[INFO] |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n[INFO] |  |  \\- com.google.api.grpc:grpc-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  |     \\- com.google.api.grpc:proto-google-longrunning-v1:jar:0.1.11:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3:compile\r\n[INFO] |  +- com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0:compile\r\n[INFO] |  |  +- commons-logging:commons-logging:jar:1.2:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-appengine:jar:0.7.0:compile\r\n[INFO] |  |  +- io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0:compile\r\n[INFO] |  |  \\- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-jackson2:jar:1.22.0:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-credentials:jar:0.7.1:compile\r\n[INFO] |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.7.1:compile\r\n[INFO] |  +- com.google.protobuf:protobuf-java:jar:3.2.0:compile\r\n[INFO] |  +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:jar:0.1.9:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n[INFO] +- org.apache.beam:beam-examples-java:jar:2.4.0:compile\r\n[INFO] |  \\- com.google.oauth-client:google-oauth-client:jar:1.22.0:compile\r\n[INFO] +- com.google.api-client:google-api-client:jar:1.22.0:compile\r\n[INFO] +- com.google.http-client:google-http-client:jar:1.22.0:compile\r\n[INFO] |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO] |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO] |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO] +- joda-time:joda-time:jar:2.4:compile\r\n[INFO] +- com.google.guava:guava:jar:20.0:compile\r\n[INFO] +- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n[INFO] +- org.slf4j:slf4j-jdk14:jar:1.7.25:runtime\r\n[INFO] +- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n[INFO] +- org.hamcrest:hamcrest-library:jar:1.3:compile\r\n[INFO] +- junit:junit:jar:4.12:compile\r\n[INFO] +- org.apache.beam:beam-runners-direct-java:jar:2.4.0:runtime\r\n[INFO] |  \\- org.apache.beam:beam-runners-local-java-core:jar:2.4.0:runtime\r\n[INFO] +- org.mockito:mockito-core:jar:1.9.5:test\r\n[INFO] |  \\- org.objenesis:objenesis:jar:1.0:test\r\n[INFO] +- com.google.api:gax:jar:1.21.0:compile\r\n[INFO] |  +- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO] |  \\- com.google.api:api-common:jar:1.5.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-storage:jar:1.24.0:compile\r\n[INFO] |  \\- com.google.cloud:google-cloud-core-http:jar:1.24.0:compile\r\n[INFO] |     +- com.google.http-client:google-http-client-appengine:jar:1.23.0:compile\r\n[INFO] |     +- io.opencensus:opencensus-api:jar:0.11.1:compile\r\n[INFO] |     \\- io.opencensus:opencensus-contrib-http-util:jar:0.11.1:compile\r\n[INFO] \\- org.ahocorasick:ahocorasick:jar:0.4.0:compile\r\n```\r\n\r\nCould you help us with this issue?\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3099",
        "number": 3099,
        "title": "google-cloud-logging-logback: NoSuchMethodError with 0.42.0",
        "labels": [
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "java.lang.NoSuchMethodError: com.google.protobuf.AbstractMessageLite$Builder.addAll(Ljava/lang/Iterable;Ljava/util/List;)V at com.google.logging.v2.WriteLogEntriesRequest$Builder.addAllEntries(WriteLogEntriesRequest.java:1818) at com.google.cloud.logging.LoggingImpl.writeLogEntriesRequest(LoggingImpl.java:511) at com.google.cloud.logging.LoggingImpl.writeAsync(LoggingImpl.java:593) at com.google.cloud.logging.LoggingImpl.writeLogEntries(LoggingImpl.java:559) at com.google.cloud.logging.LoggingImpl.write(LoggingImpl.java:522) at com.google.cloud.logging.logback.LoggingAppender.append(LoggingAppender.java:201) at com.google.cloud.logging.logback.LoggingAppender.append(LoggingAppender.java:63) at ch.qos.logback.core.UnsynchronizedAppenderBase.doAppend(UnsynchronizedAppenderBase.java:84) at ch.qos.logback.core.spi.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:51) at ch.qos.logback.classic.Logger.appendLoopOnAppenders(Logger.java:270) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:257) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383) at ch.qos.logback.classic.Logger.log(Logger.java:765) at org.apache.commons.logging.impl.SLF4JLocationAwareLog.info(SLF4JLocationAwareLog.java:155) at org.springframework.boot.SpringApplication.logStartupProfileInfo(SpringApplication.java:597) at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:342) at org.springframework.boot.SpringApplication.run(SpringApplication.java:301) at "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3098",
        "number": 3098,
        "title": "[Firestore] Need unit testing guidelines",
        "labels": [],
        "state": "closed",
        "body": "In the `google-cloud-firestore` package, many of the public API classes are `final`.  In the Android SDK we explicitly made these classes non-final to enable unit testing, with a big warning saying that general purpose subclassing is not supported.\r\n\r\nFor server-side Java we should do one of:\r\n\r\n1. Un-`final` the classes\r\n2. Recommend users to try Mockito 2.0 or PowerMock\r\n3. Adopt some other method ... maybe see what other Cloud SDKs do for testability\r\n\r\ncc @schmidt-sebastian "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3097",
        "number": 3097,
        "title": "[BigQuery] Add possibility to list partitions",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "open",
        "body": "It would be great if java version of bq library would have the similar method for listing partitions as it's in Python version:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-python/blob/master/bigquery/google/cloud/bigquery/client.py#L1336-L1357"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3087",
        "number": 3087,
        "title": "Ability to list projects with BigQuery",
        "labels": [
            ":rotating_light:",
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hello, \r\n\r\nI would like to have ability to list all projects where BIgQuery is enabled and I (as a user or service account) have required permissions. \r\nThis functionality corresponds with biqquery.projects.list api call. \r\n\r\nI have an use case, when I want to perform some actions on tables in all projects accessible for me. \r\nAbility to create BIgQuery services for each accessible project would be great. \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3086",
        "number": 3086,
        "title": "[Storage] add download directory ability to the storage client",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "Currently it is only possible to download or getContent from one blob at a time, which makes for slow processing options for directories with 1k+ files (regardless the size).\r\ngsutil offers -m flag which performs actions in \"multi-threaded/multi-processing\" context.\r\nwould it be possible to add such ability to the storage client?\r\n\r\nan example for implementation would be AWS's TransferManager: ``downloadDirectory(String bucketName, String keyPrefix, File destinationDirectory)``.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3084",
        "number": 3084,
        "title": "javadoc takes a long time to generate",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Sometimes it takes 2-ish hours to do a release, most of which is javadoc. We need to speed this up for agility. Currently javadoc generation only uses one core; maybe we can parallelize this somehow. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3083",
        "number": 3083,
        "title": "PERMISSION_DENIED for google service account",
        "labels": [
            "api: pubsub",
            "auth",
            "type: question"
        ],
        "state": "closed",
        "body": "I've successfully subscribed to Pub?Sub service under my own user account. Howewer when i set **GOOGLE_APPLICATION_CREDENTIALS** env variable to point service account key file i got permission denied exception. This service account has `Pub/Sub Admin` role. Here is stack trace of exception:\r\n```\r\nSEVERE: terminated streaming with exception\r\ncom.google.api.gax.rpc.PermissionDeniedException: io.grpc.StatusRuntimeException: PERMISSION_DENIED: User not authorized to perform this action.\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:55)\r\n\tat com.google.cloud.pubsub.v1.StreamingSubscriberConnection$1.onFailure(StreamingSubscriberConnection.java:237)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat com.google.common.util.concurrent.SettableFuture.setException(SettableFuture.java:53)\r\n\tat com.google.cloud.pubsub.v1.StreamingSubscriberConnection$StreamingPullResponseObserver.onError(StreamingSubscriberConnection.java:173)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:419)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:392)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: PERMISSION_DENIED: User not authorized to perform this action.\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 19 more\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3082",
        "number": 3082,
        "title": "Get Serving URL for images stored in Storage (Similar to App Engine Image Class)",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "Would it be possible to get something similar to get_serving_url in app engine to google-cloud-java as well?\r\nSimilar issue was fixed for python client and closed https://github.com/GoogleCloudPlatform/google-cloud-python/issues/1295 \r\n\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3081",
        "number": 3081,
        "title": "Need to flush the Google Pub/Sub batch so that it delivers immediately?",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using the batch system in Pub/Sub to increase throughput but our system also takes a check-point every so often when all of the messages should be pushed out.\r\n\r\nRight now the `Publisher.publishAllOutstanding()` method is `private`.  Please consider making it public or otherwise providing some mechanism to flush the batch buffers.\r\n\r\nThanks.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3078",
        "number": 3078,
        "title": "Facing issue while migrating from Java 7 to Java 8 on Appengine",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I have updated pom.xml with all the latest dependencies, and web.xml with all the attributes defined in\r\nofficial documentation of Google Cloud.\r\nBut facing the error ,as I have some jsp files in webapp folder. even with the empty jsp file, this issue persists. Getting the following error:\r\njava.io.IOException: Cannot run program \"C:\\jdk1.8.0_144\\jre\\bin\\java.exe\": Crea\r\nteProcess error=206, The filename or extension is too long\r\nUnable to update app: Cannot run program \"C:\\jdk1.8.0_144\\jre\\bin\\java.exe\": Cre\r\nateProcess error=206, The filename or extension is too long\r\nPlease see the logs [C:\\Users\\farhanm\\AppData\\Local\\Temp\\appcfg16888316327372592\r\n11.log] for further information.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3073",
        "number": 3073,
        "title": "[BigQuery] Provide method to retrieve Table from any project",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We have a use case, when one BigQuery service needs to retrieve tables from multiple project. Right now we need to recreate a new service for every project.\r\n\r\nCould you please overload `getTable()` method in [BigQuery.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/BigQuery.java) with additional `projectId` parameter? Example:\r\n`Table getTable(String projectId, String datasetId, String tableId, TableOption... options);`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3072",
        "number": 3072,
        "title": "DatastoreOptions.newBuilder().setProjectId(DS_PROJECT_ID).build().getService() not returning data store",
        "labels": [],
        "state": "closed",
        "body": "i try to initialize the datastore with this code\r\n\r\n```java\r\npackage com.kofera.notification;\r\n\r\n\r\nimport com.google.cloud.Service;\r\nimport com.google.cloud.datastore.Datastore;\r\nimport com.google.cloud.datastore.DatastoreOptions;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.context.annotation.Configuration;\r\n\r\n@Configuration\r\npublic class DataStoreConfig {\r\n    public static final String DS_PROJECT_ID = \"kofera-core-team\";\r\n    public static final String DS_KPI_SETTING_RULE = \"kpi-setting-rule\";\r\n\r\n    @Bean\r\n    Datastore datastore() {\r\n       return DatastoreOptions.newBuilder().setProjectId(DS_PROJECT_ID).build().getService()\r\n    }\r\n}\r\n```\r\n\r\ni've get this errror\r\n\r\n`Incompatible Types com.google.cloud.datastore.Datastore Found com.google.cloud.Service`\r\n\r\nMy POM.xml\r\n\r\n```\r\n <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-datastore</artifactId>\r\n     <version>1.14.0</version>\r\n</dependency>\r\n```\r\n\r\n\r\nIs there something wrong with the code to initialize the datastore?\r\n\r\nThanks \r\n\r\nRegards Semmi Verian"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3071",
        "number": 3071,
        "title": "[KafkaPubSubConnector] : Getting UNAVAILABLE: HTTP/2 error code: NO_ERROR and goes into retry loop forever",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using https://github.com/GoogleCloudPlatform/pubsub/tree/master/kafka-connector for publishing messages to pubsub from kafka.\r\nRunning into the below issue and the publishing enters an infinite loop of retrying same batch of messages  and not recovering. \r\n\r\n`java.lang.RuntimeException: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR`\r\n\t`Received Goaway `\r\n       `session_timed_out `\r\n\t\t`at com.google.pubsub.kafka.sink.CloudPubSubSinkTask.flush(CloudPubSubSinkTask.java:293)\r\n\t\tat org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets(WorkerSinkTask.java:192)\r\n\t\tat org.apache.kafka.connect.runtime.WorkerSinkTaskThread.iteration(WorkerSinkTaskThread.java:75)\r\n\t\tat org.apache.kafka.connect.runtime.WorkerSinkTaskThread.execute(WorkerSinkTaskThread.java:58)\r\n\t\tat org.apache.kafka.connect.util.ShutdownableThread.run(ShutdownableThread.java:82)`\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3070",
        "number": 3070,
        "title": "Improve Providing Credential Programmatically or String",
        "labels": [
            "auth",
            "type: feature request"
        ],
        "state": "open",
        "body": "Documentation for providing credentials seems outdated.\r\nFor most services, need to use a `CredentialProvider` to wrap another `Credentials` object.\r\n\r\nThere is `GoogleCredentails.fromStream` and `ServiceAccountCredentials.fromStream`. There is no documentation on when to use what and why one is not preferred.\r\n\r\nLastly, when setting credentials programmatically, setting the credential via a String as oppose to `InputStream` is common. \r\n\r\nProposed enhancements\r\n- [ ] Improve documentation on providing credentials programmatically for both HTTP-based client and gRPC-based client\r\n- [ ] De-duplicate GoogleCredentials and ServiceAccountCredentials?\r\n- [ ] Add a method to set JSON key content via a String in addition to the current InputStream."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3068",
        "number": 3068,
        "title": "ConcurrentModificationException in endpoints v2.0 tester, app engine standard, using maven archetype for hello-world",
        "labels": [
            "type: question"
        ],
        "state": "open",
        "body": "The function\r\n```javascript\r\n_.createError = function createError(msg){\r\n  return new $wnd.Error(msg);\r\n}\r\n;\r\n```\r\ninside `com.googe.apis.explorer.Explorer-0.js` reports the following Exception:\r\n\r\n`java.util.ConcurrentModificationException`\r\n\r\nSteps:\r\n1. Generate a new endpoints v2.0 app for app engine standard, using maven archetype, for hello-world\r\n1. cd hello-world\r\n1. mvn clean compile package\r\n1. mvn appengine:run\r\n1. Disable the security in Google Chrome by using the command line options and navigate to http://localhost:8080/_ah/api/explorer\r\n1. Click on Services > hello world API\r\n1. You will see a JavaScript error `Uncaught Error: com.google.gwt.event.shared.UmbrellaException`.\r\n1. Put a breakpoint in the script:function mentioned above and you will see the error `java.util.ConcurrentModificationException`\r\n\r\nI also noticed this error as a peculiar side effect of [Multiclass API](https://cloud.google.com/endpoints/docs/frameworks/java/multiclass) that I was trying earlier. This error only showed up in the  Discovery Services API and in the first custom API. It works fine up when you click the 2nd custom API. Strange.\r\n\r\nThe error stays whether you use Java 7 or Java 8 or if you user cloud version 191.0.0 or version 194.0.0. \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3065",
        "number": 3065,
        "title": "[pubsub] Subscriber.stopAsync().awaitTerminated() doesn't wait for all acks to be sent",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "In working on a gRPC emulation service for Cloud Pub/Sub, I was trying to validate correct behavior by publishing a series of messages, receiving and acknowleding the exact same set of messages, and then ensuring that no backlog existed for the subscription.\r\n\r\nHere's the general test pattern:\r\n```\r\nString messagePrefix = subscriptionProperties.getName() + System.currentTimeMillis() + \"-\";\r\nint messages = 5000;\r\nSet<String> messagesSet = new TreeSet<>();\r\nfor (int i = 0; i < messages; i++) {\r\n  messagesSet.add(messagePrefix + i);\r\n}\r\nCountDownLatch countDownLatch = new CountDownLatch(messages);\r\nSet<String> publishedIds = new ConcurrentSkipListSet<>();\r\nMap<String, Integer> receivedIds = new ConcurrentHashMap<>();\r\nfor (String data : messagesSet) {\r\n  PubsubMessage message =\r\n      PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(data)).build();\r\n  ApiFutures.addCallback(\r\n      publisher.publish(message),\r\n      new ApiFutureCallback<String>() {\r\n        @Override\r\n        public void onFailure(Throwable throwable) {\r\n          LOGGER.warning(\"Error on Publish \" + throwable.getMessage());\r\n        }\r\n\r\n        @Override\r\n        public void onSuccess(String s) {\r\n          publishedIds.add(s);\r\n        }\r\n      });\r\n}\r\npublisher.shutdown();\r\nassertEquals(messages, publishedIds.size());\r\n\r\nsubscriber =\r\n    Subscriber.newBuilder(\r\n            ProjectSubscriptionName.of(PROJECT, subscriptionProperties.getName()),\r\n            (message, consumer) -> {\r\n              consumer.ack();\r\n              LOGGER.fine(\"Received and Acknowledging \" + message.getMessageId());\r\n              if (!receivedIds.containsKey(message.getMessageId())) {\r\n                receivedIds.put(message.getMessageId(), 1);\r\n              } else {\r\n                int current = receivedIds.get(message.getMessageId());\r\n                receivedIds.put(message.getMessageId(), Integer.valueOf(++current));\r\n              }\r\n              countDownLatch.countDown();\r\n            })\r\n        //.setChannelProvider(channelProvider)\r\n        //.setCredentialsProvider(credentialsProvider)\r\n        .build();\r\n\r\npublisher.shutdown();\r\nassertEquals(messages, publishedIds.size());\r\n\r\nsubscriber.startAsync();\r\nLOGGER.info(\"Publisher complete, waiting for 5,000 messages to be received by Subscriber\");\r\ncountDownLatch.await();\r\nLOGGER.info(\"Shutting down Subscriber\");\r\nsubscriber.stopAsync().awaitTerminated();\r\n```\r\n\r\nI executed this test after creating a fresh topic and subscription. My expectation was that after the CountDownLatch reached 0, the Subscriber would shut down and block until all acknowledgements were transmitted.\r\n\r\nIn the client library debug logs, I see the following ack lines, which add up to 5,000 as expected. Interestingly, the final 1,517 acks coming from a thread named *time-limited test*, which is the main thread of my integration test case.\r\n```\r\n2018-03-20 14:10:41.694 [Thread-50] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 78 acks\r\n2018-03-20 14:10:41.693 [Thread-42] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 70 acks\r\n2018-03-20 14:10:41.696 [Thread-46] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 29 acks\r\n2018-03-20 14:10:41.700 [Thread-48] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 100 acks\r\n2018-03-20 14:10:41.695 [Thread-52] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 169 acks\r\n2018-03-20 14:10:41.702 [Thread-44] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 42 acks\r\n2018-03-20 14:10:41.723 [Thread-48] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 281 acks\r\n2018-03-20 14:10:41.729 [Thread-52] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 266 acks\r\n2018-03-20 14:10:41.823 [Thread-50] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 36 acks\r\n2018-03-20 14:10:41.830 [Thread-42] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 75 acks\r\n2018-03-20 14:10:41.832 [Thread-46] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 609 acks\r\n2018-03-20 14:10:41.831 [Thread-48] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 376 acks\r\n2018-03-20 14:10:41.841 [Thread-44] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 186 acks\r\n2018-03-20 14:10:41.841 [Thread-52] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 510 acks\r\n2018-03-20 14:10:41.845 [Thread-50] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 244 acks\r\n2018-03-20 14:10:41.868 [Thread-42] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 412 acks\r\n2018-03-20 14:10:41.887 [Time-limited test] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 106 acks\r\n2018-03-20 14:10:41.888 [Time-limited test] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 496 acks\r\n2018-03-20 14:10:41.892 [Time-limited test] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 379 acks\r\n2018-03-20 14:10:41.894 [Time-limited test] DEBUG com.google.cloud.pubsub.v1.MessageDispatcher : Sending 536 acks\r\n```\r\n\r\nNow, at this point, I can confirm the existence of a backlog by re-running the test but disabling the publisher step. The subscriber should not receive any messages and the test should time out.\r\n\r\nHowever, when I grep for the *Received and Acknowledging * line in my logs, I get a total of *981* rows indicating that those acks that should have been transmitted from the previous run of receiving and acknowledging all 5,000 messages were not received by Cloud Pub/Sub. *981* happens to be the sum of the first three ack batches sent from the *Time-limited test* thread after the subscriber shutdown sequence was invoked.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3064",
        "number": 3064,
        "title": "UnresolvedAddressException when using proxy",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nwe are facing problems with the library google-cloud-pubsub when it is running behind a proxy. Locally everything is fine, but when we deploy to our development server which needs to use system proxy (https.proxyHost, https.proxyPort and also http variants) we receive a UnresolvedAddressException. Is there some kind of workaround, or when can we expect a general fix for it?\r\n\r\n\r\nMar 20, 2018 10:55:00 AM com.google.cloud.pubsub.v1.StreamingSubscriberConnection$1 onFailure\r\nSEVERE: terminated streaming with exception\r\ncom.google.api.gax.rpc.UnknownException: io.grpc.StatusRuntimeException: UNKNOWN\r\n        at com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:47)\r\n        at com.google.cloud.pubsub.v1.StreamingSubscriberConnection$1.onFailure(StreamingSubscriberConnection.java:237)\r\n        at com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n        at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n        at com.google.common.util.concurrent.SettableFuture.setException(SettableFuture.java:53)\r\n        at com.google.cloud.pubsub.v1.StreamingSubscriberConnection$StreamingPullResponseObserver.onError(StreamingSubscriberConnection.java:173)\r\n        at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:419)\r\n        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n        at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:684)\r\n        at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n        at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:392)\r\n        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:475)\r\n        at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:557)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:478)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:590)\r\n        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n        at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: UNKNOWN\r\n        at io.grpc.Status.asRuntimeException(Status.java:526)\r\n        ... 19 more\r\nCaused by: java.nio.channels.UnresolvedAddressException\r\n        at sun.nio.ch.Net.checkAddress(Net.java:101)\r\n        at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)\r\n        at io.grpc.netty.shaded.io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:83)\r\n        at io.grpc.netty.shaded.io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:80)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at io.grpc.netty.shaded.io.netty.util.internal.SocketUtils.connect(SocketUtils.java:80)\r\n        at io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:308)\r\n        at io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:254)\r\n        at io.grpc.netty.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1291)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)\r\n        at io.grpc.netty.shaded.io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.connect(CombinedChannelDuplexHandler.java:497)\r\n        at io.grpc.netty.shaded.io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)\r\n        at io.grpc.netty.shaded.io.netty.channel.CombinedChannelDuplexHandler.connect(CombinedChannelDuplexHandler.java:298)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)\r\n        at io.grpc.netty.shaded.io.netty.handler.proxy.ProxyHandler.connect(ProxyHandler.java:181)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)\r\n        at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.connect(SslHandler.java:674)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)\r\n        at io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2ConnectionHandler.connect(Http2ConnectionHandler.java:459)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)\r\n        at io.grpc.netty.shaded.io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)\r\n        at io.grpc.netty.shaded.io.grpc.netty.ProtocolNegotiators$AbstractBufferingHandler.connect(ProtocolNegotiators.java:458)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)\r\n        at io.grpc.netty.shaded.io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)\r\n        at io.grpc.netty.shaded.io.grpc.netty.ProtocolNegotiators$AbstractBufferingHandler.connect(ProtocolNegotiators.java:458)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext.access$1000(AbstractChannelHandlerContext.java:38)\r\n        at io.grpc.netty.shaded.io.netty.channel.AbstractChannelHandlerContext$11.run(AbstractChannelHandlerContext.java:535)\r\n        at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\r\n        at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)\r\n        at io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)\r\n        at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n        at io.grpc.netty.shaded.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n        ... 1 more\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3058",
        "number": 3058,
        "title": "BigQuery Create partitioned table with Tables.insert(tableResourceObject). TimePartitioning doesnot support 'field' string",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "open",
        "body": "TimePartitioning object should ideally have   \"timePartitioning\": {\r\n    \"type\": string,\r\n    \"expirationMs\": long,\r\n    \"field\": string,\r\n    \"requirePartitionFilter\": boolean\r\n  },\r\nIn the current api, there is no support for specifying 'field' and 'requirePartitionFilter' for creating a load job for partitioned tables."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3057",
        "number": 3057,
        "title": "Google Cloud PubSub 0.40 and google cloud logging logback 0.40 interferes and creates JRE fatal error",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I try to use both google-cloud-pubsub and google-cloud-logging-logback in the same project but if I include both dependencies\r\n`compile group: 'com.google.cloud', name: 'google-cloud-pubsub', version:'0.40.0-beta'`\r\n`compile group: 'com.google.cloud', name: 'google-cloud-logging-logback', version: '0.40.0-alpha'`\r\nin the gradle build file, the JRE crashes with a fatal error at the line when I try to start the subscriber:\r\n```\r\nsubscriber.startAsync();\r\n```\r\n`subscriber` is a `com.google.cloud.pubsub.v1.Subscriber`.\r\n\r\nThis is the excerpt of the JRE fatal error log:\r\n```\r\n#\r\n# A fatal error has been detected by the Java Runtime Environment:\r\n#\r\n#  EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x00007ffcf39642a0, pid=6540, tid=18088\r\n#\r\n# JRE version: Java(TM) SE Runtime Environment (9.0+11) (build 9.0.4+11)\r\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (9.0.4+11, mixed mode, tiered, compressed oops, g1 gc, windows-amd64)\r\n# Problematic frame:\r\n# C  0x00007ffcf39642a0\r\n#\r\n# No core dump will be written. Minidumps are not enabled by default on client versions of Windows\r\n#\r\n# If you would like to submit a bug report, please visit:\r\n#   http://bugreport.java.com/bugreport/crash.jsp\r\n# The crash happened outside the Java Virtual Machine in native code.\r\n# See problematic frame for where to report the bug.\r\n#\r\n\r\n---------------  S U M M A R Y ------------\r\n\r\nCommand Line: -Dfile.encoding=UTF-8 -Duser.country=DE -Duser.language=de -Duser.variant my.package.App\r\n\r\nHost: AMD Phenom(tm) II X4 965 Processor, 4 cores, 9G,  Windows 10 , 64 bit Build 16299 (10.0.16299.15)\r\nTime: Sun Mar 18 20:30:58 2018 Mitteleurop\ufffdische Zeit elapsed time: 4 seconds (0d 0h 0m 4s)\r\n\r\n---------------  T H R E A D  ---------------\r\n\r\nCurrent thread (0x000001d347449000):  JavaThread \"Thread-0\" [_thread_in_native, id=18088, stack(0x0000001293000000,0x0000001293100000)]\r\n\r\nStack: [0x0000001293000000,0x0000001293100000],  sp=0x00000012930fe238,  free space=1016k\r\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\r\nC  0x00007ffcf39642a0\r\n\r\nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\r\nj  io.grpc.netty.shaded.io.netty.internal.tcnative.Library.aprMajorVersion()I+0\r\nj  io.grpc.netty.shaded.io.netty.internal.tcnative.Library.initialize(Ljava/lang/String;Ljava/lang/String;)Z+31\r\nj  io.grpc.netty.shaded.io.netty.internal.tcnative.Library.initialize()Z+3\r\nj  io.grpc.netty.shaded.io.netty.handler.ssl.OpenSsl.initializeTcNative()Z+0\r\nj  io.grpc.netty.shaded.io.netty.handler.ssl.OpenSsl.<clinit>()V+137\r\nv  ~StubRoutines::call_stub\r\nj  io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.defaultSslProvider()Lio/grpc/netty/shaded/io/netty/handler/ssl/SslProvider;+0\r\nj  io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.configure(Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContextBuilder;)Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContextBuilder;+1\r\nj  io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.forClient()Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContextBuilder;+3\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$NettyTransportFactory;Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContext;)V+23\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$NettyTransportFactory;Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContext;Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$1;)V+3\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(Lio/grpc/netty/shaded/io/grpc/netty/NettyChannelBuilder$TransportCreationParamsFilterFactory;Ljava/lang/Class;Ljava/util/Map;Lio/grpc/netty/shaded/io/grpc/netty/NegotiationType;Lio/grpc/netty/shaded/io/netty/handler/ssl/SslContext;Lio/grpc/netty/shaded/io/netty/channel/EventLoopGroup;IIIJJZLio/grpc/internal/TransportTracer;)V+45\r\nj  io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder.buildTransportFactory()Lio/grpc/internal/ClientTransportFactory;+59\r\nj  io.grpc.internal.AbstractManagedChannelImplBuilder.build()Lio/grpc/ManagedChannel;+6\r\nj  com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel()Lio/grpc/ManagedChannel;+216\r\nj  com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel()Lcom/google/api/gax/rpc/TransportChannel;+9\r\nj  com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel()Lcom/google/api/gax/rpc/TransportChannel;+52\r\nj  com.google.cloud.pubsub.v1.Subscriber.doStart()V+25\r\nj  com.google.api.core.AbstractApiService$InnerService.doStart()V+4\r\nj  com.google.common.util.concurrent.AbstractService.startAsync()Lcom/google/common/util/concurrent/Service;+33\r\nj  com.google.api.core.AbstractApiService.startAsync()Lcom/google/api/core/ApiService;+4\r\nj  com.google.cloud.pubsub.v1.Subscriber.startAsync()Lcom/google/api/core/ApiService;+1\r\n```\r\n\r\nIf I remove the logback dependency, it works and the JRE does not crash so I assume there is a dependency conflict between the grpc-netty versions used by both."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3056",
        "number": 3056,
        "title": "pubsub: machine runs out of memory and crashes",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hello! I'm running a simple pubsub consumer. This consumer receives a message, waits 5 seconds, and then acks the message. Running this consumer against a subscription with ~600,000 messages causes my app to repeatedly crash as it runs out of memory. This is running on GKE with no special configuration. I'm also using the java config defaults where possible. Possibly worth noting is that I do not see any warning/error logs related to these restarts.\r\n\r\nIs this expected? What can be done to prevent this?\r\n\r\n## Screenshots\r\n\r\n![screen shot 2018-03-17 at 5 07 41 pm](https://user-images.githubusercontent.com/3584893/37561214-294c7b04-2a06-11e8-86ca-97842495e9e4.png)\r\n\r\n![screen shot 2018-03-17 at 5 11 10 pm](https://user-images.githubusercontent.com/3584893/37561216-38eb43ce-2a06-11e8-99d1-6620386c0adb.png)\r\n\r\n## Repro\r\n\r\n- [Main.java](https://gist.github.com/jadekler/45a693a94cef09088f7ac592b252fde1)\r\n- [MyReceiver.java](https://gist.github.com/jadekler/fb327281ec2d65d34b86c0cc14449838)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3052",
        "number": 3052,
        "title": "Facing problem in moving from Java 7 to Java 8 environment in App Engine.",
        "labels": [
            "needs more info",
            "running on app engine",
            "type: question"
        ],
        "state": "open",
        "body": "I have followed the steps specified on URL https://cloud.google.com/appengine/docs/standard/java/runtime-java8 for changing from java 7 to java 8 for standard AppEngine. I am getting following error while executing command 'mvn appengine:update'\r\n\r\n```\r\njava.io.IOException: Cannot run program \"C:\\jdk1.8.0_144\\jre\\bin\\java.exe\": Crea\r\nteProcess error=206, The filename or extension is too long\r\nUnable to update app: Cannot run program \"C:\\jdk1.8.0_144\\jre\\bin\\java.exe\": Cre\r\nateProcess error=206, The filename or extension is too long\r\nPlease see the logs [C:\\Users\\farhanm\\AppData\\Local\\Temp\\appcfg16888316327372592\r\n11.log] for further information.\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3051",
        "number": 3051,
        "title": "Update READMEs for BigQuery",
        "labels": [],
        "state": "closed",
        "body": "- Main README: move to GA section\r\n- BigQuery README: remove warning about being work-in-progress\r\n\r\nand update anything else that is amiss..."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3049",
        "number": 3049,
        "title": "Make google-cloud-java forward compatible with Guava 23+",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "I haven't personally tried this yet, but I have evidence that google-cloud-java is not currently forward compatible with Guava 23+. We need to make sure all code can run against both Guava 20 and Guava 23 (basically only depend on classes/methods that exist in the intersection of those versions). \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3048",
        "number": 3048,
        "title": "Pub sub does not seem to work with Java 7 because of gRPC/netty stuff",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Although the docs state that Java 8 is required, this invalidates its use in my corporate code base which is back on Java 7.   I do see that the class files are Java 7 compliant however.  Is it possible to run under Java 7?  Are there versions of the API that work under 7?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3044",
        "number": 3044,
        "title": "Pubsub: ClassNotFoundException org/eclipse/jetty/alpn/ALPN with versions 0.32, 0.35, ..., 0.38",
        "labels": [
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Although I've seen similar issues, they all seem to be closed, I'm still seeing the following error with recent versions of this API.  Related to: https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2740 https://github.com/GoogleCloudPlatform/google-cloud-java/issues/3036\r\n\r\n    Caused by: java.lang.ClassNotFoundException: org/eclipse/jetty/alpn/ALPN\r\n\r\nMy test program is doing the following:\r\n\r\n\tProjectSubscriptionName subName = ProjectSubscriptionName.of(\"project\", \"subscriber\");\r\n\tBuilder builder = Subscriber.newBuilder(subName, new OurReceiver());\r\n\t// also tried adding the following\r\n\t// GoogleCredentials cred=GoogleCredentials.fromStream(new FileInputStream(\"creds.json\"));\r\n\t// builder.setCredentialsProvider(FixedCredentialsProvider.create(cred));\r\n\tSubscriber subscriber = builder.build();\r\n\tsubscriber.startAsync().awaitRunning();\r\n\r\nHere's my maven pom.xml dependency.  Dependency tree attached:\r\n\r\n\t<dependency>\r\n\t\t<groupId>com.google.cloud</groupId>\r\n\t\t<artifactId>google-cloud-pubsub</artifactId>\r\n\t\t<version>0.38.0-beta</version> <!-- also tried 32, 35, 36, 37 -->\r\n\t</dependency>\r\n\r\nAny idea what I'm doing wrong?  Can I even run this outside of the Google network?  Please excuse the obvious ignorance of this stuff.\r\n\r\n[dependencies.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1813204/dependencies.txt)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3041",
        "number": 3041,
        "title": "NIO channels could optimize buffer-invalidation on seeks",
        "labels": [
            "api: storage",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "[`BlobReadChannel` dumps its buffer on any seek](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.38.0/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobReadChannel.java#L104), therefore [so does `CloudStorageReadChannel`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.38.0/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageReadChannel.java#L164).\r\n\r\nThis causes unexpected/pathological behavior, e.g. in [hadoop-bam](https://github.com/HadoopGenomics/Hadoop-BAM)/[spark-bam](http://www.hammerlab.org/spark-bam/) where the read pattern is roughly \"read 100 bytes, rewind 99 bytes, repeat 1000x\"; basically the same [2MB](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.38.0/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobReadChannel.java#L41) is fetched over the network at every iteration.\r\n\r\nspark-bam uses a [`CachingChannel`](https://github.com/hammerlab/io-utils/blob/channel-1.4.0/channel/src/main/scala/org/hammerlab/channel/CachingChannel.scala) abstraction that LRU-caches blocks of the underlying channel, which fixes this.\r\n\r\nJust wanted to call out this \"gotcha\"; might be worth fixing here."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3038",
        "number": 3038,
        "title": "dialogflow heartbeat/ping using SDK",
        "labels": [
            "api: dialogflow",
            "type: question"
        ],
        "state": "closed",
        "body": "**Is there a way to check if my app is able to talk to dialogflow agent using java SDK?** (https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-dialogflow)\r\n\r\nThe purpose is just to verify the `credentials` are working and connectivity is working when I deploy my application, before actual traffic flows in.\r\n\r\nOne way I can think of is make a intent-request itself which is not a good solution in my opinion; I wrote something as below (in clojure using java sdk)\r\n\r\n```clojure\r\n(defn heartbeat [{nlu-agent :nlu-agent utterance :utterance creds-file :creds-file}]\r\n  (try\r\n    (send-intent-request\r\n     {:nlu-agent  nlu-agent\r\n      :utterance  utterance\r\n      :creds-file creds-file})\r\n    \"success\"\r\n    (catch Throwable e\r\n      (.getMessage e))))\r\n```\r\n\r\nAnd obviously I'm using `credentials.json` provided my `gcloud` which looks as below (taken from https://cloud.google.com/video-intelligence/docs/common/auth#authenticating_with_application_default_credentials);\r\n\r\n```json\r\n{\r\n  \"type\": \"service_account\",\r\n  \"project_id\": \"project-id\",\r\n  \"private_key_id\": \"some_number\",\r\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n....\r\n  =\\n-----END PRIVATE KEY-----\\n\",\r\n  \"client_email\": \"<api-name>api@project-id.iam.gserviceaccount.com\",\r\n  \"client_id\": \"...\",\r\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\r\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\r\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\r\n  \"client_x509_cert_url\": \"https://www.googleapis.com/...<api-name>api%40project-id.iam.gserviceaccount.com\"\r\n}\r\n```\r\n\r\nBut don't want to send actual intent-requests in PROD every minute just for the sake of heartbeat.\r\n\r\nI had same question in another place too but this seems a right place to ask questions - https://github.com/dialogflow/dialogflow-java-client-v2/issues/14"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3036",
        "number": 3036,
        "title": "java.lang.IllegalArgumentException: ALPN is not configured properly.",
        "labels": [],
        "state": "closed",
        "body": "Much has been written about this and I've been searching around it all day, but I'm running into the ALPN error when running google-cloud-monitoring.\r\n\r\n```\r\njava.lang.IllegalArgumentException: ALPN is not configured properly. See https://github.com/grpc/grpc-java/blob/master/SECURITY.md#troubleshooting for more information.\r\n\tat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:163) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:136) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:124) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:94) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(NettyChannelBuilder.java:546) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(NettyChannelBuilder.java:539) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:477) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.netty.shaded.io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:325) ~[grpc-netty-shaded-1.9.0.jar!/:1.9.0]\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:342) ~[grpc-core-1.9.0.jar!/:1.9.0]\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:185) ~[gax-grpc-1.19.0.jar!/:1.19.0]\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:142) ~[gax-grpc-1.19.0.jar!/:1.19.0]\r\n\tat com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:134) ~[gax-grpc-1.19.0.jar!/:1.19.0]\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:137) ~[gax-1.17.0.jar!/:1.17.0]\r\n\tat com.google.cloud.monitoring.v3.stub.GrpcMetricServiceStub.create(GrpcMetricServiceStub.java:171) ~[google-cloud-monitoring-0.38.0-beta.jar!/:0.38.0-beta]\r\n\tat com.google.cloud.monitoring.v3.stub.MetricServiceStubSettings.createStub(MetricServiceStubSettings.java:184) ~[google-cloud-monitoring-0.38.0-beta.jar!/:0.38.0-beta]\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.<init>(MetricServiceClient.java:158) ~[google-cloud-monitoring-0.38.0-beta.jar!/:0.38.0-beta]\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.create(MetricServiceClient.java:139) ~[google-cloud-monitoring-0.38.0-beta.jar!/:0.38.0-beta]\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.create(MetricServiceClient.java:130) ~[google-cloud-monitoring-0.38.0-beta.jar!/:0.38.0-beta]\r\n...\r\n```\r\nMy maven dependencies are as follows.\r\n\r\n```\r\n/Users/dan.ostrowski/IdeaProjects/osp_offers-orchestrator\r\n[INFO] Scanning for projects...\r\n[INFO] \r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Building orchestration 0.0.1-SNAPSHOT\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] \r\n[INFO] --- maven-dependency-plugin:2.10:tree (default-cli) @ offers-orchestrator ---\r\n[INFO] com.mycompany.mypackage:my-artifact:jar:0.0.1-SNAPSHOT\r\n[INFO] +- org.springframework.boot:spring-boot-starter-web:jar:1.5.9.RELEASE:compile\r\n[INFO] |  +- org.hibernate:hibernate-validator:jar:5.3.6.Final:compile\r\n[INFO] |  |  +- javax.validation:validation-api:jar:1.1.0.Final:compile\r\n[INFO] |  |  +- org.jboss.logging:jboss-logging:jar:3.3.1.Final:compile\r\n[INFO] |  |  \\- com.fasterxml:classmate:jar:1.3.4:compile\r\n[INFO] |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.8.10:compile\r\n[INFO] |  |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.8.0:compile\r\n[INFO] |  |  \\- com.fasterxml.jackson.core:jackson-core:jar:2.8.10:compile\r\n[INFO] |  +- org.springframework:spring-web:jar:4.3.13.RELEASE:compile\r\n[INFO] |  |  +- org.springframework:spring-aop:jar:4.3.13.RELEASE:compile\r\n[INFO] |  |  +- org.springframework:spring-beans:jar:4.3.13.RELEASE:compile\r\n[INFO] |  |  \\- org.springframework:spring-context:jar:4.3.13.RELEASE:compile\r\n[INFO] |  \\- org.springframework:spring-webmvc:jar:4.3.13.RELEASE:compile\r\n[INFO] |     \\- org.springframework:spring-expression:jar:4.3.13.RELEASE:compile\r\n[INFO] +- org.springframework.boot:spring-boot-starter-jetty:jar:1.5.9.RELEASE:compile\r\n[INFO] |  +- org.eclipse.jetty:jetty-servlets:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty:jetty-continuation:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty:jetty-http:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty:jetty-util:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  \\- org.eclipse.jetty:jetty-io:jar:9.4.7.v20170914:compile\r\n[INFO] |  +- org.eclipse.jetty:jetty-webapp:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty:jetty-xml:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  \\- org.eclipse.jetty:jetty-servlet:jar:9.4.7.v20170914:compile\r\n[INFO] |  |     \\- org.eclipse.jetty:jetty-security:jar:9.4.7.v20170914:compile\r\n[INFO] |  |        \\- org.eclipse.jetty:jetty-server:jar:9.4.7.v20170914:compile\r\n[INFO] |  +- org.eclipse.jetty.websocket:websocket-server:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty.websocket:websocket-common:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  |  \\- org.eclipse.jetty.websocket:websocket-api:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty.websocket:websocket-client:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  |  \\- org.eclipse.jetty:jetty-client:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  \\- org.eclipse.jetty.websocket:websocket-servlet:jar:9.4.7.v20170914:compile\r\n[INFO] |  |     \\- javax.servlet:javax.servlet-api:jar:3.1.0:compile\r\n[INFO] |  +- org.eclipse.jetty.websocket:javax-websocket-server-impl:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  +- org.eclipse.jetty:jetty-annotations:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  |  +- org.eclipse.jetty:jetty-plus:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  |  +- javax.annotation:javax.annotation-api:jar:1.2:compile\r\n[INFO] |  |  |  +- org.ow2.asm:asm:jar:5.1:compile\r\n[INFO] |  |  |  \\- org.ow2.asm:asm-commons:jar:5.1:compile\r\n[INFO] |  |  |     \\- org.ow2.asm:asm-tree:jar:5.1:compile\r\n[INFO] |  |  +- org.eclipse.jetty.websocket:javax-websocket-client-impl:jar:9.4.7.v20170914:compile\r\n[INFO] |  |  \\- javax.websocket:javax.websocket-api:jar:1.0:compile\r\n[INFO] |  \\- org.mortbay.jasper:apache-el:jar:8.0.33:compile\r\n[INFO] +- org.springframework.boot:spring-boot-starter:jar:1.5.9.RELEASE:compile\r\n[INFO] |  +- org.springframework.boot:spring-boot:jar:1.5.9.RELEASE:compile\r\n[INFO] |  +- org.springframework.boot:spring-boot-autoconfigure:jar:1.5.9.RELEASE:compile\r\n[INFO] |  +- org.springframework.boot:spring-boot-starter-logging:jar:1.5.9.RELEASE:compile\r\n[INFO] |  |  +- ch.qos.logback:logback-classic:jar:1.1.11:compile\r\n[INFO] |  |  |  \\- ch.qos.logback:logback-core:jar:1.1.11:compile\r\n[INFO] |  |  +- org.slf4j:jcl-over-slf4j:jar:1.7.25:compile\r\n[INFO] |  |  +- org.slf4j:jul-to-slf4j:jar:1.7.25:compile\r\n[INFO] |  |  \\- org.slf4j:log4j-over-slf4j:jar:1.7.25:compile\r\n[INFO] |  +- org.springframework:spring-core:jar:4.3.13.RELEASE:compile\r\n[INFO] |  \\- org.yaml:snakeyaml:jar:1.17:runtime\r\n[INFO] +- org.apache.thrift:libthrift:jar:0.11.0:compile\r\n[INFO] |  +- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n[INFO] |  +- org.apache.httpcomponents:httpclient:jar:4.5.3:compile\r\n[INFO] |  |  \\- commons-codec:commons-codec:jar:1.10:compile\r\n[INFO] |  \\- org.apache.httpcomponents:httpcore:jar:4.4.8:compile\r\n[INFO] +- org.springframework.boot:spring-boot-configuration-processor:jar:1.5.9.RELEASE:compile\r\n[INFO] |  \\- com.vaadin.external.google:android-json:jar:0.0.20131108.vaadin1:compile\r\n[INFO] +- com.google.cloud:google-cloud-datastore:jar:1.16.0:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core:jar:1.16.0:compile\r\n[INFO] |  |  +- joda-time:joda-time:jar:2.9.9:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client:jar:1.23.0:compile\r\n[INFO] |  |  +- com.google.api:api-common:jar:1.2.0:compile\r\n[INFO] |  |  +- com.google.api:gax:jar:1.17.0:compile\r\n[INFO] |  |  +- com.google.protobuf:protobuf-java-util:jar:3.5.1:compile\r\n[INFO] |  |  |  \\- com.google.code.gson:gson:jar:2.8.2:compile\r\n[INFO] |  |  +- com.google.api.grpc:proto-google-common-protos:jar:1.0.5:compile\r\n[INFO] |  |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.1.29:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-http:jar:1.16.0:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-credentials:jar:0.9.0:compile\r\n[INFO] |  |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.9.0:compile\r\n[INFO] |  |  +- com.google.oauth-client:google-oauth-client:jar:1.23.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-appengine:jar:1.23.0:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-jackson:jar:1.23.0:compile\r\n[INFO] |  |  |  \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.11:compile\r\n[INFO] |  |  +- com.google.http-client:google-http-client-jackson2:jar:1.23.0:compile\r\n[INFO] |  |  \\- com.google.api:gax-httpjson:jar:0.34.0:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-datastore-v1:jar:0.1.29:compile\r\n[INFO] |  |  \\- com.google.protobuf:protobuf-java:jar:3.4.0:compile\r\n[INFO] |  \\- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.6.0:compile\r\n[INFO] |     \\- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-monitoring:jar:0.38.0-beta:compile\r\n[INFO] |  +- com.google.cloud:google-cloud-core-grpc:jar:1.20.0:compile\r\n[INFO] |  |  +- io.grpc:grpc-protobuf:jar:1.9.0:compile\r\n[INFO] |  |  |  \\- io.grpc:grpc-protobuf-lite:jar:1.9.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-context:jar:1.9.0:compile\r\n[INFO] |  +- com.google.api.grpc:proto-google-cloud-monitoring-v3:jar:0.3.0:compile\r\n[INFO] |  +- io.grpc:grpc-netty-shaded:jar:1.9.0:compile\r\n[INFO] |  |  \\- io.grpc:grpc-core:jar:1.9.0:compile (version selected from constraint [1.9.0,1.9.0])\r\n[INFO] |  |     +- com.google.instrumentation:instrumentation-api:jar:0.4.3:compile\r\n[INFO] |  |     +- io.opencensus:opencensus-api:jar:0.10.0:compile\r\n[INFO] |  |     \\- io.opencensus:opencensus-contrib-grpc-metrics:jar:0.10.0:compile\r\n[INFO] |  +- io.grpc:grpc-stub:jar:1.9.0:compile\r\n[INFO] |  \\- io.grpc:grpc-auth:jar:1.9.0:compile\r\n[INFO] +- com.google.cloud:google-cloud-logging:jar:1.17.0:compile\r\n[INFO] |  +- com.google.api:gax-grpc:jar:1.19.0:compile\r\n[INFO] |  |  \\- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO] |  \\- com.google.api.grpc:proto-google-cloud-logging-v2:jar:0.1.30:compile\r\n[INFO] +- com.google.guava:guava:jar:23.6-jre:compile\r\n[INFO] |  +- com.google.code.findbugs:jsr305:jar:1.3.9:compile\r\n[INFO] |  +- org.checkerframework:checker-compat-qual:jar:2.0.0:compile\r\n[INFO] |  +- com.google.errorprone:error_prone_annotations:jar:2.1.3:compile\r\n[INFO] |  +- com.google.j2objc:j2objc-annotations:jar:1.1:compile\r\n[INFO] |  \\- org.codehaus.mojo:animal-sniffer-annotations:jar:1.14:compile\r\n[INFO] +- io.netty:netty-handler:jar:4.1.17.Final:compile\r\n[INFO] |  +- io.netty:netty-buffer:jar:4.1.17.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-common:jar:4.1.17.Final:compile\r\n[INFO] |  +- io.netty:netty-transport:jar:4.1.17.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-resolver:jar:4.1.17.Final:compile\r\n[INFO] |  \\- io.netty:netty-codec:jar:4.1.17.Final:compile\r\n[INFO] +- io.netty:netty-tcnative-boringssl-static:jar:2.0.7.Final:compile\r\n[INFO] +- org.apache.commons:commons-lang3:jar:3.5:compile\r\n[INFO] +- org.jsoup:jsoup:jar:1.11.2:compile\r\n[INFO] +- com.google.apis:google-api-services-cloudkms:jar:v1-rev26-1.23.0:compile\r\n[INFO] |  \\- com.google.api-client:google-api-client:jar:1.23.0:compile\r\n[INFO] |     \\- com.google.guava:guava-jdk5:jar:17.0:compile\r\n[INFO] +- org.springframework.boot:spring-boot-starter-test:jar:1.5.9.RELEASE:test\r\n[INFO] |  +- org.springframework.boot:spring-boot-test:jar:1.5.9.RELEASE:test\r\n[INFO] |  +- org.springframework.boot:spring-boot-test-autoconfigure:jar:1.5.9.RELEASE:test\r\n[INFO] |  +- com.jayway.jsonpath:json-path:jar:2.2.0:test\r\n[INFO] |  |  \\- net.minidev:json-smart:jar:2.2.1:test\r\n[INFO] |  |     \\- net.minidev:accessors-smart:jar:1.1:test\r\n[INFO] |  +- org.assertj:assertj-core:jar:2.6.0:test\r\n[INFO] |  +- org.hamcrest:hamcrest-core:jar:1.3:test\r\n[INFO] |  +- org.hamcrest:hamcrest-library:jar:1.3:test\r\n[INFO] |  +- org.skyscreamer:jsonassert:jar:1.4.0:test\r\n[INFO] |  \\- org.springframework:spring-test:jar:4.3.13.RELEASE:test\r\n[INFO] +- junit:junit:jar:4.12:test\r\n[INFO] +- org.mockito:mockito-core:jar:2.15.0:test\r\n[INFO] |  +- net.bytebuddy:byte-buddy:jar:1.7.9:test\r\n[INFO] |  +- net.bytebuddy:byte-buddy-agent:jar:1.7.9:test\r\n[INFO] |  \\- org.objenesis:objenesis:jar:2.6:test\r\n[INFO] \\- com.google.truth:truth:jar:0.39:test\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 2.005 s\r\n[INFO] Finished at: 2018-03-13T16:55:16-07:00\r\n[INFO] Final Memory: 26M/309M\r\n[INFO] ------------------------------------------------------------------------\r\n```\r\n\r\nMy project works locally on Mac in IntelliJ with individual credentials, but when I try to launch it on a GCE instance (CentOS Linux release 7.4.1708 (Core)) in Docker (Docker version 1.13.1, build 774336d/1.13.1), it produces the exception. \r\n\r\nOriginally, I did not have `netty-handler` or `netty-tcnative-boringssl-static` but I followed the troubleshooting guide at https://github.com/grpc/grpc-java/blob/master/SECURITY.md#troubleshooting and added them.\r\n\r\nI also, just out of desperation, changed the SpringBoot project to use Jetty instead of Tomcat, even though that should have been fixed in an earlier version of the java/grpc stack.\r\n\r\nMy understanding was that the new version of google-cloud-monitoring with the `grpc-netty-shaded` package should have fixed this."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3035",
        "number": 3035,
        "title": "Using Pubsub with Proxy that needs a basic authentication",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello, \r\n\r\nWe are using GCP SDK and pubsub service in our project and we'd need to go through an outbound proxy before reaching out to Google. We understand the transport for pubsub is gRPC. We are wondering if there is a way that we can configure the basic authentication for the outbound proxy via the SDK or any other way? We are aware of setting proxy HOST and PORT via environment variables but nothing related to the basic authentication for proxy though, any information on proxy authentication for pubsub is appreciated, thanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3031",
        "number": 3031,
        "title": "Logback logstash exception logging ",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "open",
        "body": "Logging of exception stacktraces for Logback have been resolved in #2765, however we are aiming to do  JSON logging to console and per default it seems this will not give us stack traces in the 'message' field of jsonPayload as required by [Formatting Errors in Stackdriver Logging](https://cloud.google.com/error-reporting/docs/formatting-error-messages). \r\n\r\nDo you have any advice on this can be done using [logstash-logback-encoder](https://github.com/logstash/logstash-logback-encoder)?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3030",
        "number": 3030,
        "title": "UnresolvedAddressException when using GRPC_PROXY_EXP",
        "labels": [
            "api: language",
            "api: vision",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using google-cloud-vision and google-cloud-language.\r\n\r\nI need to use the `GRPC_PROXY_EXP` environment variable. However due to a bug in grpc 1.9.0, the proxy variable causes an UnresolvedAddressException. This is documented at https://github.com/grpc/grpc-java/pull/4027.\r\n\r\nThe problem is fixed in 1.10.0. When will google-cloud-vision/language be updated to use grpc 1.10.0?\r\n\r\nAlternatively, is there any other way for me to use a forward proxy with these two libraries?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3027",
        "number": 3027,
        "title": "This repo does not compile in jdk9",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "*Note*: This might just be that I'm super rusty at java and am missing something silly.\r\n\r\nWhen I set my `JAVA_HOME` to a jdk9 path and `mvn compile`, I get:\r\n\r\n```\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:3.0.0:check (checkstyle) on \r\nproject google-cloud-pom: Execution checkstyle of goal \r\norg.apache.maven.plugins:maven-checkstyle-plugin:3.0.0:check failed: Plugin \r\norg.apache.maven.plugins:maven-checkstyle-plugin:3.0.0 or one of its dependencies could \r\nnot be resolved: Could not find artifact com.sun:tools:jar:1.7.0 at specified path\r\n/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/../lib/tools.jar -> [Help 1]\r\n```\r\n\r\nWhen I set my `JAVA_HOME` to a jdk8 path and `mvn compile`, it works.\r\n\r\nThis seems to be a [known issue with checkstyle](https://github.com/checkstyle/checkstyle/issues/5102). I'm not sure how [`org.apache.maven.plugins \u00bb maven-checkstyle-plugin`](https://mvnrepository.com/artifact/org.apache.maven.plugins/maven-checkstyle-plugin) (which we use) relates to github.com/checkstyle/checkstyle; their versioning seems quite different (github latest is [8.8](http://repo1.maven.org/maven2/com/puppycrawl/tools/checkstyle/), whereas [maven latest is 3.0.0](https://mvnrepository.com/artifact/org.apache.maven.plugins/maven-checkstyle-plugin) ).\r\n\r\nedit: the difference between the two seems to be that the github one is the checkstyle project itself, and the maven thing is just a [maven plugin](https://maven.apache.org/plugins/maven-checkstyle-plugin/) possibly _using_ the checkstyle project?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3025",
        "number": 3025,
        "title": "Pub/Sub: Server fails to deliver messages in a timely fashion",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I have a Pub / Sub subscription with an ack deadline of 5 minutes.\r\n\r\nStack Driver shows there 7k+ unacknowledged messages, with the oldest message over 2.5 hours old.\r\n\r\nMy code, which is calling the REST pull API directly shows that messages are flowing but very slowly. When the code pulls messages, it's only a few at a time, some with large latency values (11 minutes, 22 minutes, etc. from publish time to receive time.)\r\n\r\n`gcloud beta pubsub subscriptions pull <subscription name> --limit 1000 --auto-ack | grep eventType | wc -l` returns 0 message most of the time.\r\n\r\nI would expect that with an ack deadline of 5 minutes, I would be able to pull bursts of messages ( up to `maxMessages`) every 5 minutes.\r\n\r\nI was originally using the official Google Pub / Sub library (latest version) with the `Subscriber` class but would see random large latency issues.\r\n\r\nI have had an open issue with support for at least 2 weeks, with no resolution.\r\n\r\nThe latest feedback from support was that messages aren't getting acked in time ... which based on my logging ... is because they aren't getting delivered in time / getting delivered already past the ack deadline."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3021",
        "number": 3021,
        "title": "give Subscriber one-of resource name",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "- [ ] Change GAPIC config\r\n- [ ] Regenerate\r\n- [ ] Change `Subscriber` to use it."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3020",
        "number": 3020,
        "title": "Duplicate versions in transitive dependencies",
        "labels": [
            "api: datastore",
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "When adding google-cloud-datastore as a dependency, it drags in a lot of different versions of the same libraries.\r\n\r\nExample:\r\n```\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n    <modelVersion>4.0.0</modelVersion>\r\n\r\n    <groupId>test</groupId>\r\n    <artifactId>google-dependency-test</artifactId>\r\n    <version>1.0-SNAPSHOT</version>\r\n\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-datastore</artifactId>\r\n            <version>1.20.0</version>\r\n        </dependency>\r\n    </dependencies>\r\n\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-enforcer-plugin</artifactId>\r\n                <executions>\r\n                    <execution>\r\n                        <id>enforce</id>\r\n                        <configuration>\r\n                            <rules>\r\n                                <dependencyConvergence/>\r\n                            </rules>\r\n                        </configuration>\r\n                        <goals>\r\n                            <goal>enforce</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n</project>\r\n```\r\n\r\nWhen using maven-enforer-plugin, it will fail the build on duplicate versions and log which ones have duplicates.\r\nOutput from this is attached here: [output.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1799366/output.txt)\r\n\r\nShould this be fixed?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3019",
        "number": 3019,
        "title": "Storage integration tests failing",
        "labels": [
            "api: storage",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Last 8 commits have failed. https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/2684"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3015",
        "number": 3015,
        "title": "BigQuery getting a query job with a statistics.query.timeline.completedInputs property fails",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "Package: google-cloud-bigquery\r\nVersion: 0.38.0-beta\r\n\r\n```\r\n[ERROR] Tests run: 5, Failures: 0, Errors: 1, Skipped: 1, Time elapsed: 8.771 s <<< FAILURE! - in com.example.bigquery.QuerySampleIT\r\n[ERROR] testPermanentTableQuery(com.example.bigquery.QuerySampleIT)  Time elapsed: 2.743 s  <<< ERROR!\r\ncom.google.cloud.bigquery.BigQueryException: java.lang.IllegalArgumentException: key completedInputs\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: key completedInputs\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: key completedInputs, field private com.google.api.services.bigquery.model.JobStatistics com.google.api.services.bigquery.model.Job.statistics\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: key completedInputs, field private com.google.api.services.bigquery.model.JobStatistics2 com.google.api.services.bigquery.model.JobStatistics.query\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: key completedInputs, field private java.util.List com.google.api.services.bigquery.model.JobStatistics2.timeline\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: key completedInputs, field private java.util.List com.google.api.services.bigquery.model.JobStatistics2.timeline\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: key completedInputs, field private java.lang.Integer com.google.api.services.bigquery.model.QueryTimelineSample.completedInputs\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\nCaused by: java.lang.IllegalArgumentException: number field formatted as a JSON string must use the @JsonString annotation\r\n\tat com.example.bigquery.QuerySampleIT.testPermanentTableQuery(QuerySampleIT.java:111)\r\n\r\n[ERROR] Errors: \r\n[ERROR]   QuerySampleIT.testPermanentTableQuery:111 ? BigQuery java.lang.IllegalArgument...\r\n[ERROR] Tests run: 11, Failures: 0, Errors: 1, Skipped: 1\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.20.1:verify (default) on project bigquery-google-cloud-samples: There are test failures.\r\n```\r\n\r\nSee: https://github.com/GoogleCloudPlatform/java-docs-samples/pull/1055#issuecomment-371636373\r\n\r\nCode sample where this issue is seen:\r\n\r\n```java\r\n  public static void runQueryPermanentTable(\r\n      String queryString,\r\n      String destinationDataset,\r\n      String destinationTable,\r\n      boolean allowLargeResults) throws TimeoutException, InterruptedException {\r\n    QueryJobConfiguration queryConfig =\r\n        QueryJobConfiguration.newBuilder(queryString)\r\n            // Save the results of the query to a permanent table. See:\r\n            // https://cloud.google.com/bigquery/docs/writing-results#permanent-table\r\n            .setDestinationTable(TableId.of(destinationDataset, destinationTable))\r\n            // Allow results larger than the maximum response size.\r\n            // If true, a destination table must be set. See: \r\n            // https://cloud.google.com/bigquery/docs/writing-results#large-results\r\n            .setAllowLargeResults(allowLargeResults)\r\n            .build();\r\n\r\n    runQuery(queryConfig);\r\n  }\r\n\r\n  public static void runQuery(QueryJobConfiguration queryConfig)\r\n      throws TimeoutException, InterruptedException {\r\n    BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\n\r\n    // Create a job ID so that we can safely retry.\r\n    JobId jobId = JobId.of(UUID.randomUUID().toString());\r\n    Job queryJob = bigquery.create(JobInfo.newBuilder(queryConfig).setJobId(jobId).build());\r\n\r\n    // Wait for the query to complete.\r\n    queryJob = queryJob.waitFor();\r\n\r\n    // Check for errors\r\n    if (queryJob == null) {\r\n      throw new RuntimeException(\"Job no longer exists\");\r\n    } else if (queryJob.getStatus().getError() != null) {\r\n      // You can also look at queryJob.getStatus().getExecutionErrors() for all\r\n      // errors, not just the latest one.\r\n      throw new RuntimeException(queryJob.getStatus().getError().toString());\r\n    }\r\n\r\n    // Get the results.\r\n    TableResult result = queryJob.getQueryResults();\r\n\r\n    // Print all pages of the results.\r\n    while (result != null) {\r\n      for (List<FieldValue> row : result.iterateAll()) {\r\n        for (FieldValue val : row) {\r\n          System.out.printf(\"%s,\", val.toString());\r\n        }\r\n        System.out.printf(\"\\n\");\r\n      }\r\n\r\n      result = result.getNextPage();\r\n    }\r\n  }\r\n```\r\n\r\nCode: https://github.com/GoogleCloudPlatform/java-docs-samples/blob/af753bb7bfe3b72307ec42cab7cefe75af2b5bd2/bigquery/cloud-client/src/main/java/com/example/bigquery/QuerySample.java\r\n\r\nQuery used in test:\r\n```sql\r\nSELECT corpus FROM `bigquery-public-data.samples.shakespeare` GROUP BY corpus;\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3013",
        "number": 3013,
        "title": "Interop w/ other Google HTTP clients",
        "labels": [
            "auth",
            "type: feature request"
        ],
        "state": "open",
        "body": "GCP and other Google products have also published ready to use HTTP clients: https://mvnrepository.com/artifact/com.google.apis\r\n\r\nWith a little interop configurations, it can be very easy to consume these client libraries using google-cloud-java's authentication bootstrap."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3012",
        "number": 3012,
        "title": "Re-declare BigQuery as GA",
        "labels": [
            "api: bigquery",
            "priority: p1"
        ],
        "state": "closed",
        "body": "We tried to bump BigQuery to GA in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2982 , but it got erased in the version bump of the release at https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3004/files#diff-9fa081a8634fe9e631cd85762bb9ceb9 . The thing we need to do differently is to change the `released-version` version in the versions.txt file for bigquery instead of only `current-version`, since the version bump script bases the bump on `released-version`. Like last time, we shouldn't update the README files until release. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3010",
        "number": 3010,
        "title": "Copying file to storage bucket always times out/HTTP/HTTPS proxy setting",
        "labels": [],
        "state": "closed",
        "body": "I am trying to copy a file to storage bucket, but the operation always times out.\r\nI tried increasing various time out parameters but its not helping.\r\nFile size is less than 150kb.\r\nPlease refer the below code which times out.\r\nstorage.list() method times out.\r\n\r\n\t`private void uploadFile(String bucketName, String content) {\r\n        HttpTransportOptions transportOptions = StorageOptions.getDefaultHttpTransportOptions();\r\n        transportOptions = transportOptions.toBuilder().setConnectTimeout(60000).setReadTimeout(60000)\r\n                .build();\r\n        StorageOptions storageOptions = StorageOptions.newBuilder()\r\n                .setRetrySettings(retrySettings())\r\n                .setTransportOptions(transportOptions)\r\n                .build();\r\n        Storage storage = storageOptions.getService();\r\n\r\n        Page<Bucket> buckets = storage.list(BucketListOption.pageSize(10), BucketListOption.prefix(bucketName));\r\n        for (Bucket bucket : buckets.iterateAll()) {\r\n            InputStream inputStream = new ByteArrayInputStream(content.getBytes());\r\n            bucket.create(\"file_name\", inputStream, \"text/plain\");\r\n            break;\r\n        }\r\n    }\r\n    private RetrySettings retrySettings() {\r\n        return RetrySettings.newBuilder().setMaxAttempts(10)\r\n                .setMaxRetryDelay(Duration.ofMillis(30000L))\r\n                .setTotalTimeout(Duration.ofMillis(120000L))\r\n                .setInitialRetryDelay(Duration.ofMillis(250L))\r\n                .setRetryDelayMultiplier(1.0)\r\n                .setInitialRpcTimeout(Duration.ofMillis(120000L))\r\n                .setRpcTimeoutMultiplier(1.0)\r\n                .setMaxRpcTimeout(Duration.ofMillis(120000L))\r\n                .build();\r\n    }`\r\n\t\r\n\t\r\nError stack:\r\n\t12:12:27.410 [pool-3-thread-1] ERROR org.springframework.scheduling.support.TaskUtils$LoggingErrorHandler [] - Unexpected error occurred in scheduled task.\r\n\tcom.google.cloud.storage.StorageException: connect timed out\r\n\t\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:219) ~[google-cloud-storage-1.19.0.jar!/:1.19.0]\r\n\t\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.list(HttpStorageRpc.java:314) ~[google-cloud-storage-1.19.0.jar!/:1.19.0]\r\n\t\tat com.google.cloud.storage.StorageImpl$6.call(StorageImpl.java:272) ~[google-cloud-storage-1.19.0.jar!/:1.19.0]\r\n\t\tat com.google.cloud.storage.StorageImpl$6.call(StorageImpl.java:269) ~[google-cloud-storage-1.19.0.jar!/:1.19.0]\r\n\t\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89) ~[gax-1.19.0.jar!/:1.19.0]\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74) ~[google-cloud-core-1.19.0.jar!/:1.19.0]\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51) ~[google-cloud-core-1.19.0.jar!/:1.19.0]\r\n\tat com.google.cloud.storage.StorageImpl.listBuckets(StorageImpl.java:268) ~[google-cloud-storage-1.19.0.jar!/:1.19.0]\r\n\tat com.google.cloud.storage.StorageImpl.list(StorageImpl.java:257) ~[google-cloud-storage-1.19.0.jar!/:1.19.0]\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3003",
        "number": 3003,
        "title": "Create new efficient batching implementation for Pub/Sub and Logging",
        "labels": [
            "api: bigtable",
            "api: logging",
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": "Try to support BigTable too. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3002",
        "number": 3002,
        "title": "Refactor Pub/sub to use GAPIC client instead of raw Pub/Sub",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "open",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3001",
        "number": 3001,
        "title": "Refactor Spanner to use GAPIC client instead of raw grpc stubs",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3000",
        "number": 3000,
        "title": "Convert Spanner to use OperationFuture from GAX",
        "labels": [
            "api: spanner",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Deprecate https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/Operation.java , use https://github.com/googleapis/gax-java/blob/master/gax/src/main/java/com/google/api/gax/longrunning/OperationFuture.java instead."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2999",
        "number": 2999,
        "title": "Convert Spanner to use Watchdog from GAX",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Deprecate https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/spi/v1/WatchdogInterceptor.java , use https://github.com/googleapis/gax-java/blob/master/gax/src/main/java/com/google/api/gax/rpc/Watchdog.java instead.\r\n\r\nIf Spanner uses watchdogs for client streaming or bidi streaming cases, then analogs to https://github.com/googleapis/gax-java/blob/master/gax/src/main/java/com/google/api/gax/rpc/WatchdogServerStreamingCallable.java will need to be created in GAX. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2993",
        "number": 2993,
        "title": "Version management table in README.md is due for an update",
        "labels": [
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "stops at 0.30.0\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2992",
        "number": 2992,
        "title": "bigtable: update javadocs for settings to describe the defaults",
        "labels": [
            "api: bigtable",
            "type: docs"
        ],
        "state": "open",
        "body": "This is extracted from: https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2986/files/5ce135c8e7f55fd510382574357b14a775f5619b#r171952810\r\n\r\nThe javadocs should document the default timeouts\r\n\r\n\r\nPlease assign this to me"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2973",
        "number": 2973,
        "title": "Compute API: NPE in StorageImageConfiguration",
        "labels": [
            ":rotating_light:",
            "api: compute",
            "priority: p2",
            "status: blocked",
            "type: question"
        ],
        "state": "closed",
        "body": "Steps to reproduce:\r\n* Execute `compute.listImages().iterateAll()`\r\n\r\nIt throws the following exception:\r\n```java\r\njava.lang.NullPointerException\r\n        at com.google.cloud.compute.StorageImageConfiguration$Builder.<init>(StorageImageConfiguration.java:69)\r\n        at com.google.cloud.compute.StorageImageConfiguration$Builder.<init>(StorageImageConfiguration.java:49)\r\n        at com.google.cloud.compute.StorageImageConfiguration.fromPb(StorageImageConfiguration.java:202)\r\n        at com.google.cloud.compute.ImageConfiguration.fromPb(ImageConfiguration.java:188)\r\n        at com.google.cloud.compute.ImageInfo$BuilderImpl.<init>(ImageInfo.java:172)\r\n        at com.google.cloud.compute.Image.fromPb(Image.java:212)\r\n        at com.google.cloud.compute.ComputeImpl$40.apply(ComputeImpl.java:1259)\r\n        at com.google.cloud.compute.ComputeImpl$40.apply(ComputeImpl.java:1256)\r\n        at com.google.common.collect.Iterators$7.transform(Iterators.java:750)\r\n        at com.google.common.collect.TransformedIterator.next(TransformedIterator.java:47)\r\n        at com.google.cloud.PageImpl$PageIterator.computeNext(PageImpl.java:72)\r\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:145)\r\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:140)\r\n        at jetbrains.buildServer.clouds.google.connector.GoogleApiConnectorImpl$getImagesAsync$1.doResume(GoogleApiConnectorImpl.kt:312)\r\n```\r\n\r\nAccording to java docs `com.google.api.services.compute.model.Image#getRawDisk` could return null, so it's not safe to execute `imagePb.getRawDisk().getContainerType() != null`:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-compute/src/main/java/com/google/cloud/compute/deprecated/StorageImageConfiguration.java#L69-L73\r\n\r\n\r\nOriginally from: https://youtrack.jetbrains.com/issue/TW-53938"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2962",
        "number": 2962,
        "title": "Storage IT intermittently timing out (ITStorageTest: testListBlobRequesterPays)",
        "labels": [
            "api: storage",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "\r\nhttps://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/1745\r\nhttps://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/1671\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2961",
        "number": 2961,
        "title": "Firestore IT broken",
        "labels": [
            "api: firestore",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "The Firestore integration tests timed out with the latest commit which included Firestore changes:\r\n\r\nhttps://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/1742\r\n\r\nWe need to do a release today - the Firestore changes probably should be rolled back."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2960",
        "number": 2960,
        "title": "new Thread is not supported when calling GAE APIs",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm using Java 8 and:\r\n\r\n`com.google.appengine:appengine-api-1.0-sdk:1.9.62`\r\n\r\nand this import:\r\n\r\n`import com.google.appengine.api.datastore.*;`\r\n\r\nI ran some code to test storing data into the Datastore. My testing is being done locally. This works fine if you perform the operation on the same thread that the servlet's doGet is on. I then created a runnable and ran the same code from within the runnable. I created the thread like this:\r\n`\r\nnew Thread(myRunnable).start(); `\r\n\r\nAn exception was generated when the code in the runnable attempted to do this:\r\n\r\n`Entity someEntity = new Entity(\"myEntity\", \"someName\");`\r\n\r\nThe exception that got generated was:\r\n\r\n> No API environment is registered for this thread\r\n\r\nThis exception occurs in the ApiProxy.java class that is internal to the app engine sdk library.\r\n\r\nI then replaced the line of code for creating the thread with:\r\n\r\nThreadManager.currentRequestThreadFactory().newThread(myRunnable)).start();\r\n\r\nThis worked fine. This tells me that you cannot use *new Thread* but need to use the newThread method. The documentation however indicates that using \"new Thread\" is allowed:\r\n\r\n> With the Java 8 runtime, you can create threads using App Engine's ThreadManager API and Java's built-in APIs, for example new Thread().\r\n\r\nhttps://cloud.google.com/appengine/docs/standard/java/runtime-java8\r\n\r\nThis however is wrong. In the deprecated document in Java 7, it even states that you cannot use \"new Thread\", yet that statement was removed from the Java 8 doc. It should not have been. I recommend removing that statement as it is misleading and developers using it will end up with this exception. The deprecated statement should be reinserted to indicate that \"new Thread\" is not allowed when calling GAE APIs. new Thread does however work for normal Java stuff that isn't related to the GAE APIs."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2957",
        "number": 2957,
        "title": "bigtable: Rename Mutation -> Mutations",
        "labels": [
            "api: bigtable",
            "type: feature request"
        ],
        "state": "closed",
        "body": "As reported by @kevinsi4508:\r\n\r\n`Mutation` represents a set of mutations for a row, so it would be less confusing if it was pluralized.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2952",
        "number": 2952,
        "title": "Bigquery API should support external Sheets-based tables",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "open",
        "body": "Google Sheets based tables don't currently show up via the java API. There's also no way to create new tables with sheets definitions. It would be nice if this was supported."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2951",
        "number": 2951,
        "title": "Latest release missing key Classes",
        "labels": [
            "api: language",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello, I noticed that the latest jar on the maven repo doesn't contain all of the classes used and referenced in the documentation. \r\n\r\nE.g., to test, d/l the jar: http://central.maven.org/maven2/com/google/cloud/google-cloud-language/1.17.0/google-cloud-language-1.17.0.jar. Extract it, and I see this:\r\n\r\n```\r\n~/Downloads/com/google/cloud/language$ ll -R v1\r\ntotal 40\r\n-rw-r--r--  1 j  staff    23K Feb 20 10:51 LanguageServiceClient.java\r\n-rw-r--r--  1 j  staff   9.4K Feb 20 10:51 LanguageServiceSettings.java\r\n-rw-r--r--  1 j  staff   1.3K Feb 20 10:51 package-info.java\r\ndrwxr-xr-x  5 j  staff   160B Feb 13 16:40 stub/\r\n\r\nv1/stub:\r\ntotal 36\r\n-rw-r--r--  1 j  staff    12K Feb 20 10:51 GrpcLanguageServiceStub.java\r\n-rw-r--r--  1 j  staff   3.0K Feb 20 10:51 LanguageServiceStub.java\r\n-rw-r--r--  1 j  staff    17K Feb 20 10:51 LanguageServiceStubSettings.java\r\n```\r\n\r\nIt's missing key classes like [Document](https://cloud.google.com/natural-language/docs/reference/rpc/google.cloud.language.v1#google.cloud.language.v1.Document). "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2946",
        "number": 2946,
        "title": "Google Cloud Java Libraries for 32 bit",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "The GIT links state that X86_64 Bit is supported. Does it mean that 32 bit OS versions are not supported."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2945",
        "number": 2945,
        "title": "Firestore integration test ITSystemTest.addAndRemoveFields is failing intermittently",
        "labels": [],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/1543\r\nhttps://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/1365\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2942",
        "number": 2942,
        "title": "Upgrade google-api-services-cloudresourcemanager version to v1-rev6-1.22.0",
        "labels": [
            "dependencies",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Currently the BOM is specifying version `v1beta1-rev10-1.21.0`, which is pretty old and conflicts with current versions of libraries, such as `beam-runners-google-cloud-dataflow-java`.\r\n\r\nSee https://github.com/spring-cloud/spring-cloud-gcp/issues/442."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2932",
        "number": 2932,
        "title": "Mark videointelligence v1beta1 as deprecated",
        "labels": [
            "status: blocked",
            "type: feature request"
        ],
        "state": "open",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-video-intelligence/src/main/java/com/google/cloud/videointelligence/v1beta1\r\n\r\nThis may require work in toolkit to support. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2928",
        "number": 2928,
        "title": "Document gRPC and common classpath conflicts troubleshooting",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "For ALPN error, refer to [gRPC troubleshooting guide](https://github.com/grpc/grpc-java/blob/master/SECURITY.md#troubleshooting).\r\n\r\nAdd additional documentation for Guava and Protobuf related errors, and examples to shade."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2926",
        "number": 2926,
        "title": "Add IntelliJ plugin steps to the README",
        "labels": [
            "type: docs",
            "type: feature request"
        ],
        "state": "closed",
        "body": "@garrettjonesgoogle, as mentioned:\r\n\r\nWe've recently added support for the google-cloud-java libraries in IntelliJ via the [Cloud Tools for IntelliJ plugin](https://github.com/GoogleCloudPlatform/google-cloud-intellij) (sample screenshot below). This includes:\r\n\r\n- Discovering available Java client libraries and adding them to the project (Maven)\r\n- Enabling GCP APIs from the IDE\r\n- Managing service accounts from the IDE (not yet released)\r\n- BOM syncing (diamond dependency problem support) (coming soon)\r\n\r\nIt would be great to include a section on this in the google-cloud-java Github page with a link to the [IntelliJ Documentation](https://cloud.google.com/tools/intellij/docs/client-libraries) for this feature. \r\n\r\n![image](https://user-images.githubusercontent.com/1735744/36447977-0b93b322-1654-11e8-97bf-2ca2c103408e.png)\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2924",
        "number": 2924,
        "title": "Add grpc-core to google-cloud-bom",
        "labels": [
            "dependencies"
        ],
        "state": "closed",
        "body": "This should be added, as per https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2890#issuecomment-367000167 ."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2921",
        "number": 2921,
        "title": "Vision API creating Annotator client",
        "labels": [
            "api: vision",
            "auth",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI am trying to find a documentation for how to create an annotator client with a credentials file. I do not want to use goolge default credentials. When using the translate API, I load my credentials file like so:\r\n\r\n ```\r\nCredentials creds = ServiceAccountCredentials.fromStream(new FileInputStream(\"/path/to/credential/file\"));\r\nreturn TranslateOptions.newBuilder().setCredentials(creds).build().getService();\r\n```\r\n\r\nWhat is the equivalent way in Vision?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2918",
        "number": 2918,
        "title": "Eliminate all transitive guava-jdk5 dependencies",
        "labels": [
            "dependencies",
            "status: blocked",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Google Cloud dependencies are pulling in multiple incompatible versions of Guava.  Most depend on newer versions of Guava like ```com.google.guava:guava:20```, but others are pulling in ```com.google.guava:guava-jdk5:17.0```.  When I miss excluding that ancient jdk5 version from somewhere I end up with a bunch of classloader issues like:\r\n\r\n```\r\njava.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;J)V\r\n```\r\n\r\nFor some reason I see this mostly with Cloud KMS (```com.google.apis:google-api-services-cloudkms```), but it actually appears to be coming from ```com.google.api-client:google-api-client:1.23.0```.  See http://mvnrepository.com/artifact/com.google.api-client/google-api-client/1.23.0 for example.\r\n\r\nI'd be happy to contribute a PR myself, but I can't seem to find the right repo."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2917",
        "number": 2917,
        "title": "bigtable: rename convenience client methods to end with Async",
        "labels": [],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2861#discussion_r168898288"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2916",
        "number": 2916,
        "title": "bigtable: rename the `wrappers` package to something more meaningful",
        "labels": [],
        "state": "closed",
        "body": "See discussion in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2861#discussion_r168528478"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2912",
        "number": 2912,
        "title": "Logging with google-cloud-logging-logback on K8S: resources.labels are empty",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm trying the used structured logging with `google-cloud-logging-logback` on Kubernetes.\r\nMost of the resource labels are empty, except `project_id` and `zone`:\r\n```\r\n resource: {\r\n  labels: {\r\n   cluster_name: \"\"    \r\n   container_name: \"\"    \r\n   instance_id: \"\"    \r\n   namespace_id: \"\"    \r\n   pod_id: \"\"    \r\n   project_id: \"<project ID>\"    \r\n   zone: \"<zone>\"    \r\n  }\r\n  type: \"container\"   \r\n }\r\n```\r\nI guess the reason for this is that only `project_id` and `zone` are configured for resource of type `container`: \r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/937e49d7159c9327255e167f6339c51bb7372c37/google-cloud-logging/src/main/java/com/google/cloud/logging/MonitoredResourceUtil.java#L95\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2911",
        "number": 2911,
        "title": "Bucket logging configuration using library",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "open",
        "body": "I was wondering whether it is possible to set the bucket logging in the target bucket with the access logs are then stored in the bucket log as it is explained here https://cloud.google.com/storage/docs/access-logs but this is only possible using gsutil. There is the option for XML API here https://cloud.google.com/storage/docs/xml-api/put-bucket-logging but not sure if there is one in this google-cloud-java storage library. If it is possible how do I do it?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2904",
        "number": 2904,
        "title": "Logging - HttpRequest is missing latency field",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "According to [LogEntry documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) `latency` field should be present, however it's not (https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-logging/src/main/java/com/google/cloud/logging/HttpRequest.java).\r\n\r\nIs that on purpose and I should create custom field when logging response time or will it be added?\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2902",
        "number": 2902,
        "title": "Method listing the contents of a bucket in FakeStorageRpc does not use bucket name",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nThe implementation of the method `list(String bucket, Map<Option, ?> options)` in `FakeStorageRpc` does not use `bucket` parameter to retrieve the files inside the bucket passed as parameter (see [FakeStorageRpc.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.34.0/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/testing/FakeStorageRpc.java#L122)). I'm using version 0.34.0, but it seems like in previous versions the behaviour was similar. Am I missing something ?\r\n\r\nAs a consequence, when using `LocalStorageHelper` (using `FakeStorageRpc`) for local testing purposes, the following code does not retrieve only the files in the bucket passed as parameter, but all files in all created buckets : \r\n\r\n```\r\nStorage storage = LocalStorageHelper.customOptions(true).getService()\r\n\r\n[...] // creating dummy files in two separate buckets (b1 and b2)\r\n\r\nstorage.list(\"b1\") // returns all files in b1 and b2\r\n```\r\n\r\nI double checked in the doc, listing the contents of a bucket is however [defined as a supported operation](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.34.0/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/testing/FakeStorageRpc.java#L53)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2901",
        "number": 2901,
        "title": "DatastoreReader missing method overloads with the ReadOption parameter",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "`Datastore` has `Entity get(Key key, ReadOption... options);` but this method is missing from the `DatastoreReader` interface."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2899",
        "number": 2899,
        "title": "External user feedback regarding the GCS Download Object sample",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "This feedback came to the GCS Docs as bug 68217327.\r\n\r\nThe feedback applies to the Java sample for downloading objects from GCS, found at https://cloud.google.com/storage/docs/object-basics#download\r\n\r\nThe body of the feedback was:\r\n\"The example to download an object already has a populated blobId. What is a blobId? How do I make one?\"\r\n\r\nI believe they're referring to the fact that the download sample takes a BlobId parameter and assumes that users of the sample will know what a BlobId is."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2897",
        "number": 2897,
        "title": "Why is Compute going away in favor of Compute Engine Client Libraries? ",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Compute Engine Client Libraries are in maintenance mode and not receiving any updates as stated in its github project page (https://github.com/google/google-api-java-client), so why is the Compute library going away in favour of that? \r\nWhat are the plans for Compute support? Is it going away completely at some point? Is it going to be replaced with something else?\r\n\r\nThanks in advance"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2896",
        "number": 2896,
        "title": "WriteChannel.capture surprisingly may do I/O",
        "labels": [
            "api: core",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "`WriteChannel.capture` as implemented by `BaseWriteChannel` flushes the buffer before capturing. While this seems reasonable to reduce the size of the captured state, it is surprising since the javadoc doesn't mention this at all - intuitively, it does not seem like a method that just captures `RestorableState` would do blocking I/O, so the javadoc should be extended to clarify this point or the flushing should be removed.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/WriteChannel.java#L40"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2895",
        "number": 2895,
        "title": "BaseWriteChannel.setChunkSize rounds down to the nearest kilobyte instead of up",
        "labels": [
            "api: core",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Currently, when a user sets a chunk size, the channel rounds this down to the nearest multiple of `MIN_CHUNK_SIZE` (256K)\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/BaseWriteChannel.java#L106\r\n\r\nThis does not seem to be consistent with its javadoc, which says it sets the minimum amount of data sent in an RPC\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/WriteChannel.java#L34\r\n\r\nWith the rounding down, the RPC will actually have less than the minimum. I'm not sure why the rounding to chunk size multiple is needed, but if it can't be removed, it should round up instead of down."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2893",
        "number": 2893,
        "title": "Table-valued functions are not supported when SQL query which has JS based function",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi Team,\r\n         I have included the below dependency in my java app\r\n**<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-bigquery</artifactId>\r\n  <version>0.34.0-beta</version>\r\n</dependency>**\r\n\r\ni am trying to execute below sql \r\n\r\n**SELECT COUNT(*) as adj_count, adjective\r\nFROM \r\n JS(\r\n (SELECT tokens FROM pcf_sb_1_1517930560980472067.pcf_gcp_twitter_ds_table ),\r\n tokens,\r\n \"[{ name:'adjective', type: 'string'}]\",\r\n \"function(row, emit) { \r\n   try {\r\n     x = JSON.parse(row.tokens);\r\n     x.forEach(function(token) {\r\n       if (token.partOfSpeech.tag === 'ADJ') {\r\n         emit({ adjective: token.lemma.toLowerCase() });\r\n       }\r\n     });\r\n   } catch (e) {}\r\n }\" \r\n )\r\nGROUP BY adjective\r\nORDER BY adj_count DESC\r\nLIMIT 100**\r\n\r\n\r\nI am getting below exception when i executed the above query,\r\n\r\n**Exception in thread \"main\" com.google.cloud.bigquery.BigQueryException: Table-valued functions are not supported at [3:2]\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:98)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.getQueryResults(HttpBigQueryRpc.java:393)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$22.call(BigQueryImpl.java:617)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$22.call(BigQueryImpl.java:614)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.getQueryResults(BigQueryImpl.java:614)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.getQueryResults(BigQueryImpl.java:606)\r\n\tat com.google.cloud.bigquery.Job$1.call(Job.java:325)\r\n\tat com.google.cloud.bigquery.Job$1.call(Job.java:322)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.poll(RetryHelper.java:63)\r\n\tat com.google.cloud.bigquery.Job.waitForQueryResults(Job.java:321)\r\n\tat com.google.cloud.bigquery.Job.waitFor(Job.java:240)\r\n\tat com.cts.tweet.analysis.SimpleApp.main(SimpleApp.java:86)\r\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request\r\n{\r\n  \"code\" : 400,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"location\" : \"query\",\r\n    \"locationType\" : \"other\",\r\n    \"message\" : \"Table-valued functions are not supported at [3:2]\",\r\n    \"reason\" : \"invalidQuery\"\r\n  } ],\r\n  \"message\" : \"Table-valued functions are not supported at [3:2]\"\r\n}\r\n\tat com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\r\n\tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\n\tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.getQueryResults(HttpBigQueryRpc.java:391)\r\n\t... 15 more**\r\n\r\n\tI was able to execute normal SQL query using above dependency but not able to execute it above mentioned SQL..\r\n\r\n\tPlease clarify this issue."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2892",
        "number": 2892,
        "title": "documentation issues: for transaction.update()",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "https://googlecloudplatform.github.io/google-cloud-java/0.34.0/apidocs/com/google/cloud/datastore/DatastoreWriter.html#update-com.google.cloud.datastore.Entity...-\r\n\r\nthe methods return value is void and it is documented to not throw anything. Still the documentation says \"The operation will fail if an entity with the same key does not already exist.\".\r\n\r\nHow will it fail?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2890",
        "number": 2890,
        "title": "Dependency conflicts with Apache Beam Cloud Dataflow runner",
        "labels": [
            "dependencies",
            "status: blocked",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, I'm running into the following exception when using Firestore:\r\n```\r\njava.lang.NoSuchMethodError: com.google.auth.oauth2.ServiceAccountCredentials.getProjectId()Ljava/lang/String;\r\n\r\n\tat com.google.firebase.FirebaseApp.getProjectId(FirebaseApp.java:307)\r\n\tat com.google.firebase.ImplFirebaseTrampolines.getProjectId(ImplFirebaseTrampolines.java:43)\r\n\tat com.google.firebase.cloud.FirestoreClient.<init>(FirestoreClient.java:32)\r\n\tat com.google.firebase.cloud.FirestoreClient.<init>(FirestoreClient.java:26)\r\n\tat com.google.firebase.cloud.FirestoreClient$FirestoreClientService.<init>(FirestoreClient.java:81)\r\n\tat com.google.firebase.cloud.FirestoreClient.getInstance(FirestoreClient.java:71)\r\n\tat com.google.firebase.cloud.FirestoreClient.getFirestore(FirestoreClient.java:64)\r\n\tat com.google.firebase.cloud.FirestoreClient.getFirestore(FirestoreClient.java:52)\r\n```\r\n\r\nMy pom.xml file:\r\n\r\n```\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n         xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n    ...\r\n    <dependencies>\r\n        <dependency>\r\n            <groupId>org.slf4j</groupId>\r\n            <artifactId>slf4j-jdk14</artifactId>\r\n            <version>1.7.25</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.intellij</groupId>\r\n            <artifactId>annotations</artifactId>\r\n            <version>12.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.guava</groupId>\r\n            <artifactId>guava</artifactId>\r\n            <version>24.0-jre</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.auto.value</groupId>\r\n            <artifactId>auto-value</artifactId>\r\n            <version>1.5</version>\r\n            <scope>provided</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.assertj</groupId>\r\n            <artifactId>assertj-core</artifactId>\r\n            <version>3.9.0</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.junit.jupiter</groupId>\r\n            <artifactId>junit-jupiter-engine</artifactId>\r\n            <version>5.0.3</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.junit.jupiter</groupId>\r\n            <artifactId>junit-jupiter-params</artifactId>\r\n            <version>5.0.3</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.hamcrest</groupId>\r\n            <artifactId>hamcrest-all</artifactId>\r\n            <version>1.3</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.jsoup</groupId>\r\n            <artifactId>jsoup</artifactId>\r\n            <version>1.11.2</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.beam</groupId>\r\n            <artifactId>beam-sdks-java-core</artifactId>\r\n            <version>2.2.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.beam</groupId>\r\n            <artifactId>beam-runners-direct-java</artifactId>\r\n            <version>2.2.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.beam</groupId>\r\n            <artifactId>beam-runners-google-cloud-dataflow-java</artifactId>\r\n            <version>2.2.0</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>org.apache.beam</groupId>\r\n            <artifactId>beam-runners-google-cloud-dataflow-java</artifactId>\r\n            <version>2.2.0</version>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.firebase</groupId>\r\n            <artifactId>firebase-admin</artifactId>\r\n            <version>5.8.0</version>\r\n        </dependency>\r\n    </dependencies>\r\n</project>\r\n```\r\n\r\nand output of `mvn dependency:tree`\r\n\r\n```\r\ncom.canigraduate.uchicago:scraper:jar:1.0-SNAPSHOT\r\n+- org.slf4j:slf4j-jdk14:jar:1.7.25:compile\r\n|  \\- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n+- com.intellij:annotations:jar:12.0:compile\r\n+- com.google.guava:guava:jar:24.0-jre:compile\r\n|  +- com.google.code.findbugs:jsr305:jar:1.3.9:compile\r\n|  +- org.checkerframework:checker-compat-qual:jar:2.0.0:compile\r\n|  +- com.google.errorprone:error_prone_annotations:jar:2.1.3:compile\r\n|  +- com.google.j2objc:j2objc-annotations:jar:1.1:compile\r\n|  \\- org.codehaus.mojo:animal-sniffer-annotations:jar:1.14:compile\r\n+- com.google.auto.value:auto-value:jar:1.5:provided\r\n+- org.assertj:assertj-core:jar:3.9.0:test\r\n+- org.junit.jupiter:junit-jupiter-engine:jar:5.0.3:test\r\n|  +- org.apiguardian:apiguardian-api:jar:1.0.0:test\r\n|  +- org.junit.platform:junit-platform-engine:jar:1.0.3:test\r\n|  |  +- org.junit.platform:junit-platform-commons:jar:1.0.3:test\r\n|  |  \\- org.opentest4j:opentest4j:jar:1.0.0:test\r\n|  \\- org.junit.jupiter:junit-jupiter-api:jar:5.0.3:test\r\n+- org.junit.jupiter:junit-jupiter-params:jar:5.0.3:test\r\n+- org.hamcrest:hamcrest-all:jar:1.3:test\r\n+- org.jsoup:jsoup:jar:1.11.2:compile\r\n+- org.apache.beam:beam-sdks-java-core:jar:2.2.0:compile\r\n|  +- com.fasterxml.jackson.core:jackson-core:jar:2.8.9:compile\r\n|  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.8.9:compile\r\n|  +- com.fasterxml.jackson.core:jackson-databind:jar:2.8.9:compile\r\n|  +- org.apache.avro:avro:jar:1.8.2:compile\r\n|  |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.13:compile\r\n|  |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.13:compile\r\n|  |  +- com.thoughtworks.paranamer:paranamer:jar:2.7:compile\r\n|  |  +- org.apache.commons:commons-compress:jar:1.8.1:compile\r\n|  |  \\- org.tukaani:xz:jar:1.5:compile\r\n|  +- org.xerial.snappy:snappy-java:jar:1.1.4:compile\r\n|  \\- joda-time:joda-time:jar:2.4:compile\r\n+- org.apache.beam:beam-runners-direct-java:jar:2.2.0:compile\r\n+- org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.2.0:compile\r\n|  +- org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:jar:2.2.0:compile\r\n|  |  +- com.google.cloud.bigdataoss:gcsio:jar:1.4.5:compile\r\n|  |  \\- com.google.apis:google-api-services-cloudresourcemanager:jar:v1-rev6-1.22.0:compile\r\n|  +- org.apache.beam:beam-sdks-common-runner-api:jar:2.2.0:compile\r\n|  |  +- com.google.protobuf:protobuf-java:jar:3.2.0:compile\r\n|  |  +- io.grpc:grpc-core:jar:1.2.0:compile\r\n|  |  |  +- io.grpc:grpc-context:jar:1.2.0:compile\r\n|  |  |  \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n|  |  +- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n|  |  |  +- com.google.protobuf:protobuf-java-util:jar:3.2.0:compile\r\n|  |  |  \\- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n|  |  \\- io.grpc:grpc-stub:jar:1.2.0:compile\r\n|  +- org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.2.0:compile\r\n|  |  +- org.apache.beam:beam-sdks-java-extensions-protobuf:jar:2.2.0:compile\r\n|  |  +- com.google.apis:google-api-services-bigquery:jar:v2-rev355-1.22.0:compile\r\n|  |  +- com.google.api:gax-grpc:jar:0.20.0:compile\r\n|  |  |  +- com.google.api:gax:jar:1.3.1:compile\r\n|  |  |  \\- org.threeten:threetenbp:jar:1.3.3:compile\r\n|  |  +- com.google.cloud:google-cloud-core-grpc:jar:1.2.0:compile\r\n|  |  +- com.google.apis:google-api-services-pubsub:jar:v1-rev10-1.22.0:compile\r\n|  |  +- com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n|  |  +- com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:0.1.18:compile\r\n|  |  |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.1.18:compile\r\n|  |  +- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.4.0:compile\r\n|  |  |  +- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n|  |  |  \\- com.google.http-client:google-http-client-jackson:jar:1.20.0:compile\r\n|  |  +- com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0:compile\r\n|  |  |  \\- com.google.api.grpc:grpc-google-common-protos:jar:0.1.0:compile\r\n|  |  +- io.grpc:grpc-auth:jar:1.2.0:compile\r\n|  |  +- io.grpc:grpc-netty:jar:1.2.0:compile\r\n|  |  |  +- io.netty:netty-codec-http2:jar:4.1.8.Final:compile (version selected from constraint [4.1.8.Final,4.1.8.Final])\r\n|  |  |  \\- io.netty:netty-handler-proxy:jar:4.1.8.Final:compile\r\n|  |  |     \\- io.netty:netty-codec-socks:jar:4.1.8.Final:compile\r\n|  |  +- io.grpc:grpc-all:jar:1.2.0:compile\r\n|  |  |  +- io.grpc:grpc-okhttp:jar:1.2.0:compile\r\n|  |  |  |  +- com.squareup.okhttp:okhttp:jar:2.5.0:compile\r\n|  |  |  |  \\- com.squareup.okio:okio:jar:1.6.0:compile\r\n|  |  |  \\- io.grpc:grpc-protobuf-nano:jar:1.2.0:compile\r\n|  |  |     \\- com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\r\n|  |  +- com.google.cloud:google-cloud-core:jar:1.0.2:compile\r\n|  |  +- com.google.cloud:google-cloud-spanner:jar:0.20.0-beta:compile\r\n|  |  |  +- com.google.api.grpc:proto-google-cloud-spanner-v1:jar:0.1.11:compile\r\n|  |  |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n|  |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.11:compile\r\n|  |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.11:compile\r\n|  |  |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.11:compile\r\n|  |  |  +- com.google.api.grpc:grpc-google-longrunning-v1:jar:0.1.11:compile\r\n|  |  |  |  \\- com.google.api.grpc:proto-google-longrunning-v1:jar:0.1.11:compile\r\n|  |  |  \\- junit:junit:jar:4.12:compile\r\n|  |  |     \\- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n|  |  +- com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3:compile\r\n|  |  +- com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0-pre3:compile\r\n|  |  |  +- commons-logging:commons-logging:jar:1.2:compile\r\n|  |  |  +- com.google.auth:google-auth-library-appengine:jar:0.7.0:compile\r\n|  |  |  \\- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile\r\n|  |  +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26:compile\r\n|  |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:jar:0.1.9:compile\r\n|  |  \\- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n|  +- com.google.api-client:google-api-client:jar:1.22.0:compile\r\n|  |  \\- com.google.oauth-client:google-oauth-client:jar:1.22.0:compile\r\n|  +- com.google.http-client:google-http-client:jar:1.22.0:compile\r\n|  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n|  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n|  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n|  +- com.google.http-client:google-http-client-jackson2:jar:1.22.0:compile\r\n|  +- com.google.apis:google-api-services-dataflow:jar:v1b3-rev213-1.22.0:compile\r\n|  +- com.google.apis:google-api-services-clouddebugger:jar:v2-rev8-1.22.0:compile\r\n|  +- com.google.apis:google-api-services-storage:jar:v1-rev71-1.22.0:compile\r\n|  +- com.google.auth:google-auth-library-credentials:jar:0.7.1:compile\r\n|  +- com.google.auth:google-auth-library-oauth2-http:jar:0.7.1:compile\r\n|  \\- com.google.cloud.bigdataoss:util:jar:1.4.5:compile\r\n|     +- com.google.api-client:google-api-client-java6:jar:1.20.0:compile\r\n|     +- com.google.api-client:google-api-client-jackson2:jar:1.20.0:compile\r\n|     \\- com.google.oauth-client:google-oauth-client-java6:jar:1.20.0:compile\r\n\\- com.google.firebase:firebase-admin:jar:5.8.0:compile\r\n   +- com.google.api-client:google-api-client-gson:jar:1.22.0:compile\r\n   |  \\- com.google.http-client:google-http-client-gson:jar:1.22.0:compile\r\n   |     \\- com.google.code.gson:gson:jar:2.1:compile\r\n   +- com.google.api:api-common:jar:1.2.0:compile\r\n   +- com.google.cloud:google-cloud-storage:jar:1.7.0:compile\r\n   |  \\- com.google.cloud:google-cloud-core-http:jar:1.7.0:compile\r\n   |     \\- com.google.http-client:google-http-client-appengine:jar:1.22.0:compile\r\n   +- com.google.cloud:google-cloud-firestore:jar:0.25.0-beta:compile\r\n   |  \\- com.google.api.grpc:proto-google-cloud-firestore-v1beta1:jar:0.1.20:compile\r\n   +- org.json:json:jar:20160810:compile\r\n   +- io.netty:netty-codec-http:jar:4.1.14.Final:compile\r\n   |  \\- io.netty:netty-codec:jar:4.1.14.Final:compile\r\n   +- io.netty:netty-handler:jar:4.1.14.Final:compile\r\n   |  \\- io.netty:netty-buffer:jar:4.1.14.Final:compile\r\n   |     \\- io.netty:netty-common:jar:4.1.14.Final:compile\r\n   \\- io.netty:netty-transport:jar:4.1.14.Final:compile\r\n      \\- io.netty:netty-resolver:jar:4.1.14.Final:compile\r\n```\r\n\r\nIt looks like this is due to Beam pulling in old dependencies that aren't sufficient for `firebase-admin`, so I tried pinning\r\n\r\n```\r\n<dependency>\r\n  <groupId>com.google.auth</groupId>\r\n  <artifactId>google-auth-library-oauth2-http</artifactId>\r\n  <version>0.9.0</version>\r\n</dependency>\r\n```\r\n\r\nwhich resulted in #2496:\r\n\r\n```\r\njava.lang.NoClassDefFoundError: com/google/api/gax/rpc/ClientSettings\r\n\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n```\r\n\r\nso I tried adding\r\n\r\n```\r\n<dependency>\r\n  <groupId>com.google.api</groupId>\r\n  <artifactId>gax</artifactId>\r\n  <version>1.19.0</version>\r\n</dependency>\r\n<dependency>\r\n  <groupId>com.google.api</groupId>\r\n  <artifactId>gax-grpc</artifactId>\r\n  <version>1.19.0</version>\r\n</dependency>\r\n```\r\n\r\nbut this results in\r\n\r\n```\r\njava.lang.NoClassDefFoundError: com/google/api/gax/rpc/TransportProvider\r\n\r\n\tat com.google.cloud.firestore.FirestoreOptions.<clinit>(FirestoreOptions.java:41)\r\n\tat com.google.firebase.cloud.FirestoreClient.<init>(FirestoreClient.java:37)\r\n\tat com.google.firebase.cloud.FirestoreClient.<init>(FirestoreClient.java:26)\r\n\tat com.google.firebase.cloud.FirestoreClient$FirestoreClientService.<init>(FirestoreClient.java:81)\r\n\tat com.google.firebase.cloud.FirestoreClient.getInstance(FirestoreClient.java:71)\r\n```\r\n\r\nat which point I'm sort of stuck, since I thought this was provided by the `gax-grpc` artifact. I've also tried putting `firebase-admin` before all the beam dependencies, however this results in similar version conflicts...\r\n\r\nIs there an easier way to resolve the dependency conflict between Beam and firebase-admin?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2889",
        "number": 2889,
        "title": "java.lang.ClassNotFoundException: com.google.api.gax.rpc.StubSettings",
        "labels": [
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "java.lang.ClassNotFoundException: com.google.api.gax.rpc.StubSettings\r\nI just \"exactly\" followed this [link](https://cloud.google.com/logging/docs/reference/libraries)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2888",
        "number": 2888,
        "title": "Firestore Realtime Listener Timing Out",
        "labels": [
            "api: firestore",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm trying to use Firestore in order to set up realtime listeners for a collection. Whenever a document is added, modified, or deleted in a collection, I want the listener to be called. My code is currently working for one collection, but when I try the same code on a larger collection, it fails with the error:\r\n\r\n`Listen failed: com.google.cloud.firestore.FirestoreException: Backend ended Listen stream: The datastore operation timed out, or the data was temporarily unavailable.`\r\n\r\nHow should I deal with this issue in order to track changes in this collection? Can I manually set a higher time out threshold or use some other technique? My code implementation is below for reference:\r\n\r\n```\r\n/**\r\n * Sets up a listener at the given collection reference. When changes are made in this collection, it writes a flat\r\n * text file for import into backend.\r\n * @param collectionReference The Collection Reference that we want to listen to for changes.\r\n */\r\npublic static void listenToCollection(CollectionReference collectionReference) {\r\n\r\n    AtomicBoolean initialUpdate = new AtomicBoolean(true);\r\n\r\n    System.out.println(\"Initializing listener for: \" + collectionReference.getId());\r\n\r\n    collectionReference.addSnapshotListener(new EventListener<QuerySnapshot>() {\r\n        @Override\r\n        public void onEvent(@Nullable QuerySnapshot queryDocumentSnapshots, @Nullable FirestoreException e) {\r\n            // Error Handling\r\n            if (e != null) {\r\n                System.err.println(\"Listen failed: \" + e);\r\n                return;\r\n            }\r\n\r\n            // If this is the first time this function is called, it's simply reading everything in the collection\r\n            // We don't care about the initial value, only the updates, so we simply ignore the first call\r\n            if (initialUpdate.get()) {\r\n                initialUpdate.set(false);\r\n                System.out.println(\"Initial update complete...\\nListener active for \" + collectionReference.getId() + \"...\");\r\n                return;\r\n            }\r\n\r\n            // A document has changed, propagate this back to backend by writing text file.\r\n            for (DocumentChange dc : queryDocumentSnapshots.getDocumentChanges()) {\r\n\r\n                String docId = dc.getDocument().getId();\r\n                Map<String, Object> docData = dc.getDocument().getData();\r\n\r\n                String folderPath = createFolderPath(collectionReference, docId, docData);\r\n\r\n                switch (dc.getType()) {\r\n                    case ADDED:\r\n                        System.out.println(\"Document Created: \" + docId);\r\n                        writeMapToFile(docData, folderPath, \"CREATE\");\r\n                        break;\r\n                    case MODIFIED:\r\n                        System.out.println(\"Document Updated: \" + docId);\r\n                        writeMapToFile(docData, folderPath, \"UPDATE\");\r\n                        break;\r\n                    case REMOVED:\r\n                        System.out.println(\"Document Deleted: \" + docId);\r\n                        writeMapToFile(docData, folderPath, \"DELETE\");\r\n                        break;\r\n                    default:\r\n                        break;\r\n                }\r\n            }\r\n\r\n        }\r\n    });\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2884",
        "number": 2884,
        "title": "Fix Storage integration test failures",
        "labels": [
            "api: storage",
            "priority: p1"
        ],
        "state": "closed",
        "body": "It turns out that the failures in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2872 were intermittent because of a change being rolled out to Storage. Storage tests are now failing reliably on one case that wasn't updated: https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/563 . We should update the integration tests to expect Invalid Argument and fail if anything else happens. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2882",
        "number": 2882,
        "title": "Perform snapshot releases after successful builds to master",
        "labels": [
            "type: feature request",
            "type: process"
        ],
        "state": "open",
        "body": "We lost releases of snapshot versions when we turned off the oraclejdk7 build on Travis (since the after_success.sh script only performed releases for that build variant). \r\n\r\nNow that we are using Circle, we should add a step in the CircleCI workflow to perform a snapshot release after all jobs finish (operating systems + integration tests). \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2880",
        "number": 2880,
        "title": "FieldValue.of is not public",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "For some reason FieldValue \"of\" method is not \"public static\" which means I can't create an instance of FieldValue. I can create instances of other, similar objects like Field, Schema, etc. though.\r\n\r\nThis is major problem, because it means you can't create bigquery result objects for things like testing. Could we please make this available?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2879",
        "number": 2879,
        "title": "Add String-based overloads for flattened methods using resource name types",
        "labels": [
            ":rotating_light:",
            "api: pubsub",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2878",
        "number": 2878,
        "title": "Convert resource name one-of types to use inheritance",
        "labels": [
            ":rotating_light:",
            "api: pubsub",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2876",
        "number": 2876,
        "title": "Spanner unit tests timing out intermittently",
        "labels": [
            ":rotating_light:",
            "api: spanner",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "- https://ci.appveyor.com/project/googlejavacloud/google-cloud-java-v0gf7/build/1785\r\n- https://ci.appveyor.com/project/googlejavacloud/google-cloud-java-v0gf7/build/1803\r\n\r\nThe build gets stuck on Spanner tests, and AppVeyor kills it after 60 minutes. It's not clear from the log which test is getting stuck.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2875",
        "number": 2875,
        "title": "Expose a true asynchronous DatabaseClient",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Deep inside (google.cloud.spanner.SpannerImpl) the client library grpc is used. Grpc enables non-blocking/asynchronous paradigms.\r\nSo it should be possible to expose a real asynchronous api. With real I mean a true event-driven approach and not just wrap the current blocking DatabaseClientImpl using a thread pool.\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2874",
        "number": 2874,
        "title": "Could not get list of permissions from pre-defined roles using IAM API ",
        "labels": [],
        "state": "closed",
        "body": "I am not sure if this issue should be put in this repo but I could not find the correct responding github for IAM API.\r\n\r\nSo I was using google-api-services-iam library ver v1-rev231-1.23.0 and I would like to get list of permissions from certain roles using code like this:\r\n\r\n```\r\npublic static List<String> getPermissionsFromRole(Iam iam, String projectName, String roleName) throws IOException{\r\n\t\tRole d = iam.projects().roles().get(roleName).execute();\r\n\t\treturn d.getIncludedPermissions();\r\n\t}\r\n```\r\n\r\nSo it works for custom role with the format like projects/projectName/roles/SecurityReviewer but when I try to use pre-defined role like roles/storage.legacyBucketOwnerthen it gave error like\r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalArgumentException: Parameter name must conform to the pattern ^projects/[^/]+/roles/[^/]+$\r\n\tat com.google.api.client.repackaged.com.google.common.base.Preconditions.checkArgument(Preconditions.java:125)\r\n\tat com.google.api.client.util.Preconditions.checkArgument(Preconditions.java:49)\r\n\tat com.google.api.services.iam.v1.Iam$Projects$Roles$Get.<init>(Iam.java:1899)\r\n\tat com.google.api.services.iam.v1.Iam$Projects$Roles.get(Iam.java:1867)\r\n\tat gcp.GoogleIAM.getPermissionsFromRole(GoogleIAM.java:291)\r\n\tat gcp.GoogleIAM.main(GoogleIAM.java:90)\r\n```\r\nObviously using pre-defined roles with format projects/projectName/roles/storage.legacyBucketOwner will give error like\r\n\r\n```\r\nException in thread \"main\" com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found\r\n{\r\n  \"code\" : 404,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"message\" : \"The role named projects/testing-123-ok/roles/storage.legacyBucketOwner was not found.\",\r\n    \"reason\" : \"notFound\"\r\n  } ],\r\n  \"message\" : \"The role named projects/testing-123-ok/roles/storage.legacyBucketOwner was not found.\",\r\n  \"status\" : \"NOT_FOUND\"\r\n}\r\n\tat com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\r\n\tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\n\tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat gcp.GoogleIAM.getPermissionsFromRole(GoogleIAM.java:291)\r\n\tat gcp.GoogleIAM.main(GoogleIAM.java:90)\r\n```\r\n\r\nDo you know the fix to this issue?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2871",
        "number": 2871,
        "title": "Remove ssl context customization in Spanner",
        "labels": [
            "api: spanner",
            "dependencies",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Specifically, ciphers should not be set to null:\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/SpannerOptions.java#L311\r\n\r\nThen this line can be removed, which is netty specific:\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/SpannerOptions.java#L299\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2869",
        "number": 2869,
        "title": "Google cloud java package summary is unreachable.",
        "labels": [],
        "state": "closed",
        "body": "This URL is unreachable?\r\nhttps://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/com/google/cloud/compute/package-summary.html\r\n\r\nThis is breaking tests that depend on it (not sure if it affects customers), for example: https://travis-ci.org/GoogleCloudPlatform/appengine-plugins-core/builds/338186738#L1512\r\n\r\nHas this page moved? Or is it just down?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2867",
        "number": 2867,
        "title": "BigQuery: Job already exists, probably for internal backoff or something",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, \r\nI'm currently using library 0.33.0-beta for an App Engine Std project,\r\n\r\nWhen I need to execute a QueryJob, I have this method\r\n```\r\npublic static TableResult executeQuery(QueryJobConfiguration queryConfig) throws IOException {\r\n\tBigQuery service = getService();\r\n\r\n\tJobId jobId = JobId.of(UUID.randomUUID().toString() + \"-\" + System.nanoTime());\r\n\tJob queryJob = service.create(JobInfo.newBuilder(queryConfig).setJobId(jobId).build());\r\n\r\n\t// Wait for job to finish\r\n\tqueryJob = job.waitFor(retryOption);\r\n\r\n\t// Get the results\r\n\tTableResult result = queryJob.getQueryResults();\r\n\t\r\n\t// TODO Do something with the results...\r\n}\r\n```\r\n\r\nYou can see from the code itself the JobID is unique, due it has a random part and a time part.\r\n\r\nBut sometimes I get this error:\r\n```\r\n{\r\n  \"code\": 409,\r\n  \"errors\": [\r\n    {\r\n      \"domain\": \"global\",\r\n      \"message\": \"Already Exists: Job xxxxxxxxxxxxxxxx:EU.80760581-e8df-4c87-a538-1efbcf917778-1517936402050522782\",\r\n      \"reason\": \"duplicate\"\r\n    }\r\n  ],\r\n  \"message\": \"Already Exists: Job  xxxxxxxxxxxxxxxx:EU.80760581-e8df-4c87-a538-1efbcf917778-1517936402050522782\"\r\n}\r\n```\r\n\r\nand here is the stacktrace\r\n```\r\ncom.google.cloud.bigquery.BigQueryException: Already Exists: Job xxxxxxxxxxxxxxxx:EU.80760581-e8df-4c87-a538-1efbcf917778-1517936402050522782\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:83)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.create(HttpBigQueryRpc.java:167)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$3.call(BigQueryImpl.java:186)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$3.call(BigQueryImpl.java:183)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:183)\r\n\t--- my class ---\r\n```\r\n\r\nBecause I'm sure that my code generates every time a random/unique JobId (even if i Try multiple times the same query the id will be different) I'm wondering the conditions on how this kind of error is genereated.\r\n\r\nI'm open this issue because I'm thinking about an internal backoff functionality (I can see the method **runWithRetries** from the stacktrace, this is why i'm suggesting this), where the jobs.create call ends w/o response (so the backoff try again to run the job) but the job successfully started the first time. In this way, trying to start a new job (same id) a second time, will produce this error.\r\n\r\nIt does not happens very often, so probably are temporary errors related to BigQuery infrastructure (and because of this is hard to replicate behaviour).\r\n\r\nIs this a known behaviour?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2866",
        "number": 2866,
        "title": "BigQuery: Add support for BigQuery customer-managed encryption keys",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "BigQuery customer-managed encryption keys allow users to specify a Cloud KMS key to protect their BigQuery table.\r\n\r\nAPI:\r\nJobs: https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs\r\nIn a job, there is a destinationEncryptionConfiguration field, which indicates which Cloud KMS key should be used for the destination.\r\n\r\nTables: https://cloud.google.com/bigquery/docs/reference/rest/v2/tables\r\nIn a table, there is a encryptionConfiguration field, which indicates which Cloud KMS key protects (or should protect in case of CreateTable) a BigQuery table.\r\n\r\nThese are the main APIs that are required for day-to-day interaction.\r\nWith lower priority, support for getServiceAccount would also be nice: https://cloud.google.com/bigquery/docs/reference/rest/v2/projects/getServiceAccount\r\nNote that unlike the other methods mentioned above, this would generally only be called once and the resulting value (the email address) does not change - so it can easily also be called from UI/API/CLI without much hindrance (hence lower priority).\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2865",
        "number": 2865,
        "title": "BigQuery table info is missing Labels",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "The big query table info is missing the labels map\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/b7b3f21b784a3524f7830f34148abfd3e39677d4/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/TableInfo.java\r\n\r\nIt is present on the dataset and on the underlying model object so it seems to just have been missed out on the mapping"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2864",
        "number": 2864,
        "title": "Storage integration test intermittently failing",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Storage integration tests are failing intermittently with an \"Invalid argument\" failure. The tests will pass after they are rerun. \r\n\r\n- https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/343\r\n- https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/311\r\n\r\n```\r\nTests run: 65, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 151.382 sec <<< FAILURE! - in com.google.cloud.storage.it.ITStorageTest\r\ntestGetBlobFailNonExistingGeneration(com.google.cloud.storage.it.ITStorageTest)  Time elapsed: 0.856 sec  <<< ERROR!\r\ncom.google.cloud.storage.StorageException: Invalid argument\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:191)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:342)\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198)\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195)\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:209)\r\n\tat com.google.cloud.storage.it.ITStorageTest.testGetBlobFailNonExistingGeneration(ITStorageTest.java:329)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)\r\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request\r\n{\r\n  \"code\" : 400,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"message\" : \"Invalid argument\",\r\n    \"reason\" : \"invalid\"\r\n  } ],\r\n  \"message\" : \"Invalid argument\"\r\n}\r\n\tat com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\r\n\tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\n\tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340)\r\n\t... 34 more\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2855",
        "number": 2855,
        "title": "ServiceOptions.getDefaultProjectId() in Cloud Shell picks up \"no-project-id\" from metadata server",
        "labels": [
            "api: core",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "In Cloud Shell, where a project ID is properly configured in gcloud:\r\n`gcloud config list --format 'value(core.project)'` shows the project ID, and\r\n`echo $CLOUDSDK_CONFIG` shows the configuration directory.\r\n\r\nRun a Java application that uses `ServiceOptions.getProjectId()` in cloud shell. It picks up `no-project-id` from the metadata server."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2853",
        "number": 2853,
        "title": "Consider using partial builds for PRs",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be nice to narrow PR builds to just the clients/modules that that PR affects while it's open. And a run the full test suite less frequently: either on merge, daily or when cutting a release.\r\n\r\nTo limit the affect modules, something like https://github.com/lesfurets/partial-build-plugin can be used."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2852",
        "number": 2852,
        "title": "Generalize Bigtable's regenerate scripts to applicable to other clients",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "The new Bigtable client has 2 scripts to help test GAPIC config changes. The scripts allow the developer to make a change in a local googleapis checkout and see how the changes will look in `api-client-staging` and `google-cloud-java`. It would be nice to open these scripts to other clients.\r\n\r\nAlso, the update script is currently pretty careless about overwriting local changes, this will need to narrowed down to autogenerated files to avoid destroying local changes"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2847",
        "number": 2847,
        "title": "Support for Container Builder",
        "labels": [],
        "state": "closed",
        "body": "It will be nice to have a library to work with [Container Builder](https://cloud.google.com/container-builder/) API"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2835",
        "number": 2835,
        "title": "Logging integration tests are failing",
        "labels": [
            "api: logging",
            "priority: p1"
        ],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/100?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\nFirst failure:\r\n\r\n```\r\ntestListMetrics(com.google.cloud.logging.it.ITLoggingTest)  Time elapsed: 3.079 sec  <<< ERROR!\r\ncom.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: RESOURCE_EXHAUSTED: Insufficient tokens for quota 'logging.googleapis.com/control_requests' and limit 'ControlRequestsPerMinutePerProject' of service 'logging.googleapis.com' for consumer 'project_number:1016721519174'.\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2834",
        "number": 2834,
        "title": "Dns integration tests are failing",
        "labels": [
            "api: dns",
            "priority: p1"
        ],
        "state": "closed",
        "body": "https://circleci.com/gh/GoogleCloudPlatform/google-cloud-java/105?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\r\n\r\nFirst of the test failures:\r\n\r\n```\r\ntestListChangesBatch(com.google.cloud.dns.it.ITDnsTest)  Time elapsed: 0.286 sec  <<< ERROR!\r\ncom.google.cloud.dns.DnsException: \r\n404 Not Found\r\nNot Found\r\n\tat com.google.cloud.dns.spi.v1.HttpDnsRpc.translate(HttpDnsRpc.java:175)\r\n\tat com.google.cloud.dns.spi.v1.HttpDnsRpc.access$200(HttpDnsRpc.java:45)\r\n\tat com.google.cloud.dns.spi.v1.HttpDnsRpc$DefaultRpcBatch.submit(HttpDnsRpc.java:154)\r\n\tat com.google.cloud.dns.DnsBatch.submit(DnsBatch.java:217)\r\n\tat com.google.cloud.dns.it.ITDnsTest.testListChangesBatch(ITDnsTest.java:1596)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)\r\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: com.google.api.client.http.HttpResponseException: 404 Not Found\r\nNot Found\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070)\r\n\tat com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:241)\r\n\tat com.google.cloud.dns.spi.v1.HttpDnsRpc$DefaultRpcBatch.submit(HttpDnsRpc.java:152)\r\n\t... 14 more\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2823",
        "number": 2823,
        "title": "bigquery: should retry on 502 status code",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Not a \"bug\", but easy to do."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2820",
        "number": 2820,
        "title": "can not set fieldDelimiter and encoding at load job configuration java client",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, \r\n\r\nI want to load tab separated file from bucket to BiqQuery table. \r\nUnfortunately, there is no option to set delimiter type and encoding at LoadJobConfiguration at Java client. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2816",
        "number": 2816,
        "title": "Firestore Query: unsupported FieldFilter value type: 6",
        "labels": [
            "api: firestore",
            "type: feature request"
        ],
        "state": "open",
        "body": "Hello,\r\nI was using a filter like this on a firestore collection:\r\n`whereEqualTo(\"access\", emptyMap<String, Any>())`\r\nI want to find all documents, where all users stopped using them and hence delete them afterwards.\r\n\r\nAfter setting up the listener I get the correct result, but directly after that I get the following error:\r\n`com.google.cloud.firestore.FirestoreException: Backend ended Listen stream: Unsupported FieldFilter value type: 6`\r\n\r\nSo my question:\r\nWill you add support for such Queries? If not, why do I get a correct the result at first?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2813",
        "number": 2813,
        "title": "Compatibility Issue with Play 2.5.9",
        "labels": [
            "dependencies",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I have a Play framework project (version 2.5.9).\r\n\r\nI append the following in its `build.sbt`'s `libraryDependencies`:\r\n\"com.google.cloud\"        % \"google-cloud-vision\"      % \"1.15.0\"\r\n\r\nThen I run `sbt clean && sbt \"project frontend\" run`. Instead of the app starting, it errors with the following:\r\n\r\n--- (Running the application, auto-reloading is enabled) ---\r\n\r\njava.lang.NoSuchFieldError: DEFAULT_MAX_PENDING_TASKS\r\n\tat io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:141)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:127)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:36)\r\n\tat io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)\r\n\tat io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)\r\n\tat io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)\r\n\tat io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:49)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:77)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:72)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:59)\r\n\tat play.core.server.NettyServer.<init>(NettyServer.scala:77)\r\n\tat play.core.server.NettyServerProvider.createServer(NettyServer.scala:279)\r\n\tat play.core.server.NettyServerProvider.createServer(NettyServer.scala:278)\r\n\tat play.core.server.DevServerStart$$anonfun$mainDev$1.apply(DevServerStart.scala:235)\r\n\tat play.core.server.DevServerStart$$anonfun$mainDev$1.apply(DevServerStart.scala:65)\r\n\tat play.utils.Threads$.withContextClassLoader(Threads.scala:21)\r\n\tat play.core.server.DevServerStart$.mainDev(DevServerStart.scala:64)\r\n\tat play.core.server.DevServerStart$.mainDevHttpMode(DevServerStart.scala:54)\r\n\tat play.core.server.DevServerStart.mainDevHttpMode(DevServerStart.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat play.runsupport.Reloader$.startDevMode(Reloader.scala:234)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.devModeServer$lzycompute$1(PlayRun.scala:74)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.play$sbt$run$PlayRun$$anonfun$$anonfun$$anonfun$$devModeServer$1(PlayRun.scala:74)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.apply(PlayRun.scala:100)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.apply(PlayRun.scala:53)\r\n\tat scala.Function1$$anonfun$compose$1.apply(Function1.scala:47)\r\n[trace] Stack trace suppressed: run last frontend/compile:run for the full output.\r\n[error] (frontend/compile:run) java.lang.reflect.InvocationTargetException\r\n[error] Total time: 77 s, completed Jan 28, 2018 1:05:10 PM"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2812",
        "number": 2812,
        "title": "1st party - Composite GCS Uploads",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It'd be great to have first party support for GCS composit uploads of large files / streams. While technically possible the SDK now, its not nearly as easy as using gsutil:\r\n`gsutil -o GSUtil:parallel_composite_upload_threshold=150M cp bigfile gs://your-bucket`\r\n\r\n\r\nThinking something like this would be great:\r\n```\r\nstorage = ....\r\nblobInfo = ...\r\nstorage.parallelCompositUpload(readChannel, blobInfo);\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2810",
        "number": 2810,
        "title": "ProviderNotFoundException while using Pub/Sub and BigTanle on DataProc",
        "labels": [
            "api: bigtable",
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi everybody,\r\n\r\nI am trying to build an application with both Pub/Sub and BigTable on top of Dataproc cluster with Spark.\r\n\r\nHowever while connecting to BigTable, this line throw an exception:\r\n`BigtableConfiguration.connect(projectId, instanceId)`\r\n\r\n```\r\nException in thread \"main\" java.lang.ExceptionInInitializerError\r\n        at mycompany.batch.SinglePredictorBatchLauncher.main(SinglePredictorBatchLauncher.scala)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)\r\n        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\r\n        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\r\n        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)\r\n        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.lang.IllegalStateException: Could not find an appropriate constructor for my_conf.cloud.bigtable.hbase1_x.BigtableConnection\r\n        at my_conf.cloud.bigtable.hbase.BigtableConfiguration.connect(BigtableConfiguration.java:114)\r\n        at my_conf.cloud.bigtable.hbase.BigtableConfiguration.connect(BigtableConfiguration.java:99)\r\n        at mycompany.util.app.EbapContext$.hBaseRuntime$lzycompute(EbapContext.scala:57)\r\n        at mycompany.util.app.EbapContext$.hBaseRuntime(EbapContext.scala:44)\r\n        at mycompany.util.app.HBaseSupport$class.$init$(HBaseSupport.scala:4)\r\n        at mycompany.batch.SinglePredictorBatchLauncher$.<init>(SinglePredictorBatchLauncher.scala:10)\r\n        at mycompany.batch.SinglePredictorBatchLauncher$.<clinit>(SinglePredictorBatchLauncher.scala)\r\n        ... 10 more\r\nCaused by: java.lang.reflect.InvocationTargetException\r\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n        at my_conf.cloud.bigtable.hbase.BigtableConfiguration.connect(BigtableConfiguration.java:111)\r\n        ... 16 more\r\nCaused by: io.grpc.ManagedChannelProvider$ProviderNotFoundException: No functional channel service provider found. Try adding a dependency on the grpc-okhttp or grpc-netty artifact\r\n        at io.grpc.ManagedChannelProvider.provider(ManagedChannelProvider.java:124)\r\n        at io.grpc.ManagedChannelBuilder.forAddress(ManagedChannelBuilder.java:36)\r\n        at my_conf.cloud.bigtable.grpc.BigtableSession.createNettyChannel(BigtableSession.java:471)\r\n        at my_conf.cloud.bigtable.grpc.BigtableSession$3.create(BigtableSession.java:398)\r\n        at my_conf.cloud.bigtable.grpc.io.ChannelPool.<init>(ChannelPool.java:246)\r\n        at my_conf.cloud.bigtable.grpc.BigtableSession.createChannelPool(BigtableSession.java:401)\r\n        at my_conf.cloud.bigtable.grpc.BigtableSession.createManagedPool(BigtableSession.java:413)\r\n        at my_conf.cloud.bigtable.grpc.BigtableSession.getDataChannelPool(BigtableSession.java:276)\r\n        at my_conf.cloud.bigtable.grpc.BigtableSession.<init>(BigtableSession.java:236)\r\n        at org.apache.hadoop.hbase.client.AbstractBigtableConnection.<init>(AbstractBigtableConnection.java:143)\r\n        at org.apache.hadoop.hbase.client.AbstractBigtableConnection.<init>(AbstractBigtableConnection.java:110)\r\n        at my_conf.cloud.bigtable.hbase1_x.BigtableConnection.<init>(BigtableConnection.java:53)\r\n        ... 21 more\r\n```\r\n\r\nMy SBT dependencies are listed below:\r\n```\r\n\"com.google.cloud\" % \"google-cloud-storage\" % \"1.15.0\"\r\n\"com.google.cloud.bigtable\" % \"bigtable-hbase-1.x\" % \"1.0.0\" exclude(\"io.netty\",\"netty-tcnative-boringssl-static\")\r\n\"com.google.apis\" % \"google-api-services-dataproc\" % \"v1-rev69-1.23.0\"\r\n\"com.google.cloud\" % \"google-cloud-pubsub\" % \"0.33.0-beta\"\r\n```\r\n\r\nand assembly rules:\r\n```\r\nval settings = Seq(\r\n    assemblyMergeStrategy in assembly := {\r\n      case PathList(\"META-INF\", xs @ _*) =>\r\n        xs map {_.toLowerCase} match {\r\n          case \"native\" :: _ =>\r\n            MergeStrategy.first\r\n          case _ => MergeStrategy.discard\r\n        }\r\n      case \"reference.conf\" => MergeStrategy.concat\r\n      case x => MergeStrategy.first\r\n    },\r\n    assemblyShadeRules in assembly := Seq(\r\n      ShadeRule.rename(\"com.google.**\" -> \"my_conf.@1\").inAll,\r\n      ShadeRule.rename(\"io.netty.**\" -> \"my_conf2.@1\").inAll\r\n  )\r\n  )\r\n```\r\n\r\nThe first strange thing is that `grpc-netty-1.7.0` is on the classpath.\r\nThe second one is that my code runs perfectly well locally, on top of the spark standalone node on my dev machine.\r\n\r\nI have tried to remove the netty jar located in `/usr/lib/hadoop/lib` at cluster creation with the initialization action option but it still does not work for me.\r\n\r\nI have tried different shading options with no working configuration.\r\n\r\nThanks for your help"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2805",
        "number": 2805,
        "title": "PlatformInformation.isOnGAEStandard7 returns erroneous false positive",
        "labels": [
            "priority: p2",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "Seen from a Java 8 app in Flex. (Discovered because it's trying to construct a URLFetch transport for API clients.) Can provide further details, of course, but tbh I think there are better ways to detect this information than what that class does right now."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2804",
        "number": 2804,
        "title": "Bigquery 0.32.0-beta - Needs new guava version",
        "labels": [],
        "state": "closed",
        "body": "Getting the following error w/bigquery 0.32.0-beta when doing dataset.exists()\r\n\r\n```\r\nException in thread \"main\" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V\r\n\tat com.google.cloud.bigquery.BigQueryImpl.optionMap(BigQueryImpl.java:684)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.getDataset(BigQueryImpl.java:224)\r\n\tat com.google.cloud.bigquery.Dataset.exists(Dataset.java:174)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2803",
        "number": 2803,
        "title": "Avoid exporting multiple versions of the same dependency.",
        "labels": [
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "This is a good practice to do in general, opencensus tried to enable Maven Enforcer's dependencyConvergence and we found some issues (same issues apply for the trace library as well), see the bolded targets as an example:\r\n\r\n+--- com.google.cloud:google-cloud-monitoring:0.33.0-beta\r\n|    +--- io.netty:netty-tcnative-boringssl-static:2.0.7.Final\r\n|    +--- com.google.cloud:google-cloud-core:1.15.0\r\n|    |    +--- joda-time:joda-time:2.9.2\r\n|    |    +--- com.google.http-client:google-http-client:1.23.0\r\n|    |    |    +--- **com.google.code.findbugs:jsr305:1.3.9 -> 3.0.1**\r\n|    |    |    \\--- org.apache.httpcomponents:httpclient:4.0.1\r\n|    |    |         +--- org.apache.httpcomponents:httpcore:4.0.1\r\n|    |    |         +--- commons-logging:commons-logging:1.1.1\r\n|    |    |         \\--- commons-codec:commons-codec:1.3\r\n|    |    +--- **com.google.code.findbugs:jsr305:3.0.1**\r\n|    |    +--- com.google.api:api-common:1.2.0\r\n|    |    |    \\--- **com.google.code.findbugs:jsr305:3.0.0 -> 3.0.1**\r\n|    |    +--- com.google.api:gax:1.16.0\r\n|    |    |    +--- com.google.auto.value:auto-value:1.2\r\n|    |    |    +--- com.google.code.findbugs:jsr305:3.0.0 -> 3.0.1\r\n|    |    |    +--- org.threeten:threetenbp:1.3.3\r\n|    |    |    +--- com.google.auth:google-auth-library-oauth2-http:0.9.0\r\n|    |    |    |    +--- com.google.auth:google-auth-library-credentials:0.9.0\r\n|    |    |    |    +--- com.google.http-client:google-http-client:1.19.0 -> 1.23.0 (*)\r\n|    |    |    |    \\--- com.google.http-client:google-http-client-jackson2:1.19.0\r\n|    |    |    |         +--- com.google.http-client:google-http-client:1.19.0 -> 1.23.0 (*)\r\n|    |    |    |         \\--- com.fasterxml.jackson.core:jackson-core:2.1.3\r\n|    |    |    \\--- com.google.api:api-common:1.2.0 (*)\r\n|    |    +--- com.google.protobuf:protobuf-java-util:3.5.1\r\n|    |    |    +--- **com.google.protobuf:protobuf-java:3.5.1**\r\n|    |    |    \\--- com.google.code.gson:gson:2.7\r\n|    |    +--- com.google.api.grpc:proto-google-common-protos:1.0.4\r\n|    |    |    \\--- **com.google.protobuf:protobuf-java:3.4.0 -> 3.5.1**\r\n|    |    \\--- com.google.api.grpc:proto-google-iam-v1:0.1.28\r\n|    |         +--- com.google.api.grpc:proto-google-common-protos:1.0.4 (*)\r\n|    |         +--- **com.google.protobuf:protobuf-java:3.4.0 -> 3.5.1**\r\n|    |         \\--- com.google.api:api-common:1.2.0 (*)\r\n|    +--- com.google.cloud:google-cloud-core-grpc:1.15.0\r\n|    |    +--- io.netty:netty-tcnative-boringssl-static:2.0.7.Final\r\n|    |    +--- com.google.auth:google-auth-library-credentials:0.9.0\r\n|    |    +--- com.google.cloud:google-cloud-core:1.15.0 (*)\r\n|    |    +--- com.google.protobuf:protobuf-java:3.5.1\r\n|    |    +--- com.google.protobuf:protobuf-java-util:3.5.1 (*)\r\n|    |    +--- io.grpc:grpc-protobuf:1.9.0\r\n|    |    |    +--- io.grpc:grpc-core:1.9.0\r\n|    |    |    |    +--- io.grpc:grpc-context:1.9.0\r\n|    |    |    |    +--- com.google.errorprone:error_prone_annotations:2.1.2 -> 2.2.0\r\n|    |    |    |    +--- com.google.code.findbugs:jsr305:3.0.0 -> 3.0.1\r\n|    |    |    |    +--- com.google.instrumentation:instrumentation-api:0.4.3\r\n|    |    |    |    |    \\--- com.google.code.findbugs:jsr305:3.0.0 -> 3.0.1\r\n|    |    |    |    \\--- io.opencensus:opencensus-contrib-grpc-metrics:0.10.0\r\n|    |    |    |         \\--- com.google.errorprone:error_prone_annotations:2.1.2 -> 2.2.0\r\n|    |    |    +--- com.google.protobuf:protobuf-java:3.5.1\r\n|    |    |    +--- com.google.protobuf:protobuf-java-util:3.5.1 (*)\r\n|    |    |    +--- com.google.api.grpc:proto-google-common-protos:1.0.0 -> 1.0.4 (*)\r\n|    |    |    \\--- io.grpc:grpc-protobuf-lite:1.9.0\r\n|    |    |         \\--- io.grpc:grpc-core:1.9.0 (*)\r\n|    |    +--- **io.grpc:grpc-context:1.9.0**\r\n|    |    +--- **io.grpc:grpc-netty:1.9.0**\r\n|    |    |    +--- io.grpc:grpc-core:[1.9.0] -> 1.9.0 (*)\r\n|    |    |    +--- io.netty:netty-codec-http2:[4.1.17.Final] -> 4.1.17.Final\r\n|    |    |    |    +--- io.netty:netty-codec-http:4.1.17.Final\r\n|    |    |    |    |    \\--- io.netty:netty-codec:4.1.17.Final\r\n|    |    |    |    |         \\--- io.netty:netty-transport:4.1.17.Final\r\n|    |    |    |    |              +--- io.netty:netty-buffer:4.1.17.Final\r\n|    |    |    |    |              |    \\--- io.netty:netty-common:4.1.17.Final\r\n|    |    |    |    |              \\--- io.netty:netty-resolver:4.1.17.Final\r\n|    |    |    |    |                   \\--- io.netty:netty-common:4.1.17.Final\r\n|    |    |    |    \\--- io.netty:netty-handler:4.1.17.Final\r\n|    |    |    |         +--- io.netty:netty-buffer:4.1.17.Final (*)\r\n|    |    |    |         +--- io.netty:netty-transport:4.1.17.Final (*)\r\n|    |    |    |         \\--- io.netty:netty-codec:4.1.17.Final (*)\r\n|    |    |    \\--- io.netty:netty-handler-proxy:4.1.17.Final\r\n|    |    |         +--- io.netty:netty-transport:4.1.17.Final (*)\r\n|    |    |         +--- io.netty:netty-codec-socks:4.1.17.Final\r\n|    |    |         |    \\--- io.netty:netty-codec:4.1.17.Final (*)\r\n|    |    |         \\--- io.netty:netty-codec-http:4.1.17.Final (*)\r\n|    |    +--- **io.grpc:grpc-stub:1.9.0**\r\n|    |    |    \\--- io.grpc:grpc-core:1.9.0 (*)\r\n|    |    +--- **io.grpc:grpc-auth:1.9.0**\r\n|    |    |    +--- io.grpc:grpc-core:[1.9.0] -> 1.9.0 (*)\r\n|    |    |    \\--- com.google.auth:google-auth-library-credentials:0.9.0\r\n|    |    \\--- com.google.api:gax-grpc:1.16.0\r\n|    |         +--- com.google.auto.value:auto-value:1.2\r\n|    |         +--- com.google.code.findbugs:jsr305:3.0.0 -> 3.0.1\r\n|    |         +--- com.google.api:gax:1.16.0 (*)\r\n|    |         +--- **io.grpc:grpc-netty:1.7.0 -> 1.9.0 (*)**\r\n|    |         +--- **io.grpc:grpc-stub:1.7.0 -> 1.9.0 (*)**\r\n|    |         +--- **io.grpc:grpc-auth:1.7.0 -> 1.9.0 (*)**\r\n|    |         +--- **io.grpc:grpc-protobuf:1.7.0 -> 1.9.0 (*)**\r\n|    |         +--- org.threeten:threetenbp:1.3.3\r\n|    |         +--- com.google.auth:google-auth-library-oauth2-http:0.9.0 (*)\r\n|    |         +--- com.google.auth:google-auth-library-credentials:0.9.0\r\n|    |         +--- com.google.api.grpc:proto-google-common-protos:1.0.0 -> 1.0.4 (*)\r\n|    |         \\--- com.google.api:api-common:1.2.0 (*)\r\n|    +--- com.google.api.grpc:proto-google-cloud-monitoring-v3:0.1.28\r\n|    |    +--- com.google.api.grpc:proto-google-common-protos:1.0.4 (*)\r\n|    |    +--- com.google.protobuf:protobuf-java:3.4.0 -> 3.5.1\r\n|    |    \\--- com.google.api:api-common:1.2.0 (*)\r\n|    +--- io.grpc:grpc-netty:1.9.0 (*)\r\n|    +--- io.grpc:grpc-stub:1.9.0 (*)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2802",
        "number": 2802,
        "title": "firestore.googleapis.com:443 was not shutdown properly",
        "labels": [
            "api: firestore",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello, we're using java client `google-cloud-firestore 0.32.0-beta` library in our backend app for pushing records into a Firestore instance.\r\nHere is a java code snippet that reflects our processing flow:\r\n\r\n`            \r\nFirestoreOptions firestoreOptions =\r\n                    FirestoreOptions.getDefaultInstance().toBuilder()\r\n                            .setProjectId(projectId)\r\n                            .setCredentials(credentials)\r\n                            .build();\r\n\r\n            Firestore db = firestoreOptions.getService();\r\n            final List<String> results = new ArrayList<>();\r\n            List<Object> records = new ArrayList<>(); // get list of records\r\n            for (Object record : records) {\r\n\r\n                String path = \"path/to/collection/\" + record.id;\r\n                final DocumentReference doc = db.document(path);\r\n                ApiFuture<String> transaction = db.runTransaction(\r\n                        new Transaction.Function<String>() {\r\n                            @Override\r\n                            public String updateCallback(Transaction transaction) throws Exception {\r\n                                DocumentSnapshot snapshot = transaction.get(doc).get();\r\n\r\n                                if (!snapshot.exists()) {\r\n                                    transaction.set(snapshot.getReference(), record);\r\n                                    return \"New record is inserted\";\r\n                                }\r\n\r\n                                if (condition) {\r\n                                    transaction.update(doc, \"field\", \"new value\");\r\n                                    return \"Record is updated\";\r\n                                } else {\r\n                                    return \"Record is skipped\";\r\n                                }\r\n                            }\r\n                        });\r\n\r\n                results.add(transaction.get());\r\n            }\r\n`\r\n\r\nHowever in our Logs entries we constantly see the following error:\r\n\r\n`io.grpc.internal.ManagedChannelImpl *~*~*~ Channel io.grpc.internal.ManagedChannelImpl-609 for target firestore.googleapis.com:443 was not shutdown properly!!! ~*~*~*\r\n    Make sure to call shutdown()/shutdownNow() and awaitTermination().`\r\n\r\nI guess, it causes a memory leak in our app as we often see OOM exceptions and crashes. We suppose it can be related to this issue https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2497 . Can you confirm that ? What can you suggest us as a fix ? (btw, we can't use batch updates as there are no ability to check specific conditions with batches)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2800",
        "number": 2800,
        "title": " improve LocalDatastoreHelper docs.",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "It would be nice to improve the javadocs for\r\nhttp://googlecloudplatform.github.io/google-cloud-java/0.9.2/apidocs/com/google/cloud/datastore/testing/LocalDatastoreHelper.html\r\n\r\nEspecially the docs for reset look like generated docs string :). Please tell when one would call reset.\r\n\r\nE.g. Does this setup for junit make sense? What bout including the code snippet into the docs?\r\n``` java\r\n  private static final LocalDatastoreHelper datastoreHelper = ...\r\n\r\n  @BeforeClass\r\n  public static void setUpOnce() throws Exception {\r\n    datastoreHelper.start();\r\n  }\r\n\r\n  @AfterClass\r\n  public static void tearDownOnce() throws Exception {\r\n    datastoreHelper.stop(Duration.ofSeconds(5));\r\n  }\r\n\r\n  @Before\r\n  public void setUp() throws Exception {\r\n    datastoreHelper.reset();\r\n  }\r\n```\r\n\r\nFor start()/stop() it would be interesting to be explicit and tell if there is going to be any state (e.g. should I call reset() before calling stop())."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2797",
        "number": 2797,
        "title": "ConcurrentModificationException  in Google Cloud  Logging",
        "labels": [],
        "state": "closed",
        "body": "Getting this exception in the `LoggingImpl`. Using  Flexible Environment\r\nUsing  `commons-logging:commons-logging` version  1.2\r\n```\r\njava.util.ConcurrentModificationException at \r\njava.util.IdentityHashMap$KeySet.toArray(IdentityHashMap.java:1037) at \r\njava.util.IdentityHashMap$KeySet.toArray(IdentityHashMap.java:1015) at \r\njava.util.Collections$SetFromMap.toArray(Collections.java:5463) at \r\njava.util.ArrayList.addAll(ArrayList.java:577) at \r\ncom.google.cloud.logging.LoggingImpl.flush(LoggingImpl.java:539) at \r\ncom.google.cloud.logging.LoggingImpl.write(LoggingImpl.java:525) at \r\ncom.google.cloud.logging.LoggingHandler.publish(LoggingHandler.java:273) at \r\njava.util.logging.Logger.log(Logger.java:738) at \r\njava.util.logging.Logger.doLog(Logger.java:765) at \r\njava.util.logging.Logger.log(Logger.java:788) at \r\njava.util.logging.Logger.severe(Logger.java:1464)\r\n```\r\n\r\nSee also https://issuetracker.google.com/issues/72150069"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2796",
        "number": 2796,
        "title": "LoggingHandler hangs the thread",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "open",
        "body": "Our application is running on Google Kubernetes Engine using `gcr.io/google-appengine/jetty` image and used `com.google.cloud.logging.LoggingHandler` to publish logs on Stackdriver. We noticed some worker threads becoming unresponsive over time. When the pod is shutting down we can see the following exception for each:\r\n```java\r\njava.lang.RuntimeException: java.lang.InterruptedException\r\n\tat com.google.cloud.logging.LoggingImpl.flush(LoggingImpl.java:545)\r\n\tat com.google.cloud.logging.LoggingImpl.write(LoggingImpl.java:525)\r\n\tat com.google.cloud.logging.LoggingHandler.publish(LoggingHandler.java:273)\r\n\tat java.util.logging.Logger.log(Logger.java:738)\r\n\tat org.slf4j.impl.JDK14LoggerAdapter.log(JDK14LoggerAdapter.java:582)\r\n\tat org.slf4j.impl.JDK14LoggerAdapter.error(JDK14LoggerAdapter.java:500)\r\n        ...\r\nCaused by: java.lang.InterruptedException\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:449)\r\n\tat com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:79)\r\n\tat com.google.common.util.concurrent.ForwardingFuture.get(ForwardingFuture.java:63)\r\n\tat com.google.cloud.logging.LoggingImpl.flush(LoggingImpl.java:543)\r\n\t... 30 more\r\n```\r\nWe'll try to extract a thread dump to see why the future never completes, but the issue seems dangerous by itself: `LoggingImpl.java:543` uses the non-timeout version of `Future.get()` which can cause any logger call to block the current thread forever unless interrupted. Would it be possible to use the timeout version with a reasonably big timeout, e.g. 60 seconds?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2795",
        "number": 2795,
        "title": "monitoring.v3.MetricServiceClient throws StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR  ",
        "labels": [
            "api: monitoring",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI have an exporter that repeatedly call MetricServiceClient.createTimeSeries() and upload data. Occasionally, after running for some time, the MetricServiceClient will throw a StatusRuntimeException saying: \r\n\r\n```\r\ncom.google.api.gax.rpc.UnavailableException: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR\r\nReceived Goaway\r\nmax_age\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:69)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.setException(GrpcExceptionCallable.java:118)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:101)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:61)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:491)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:466)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:663)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:392)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:443)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:525)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:446)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:557)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: io.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR\r\nReceived Goaway\r\nmax_age\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 19 more\r\n```\r\n\r\nAny idea why this happens? Does this have any impact on the uploaded data?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2794",
        "number": 2794,
        "title": "Error with spring boot in app engine java 8 standard ",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Hello: I was trying to configure my first spring boot project in app engine.  As soon as I add the dependancy, I get this error below. Any idea what may be causing this?\r\n\r\nSuppressed: \r\n[INFO] GCLOUD: \t|java.lang.RuntimeException: Error scanning entry autovalue/shaded/com/google$/common/collect/$Maps$FilteredEntrySortedMap$SortedKeySet.class from jar file:///Users/masudhasan/Documents/workspace-sts-3.8.4.RELEASE/demo/target/appengine-staging/WEB-INF/lib/auto-value-1.2.jar\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationParser.parseJar(AnnotationParser.java:906)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationParser.parse(AnnotationParser.java:851)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationConfiguration$ParserTask.call(AnnotationConfiguration.java:163)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationConfiguration$1.run(AnnotationConfiguration.java:546)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n[INFO] GCLOUD: \t|\tat java.lang.Thread.run(Thread.java:745)\r\n[INFO] GCLOUD: \t|Caused by: \r\n[INFO] GCLOUD: \t|java.util.zip.ZipException: invalid LOC header (bad signature)\r\n[INFO] GCLOUD: \t|\tat java.util.zip.ZipFile.read(Native Method)\r\n[INFO] GCLOUD: \t|\tat java.util.zip.ZipFile.access$1400(ZipFile.java:60)\r\n[INFO] GCLOUD: \t|\tat java.util.zip.ZipFile$ZipFileInputStream.read(ZipFile.java:717)\r\n[INFO] GCLOUD: \t|\tat java.util.zip.ZipFile$ZipFileInflaterInputStream.fill(ZipFile.java:419)\r\n[INFO] GCLOUD: \t|\tat java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158)\r\n[INFO] GCLOUD: \t|\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\r\n[INFO] GCLOUD: \t|\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\r\n[INFO] GCLOUD: \t|\tat org.objectweb.asm.ClassReader.readClass(ClassReader.java:480)\r\n[INFO] GCLOUD: \t|\tat org.objectweb.asm.ClassReader.<init>(ClassReader.java:443)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationParser.scanClass(AnnotationParser.java:977)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationParser.parseJarEntry(AnnotationParser.java:958)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationParser.parseJar(AnnotationParser.java:902)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationParser.parse(AnnotationParser.java:851)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationConfiguration$ParserTask.call(AnnotationConfiguration.java:163)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.annotations.AnnotationConfiguration$1.run(AnnotationConfiguration.java:546)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n[INFO] GCLOUD: \t|\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n[INFO] GCLOUD: \t|\tat java.lang.Thread.run(Thread.java:745)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2793",
        "number": 2793,
        "title": "LocalDatastoreHelper uses org.threeten.bp.Duration instead of the jdk version",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Could you please use java.time.Duration? Any reason for why to use the backport?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2788",
        "number": 2788,
        "title": "[Firestore] Permission denials different when using `GOOGLE_APPLICATION_CREDENTIALS` versus setCredentials",
        "labels": [
            "auth",
            "type: question"
        ],
        "state": "open",
        "body": "I've got the following piece of code in the Firestore snippets:\r\n\r\n```java\r\n  String returnInfoFromTransaction(long population) throws Exception {\r\n    Map<String, Object> map = new HashMap<>();\r\n    map.put(\"population\", population);\r\n    // Block until transaction is complete is using transaction.get()\r\n    db.collection(\"cities\").document(\"SF\").set(map).get();\r\n    // [START fs_return_info_transaction]\r\n    final DocumentReference docRef = db.collection(\"cities\").document(\"SF\");\r\n    ApiFuture<String> transaction =\r\n        db.runTransaction(\r\n            new Transaction.Function<String>() {\r\n              @Override\r\n              public String updateCallback(Transaction transaction) throws Exception {\r\n                DocumentSnapshot snapshot = transaction.get(docRef).get();\r\n                Long newPopulation = snapshot.getLong(\"population\") + 1;\r\n                // conditionally update based on current population\r\n                if (newPopulation <= 1000000L) {\r\n                  transaction.update(docRef, \"population\", newPopulation);\r\n                  return \"Population increased to \" + newPopulation;\r\n                } else {\r\n                  throw new Exception(\"Sorry! Population is too big.\");\r\n                }\r\n              }\r\n            });\r\n    // Print information retrieved from transaction\r\n    System.out.println(transaction.get());\r\n    // [END fs_return_info_transaction]\r\n    return transaction.get();\r\n  }\r\n```\r\n\r\nI can initialize Firestore in two ways:\r\n\r\n**Option 1: Environment var**\r\n\r\n```bash\r\n$ export GOOGLE_APPLICATION_CREDENTIALS=\"/usr/local/google/home/samstern/service-accounts/firestore-snippets/keyfile.json\"\r\n```\r\n\r\n```java\r\n    FirestoreOptions firestoreOptions = FirestoreOptions.getDefaultInstance().toBuilder()\r\n        .setProjectId(projectId)\r\n        .build();\r\n```\r\n\r\n**Option 2: Explicit**\r\n\r\n```java\r\n    FirestoreOptions firestoreOptions = FirestoreOptions.getDefaultInstance().toBuilder()\r\n        .setCredentials(GoogleCredentials.fromStream(new FileInputStream(\"/usr/local/google/home/samstern/service-accounts/firestore-snippets/keyfile.json\")))\r\n        .setProjectId(projectId)\r\n        .build();\r\n```\r\n\r\nIn both cases **most** of my API calls work (read, write, update, etc).  However in the case of using the `GOOGLE_APPLICATION_CREDENTIALS` environment variable I get failures when running transactions and calling `DocumentReference#getCollections()`:\r\n\r\n```\r\njava.util.concurrent.ExecutionException: com.google.api.gax.rpc.PermissionDeniedException: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Missing or insufficient permissions.\r\n\r\n\tat com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:500)\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:479)\r\n\tat com.google.api.core.AbstractApiFuture.get(AbstractApiFuture.java:56)\r\n\tat com.example.firestore.snippets.ManageDataSnippetsIT.testSimpleTransaction(ManageDataSnippetsIT.java:150)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\r\n\tat org.junit.runners.Suite.runChild(Suite.java:27)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\r\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\r\n\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\r\nCaused by: com.google.api.gax.rpc.PermissionDeniedException: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Missing or insufficient permissions.\r\n\tat com.google.api.gax.rpc.ApiExceptionFactory.createException(ApiExceptionFactory.java:55)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.setException(GrpcExceptionCallable.java:118)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:101)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:61)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:458)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:433)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:41)\r\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:339)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:443)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:525)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:446)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:557)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:107)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:295)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Missing or insufficient permissions.\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 17 more\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2781",
        "number": 2781,
        "title": "Don't set versions of external dependencies in BOM",
        "labels": [
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "For example, in https://github.com/GoogleCloudPlatform/google-cloud-java/blob/184c219c7a7d38bd8146e3a4d35f0972a1d24a10/google-cloud-bom/pom.xml#L136 we're setting the version of `netty-tcnative-boringssl-static`. This conflicts with the version we're using in [spring-cloud-gcp](https://github.com/spring-cloud/spring-cloud-gcp).\r\n\r\nIf users build their application, they get\r\n\r\n```\r\njava.lang.NoClassDefFoundError: Could not initialize class io.netty.handler.ssl.OpenSslEngine\r\n\tat io.netty.handler.ssl.OpenSslContext.newEngine0(OpenSslContext.java:49)\r\n\tat io.netty.handler.ssl.ReferenceCountedOpenSslContext.newEngine(ReferenceCountedOpenSslContext.java:378)\r\n\tat io.grpc.netty.ProtocolNegotiators$TlsNegotiator$1.handlerAdded(ProtocolNegotiators.java:306)\r\n\tat io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:606)\r\n\t... 19 common frames omitted\r\n```\r\n\r\nIdeally, BOMs only export the versions of the modules the project implements. The dependencies used by the project should go in another pom, e.g., https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/pom.xml\r\n\r\nCan we remove the versions of the dependencies of `google-cloud-java` from the BOM?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2778",
        "number": 2778,
        "title": "Integration tests stall when installing locally",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I followed the instructions in https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/CONTRIBUTING.md, but all the integration tests got stuck indefinitely, some throwing error messages and either resuming or staying stalled.\r\n\r\nI eventually had to use the -DskipTests flag to install."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2777",
        "number": 2777,
        "title": "Record leaf types are not supported.repeated",
        "labels": [],
        "state": "closed",
        "body": "I am trying to stream data using _insertAll_ API to a column in **BigQuery** table with type **Record** which has a **Nested Record** with **Repeated** mode. \r\n\r\nBut the insert failed with message: \r\nRecord leaf types are not supported.repeated"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2775",
        "number": 2775,
        "title": "FR: support for HTTP proxy & SOCKS proxy",
        "labels": [
            "api: core",
            "type: feature request"
        ],
        "state": "open",
        "body": "Many corporate networks require the use of either a [HTTP Proxy](https://en.wikipedia.org/wiki/Proxy_server) or a [SOCKS](https://en.wikipedia.org/wiki/SOCKS) proxy.  Our client libraries should support this.\r\n\r\n@bullet-tooth in google/google-auth-library-java#127 asked that we support both an `HTTP_PROXY` and `SOCKS_PROXY` in our auth libraries.  We need to also support through all the client libraries as many of our customers have this issue on their corporate networks.\r\n\r\n@jonparrott FYI\r\n@garrettjonesgoogle FYI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2771",
        "number": 2771,
        "title": "Firestore: DocumentReference#getCollections() should be async",
        "labels": [
            "api: firestore",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Most of the Firestore operations return `ApiFuture<T>`.  The method `DocumentReference#getCollections()` returns an `Iterable<CollectionReference>` but it should probably return `ApiFuture<Iterable<CollectionReference>>` since it calls over the network."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2769",
        "number": 2769,
        "title": "it's very difficult to unit test with non-publicly-constructable data types",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I am writing a small wrapper around google-cloud-bigquery that is illustrated by\r\n\r\n```java\r\n  public long getNumRows(BigQuery bq, String dataset, String table) {\r\n    return bq.getTable(dataset, table)\r\n        .<StandardTableDefinition>getDefinition()\r\n        .getNumRows();\r\n  }\r\n```\r\n\r\nWhen I go to unit test this method I have to mock out `Table` and `StandardTableDefinition`, because `Table` doesn't have a public builder and `StandardTableDefinition`'s public builder does not have a public `setNumRows`.\r\n\r\nThis less usable than the underlying generated library where I can construct all the model objects directly. I have had this issue with other google-cloud-java components as well.\r\n\r\nI understand the desire to minimize the public API for maintainability, but some kind of testing visibility for constructing ADTs would help a lot. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2759",
        "number": 2759,
        "title": "Spanner: Add API for binding lists of tuples into queries",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Spanner supports queries with lists of tuples: `SELECT * FROM Foo WHERE (a, b) IN ((\"x\", 1), (\"y\", 2))`. The Spanner API library's Statement builder seems to not support any way of binding the tuple list dynamically into the query. As far as I can tell, there's no way to give it a string like `SELECT * FROM Foo WHERE (a, b) IN @var` and construct a query like the one above. (I imagine that value would be given as a List of Struct objects each with \"a\" and \"b\" properties.)\r\n\r\nThere's methods for binding various types of arrays (`Statement.newBuilder(...).bind(...).toStringArray(...).build()`), but no way to provide an array or list of Struct objects or equivalent.\r\n\r\nCurrently, it seems like I have to dynamically create the query string and escape the values into the string myself."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2758",
        "number": 2758,
        "title": "all: license headers shouldn't have \"All rights reserved\"",
        "labels": [],
        "state": "closed",
        "body": "Originally reported by @tswast \r\n\r\nPer https://opensource.google.com/docs/releasing/preparing/#include-license-file-and-source-code-headers the top line should be Copyright 2017 Google LLC (no All rights reserved.)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2756",
        "number": 2756,
        "title": "CloudStorageFileSystem: can not list content of root directory",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "```\r\nCloudStorageFileSystem.forBucket(\"someBucket\", CloudStorageConfiguration.builder().permitEmptyPathComponents(true).build()).use {\r\n            println(Files.list(it.getPath(\".\")).toList().size) // prints 0 although there is a file in the bucket\r\n        }\r\n```\r\nprintln(Files.list(it.getPath(\"/\")).toList().size) throws an exception\r\njava.lang.IllegalArgumentException: I/O not allowed on empty Google Cloud Storage object names.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2753",
        "number": 2753,
        "title": "BigQuery: Create new Table using schema from json file",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I have an App Engine Standard Maven project, where a procedure need to create a Table on BigQuery.\r\n```\r\n<dependency>\r\n    <groupId>com.google.cloud</groupId>\r\n    <artifactId>google-cloud-bigquery</artifactId>\r\n    <version>0.32.0-beta</version>\r\n</dependency>\r\n```\r\n\r\nI'm using the sample code provided here https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-bigquery#creating-a-table\r\n```\r\nTableId tableId = TableId.of(datasetId, \"my_table_id\");\r\n// Table field definition\r\nField stringField = Field.of(\"StringField\", LegacySQLTypeName.STRING);\r\n// Table schema definition\r\nSchema schema = Schema.of(stringField);\r\n// Create a table\r\nStandardTableDefinition tableDefinition = StandardTableDefinition.of(schema);\r\nTable createdTable = bigquery.create(TableInfo.of(tableId, tableDefinition));\r\n```\r\n\r\nThe difference with my need, compared to this example, is that I have a json file which contains the schema. Here is an example:\r\n```\r\n[\r\n\t{\r\n\t\t\"mode\": \"REQUIRED\",\r\n\t\t\"name\": \"identifier\",\r\n\t\t\"type\": \"STRING\"\r\n\t},\r\n\t{\r\n\t\t\"mode\": \"REQUIRED\",\r\n\t\t\"name\": \"code\",\r\n\t\t\"type\": \"STRING\"\r\n\t},\r\n\t{\r\n\t\t\"mode\": \"REQUIRED\",\r\n\t\t\"name\": \"description\",\r\n\t\t\"type\": \"STRING\"\r\n\t}\r\n]\r\n```\r\n\r\nI'm unable to find an existing method which load the table schema from a json file, instead of creating it manually from Schema/FieldList/Field classes.\r\nSomething like\r\n```\r\nSchema schema = Schema.parseJson(jsonSchema);\r\n```\r\n**Is there way to load the json file or do I need to build a custom parser?**\r\n  \r\n\r\nWhile I'm waiting for a reply, I wrote a custom deserializer based on Gson library. It is working, but if there is an already built-in method, I'll be more than happy to use it\r\n```\r\npublic static void main(String[] args) {\r\n    // TODO Load schema from file\r\n    String jsonSchema = \"[{\\\"mode\\\":\\\"REQUIRED\\\",\\\"name\\\":\\\"identifier\\\",\\\"type\\\":\\\"STRING\\\"},{\\\"mode\\\":\\\"REQUIRED\\\",\\\"name\\\":\\\"code\\\",\\\"type\\\":\\\"STRING\\\"},{\\\"mode\\\":\\\"REQUIRED\\\",\\\"name\\\":\\\"description\\\",\\\"type\\\":\\\"STRING\\\"}]\";\r\n\r\n    // Json schema uses \"fields\"\r\n    // com.google.cloud.bigquery.Field uses \"subFields\"\r\n    // FIXME Unable to use @SerializedName policy\r\n    jsonSchema = jsonSchema.replace(\"\\\"fields\\\"\", \"\\\"subFields\\\"\");\r\n\r\n    // Deserialize schema with custom Gson\r\n    Field[] fields = getGson().fromJson(jsonSchema, Field[].class);\r\n    Schema schema = Schema.of(fields);\r\n\r\n    System.out.println(schema.toString());\r\n}\r\n\r\npublic static Gson getGson() {\r\n    JsonDeserializer<LegacySQLTypeName> typeDeserializer = (jsonElement, type, deserializationContext) -> {\r\n        return LegacySQLTypeName.valueOf(jsonElement.getAsString());\r\n    };\r\n\r\n    JsonDeserializer<FieldList> subFieldsDeserializer = (jsonElement, type, deserializationContext) -> {\r\n        Field[] fields = deserializationContext.deserialize(jsonElement.getAsJsonArray(), Field[].class);\r\n        return FieldList.of(fields);\r\n    };\r\n\r\n    return new GsonBuilder()\r\n        .registerTypeAdapter(LegacySQLTypeName.class, typeDeserializer)\r\n        .registerTypeAdapter(FieldList.class, subFieldsDeserializer)\r\n        .create();\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2748",
        "number": 2748,
        "title": "make standard sql the default",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2746",
        "number": 2746,
        "title": "Add option to clear traceId thread-local in TraceLoggingEnhancer",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "When the `traceId` thread-local needs to be removed, calling `setCurrentTraceId(null)` is not appropriate because it still leaves a thread-local entry. Instead, and indirect call to `ThreadLocal.remove()` should be exposed. One option is to provide a method called `removeCurrentTraceId`. Another alternative, is to detect the `null` argument to `setCurrentTraceId` and call `remove()` instead of `set(null)` in that case."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2745",
        "number": 2745,
        "title": "Add google-cloud-logging-logback to the dependencies BOM",
        "labels": [
            "dependencies",
            "priority: p2"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2744",
        "number": 2744,
        "title": "Pub/Sub should use a dedicated executor for offloading messages to the user",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "Right now, if a user blocks while processing messages, they will cause acks/mod acks to be delayed causing a greater number of duplicates. If we use a separate executor, they will instead just process messages slower, without affecting normal client library operation."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2740",
        "number": 2740,
        "title": "java.lang.ClassNotFoundException: org/eclipse/jetty/alpn/ALPN",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "My team has built a very thing wrapper around the spanner java driver and we have ran a number of tests successfully. \r\n\r\nAn issue came up when we tried to integrate the layer we built with vert.x (http://vertx.io) \r\n\r\nAn exception is occurring on the following code block:\r\n\r\n```java\r\nSpannerOptions.newBuilder().build();\r\n```\r\n\r\nThe following exception is being thrown: \r\n```\r\njava.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:162)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:136)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:124)\r\n\tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:94)\r\n\tat com.google.cloud.spanner.SpannerOptions$NettyRpcChannelFactory.newSslContext(SpannerOptions.java:318)\r\n\tat com.google.cloud.spanner.SpannerOptions$NettyRpcChannelFactory.newChannel(SpannerOptions.java:306)\r\n\tat com.google.cloud.spanner.SpannerOptions.createChannel(SpannerOptions.java:279)\r\n\tat com.google.cloud.spanner.SpannerOptions.createChannels(SpannerOptions.java:266)\r\n\tat com.google.cloud.spanner.SpannerOptions.<init>(SpannerOptions.java:91)\r\n\tat com.google.cloud.spanner.SpannerOptions.<init>(SpannerOptions.java:45)\r\n\tat com.google.cloud.spanner.SpannerOptions$Builder.build(SpannerOptions.java:202)\r\n\tat com.godaddy.commerce.store.core.RelationalStoreSpanner.<init>(RelationalStoreSpanner.java:52)\r\n\tat com.godaddy.commerce.store.core.RelationalStore.<init>(RelationalStore.java:38)\r\n\tat com.godaddy.commerce.store.examples.SpannerExampleVerticle.start(SpannerExampleVerticle.java:36)\r\n\tat io.vertx.core.AbstractVerticle.start(AbstractVerticle.java:111)\r\n\tat io.vertx.core.impl.DeploymentManager.lambda$doDeploy$10(DeploymentManager.java:481)\r\n\tat io.vertx.core.impl.ContextImpl.lambda$wrapTask$2(ContextImpl.java:344)\r\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: org/eclipse/jetty/alpn/ALPN\r\n\tat java.lang.Class.forName0(Native Method)\r\n\tat java.lang.Class.forName(Class.java:348)\r\n\tat io.grpc.netty.JettyTlsUtil.isJettyAlpnConfigured(JettyTlsUtil.java:34)\r\n\tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:153)\r\n\t... 21 more\r\n```\r\n\r\nThe dependency tree is as follows:\r\n```com.godaddy.commerce.store.examples:spanner-example:jar:0.0.1-SNAPSHOT\r\n+- io.vertx:vertx-core:jar:3.5.0:compile\r\n|  +- io.netty:netty-common:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-buffer:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-transport:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-handler:jar:4.1.15.Final:compile\r\n|  |  \\- io.netty:netty-codec:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-handler-proxy:jar:4.1.15.Final:compile\r\n|  |  \\- io.netty:netty-codec-socks:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-codec-http:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-codec-http2:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-resolver:jar:4.1.15.Final:compile\r\n|  +- io.netty:netty-resolver-dns:jar:4.1.15.Final:compile\r\n|  |  \\- io.netty:netty-codec-dns:jar:4.1.15.Final:compile\r\n|  +- com.fasterxml.jackson.core:jackson-core:jar:2.9.1:compile\r\n|  \\- com.fasterxml.jackson.core:jackson-databind:jar:2.9.1:compile\r\n+- io.vertx:vertx-web:jar:3.5.0:compile\r\n|  +- io.vertx:vertx-auth-common:jar:3.5.0:compile\r\n|  \\- io.vertx:vertx-bridge-common:jar:3.5.0:compile\r\n+- io.vertx:vertx-web-client:jar:3.5.0:compile\r\n|  \\- io.vertx:vertx-web-common:jar:3.5.0:compile\r\n+- io.vertx:vertx-unit:jar:3.5.0:compile\r\n+- junit:junit:jar:4.12:compile\r\n|  \\- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n\\- com.x.y:0.0.1-SNAPSHOT:compile\r\n   +- com.google.cloud:google-cloud-spanner:jar:0.32.0-beta:compile\r\n   |  +- io.netty:netty-tcnative-boringssl-static:jar:2.0.6.Final:test\r\n   |  +- com.google.cloud:google-cloud-core:jar:1.14.0:compile\r\n   |  |  +- com.google.guava:guava:jar:20.0:compile\r\n   |  |  +- org.json:json:jar:20160810:compile\r\n   |  |  +- com.google.http-client:google-http-client:jar:1.23.0:compile\r\n   |  |  |  \\- org.apache.httpcomponents:httpclient:jar:4.5.3:compile\r\n   |  |  |     +- org.apache.httpcomponents:httpcore:jar:4.4.7:compile\r\n   |  |  |     +- commons-logging:commons-logging:jar:1.2:compile\r\n   |  |  |     \\- commons-codec:commons-codec:jar:1.10:compile\r\n   |  |  +- com.google.api:api-common:jar:1.2.0:compile\r\n   |  |  +- com.google.api:gax:jar:1.15.0:compile\r\n   |  |  +- com.google.protobuf:protobuf-java-util:jar:3.4.0:compile\r\n   |  |  +- com.google.api.grpc:proto-google-common-protos:jar:1.0.2:compile\r\n   |  |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.1.26:compile\r\n   |  +- com.google.cloud:google-cloud-core-grpc:jar:1.14.0:compile\r\n   |  |  +- com.google.auth:google-auth-library-credentials:jar:0.9.0:compile\r\n   |  |  +- com.google.protobuf:protobuf-java:jar:3.4.0:compile\r\n   |  |  +- io.grpc:grpc-protobuf:jar:1.7.0:compile\r\n   |  |  |  \\- io.grpc:grpc-protobuf-lite:jar:1.7.0:compile\r\n   |  |  \\- io.grpc:grpc-context:jar:1.7.0:compile\r\n   |  +- com.google.api:gax-grpc:jar:1.15.0:compile\r\n   |  |  +- com.google.auto.value:auto-value:jar:1.2:compile\r\n   |  |  +- org.threeten:threetenbp:jar:1.3.3:compile\r\n   |  |  \\- com.google.auth:google-auth-library-oauth2-http:jar:0.9.0:compile\r\n   |  |     \\- com.google.http-client:google-http-client-jackson2:jar:1.19.0:compile\r\n   |  +- com.google.api.grpc:proto-google-cloud-spanner-v1:jar:0.1.26:compile\r\n   |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-database-v1:jar:0.1.26:compile\r\n   |  +- com.google.api.grpc:proto-google-cloud-spanner-admin-instance-v1:jar:0.1.26:compile\r\n   |  +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.26:compile\r\n   |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.26:compile\r\n   |  +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.26:compile\r\n   |  +- com.google.api.grpc:grpc-google-common-protos:jar:1.0.2:compile\r\n   |  +- io.grpc:grpc-netty:jar:1.7.0:compile\r\n   |  |  \\- io.grpc:grpc-core:jar:1.7.0:compile (version selected from constraint [1.7.0,1.7.0])\r\n   |  |     +- com.google.errorprone:error_prone_annotations:jar:2.0.19:compile\r\n   |  |     +- com.google.instrumentation:instrumentation-api:jar:0.4.3:compile\r\n   |  |     \\- io.opencensus:opencensus-api:jar:0.6.0:compile\r\n   |  +- io.grpc:grpc-auth:jar:1.7.0:compile\r\n   |  +- io.grpc:grpc-stub:jar:1.7.0:compile\r\n   |  +- com.google.code.findbugs:jsr305:jar:3.0.0:compile\r\n   |  \\- joda-time:joda-time:jar:2.9.2:compile\r\n   +- org.slf4j:slf4j-api:jar:1.7.25:compile\r\n```\r\n\r\nThe environment I'm developing on is the following:\r\n\r\nOS: MacOSX\r\nJDK Version: 1.8.0_152\r\nSpanner Driver version: 0.32.0-beta \r\n\r\nI believe this is a gRPC error. I have tried excluding dependencies such as grpc-netty but that hasn't sorted the issue yet. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2737",
        "number": 2737,
        "title": "Pipeline throws exceptions on Data Flow indicating bad linking with existing class ",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I'm having a similar problem to https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2496\r\n\r\nMy pipeline presets problems on executing queries. Which is done based in a class of mine. Basically, he initiates, but can't proceed.\r\n\r\n[Exception.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1597566/Exception.txt)\r\n\r\n\r\nthis is my pom.xml:\r\n\r\n[pom.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1597554/pom.txt)\r\n\r\nand, finally, my class:\r\n\r\n\r\n[BigQueryConnectionBuilder_java.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1597557/BigQueryConnectionBuilder_java.txt)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2736",
        "number": 2736,
        "title": "BigQuery Data Transfer: ListDataSourcesRequest not documented / not linked to",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: process"
        ],
        "state": "closed",
        "body": "See: https://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/com/google/cloud/bigquery/datatransfer/v1/DataTransferServiceClient.html#listDataSources-com.google.cloud.bigquery.datatransfer.v1.ListDataSourcesRequest-\r\n\r\nI would expect `com.google.cloud.bigquery.datatransfer.v1.ListDataSourcesRequest` to be a hyperlink to the ListDataSourcesRequest class, but it is not. A search within that page for ListDataSourcesRequest does not show any documentation for that class."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2735",
        "number": 2735,
        "title": "Exceptions logged with Logback + SLF4J don't show up in Stackdriver",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I'm using the Logback + SLF4J logging configuration described in the official documentation [here](https://cloud.google.com/logging/docs/setup/java).\r\nEverything works fine with simple log messages like:\r\n```java\r\nimport org.slf4j.Logger;\r\nimport org.slf4j.LoggerFactory;\r\n...\r\nprivate static final Logger logger = LoggerFactory.getLogger(MyClass.class);\r\n...\r\nlogger.info(\"Hello world\");\r\n```\r\n\r\nThe problem appears when I try to log exceptions like this:\r\n```java\r\nlogger.error(\"Something went wrong:\", ex);\r\n```\r\n\r\nI see only my description message in Stackdriver but not the stack trace from the provided exception.\r\nWhat can be the problem here?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2733",
        "number": 2733,
        "title": "Pub/Sub Subscriber service that should never stop listening for new messages",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI think I've now looked at all Pub/Sub Java client examples in the official docs and seems all of them have an idea of stopping Subscriber service at some point with `subscriber.stopAsync();` call. But what if I want to implement a service that should listen for Pub/Sub messages on a subscription and never exit. What would be a recommended way of doing it?\r\nMaybe you can explain a common idea or provide such an example here and also add it to the docs?\r\nIn case there is already such an example, could you please point me to it."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2732",
        "number": 2732,
        "title": "Is google-cloud-java GCE misrepresented in root README",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "From b/70926158\r\n\r\nIn the README for GCE:\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-compute/README.md\r\n\r\n\"Note: This client is no longer receiving updates; new features in the Compute API will not be added to this client. Check https://cloud.google.com/compute/docs/api/libraries for the recommended Java client library to use for accessing Compute.\"\r\n\r\nYet this is listed in the main README as having \"alpha\" support:\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/README.md\r\n\r\n\"This client supports the following Google Cloud Platform services at an Alpha quality level:\r\n- Cloud Compute (Alpha)\"\r\n\r\nThis seems misleading, and that the GCE component should be in a separate section, or marked somehow at this level, especially since the following page points people to this component as the \"preferred\" client library, in general:\r\n\r\nhttps://cloud.google.com/apis/docs/cloud-client-libraries"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2731",
        "number": 2731,
        "title": "Pub/Sub client should allow connecting to different backends without changes in code",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Current Pub/Sub client can be made to use an emulator service instead of pubsub.googleapis.com as the API service. The way this is implemented, however,  appears to require the users to both set an environment variable AND change the client code.  It seems to me this makes hermetic testing difficult.   I think, as an application developer, I would be much happier if I could test my code against an emulator or an alternate backend without touching the code itself.  So the feature request here is that:\r\n\r\nThe code required to use the emulator currently looks kind of like this:\r\n```bash \r\n$export PUBSUB_EMULATOR_HOST=10.0.0.200:1234\r\n```\r\n```java\r\n String hostport = System.getenv(\"PUBSUB_EMULATOR_HOST\");\r\n    ManagedChannel channel = ManagedChannelBuilder.forTarget(hostport).usePlaintext(true).build();\r\n    try {\r\n      TransportChannelProvider channelProvider =\r\n          FixedTransportChannelProvider.create(GrpcTransportChannel.create(channel));\r\n      CredentialsProvider credentialsProvider = NoCredentialsProvider.create();\r\n\r\n      TopicName topicName = TopicName.of(\"my-project-id\", \"my-topic-id\");\r\n      // Set the channel and credentials provider when creating a `Publisher`.\r\n      // Similarly for Subscriber\r\n      Publisher publisher =\r\n          Publisher.newBuilder(topicName)\r\n              .setChannelProvider(channelProvider)\r\n              .setCredentialsProvider(credentialsProvider)\r\n              .build();\r\n```\r\nMight we make it look identical to \"normal production code\" used to accomplish the same thing? That is:\r\n```java\r\n      TopicName topicName = TopicName.of(\"my-project-id\", \"my-topic-id\");\r\n      // Create a publisher instance with default settings bound to the topic\r\n      publisher = Publisher.newBuilder(topicName).build();\r\n```\r\nand all the channel building would happen automatically? I presume all but the hostport line are already part of the client library code base. \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2727",
        "number": 2727,
        "title": "Make google-cloud-logging work with cloud-trace-java",
        "labels": [
            "api: cloudtrace",
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "I want both stackdriver tracing and logging in my project and seems like there is no way to make both of them work on the same project. \r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-logging\r\nhttps://github.com/GoogleCloudPlatform/cloud-trace-java\r\n\r\nThe issue is the library conflict for `com.google.api:gax-grpc` (and possibly others):\r\n\r\nThe latest `com.google.cloud:google-cloud-logging:1.14.0` depends on `om.google.api:gax-grpc:1.15.0` but \r\nthe latest `com.google.cloud.trace:trace-grpc-api-service:0.5.0` depends on ` com.google.cloud.trace.v1:grpc-consumer:0.5.0` -> `com.google.cloud:google-cloud-trace:0.24.0-alpha` -> `com.google.cloud:google-cloud-core-grpc:1.6.0` -> `com.google.api:gax-grpc:0.25.1`.\r\n\r\nSo the logging depends on `gax-grpc:1.15.0` but the tracing depends on `gax-grpc:0.25.1` and they are not backward compatible (some classes are removed/renamed).\r\n\r\nIs there any way to have a set of versions for these two libraries to work together?\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2724",
        "number": 2724,
        "title": "Pub/Sub : Large number of threads created leading to OutOfMemory",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "This is described in detail in https://github.com/netty/netty/issues/7520 . Since I narrowed it down to being a PubSub problem, I'm logging it here. Please let me know if I should copy-paste the contents of the other issue here. \r\n\r\nTurning off PubSub (and replacing it with an in-memory messaging system) in the same application leads to perfectly normal behaviour without any memory issues. I've also monitored this using jvisualvm, and one observation is that each time com.google.cloud.pubsub.v1.MessageDispatcher$2.run is called, lot of new threads get created and don't die. The heap dump also shows this, with around 37k threads.\r\n\r\n**PubSub version**\r\n0.26.0-beta\r\n\r\n**JVM version**\r\nopenjdk version \"1.8.0_151\"\r\nOpenJDK Runtime Environment (build 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12)\r\nOpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode)\r\n\r\n**OS version**\r\nLinux 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nDISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=16.04\r\nDISTRIB_CODENAME=xenial\r\nDISTRIB_DESCRIPTION=\"Ubuntu 16.04.3 LTS\""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2722",
        "number": 2722,
        "title": "Pub/Sub: publisher fails to publish more than 1000 messages, with DEADLINE_EXCEEDED",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "I've slightly modified this very basic publisher code offered to me by one of the customers. The code runs when we try to publish 1000 messages, but fails with a gRPC timeout exception when I try to run it with 10K messages.    \r\n<pre>\r\nimport com.codahale.metrics.Counter;\r\nimport com.codahale.metrics.MetricRegistry;\r\nimport com.google.api.core.ApiFuture;\r\nimport com.google.api.core.ApiFutureCallback;\r\nimport com.google.api.core.ApiFutures;\r\nimport com.google.cloud.ServiceOptions;\r\nimport com.google.cloud.pubsub.v1.Publisher;\r\nimport com.google.protobuf.ByteString;\r\nimport com.google.pubsub.v1.PubsubMessage;\r\nimport com.google.pubsub.v1.TopicName;\r\n\r\n\r\nimport java.util.Random;\r\n\r\npublic class App {\r\n    public static void main(String[] args) throws Exception {\r\n        MetricRegistry metricRegistry = new MetricRegistry();\r\n        Counter failedPubSubSends = metricRegistry.counter(\"fail\");\r\n        Counter successfulPubSubSends = metricRegistry.counter(\"success\");\r\n        TopicName topicName = TopicName.of(ServiceOptions.getDefaultProjectId(), args[0]);\r\n        Publisher.Builder builder = Publisher.newBuilder(topicName);\r\n        Publisher publisher = builder.build();\r\n        long millis = System.currentTimeMillis();\r\n        Integer numberOfMessages = Integer.valueOf(args[1   ]);\r\n        try {\r\n            byte[] data = new byte[700];\r\n            new Random().nextBytes(data);\r\n            for (int i = 0; i < numberOfMessages; i++) {\r\n                ApiFuture<String> resultFuture = publisher.publish(PubsubMessage.newBuilder().setData(ByteString.copyFrom(data)).build());\r\n                ApiFutures.addCallback(resultFuture, new ApiFutureCallback<String>() {\r\n                    public void onSuccess(String result) {\r\n                        successfulPubSubSends.inc();\r\n                    }\r\n                    public void onFailure(Throwable t) {\r\n                        failedPubSubSends.inc();\r\n                        System.out.println(t.toString());\r\n                    }\r\n                });\r\n            }\r\n        } finally {\r\n            publisher.shutdown();\r\n            System.out.println(\"took \" + (System.currentTimeMillis() - millis) + \" ms for \" + numberOfMessages\r\n                    + \" (success \" + successfulPubSubSends.getCount() + \" / failed \" + failedPubSubSends.getCount() + \")\");\r\n        }\r\n    }\r\n}\r\n</pre>\r\nThe output is mainly lines like this:\r\n<pre> \r\ncom.google.api.gax.rpc.DeadlineExceededException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 9999990738ns\r\n</pre>\r\nAnd the final outcome is a typical 80-90% failure rate.\r\n<pre>\r\ntook 16906 ms for 100000 (success 12232 / failed 87768)\r\n</pre>\r\n\r\nServerside, I see no errors which suggests that this is a client side issue. \r\n\r\nWhat I would expect in this case: the code just publishes this set of messages."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2721",
        "number": 2721,
        "title": "Pub/Sub publisher retrySettings: runtime errors that should be compile time",
        "labels": [
            "api: pubsub",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Publisher built with these retry settings fails at runtime, with generic \"illegal argument exception.\"\r\nThe error does point to specific failed pre-conditions, which have to do with minTotalTimeout -- which I had not set here. \r\n\r\n<pre>\r\n        RetrySettings retrySetting = RetrySettings.newBuilder()\r\n                .setInitialRpcTimeout(Duration.ofMillis(500))\r\n                .setMaxAttempts(10)\r\n                .setJittered(Boolean.TRUE)\r\n                .setMaxRpcTimeout(Duration.ofMillis(500))\r\n                .build();\r\n</pre>\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2720",
        "number": 2720,
        "title": "bigquery: setUseLegacySql missing in java API",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Original bug created here: https://issuetracker.google.com/issues/70662064\r\n\r\n```\r\nThe new Java API does not offer the setUseLegacySql() method that had the old API.\r\nThat means we can only create views in LegacySQL.\r\n\r\nCould you please add this method back to the new API?\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2714",
        "number": 2714,
        "title": "Default FlowControlSettings LimitExceededBehavior",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi I'm having an issue with my code, I recently started getting\r\ncom.google.api.gax.batching.FlowController$FlowControlRuntimeException: The maximum number of batch bytes: 10485760 have been reached.\r\n\r\nI can see that's the default behaviour for LoggingOptions.getDefaultInstance().getService(); but the documentation isn't very clear on why its that way or what the alternatives are.\r\nI can see from com.google.api.gax.batching.FlowControlSettings that there are 2 other alternatives Block and Ignore.\r\n\r\nI think it would be helpful if somewhere in the documentation these options and their implications were explained and also how to switch between them.\r\n\r\nI'd be interested to know if I can switch to Block and what that would mean for my program.\r\n\r\nMy program is pulling data from an activeMQ queue, logging it to google and then further processing it.\r\nI have to restart the program or else the error continues on indefinitely. Could this error be caused by a message from the queue being above the limit? and if so if set to block will it process the message anyway?\r\n\r\nHow should this exception be handled so that I can log the data?\r\n\r\nThanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2710",
        "number": 2710,
        "title": "NoSuchMethodError while using cloud pubsub java client",
        "labels": [],
        "state": "closed",
        "body": "Hi - I am new to GCP. I am trying to integrate java app with cloud pubsub emulator. I use java 8 on Windows 10 machine. I simply added the below dependency to pom and ran the example program `CreateSubscriptionAndConsumeMessages`.\r\n\r\n```\r\n<dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-pubsub</artifactId>\r\n            <version>0.32.0-beta</version>\r\n        </dependency>\r\n```\r\nI get the below error. Shouldn't all the dependencies be managed by google java client?. If there are exceptions, please document it.\r\n\r\n```\r\nException in thread \"main\" java.lang.NoSuchMethodError: com.google.common.base.Throwables.throwIfInstanceOf(Ljava/lang/Throwable;Ljava/lang/Class;)V\r\n\tat com.google.api.gax.rpc.ApiExceptions.callAndTranslateApiException(ApiExceptions.java:56)\r\n\tat com.google.api.gax.rpc.UnaryCallable.call(UnaryCallable.java:112)\r\n\tat com.google.cloud.pubsub.v1.SubscriptionAdminClient.createSubscription(SubscriptionAdminClient.java:282)\r\n\tat com.google.cloud.pubsub.v1.SubscriptionAdminClient.createSubscription(SubscriptionAdminClient.java:250)\r\n\tat io.flux.modelservice.subscribers.CreateSubscriptionAndConsumeMessages.main(CreateSubscriptionAndConsumeMessages.java:24)\r\n\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2708",
        "number": 2708,
        "title": "Please add a README to google-cloud-bom",
        "labels": [],
        "state": "closed",
        "body": "google-cloud-java/google-cloud-bom/pom.xml\r\n\r\nso it is clear to users what is the latest release version to include and how to include that in a `dependencyManagement` section"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2707",
        "number": 2707,
        "title": "google-api-client-appengine dependency for App Engine apps",
        "labels": [],
        "state": "closed",
        "body": "On https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-compute, we read:\r\n\r\n\"In CreateAddressDiskAndInstance.java we put together all the code shown above into one program. The program assumes that you are running on Compute Engine or from your own desktop. To run the example on App Engine, simply move the code from the main method to your application's servlet class and change the print statements to display on your webpage.\"\r\n\r\nThis might not be all that's required to run on App Engine. In particular it might also be necessary to add a dependency on google-api-client-appengine to pom.xml. Do you know anything about this?\r\n\r\nSee https://github.com/GoogleCloudPlatform/google-cloud-eclipse/issues/2674 and https://developers.google.com/api-client-library/java/google-api-java-client/setup#google-api-client-appengine\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2706",
        "number": 2706,
        "title": "Docs have squashed text",
        "labels": [],
        "state": "closed",
        "body": "An image says it all: \r\n<img width=\"555\" alt=\"screen shot 2017-12-13 at 10 52 32 am\" src=\"https://user-images.githubusercontent.com/468559/33956560-c5bf5bda-dff3-11e7-8eda-cdd4f7c53f5f.png\">\r\n\r\nThis is on https://googlecloudplatform.github.io/google-cloud-java/0.32.0/index.html."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2702",
        "number": 2702,
        "title": "Feature Request: Signed URLs for Google Cloud Storage Blobs and Buckets ",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Would it be possible to add functionality to Blob and Bucket to provide signed URLs?\r\n\r\nWe were discussing this topic (spring-cloud/spring-cloud-gcp#251) and it looks like the existing instructions on the dev site has users construct that URL themselves."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2701",
        "number": 2701,
        "title": "Home page on website looks screwy",
        "labels": [],
        "state": "closed",
        "body": "Something is amiss with the [home page for the google-cloud-java website](https://googlecloudplatform.github.io/google-cloud-java/0.32.0/index.html). The text \"google-cloud\" is overlapping with itself:\r\n\r\n![google-cloud-java-home-page](https://user-images.githubusercontent.com/1522391/33903052-d786e176-df2b-11e7-8864-0668654702df.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2699",
        "number": 2699,
        "title": "Class name which contain special character like '$' not added",
        "labels": [
            "api: translation",
            "type: question"
        ],
        "state": "closed",
        "body": "I am not using your project.. I am using google cloud translate jar file in my project. I know this is not the place to ack question not related to this project but i need help.\r\nwhen i add jar file in my lib folder in android studio the .class files which contain '$' sign in there name not added. And due to this when i run my project it gives error that this file is missing. The error is.\r\n\r\n>  java.lang.NoClassDefFoundError: com.google.cloud.translate.TranslateOptions$TranslateDefaults\r\n>                                                                                 at com.google.cloud.translate.TranslateOptions.<init>(TranslateOptions.java:147)\r\n>                                                                                 at com.google.cloud.translate.TranslateOptions.<init>(TranslateOptions.java:39)\r\n>                                                                                 at com.google.cloud.translate.TranslateOptions$Builder.build(TranslateOptions.java:142)\r\n>                                                                                 at edu.nic.dell.naseemchatbot.ChatActivity.translateTextWithOptionsAndModel(ChatActivity.java:938)\r\n>                                                                                 at edu.nic.dell.naseemchatbot.ChatActivity$5.onClick(ChatActivity.java:272)\r\n>                                                                                 at android.view.View.performClick(View.java:4766)\r\n>                                                                                 at android.view.View$PerformClick.run(View.java:19683)\r\n>                                                                                 at android.os.Handler.handleCallback(Handler.java:739)\r\n>                                                                                 at android.os.Handler.dispatchMessage(Handler.java:95)\r\n>                                                                                 at android.os.Looper.loop(Looper.java:135)\r\n>                                                                                 at android.app.ActivityThread.main(ActivityThread.java:5538)\r\n>                                                                                 at java.lang.reflect.Method.invoke(Native Method)\r\n>                                                                                 at java.lang.reflect.Method.invoke(Method.java:372)\r\n>                                                                                 at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:960)\r\n>                                                                                 at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:755)\r\n\r\nPlease help me out here. Thank you"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2698",
        "number": 2698,
        "title": "google cloud storage signed url with custom meta header",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "I don't see any option to generate signed url with headers other than 'Content-Type'\r\nI want to generate signed url with `x-goog-meta-*` header how to achieve that with this client library."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2696",
        "number": 2696,
        "title": "Please update video intelligence README to v1",
        "labels": [
            "api: videointelligence",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Video Intelligence [README](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-video-intelligence/README.md) continues to reference v1beta1 post the release of v1 API.  Can we please update links e.g. to Maven Central and to reference docs?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2694",
        "number": 2694,
        "title": "Specify custom machine type while Compute instance creation",
        "labels": [],
        "state": "closed",
        "body": "We want to use custom machines type while creating new compute instances with a specific number of CPUs and size of memory: https://github.com/JetBrains/teamcity-google-agent/issues/9\r\n\r\nBut at the moment I could not figure out how to create custom machine type for that. Currently to configure instance we're using the [following code fragment](https://github.com/JetBrains/teamcity-google-agent/blob/master/google-cloud-server/src/main/kotlin/jetbrains/buildServer/clouds/google/connector/GoogleApiConnectorImpl.kt#L94-L95).\r\n\r\nCould you please share the code fragment for that?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2693",
        "number": 2693,
        "title": "Datastore driver should support ID reservation",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This is supported in the low-level client as of version 1.5, which this library [already depends on](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/96fd92b45a1782bfd2304fcf2f2df7e985a4ce4f/google-cloud-bom/pom.xml#L263). #2589 would obviate this."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2688",
        "number": 2688,
        "title": "Spanner client session pool: timeout for creating sessions, more visibility",
        "labels": [
            "api: spanner",
            "type: docs"
        ],
        "state": "open",
        "body": "Hi,\r\n\r\nI've noticed that sometimes `com.google.cloud.spanner.DatabaseClient#readWriteTransaction` takes a long time (~5 seconds) to return the transaction runner.\r\n\r\nWe have `setFailIfPoolExhausted` set to true, so I believe this is the result of a `CreateSession` request taking a long time, possibly due to failing + retrying the rpc, though we have no visibility into this.\r\n\r\nThe library does not allow us to set a timeout for attempts to create sessions which can result in our threads being hung up for several seconds waiting for a session. This is problematic when clients retry and exhausting our server's thread pool since all the threads are blocked waiting for sessions.\r\n\r\nIt would be great if there was the option (either set in `SessionPoolOption` or as a parameter on the `DatabaseClient` functions) that dictates the maximum amount of time to wait trying to get a session.\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2687",
        "number": 2687,
        "title": "Can't attach custom role to service account or container",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I created a custom role that consists of some permission but when I tried to attach it to service account or container programatically it always give error. Is it not supported yet? If it is supported how can I attach it to service account or container?\r\n\r\nMy code are as follow:\r\nIn Google Cloud Storage\r\n```\r\nPolicy policy = storage.getIamPolicy(bucketName);\r\n\r\nPolicy updatedPolicy = storage.setIamPolicy(bucketName, policy.toBuilder().addIdentity(Role.of(\"roles/CustomRole341\"), Identity.serviceAccount(emailServiceAccount)).build());\r\n```\r\n\r\n\r\n\r\n```\r\nServiceAccount user = findServiceAccount(iam, username, projectName);\r\nList<String> member = new ArrayList<String>();\r\nmember.add(Identity.serviceAccount(user.getEmail()).toString());\r\n\r\nBinding s = new Binding();\r\ns.setRole(\"roles/CustomRole341\");\r\ns.setMembers(member);\r\n\r\nList<Binding> bindings = new ArrayList<Binding>();\r\nbindings.add(s);\r\n\r\nPolicy a = new Policy();\r\na.setBindings(bindings);\r\n\r\nSetIamPolicyRequest req = new SetIamPolicyRequest();\r\nreq.setPolicy(a);\r\n\r\niam.projects().serviceAccounts().setIamPolicy(\"projects/\" + projectName + \"/serviceAccounts/\" + username +  \"@\" + projectName + \".iam.gserviceaccount.com\" , req).execute()\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2686",
        "number": 2686,
        "title": "Small inconsistency in Compute interface",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi there,\r\n\r\nJust noticed what i think is a small inconsistency in Compute Interface:\r\nCompute.getNetwork() accepts a **string** (network name) and Compute.getSubnetwork() accepts a **SubnetworkId**\r\n\r\nMost, if not all, other **get** methods accept a ResourceId object"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2683",
        "number": 2683,
        "title": "Resolving project-id when not specified is very slow",
        "labels": [
            "api: storage",
            "performance",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "After recently updating gcloud from 0.26 to 0.30 (cloud storage 1.8.0 to 1.12.0), I found that it became much slower when starting up. Looking at logs, I noticed that this URL fetch of the current project-id (when using `getDefaultInstance()` to initialize a service) is very slow, taking ~5-10 seconds\r\n\r\nhttp://metadata.google.internal/computeMetadata/v1/project/project-id\r\n\r\nI'm not sure if 0.26 did not make this call or not, but I don't think it had the performance issue.\r\n\r\nExplicitly setting project id isn't so bad and eliminates this slowness completely, so it's not a huge issue, but I was surprised to see the significant slow-down when upgrading versions and wonder if this is intended. For context, this is not used in a server but rather in a build task (gradle build cache plugin), so this slow request happens at the start of every build, making them take several seconds longer."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2678",
        "number": 2678,
        "title": "[Bigquery] Empty arrays are not supported as query parameter values ",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "It is perfectly valid to run queries with an empty array as a parameter. Our application has one such query that takes two `ARRAY<INT64>` parameters; either of which (but never both) could potentially be empty. Said query is trivial and is quoted in its entirety below:\r\n```sql\r\nSELECT\r\n  (SELECT AS STRUCT FT.*) AS form_transaction,\r\n  IF(FS.id IS NULL, NULL, (SELECT AS STRUCT FS.*)) AS form_session\r\nFROM\r\n  dev1_1208.FormTransaction AS FT\r\nLEFT JOIN\r\n  dev1_1208.FormSession AS FS\r\nON\r\n  FS.form_transaction_id = FT.id\r\nWHERE\r\n  FT.id IN UNNEST(@transactionIds) OR\r\n  FS.id IN UNNEST(@sessionIds)\r\n```\r\n\r\nRunning this query with explicit array literals (i.e. building the query string with these values pre-substituted, rather than via proper query parameters) works fine, even if one of the arrays is empty (e.g. `FS.id IN UNNEST([])`). Executing this same request against the Bigquery REST API manually via the API Explorer correctly handles empty array parameters also; so this issue is certainly within google-cloud-bigquery itself - it's not a backend API limitation.\r\n\r\nAttempting to execute this query via google-cloud-bigquery fails when handling the response from the Bigquery API with a `NullPointerException` in `QueryParameterValue.fromPb` upon executing the query, at the following line (427):\r\n```java\r\nvalueBuilder.setValue(valuePb.getValue());\r\n```\r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat com.google.cloud.bigquery.QueryParameterValue.fromPb(QueryParameterValue.java:427)\r\n\tat com.google.cloud.bigquery.QueryJobConfiguration$Builder.<init>(QueryJobConfiguration.java:143)\r\n\tat com.google.cloud.bigquery.QueryJobConfiguration$Builder.<init>(QueryJobConfiguration.java:85)\r\n\tat com.google.cloud.bigquery.QueryJobConfiguration.fromPb(QueryJobConfiguration.java:813)\r\n\tat com.google.cloud.bigquery.JobConfiguration.fromPb(JobConfiguration.java:140)\r\n\tat com.google.cloud.bigquery.JobInfo$BuilderImpl.<init>(JobInfo.java:184)\r\n\tat com.google.cloud.bigquery.Job.fromPb(Job.java:307)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:595)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:567)\r\n\tat com.avoka.transact.insights.common.model.BaseQuery$DoSyncQuery.call(BaseQuery.java:489)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat com.google.apphosting.runtime.ApiProxyImpl$CurrentRequestThreadFactory$1$1.run(ApiProxyImpl.java:1249)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat com.google.apphosting.runtime.ApiProxyImpl$CurrentRequestThreadFactory$1.run(ApiProxyImpl.java:1243)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\tat com.google.apphosting.runtime.ApiProxyImpl$CurrentRequestThread.run(ApiProxyImpl.java:1210)\r\n```\r\n\r\nThis occurs due to a number of reasons, detailed as follows:\r\n\r\n`QueryParameterValue.toValuePb` does not set `arrayValues` when the provided array is empty:\r\n```java\r\nif (arrayValues != null && !arrayValues.isEmpty()) {\r\n  valuePb.setArrayValues(\r\n      Lists.transform(arrayValues, QueryParameterValue.TO_VALUE_PB_FUNCTION));\r\n}\r\n```\r\n\r\n`google-cloud-bigquery` defers to the older `google-api-services-bigquery` client library internally, which seems to strip empty arrays from the returned Job object, in `HttpBigQueryRpc.create(Job, ...)`:\r\n\r\n```java\r\n  @Override\r\n  public Job create(Job job, Map<Option, ?> options) {\r\n    try {\r\n      String projectId = job.getJobReference() != null\r\n          ? job.getJobReference().getProjectId() : this.options.getProjectId();\r\n\r\n      // job.getConfiguration().getQuery().getQueryParameters() at this point is:\r\n      //  [{name=transactionIds, parameterType={arrayType={type=INT64}, type=ARRAY}, parameterValue={arrayValues=[{value=688}, {value=689}, {value=690}, {value=686}, {value=687}]}}, {name=sessionIds, parameterType={arrayType={type=INT64}, type=ARRAY}, parameterValue={arrayValues=[]}}]\r\n   \r\n      return bigquery.jobs()\r\n          .insert(projectId, job)\r\n          .setFields(Option.FIELDS.getString(options))\r\n          .execute();\r\n      // getConfiguration().getQuery().getQueryParameters() on the returned job is as follows. Note that the 'arrayValues' field of the 'sessionIds' parameter has been dropped:\r\n      // [{\"name\":\"transactionIds\",\"parameterType\":{\"arrayType\":{\"type\":\"INT64\"},\"type\":\"ARRAY\"},\"parameterValue\":{\"arrayValues\":[{\"value\":\"688\"},{\"value\":\"689\"},{\"value\":\"690\"},{\"value\":\"686\"},{\"value\":\"687\"}]}}, {\"name\":\"sessionIds\",\"parameterType\":{\"arrayType\":{\"type\":\"INT64\"},\"type\":\"ARRAY\"}}]\r\n    } catch (IOException ex) {\r\n      throw translate(ex);\r\n    }\r\n  }\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2675",
        "number": 2675,
        "title": "Artman code generation: can't configure channel size",
        "labels": [],
        "state": "closed",
        "body": "I use artman to generate Java client libraries for my gRPC-based service. Specifically, I'm using the googleapis and toolkit versions from this commit: https://github.com/googleapis/artman/commit/d065fbb63c5778756eb8b6f42ca417079dae04e4\r\n\r\nMy service interface requires that I increase the inbound message size up to 10 mb. However, it doesn't appear that this option is supported currently in artman / gapic -- I had to manually edit the emitted code to make this work."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2674",
        "number": 2674,
        "title": "Artman code generation: wrong version of netty-tcnative",
        "labels": [],
        "state": "closed",
        "body": "I use artman to generate Java client libraries for my gRPC-based service. Specifically, I'm using the googleapis and toolkit versions from this commit: https://github.com/googleapis/artman/commit/d065fbb63c5778756eb8b6f42ca417079dae04e4.\r\n\r\nThe emitted code builds, but I can't use it to talk to my service since the Gradle dependencies specify the wrong version of the netty-tcnative library. Specifically, the emitted code uses 1.1.33.Fork26:\r\n\r\n```\r\ndependencies {\r\n  compile project(\":grpc-myproject\"),\r\n    'com.google.api:gax:1.15.0',\r\n    'com.google.api:gax-grpc:1.15.0',\r\n    'commons-cli:commons-cli:1.4',\r\n    'commons-lang:commons-lang:2.6',\r\n    // This dependency needs to be update-to-date with the version that gRPC expects.\r\n    'io.netty:netty-tcnative-boringssl-static:1.1.33.Fork26'\r\n}\r\n```\r\n\r\nHowever, gax-grpc 1.15.0 depends on grpc 1.7.0, which in turn uses netty-tcnative-boringssl-static 2.0.6.Final for testing purposes. Updating this dependency produces working code:\r\n\r\n```\r\ndependencies {\r\n  compile project(\":myproject\"),\r\n    'com.google.api:gax:1.15.0',\r\n    'com.google.api:gax-grpc:1.15.0',\r\n    'commons-cli:commons-cli:1.4',\r\n    'commons-lang:commons-lang:2.6',\r\n    // This dependency needs to be update-to-date with the version that gRPC expects.\r\n    'io.netty:netty-tcnative-boringssl-static:2.0.6.Final'\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2673",
        "number": 2673,
        "title": "Artman code generation: emitted test code doesn't build",
        "labels": [],
        "state": "closed",
        "body": "I use artman to generate Java client libraries for my gRPC-based service. Specifically, I'm using the googleapis and toolkit versions from this commit: https://github.com/googleapis/artman/commit/d065fbb63c5778756eb8b6f42ca417079dae04e4.\r\n\r\nThe emitted production code builds and runs, but the test code doesn't compile as it's emitted. Two fixes are required to make it build:\r\n\r\n1. Gradle dependencies\r\n\r\nThe following Gradle dependencies are emitted:\r\n\r\n```\r\ndependencies {\r\n  compile project(\":grpc-myproject\"),\r\n    'com.google.api:gax:1.15.0',\r\n    'com.google.api:gax-grpc:1.15.0',\r\n    'commons-cli:commons-cli:1.4',\r\n    'commons-lang:commons-lang:2.6',\r\n    // This dependency needs to be update-to-date with the version that gRPC expects.\r\n    'io.netty:netty-tcnative-boringssl-static:1.1.33.Fork26'\r\n}\r\n```\r\n\r\nIn order to get the test code to build, I have to add dependencies on JUnit and on the test configuration of the gax-grpc library:\r\n\r\n```\r\ndependencies {\r\n  testCompile 'junit:junit:4.11',\r\n    'com.google.api:gax-grpc:1.15.0:testlib'\r\n}\r\n```\r\n\r\n2. Mock service imports\r\n\r\nThe test code emits a mock service .java class which imports the service implementation base class from the wrong package. Specifically:\r\n\r\n```\r\nimport mypackage.PackageName.MyPackageServiceGrpc.MyPackageServiceImplBase;\r\n```\r\n\r\n... has to be changed to ...\r\n\r\n```\r\nimport mypackage.MyPackageServiceGrpc.MyPackageServiceImplBase;\r\n```\r\n\r\n... in order to get the test code to compile."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2672",
        "number": 2672,
        "title": "Make Storage.update() rename an object",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request",
            "type: question"
        ],
        "state": "closed",
        "body": "I expected the following call to rename an object. Unfortunately, its behaviour is not the expected, and it's very different from other similar calls like `setMetadata()`.\r\n\r\n```\r\nStorage gcs = ...;\r\n\r\ngcs.update(BlobInfo.newBuilder(\"existingBucket\", \"existingObject\")\r\n\t\t\t\t.setBlobId(BlobId.of(\"existingBucket\", \"newObject\"))\r\n\t\t\t\t.build());\r\n```\r\n\r\nAFAICT, this tries to make a dummy update to `gs://existingBucket/newObject`, which fails because the URI doesn't exist.\r\nLogically, the behaviour of this call should be to rename the object, which is what I want to do, and appears to be impossible as per [this](https://github.com/GoogleCloudPlatform/gsutil/blob/master/gslib/commands/mv.py#L101): `gsutil mv` copies and removes, which ideally we would avoid doing.\r\n\r\nIs there any way to rename a file that doesn't involve copying and removing?\r\nIf not, then I'd like to request one."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2671",
        "number": 2671,
        "title": "gax-java does not convert native gRPC exceptions in the server streaming case",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I have a gRPC-based service consisting of a unary API and a server streaming API:\r\n\r\n```\r\nservice myService {\r\n  rpc UnaryMethod(UnaryRequest) returns (UnaryResponse) {\r\n  };\r\n\r\n  rpc ServerStreamingMethod(ServerStreamingRequest) returns (stream ServerStreamingResponse) {\r\n  };\r\n}\r\n```\r\n\r\nWhen the server returns a `google.rpc.Status` error, the gRPC runtime raises an `io.grpc.StatusException` in both cases. In the unary case, the exception is translated to a `com.google.api.gax.rpc.ApiException` inside `com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture`, but in the server streaming case, the `io.grpc.StatusException` is surfaced directly. I believe the behavior should be consistent between these two cases (and presumably in the client and bidirectional streaming cases as well)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2670",
        "number": 2670,
        "title": "Google Cloud Container Library",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It will be nice to have a google cloud library to work with GKE APIs e.g. `google-cloud-container`.\r\n\r\nMy use case is to write some custom automation for managing clusters. Methods like [get-credentials](https://cloud.google.com/sdk/gcloud/reference/container/clusters/get-credentials) and others can be handy."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2669",
        "number": 2669,
        "title": "Structured Logging with Stack Driver Logback Appender",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently there is a Java Logback Appender that allows Java Applications to utilize the SLF4J interface and log to StackDriver. \r\n\r\nSLF4J has the concept of Marker objects that allows users to include objects to enrich the log messages. It seems that the StackDriver Logback Appender is ignoring these Marker objects while logging to StackDriver.\r\n\r\nTo show an example, the following log statement: \r\n```\r\nlogger.with(anObject).info(\"The request was successful\");\r\n```\r\nwill result a Logstash with the following structure:\r\n```\r\n{\r\n   labels: { ... labels here ... },\r\n   logName: 'java.log',\r\n   resource: { ... resource here ... },\r\n   severity: 'INFO',\r\n   textPayload: \"The request was successful\",\r\n   timestamp: \"2017-11-30T01:21:59.205Z\r\n}\r\n```\r\n\r\nIt seems like the Appender is completely ignoring these Marker objects when the should be getting jumped into the `jsonPayload` attribute of the `com.google.logging` `LogEntry` class. \r\n\r\nAny help surrounding getting structured logging working with the StackDriver Logback Appender working would be greatly appreciated! \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2668",
        "number": 2668,
        "title": "Pub/Sub: synchronous pull \"Received data on closed stream\"",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm using the solution for Issue https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1661 to pull a batch of messages to process asynchronously.\r\n\r\nI cannot use the recommended class `Subscriber` due to the fact that I need to process / ack messages asynchronously (producer / consumer scenario ... consumer processes, then acks the messages.)\r\n\r\nUsing `GrpcSubscriberStub` I get random batches of the following logging `INFO` messages ...\r\n\r\n```2017-11-30 05:43:51,513 [grpc-default-worker-ELG-2-2] INFO  i.g.internal.AbstractClientStream - Received data on closed stream\r\n2017-11-30 05:43:51,545 [grpc-default-worker-ELG-2-2] INFO  i.g.internal.AbstractClientStream - Received data on closed stream\r\n2017-11-30 05:43:51,557 [grpc-default-worker-ELG-2-2] INFO  i.g.internal.AbstractClientStream - Received data on closed stream\r\n2017-11-30 05:43:51,573 [grpc-default-worker-ELG-2-2] INFO  i.g.internal.AbstractClientStream - Received data on closed stream\r\n2017-11-30 05:43:51,593 [grpc-default-worker-ELG-2-2] INFO  i.g.internal.AbstractClientStream - Received data on closed stream```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2667",
        "number": 2667,
        "title": "Provide Storage.BlobListOption.defaultInstance() method for idiomatically listing every item in a GCS bucket",
        "labels": [],
        "state": "closed",
        "body": "I want to list every object in a bucket and add it to a list.\r\n\r\nI want to use code similar to this:\r\n\r\n```\r\n\t\tStorage.BlobListOption blobListOption = null;\r\n\r\n\t\tdo {\r\n\t\t\tpage = this.gcs.list(path, blobListOption);\r\n\t\t\tfor (BlobInfo blob : page.getValues()) {\r\n\t\t\t\tblobs.add(blob);\r\n\t\t\t}\r\n\t\t\tblobListOption = Storage.BlobListOption.pageToken(page.getNextPageToken());\r\n\t\t} while (page.hasNextPage());\r\n```\r\n\r\nThis code blows up with an NPE as expected. In order to make it work, I either need to duplicate the logic inside the while loop to get the first page with a `this.gcs.list(path)` call, or add a bogus `Storage.BlobListOption`, like `Storage.BlobListOption.pageSize(50)` instead of `null` at the beginning.\r\n\r\nTo support cases like this, there should be a `Storage.BlobListOption` factory for an empty `Storage.BlobListOption`.\r\n\r\nUnless I'm missing anything?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2666",
        "number": 2666,
        "title": "Spanner: Automatically release session to the pool when read/query ends on single use transaction",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently in a single use transaction, when the `ResultSet` returned by read/executeQuery is closed or it completely iterated on (till `next` returns false), we release the session to the pool. This is error prone as the user might not do either.\r\nInstead of this we should automatically free up the session when the rpc finished."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2664",
        "number": 2664,
        "title": "broken design on documentation site",
        "labels": [],
        "state": "closed",
        "body": "See the 'google-cloud' title on \r\nhttps://googlecloudplatform.github.io/google-cloud-java/0.30.0/index.html\r\n\r\n<img width=\"1432\" alt=\"screen shot 2017-11-27 at 11 17 25 am 1\" src=\"https://user-images.githubusercontent.com/360895/33284641-9b24e124-d364-11e7-9151-bd4730363496.png\">\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2663",
        "number": 2663,
        "title": "CSS Issue on github.io page header element",
        "labels": [
            "priority: p2"
        ],
        "state": "closed",
        "body": "![screen shot 2017-11-26 at 6 20 01 pm](https://user-images.githubusercontent.com/5672035/33247948-b44db024-d2d6-11e7-89eb-db4c3f79a582.png)\r\n\r\nThe QuickStart code on the right pushes the content further than the other runtime languages.\r\n\r\nCan be fixed with the following css rule change.\r\n\r\n`@media only screen and (min-width: 60em)\r\nsite.css:1148\r\n.col {\r\n    width: 48%;\r\n}`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2656",
        "number": 2656,
        "title": "Add LocalDatastoreHelper index support",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "I am attempting to use LocalDatastoreHelper to test my datastore workflow, however all of my query methods fail due to missing indices. \r\n\r\nFor example a query like this:\r\n```java\r\nQuery<Entity> query = Query.newEntityQueryBuilder()\r\n  .setKind(KIND)\r\n  .setFilter(CompositeFilter.and(\r\n    PropertyFilter.eq(BQPipelineRun.STATUS, BQPipelineRun.STATUS_DONE),\r\n    PropertyFilter.eq(BQPipelineRun.TYPE, type)))\r\n  .setLimit(1)\r\n  .setOrderBy(OrderBy.desc(BQPipelineRun.DATA_END_DATE))\r\n.build();\r\n```\r\nThis works in production because I created those indices via gcloud. What is the correct way to ensure those indices are available in the emulator? I am running my tests through maven.\r\n\r\nThanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2655",
        "number": 2655,
        "title": "Missing method AIRequest.setcontexts in version 2",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Actually, i am using the V1 Dialogflow Client Java SDK.\r\n<dependency>\r\n    <groupId>ai.api</groupId>\r\n    <artifactId>libai</artifactId>\r\n    <version>1.6.12</version>\r\n</dependency>\r\n\r\nIn the current stable version (1.6.12) we have the possibility to set the Contexts before the query is sent to the server, using the method:\r\n\r\n**AIRequest setContexts(List\\<AIContext\\> contexts)**\r\n\r\nThis is usefull because we can set (prepare) the status of the dialogflow (chatbot).\r\nHow can i do the same with the new V2 DialogFlow Beta version?\r\n<dependency>\r\n    <groupId>com.google.cloud</groupId>\r\n    <artifactId>google-cloud-dialogflow</artifactId>\r\n    <version>0.29.0-alpha</version>\r\n</dependency>\r\n\r\nThe samples for the new version are here https://github.com/dialogflow/dialogflow-java-client-v2 but i dont find the way to do that using the new library java version (2).\r\n\r\nIs in the roadmap ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2654",
        "number": 2654,
        "title": "build failed  after adding google cloud dependency ",
        "labels": [
            "dependencies",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi \r\n I am added google cloud  dependency by\r\n```\r\n implementation ('com.google.cloud:google-cloud-storage:1.12.0'){\r\n        exclude group: 'com.google.guava'\r\n    }\r\n```\r\n\r\nbut my build is failed with the following error \r\n\r\nAnnotation processors must be explicitly declared now.  The following dependencies on the compile classpath are found to contain annotation processor.  Please add them to the annotationProcessor configuration.\r\n    - auto-value-1.2.jar (com.google.auto.value:auto-value:1.2)\r\n  Alternatively, set android.defaultConfig.javaCompileOptions.annotationProcessorOptions.includeCompileClasspath = true to continue with previous behavior.  Note that this option is deprecated and will be removed in the future.\r\n  \r\n\r\n> tried by disabling annotation processor\r\n\r\n```\r\npackagingOptions {\r\n        exclude 'META-INF/ASL2.0'\r\n        exclude 'META-INF/LICENSE.txt'\r\n        exclude 'META-INF/NOTICE.txt'\r\n        exclude 'META-INF/LICENSE'\r\n        exclude 'META-INF/NOTICE'\r\n        exclude 'META-INF/project.properties'\r\n    }\r\n\r\n.................\r\n.........\r\n\r\njavaCompileOptions {\r\n            annotationProcessorOptions {\r\n                includeCompileClasspath false\r\n            }\r\n        }\r\n........................\r\n```\r\n\r\nI am getting following error\r\n More than one file was found with OS independent path 'project.properties'\r\n\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2652",
        "number": 2652,
        "title": "LoadStatistics stats = job.getStatistics() yields java.lang.ClassCastException",
        "labels": [],
        "state": "closed",
        "body": "Hi all,\r\n\r\nI am trying to insert some json data into a BigQuery table with Spark. Here is a snippet of code that is supposed to be doing the insertion:\r\n```java\r\n        ...\r\n        TableId tableId = TableId.of(dataset_id, table_id);\r\n        BigQuery bigQuery = createAuthorizedClient(credential_json, project_id);\r\n\r\n        WriteChannelConfiguration writeChannelConfiguration =\r\n                WriteChannelConfiguration.newBuilder(tableId)\r\n                        .setFormatOptions(FormatOptions.json())\r\n                        .build();\r\n        TableDataWriteChannel writer = bigQuery.writer(writeChannelConfiguration);\r\n\r\n        ArrayList<StatementResult> al = new ArrayList<StatementResult>();\r\n\r\n        String jsonString = \"\";\r\n        long count = 0;\r\n\r\n        // concatenate all rows into one string.\r\n        for (Iterator<String> iter = stringIterator; iter.hasNext();) {\r\n            count++;\r\n            jsonString += \"\\n\" + iter.next();\r\n        }\r\n\r\n        try {\r\n\r\n            if (count == 0) {\r\n                StatementResult sr = new StatementResult(\"\", 0,0);\r\n                al.add(sr);\r\n                return al.iterator();\r\n            }\r\n\r\n            writer = bigQuery.writer(writeChannelConfiguration);\r\n            writer.write(ByteBuffer.wrap(jsonString.getBytes(Charsets.UTF_8)));\r\n\r\n            writer.close();\r\n            // Get load job\r\n            Job job = writer.getJob();\r\n\r\n            job = job.waitFor();\r\n\r\n            LoadStatistics stats = job.getStatistics();\r\n            long success =  stats.getOutputRows();\r\n\r\n            StatementResult sr = new StatementResult(null, success,count - success);\r\n            al.add(sr);\r\n\r\n\r\n        }  catch (IOException | InterruptedException | TimeoutException e) {\r\n\r\n            StatementResult sr = new StatementResult(e.getMessage(), 1,1);\r\n            al.add(sr);\r\n\r\n\r\n        } finally {\r\n            writer.close();\r\n        }\r\n        return al.iterator();\r\n```\r\nHowever,  the line`LoadStatistics stats = job.getStatistics();` yields an exception of `java.lang.ClassCastException: shaded.guava.cloud.bigquery.JobStatistics$CopyStatistics cannot be cast to shaded.guava.cloud.bigquery.JobStatistics$LoadStatistics`. The code structure is pretty much the same as examples I found online, so I don't know what's wrong with this. Any help would be highly appreciated. Thanks! "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2651",
        "number": 2651,
        "title": "OrderBy needs a toString()",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`com.google.cloud.datastore.StructuredQuery.OrderBy` is missing a `toString()` implementation. This would be valuable for debugging queries and creating stable query cache keys."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2650",
        "number": 2650,
        "title": "README.MD for Google Cloud Firestore missing transport section",
        "labels": [
            "api: firestore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "e.g.\r\n\r\nTransport\r\n\r\nCompute uses HTTP for the transport layer."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2644",
        "number": 2644,
        "title": "pubsub: allow users to configure number of Publisher connection",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2643",
        "number": 2643,
        "title": "Storage: Can't specify project when creating a bucket",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The client library allows users to create GCS buckets, and it will create them using the project specified when setting up the client. However, there is no way to overrule this and specify a project number at the time of bucket creation."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2636",
        "number": 2636,
        "title": "Please update readme to reflect release of Dialogflow Enterprise Edition Beta",
        "labels": [
            "priority: p1"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2629",
        "number": 2629,
        "title": "Storage.signUrl() fails with default credentials in java8 standard runtime",
        "labels": [
            ":rotating_light:",
            "api: storage",
            "auth",
            "priority: p1",
            "status: blocked",
            "type: bug"
        ],
        "state": "closed",
        "body": "Invocation:\r\n```\r\n// initialization\r\nstorage = StorageOptions.getDefaultInstance().getService();\r\n\r\n// later\r\nstorage.signUrl(info, 5L, TimeUnit.MINUTES,\r\n                Storage.SignUrlOption.httpMethod(HttpMethod.valueOf(method)),\r\n                Storage.SignUrlOption.withContentType()\r\n        );\r\n```\r\nStacktrace:\r\n```\r\nCaused by: java.lang.IllegalStateException: Signing key was not provided and could not be derived\r\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:444)\r\n\tat com.google.cloud.storage.StorageImpl.signUrl(StorageImpl.java:508)\r\n```\r\n\r\nI tracked the problem down to the `com.google.auth.oauth2.GoogleCredentials.getDefaultCredentialsUnsynchronized()`(https://github.com/google/google-auth-library-java/blob/51a5445b33d10f252cadfdcca82dd9e68512e483/oauth2_http/java/com/google/auth/oauth2/DefaultCredentialsProvider.java#L182) where it skips over `tryGetAppEngineCredential()` to return an instance of `com.google.auth.oauth2.AppengineCredentials` which is one of the implementations of `ServiceAccountSigner` required by the `signUrl` call with default credentials.\r\n\r\nThis may also affect other services assuming an instance of  `com.google.auth.oauth2.AppengineCredentials`.\r\n\r\nIs there any specific reason why to check for java7 only?\r\n\r\nBackground: We moved to the java8 runtime on GAE and upgraded our api clients to the google-cloud-java api clients version 1.10.0."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2624",
        "number": 2624,
        "title": "Implement auto tuning of writeSessionFraction in Cloud Spanner Client",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently in `SessionPoolOptions` users can specify what proportion of sessions they want to be pre warmed for read write transactions. It defaults to 0.2 which causes #2540  where the client does not have permissions to write to the database thus causing all the pre warming rpcs to fail.\r\nAlso it might not be obvious to users that they can tune this parameter to achieve better performance and default of 0.2 might not be best for everyone. \r\nTo solve this, we should implement auto tuning of this parameter in the client. We can keep track of what proportions of transactions were read write transactions over some window and use that to tune this parameter. We can continuously update this as the usage pattern changes over the lifetime of a client.\r\nWe can expose a new option to turn this feature on/off.\r\ncc @tomayles "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2623",
        "number": 2623,
        "title": "Update docs to  0.28.0",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "At least some of the javadocs are still on 0.26.0. e.g.\r\n\r\nhttps://googlecloudplatform.github.io/google-cloud-java/0.26.0/apidocs/?com/google/cloud/resourcemanager/package-summary.html"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2622",
        "number": 2622,
        "title": "Pubsub messages always expire after 30 minutes",
        "labels": [
            ":rotating_light:",
            "api: pubsub",
            "priority: p1",
            "status: blocked",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "We have the following setup for processing pubsub messages (some of which can require a large amount of processing - up to 2 or 3 hours!):\r\n\r\n- A pubsub subscription with an acknowledgement deadline of 600s/10 minutes-\r\n- A maximum acknowledgement deadline (including extensions) of 8 hours, set using `setMaxAckExtensionPeriod` on the `Subscriber.Builder`\r\n- A policy to renew the period of the message 5 minutes before expiry, set using `setAckExpirationPadding` on the `Subscriber.Builder`\r\n\r\nUnder these circumstances, I would expect:\r\n\r\n- The subscriber to accept the message from the queue, with an initial deadline of 10 minutes.\r\n- The subscriber to renew the acknowledgement deadline for another 10 minutes every 5 minutes, until:\r\n\r\n1. the process function acks/nacks the message\r\n2. 10 minutes after the process function fails, and the expiry deadline (no longer being renewed) expires\r\n3. after 8 hours of extensions, the max deadline is reached and the deadline can no longer be extended\r\n \r\nWhat we actually see - the message goes back on the queue after 30 minutes. Tried processing a long-running message three times, every single time the message gets picked back up off the queue by a worker 30 minutes later. I just can't understand why this would be the case. We never mention 30 minutes in our settings, and I can't see 30 minutes in the defaults anywhere (for example the default max extension period is 60 minutes).\r\n\r\nIt's entirely possible I've completely misunderstood the way the acknowledgement deadline renewal is supposed to work and am barking up the wrong tree entirely, if so deepest apologies, but I'm at my wits' end trying to understand what's going on here!\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2621",
        "number": 2621,
        "title": "google-cloud-datastore depends both on protobuf-java and protobuf-lite",
        "labels": [
            "api: datastore",
            "dependencies",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Recent versions of `google-cloud-datastore` have transitive dependencies on both `com.google.protobuf:protobuf-lite:3.0.1` and `com.google.protobuf:protobuf-java:3.4.0`. These libraries contain incompatible classes with the same name, which for us intermittently causes `java.lang.NoSuchMethodError: com.google.protobuf.CodedOutputStream.isSerializationDeterministic()Z`.\r\n\r\nThis problem was fixed in the past by excluding `protobuf-lite` dependency, but it appeared again in 1.9.0. Here is the output of `gradle dependencyInsight`:\r\n```\r\ncom.google.protobuf:protobuf-lite:3.0.1\r\n\\--- io.grpc:grpc-protobuf-lite:1.0.1\r\n     +--- io.grpc:grpc-all:1.0.1\r\n     |    \\--- com.google.api.grpc:grpc-google-common-protos:0.1.0\r\n     |         \\--- com.google.cloud.datastore:datastore-v1-protos:1.3.0\r\n     |              +--- com.google.cloud:google-cloud-datastore:1.10.0\r\n     |              |    \\--- runtime\r\n     |              \\--- com.google.cloud.datastore:datastore-v1-proto-client:1.4.1\r\n     |                   \\--- com.google.cloud:google-cloud-datastore:1.10.0 (*)\r\n     \\--- io.grpc:grpc-protobuf:1.0.1\r\n          \\--- io.grpc:grpc-all:1.0.1 (*)\r\n```\r\n\r\nFrom what I see this is caused by #2557 unintentionally reverting #2029 and downgrading `grpc-google-common-protos` to an old version (0.1.0) used by `datastore-v1-proto-client`. I understand the proper fix for that is GoogleCloudPlatform/google-cloud-datastore#170, but not sure about the timeline for that one. Would it be possible to upgrade `grpc-google-common-protos` back to a recent version?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2620",
        "number": 2620,
        "title": "Add Storage.create() method which takes a restartable input stream",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "In https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2359 , retries had to be turned off for `Blob create(BlobInfo blobInfo, InputStream content, BlobWriteOption... options)` because the `InputStream` can only be consumed once.\r\n\r\nWe should create a new abstraction named `RetryableInputStream` which can produce a new input stream on the original content, and add a new create method which accepts it, so that it is easier for users to create blobs without loading the entire content into memory. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2616",
        "number": 2616,
        "title": "pubsub: sleep in example is confusing",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Originally reported [here](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1827#issuecomment-343760699). The code snippet can be run and tested, so we'd like to make it terminate at some point, but this is confusing to users."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2614",
        "number": 2614,
        "title": "pubsub: streaming connection logs too aggressively",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "First reported [here](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1827#issuecomment-343760699).\r\n\r\nThe connection logs a warning even though the subscriber is shutting down. When shutting down, this error is normal. The subscriber waits to process all messages, but by the time this happens, another message might have already arrived. Trying to ack this message could error: it races with us trying to shutdown streaming channel.\r\n\r\nThis is sub-optimal but \"OK\". The message will be redelivered to another machine. The fix for this is to not log such errors when the the subscriber is shutting down."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2610",
        "number": 2610,
        "title": "TraceServiceSettings.Builder not very idiomatic",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I'm having to do this weird cast, which should be avoidable:\r\n\r\n```\r\nTraceServiceClient.create(\r\n\t((TraceServiceSettings.Builder) TraceServiceSettings.newBuilder()\r\n\t.setCredentialsProvider(\r\n\t\tStackdriverTraceAutoConfiguration.this.finalCredentialsProvider)\r\n\t.setExecutorProvider(executorProvider))\r\n\t.build())\r\n```\r\n\r\nNotice the `(TraceServiceSettings.Builder)` cast, because `setExecutorProvider()` is inherited from the abstract `ClientSettings` and should probably be overwritten to return a `TraceServiceSettings.Builder`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2609",
        "number": 2609,
        "title": "Long-running operations throw DEADLINE_EXCEEDED (Affects Speech, DLP, others)",
        "labels": [
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "It appears that there is a bug in gax that sends a deadline in the past to GRPC, but only for long-running operation polling calls."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2594",
        "number": 2594,
        "title": "com.google.cloud.firestore.FieldPath is not public",
        "labels": [
            "api: firestore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The FieldPath class is used in many methods of the Firestore API especially in Query, however the class is not public. I assume this is a bug because essentially all these methods requiring a FieldPath cannot be used outside of the com.google.cloud.firestore package. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2591",
        "number": 2591,
        "title": "bigquery: tabledata.list tracking",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This issue tracks things we need to migrate query to use `tabledata.list` instead of `getQueryResults` RPC.\r\nWork is in `bq-perf` branch.\r\n\r\n- [x] ~Remove~ InternalApi `QueryResponse` type\r\n- [x] ~Remove~ InternalApi `BigQuery.getQueryResults`\r\n  - Use `getJob().getQueryResults` instead\r\n- [x] Give `QueryResults` fewer fields (#2592)\r\n  - To get details of a job, use `Job`\r\n- [x] Should `Job.getQueryResults` wait for query to finish?\r\n- [x] What should `BigQuery.query` do?\r\n  - alias of `create`?\r\n  - return completed job?\r\n  - return iterator?\r\n    - What option should it accept?\r\n    - Accept option for iterating, use default option for waiting?\r\n- [x] Consider unified types of `Job.getQueryResults` and `BigQuery.listTableData`\r\n- [x] Make sure benchmark actually improves\r\n- [x] Make sure we don't retrogress on small queries\r\n  "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2589",
        "number": 2589,
        "title": "Migrate google-cloud-java/google-cloud-datastore to use GAPIC low-level libraries",
        "labels": [
            "type: feature request"
        ],
        "state": "open",
        "body": "Right now, https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-datastore depends on https://github.com/GoogleCloudPlatform/google-cloud-datastore, which is suboptimal for several reasons:\r\n\r\n1. No support for gRPC.\r\n2. Lack of uniformity with other google-cloud-java clients.\r\n3. Continued dependence on the separate google-cloud-datastore artifact, which frequently leads to confusion because of the unfortunate naming similarity. We'd like to deprecate this artifact altogether."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2588",
        "number": 2588,
        "title": "pubsub async subscriber listener logging error on stop",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I have the same situation as described in #2485. Using version 0.26.0.\r\n\r\nA listener for failed state is logging an error message when stopping an async subscriber:\r\n\r\n```\r\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@779f4acb rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7fb36e19[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 41]\r\n```\r\n\r\nAlthough this error is described as harmless in the referenced issue, it pollutes our logs during shutdown and deployments. The only seam I can find is detect if the `from` state is `STOPPING`, and ignore any failure. But I feel like this would potentially miss real errors if they were to occur during shutdown. \r\n\r\nAre there any suggested ways to better handle this?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2587",
        "number": 2587,
        "title": "Include stack trace in logged text",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "I would like to include the stack trace from ERROR level logs in my logs sent back to StackDriver. How would I implement this?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2586",
        "number": 2586,
        "title": "Add Automatic-Module-Name to JAR MANIFEST.MF",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "Configure JAR plugin to add Automatic-Module-Name for our JAR distributions. Each artifact should have its own module name."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2581",
        "number": 2581,
        "title": "Table.exists hangs",
        "labels": [
            "api: bigtable",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I've a Bigtable client that connects to a local emulator. Lately it has started hanging on table.exists - the only thing that was updated recently was the emulator itself via apt. A thread dump reveals (client class names snipped at the bottom)\r\n```\r\n\"main\" #1 prio=5 os_prio=0 tid=0x00007ff678010000 nid=0x67c2 waiting on condition [0x00007ff67f143000]\r\n   java.lang.Thread.State: WAITING (parking)\r\n\tat sun.misc.Unsafe.park(Native Method)\r\n\t- parking to wait for  <0x00000007441b7ad0> (a com.google.cloud.bigtable.grpc.async.AbstractRetryingOperation$GrpcFuture)\r\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:469)\r\n\tat com.google.cloud.bigtable.grpc.async.AbstractRetryingOperation.getBlockingResult(AbstractRetryingOperation.java:293)\r\n\tat com.google.cloud.bigtable.grpc.BigtableDataGrpcClient.readFlatRowsList(BigtableDataGrpcClient.java:327)\r\n\tat com.google.cloud.bigtable.hbase.BigtableTable.getResults(BigtableTable.java:257)\r\n\tat com.google.cloud.bigtable.hbase.BigtableTable.exists(BigtableTable.java:166)\r\n..........\r\n```\r\nSubsequent thread dumps taken at 30 second intervals reveals the the thread is stuck at the same place. \r\n\r\nLibrary versions:\r\ngoogle-cloud-core 1.8.0, \r\ngoogle-cloud-core-grpc 1.8.0, \r\ngoogle-cloud-core 1.8.0, \r\nbigtable-hbase-1.x 1.0.0-pre3\r\n\r\ngcloud version output:\r\nGoogle Cloud SDK 177.0.0\r\nalpha 2017.10.20\r\nbeta 2017.10.20\r\nbigtable \r\nbq 2.0.27\r\ncbt \r\ncore 2017.10.20\r\ngsutil 4.28\r\npubsub-emulator 2017.10.20\r\n\r\nOS: Ubuntu 17.10\r\n\r\njava -version output: \r\njava version \"1.8.0_102\"\r\nJava(TM) SE Runtime Environment (build 1.8.0_102-b14)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2579",
        "number": 2579,
        "title": "google-cloud-firestore Extension point to serialize pojo to map",
        "labels": [
            "api: firestore",
            "type: question"
        ],
        "state": "closed",
        "body": "Converting custom types like BigDecimal fail with error:\r\n\r\n`Cannot convert 12.0099999999999997868371792719699442386627197265625 to Firestore Value`\r\n\r\nLooking through the code couldn't find a way how I could add a custom converter that would allow anyone to do conversion before serialization without creating additional layer that is specific to firestore.\r\n\r\nIt would be great if one of following could be provided to add ability to apply custom coversions:\r\n\r\n- inject a whole new class mapper (instead of using ***CustomClassMapper***) - but that could potentially be a big ask \r\n- have a converter annotation similar to `@Exclude`, `@PropertyName` that would enable to add converter to ***CustomClassMapper***\r\n- alternatives?\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2577",
        "number": 2577,
        "title": "FireStore Realtime functionality",
        "labels": [
            "api: firestore",
            "type: question"
        ],
        "state": "closed",
        "body": "I would like to know if there is FireStore realtime functionality like in the android SDK is planned. The old firebase admin SDK had it.\r\n\r\nThanks in advance."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2576",
        "number": 2576,
        "title": "API Quotas for Monitoring",
        "labels": [
            "api: monitoring",
            "auth",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, I'm using the `MetricServiceClient` for getting StackDriver timeseries.  I am authenticating using a user oauth token (this user has access to multiple projects), but there seems to be a global quota across multiple projects because when I fetch only one or two projects at a time I have no throttling, but when I fetch four or five different projects at a time, I start getting throttled with errors like the following:\r\n\r\n```\r\nio.grpc.StatusRuntimeException: RESOURCE_EXHAUSTED: Insufficient tokens for quota 'DefaultGroup' and limit 'USER-100s' of service 'monitoring.googleapis.com' for consumer 'project_number:764086051850'.\r\n```\r\n\r\nThe strange thing is, that project_number doesn't correspond to any project I am fetching, or even have access to -- it is meaningless to me.\r\n\r\nThis appears to be the quota for # of requests per 100 seconds, but I have that set to 10,000 on all projects and I'm not doing nearly that many requests, as the quota historical chart in the web console confirms.\r\n\r\nIs there really some global quota that applies across multiple projects and if so, is there some way to work around it?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2569",
        "number": 2569,
        "title": "Repeated error messages - UNAVAILABLE: The service was unable to fulfill your request. Please try again. [code=8a75]",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm running a PubSub emulator and a client using the Java APIs. The client does some simple stuff like creating a topic, subscribing and publishing to it. After a while, the following error messages keep coming continuously\r\n```\r\nNov 01, 2017 3:24:52 PM com.google.cloud.pubsub.v1.StreamingSubscriberConnection$1 onFailure\r\nWARNING: Terminated streaming with exception\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: The service was unable to fulfill your request. Please try again. [code=8a75]\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:385)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\nNov 01, 2017 3:24:52 PM com.google.cloud.pubsub.v1.StreamingSubscriberConnection$1 onFailure\r\nWARNING: Terminated streaming with exception\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: The service was unable to fulfill your request. Please try again. [code=8a75]\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:385)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\nNov 01, 2017 3:25:13 PM com.google.cloud.pubsub.v1.StreamingSubscriberConnection$1 onFailure\r\nWARNING: Terminated streaming with exception\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: The service was unable to fulfill your request. Please try again. [code=8a75]\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:385)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2568",
        "number": 2568,
        "title": "No newBuilder() method in class Job",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "How am I supposed to build an instance of class `Job`? It contains a `Job.Builder` nested class but I am unable to get an instance of it. `Job` extends `JobInfo` which does contain a `newBuilder` method but that returns an instance of `JobInfo` not `Job`. Is this a forgotten implementation? Am I misunderstanding the usage of `Job` class?\r\n\r\nhttp://googlecloudplatform.github.io/google-cloud-java/0.26.0/apidocs/com/google/cloud/bigquery/Job.html\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2567",
        "number": 2567,
        "title": "table.load doesn't work for local files",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "BigQuery `table.load` in Ruby works for local files. Java BigQuery requires a GCS URI. Is there a reason why local file loading isn't supported?\r\n\r\n```ruby\r\n# Ruby\r\ndef load_job(table_obj, rows)\r\n  Tempfile.create(['tmp', '.json']) do |json_file|\r\n    json_file.write rows.map(&:to_json).join(\"\\n\")\r\n    json_file.rewind\r\n\r\n    puts \"Uploading:\\n #{File.read(json_file)}\"\r\n\r\n    validate_table(table_obj)\r\n    job = table_obj.load(json_file,\r\n                          format: 'JSON',\r\n                          create: 'never',\r\n                          write:  'append')\r\n\r\n    wait_for_job job\r\n  end\r\nend\r\n```\r\n\r\n\r\n```java\r\n// Java\r\nval loadJob = table.load(FormatOptions.json(), jsonFile.canonicalPath)\r\nloadJob.waitFor(RetryOption.totalTimeout(Duration.ofMinutes(20)))\r\n```\r\n\r\n```\r\nException in thread \"main\" com.google.cloud.bigquery.BigQueryException: Source URI must be a Google Cloud Storage location: /private/var/folders/14/h2zk5sx1315b__blzdt7hz1m4k0by8/T/build255306573373834232.json\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:84)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.create(HttpBigQueryRpc.java:168)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$3.call(BigQueryImpl.java:208)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$3.call(BigQueryImpl.java:205)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91)\r\n\tat com.google.cloud.RetryHelper.run(RetryHelper.java:74)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:205)\r\n\tat com.google.cloud.bigquery.Table.load(Table.java:517)\r\n\tat com.google.cloud.bigquery.Table.load(Table.java:479)\r\n\tat bigquery.BitriseQuery.updateData(BitriseQuery.kt:26)\r\n\tat tasks.UpdateBigQueryKt.main(UpdateBigQuery.kt:11)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2559",
        "number": 2559,
        "title": "cloud-datastore-emulator Version 1.3 leads to \"Invalid version format\"",
        "labels": [
            "api: datastore",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "After updating to Google Cloud SDK 177.0.0, we found the LocalDatastoreHelper crashing in the following way:\r\n\r\n\r\n<code>\r\njava.lang.IllegalStateException: Failed to load ApplicationContext\r\n\tat org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)\r\n\tat org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)\r\n\tat org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener.prepareTestInstance(SpringBootDependencyInjectionTestExecutionListener.java:47)\r\n{...}\r\nCaused by: java.lang.IllegalArgumentException: Invalid version format\r\n        at com.google.cloud.testing.Version.fromString(Version.java:90) ~[google-cloud-core-1.0.2.jar:1.0.2]\r\n        at com.google.cloud.testing.BaseEmulatorHelper$GcloudEmulatorRunner.getInstalledEmulatorVersion(BaseEmulatorHelper.java:327) ~[google-cloud-core-1.0.2.jar:1.0.2]\r\n        at com.google.cloud.testing.BaseEmulatorHelper$GcloudEmulatorRunner.isEmulatorUpToDate(BaseEmulatorHelper.java:306) ~[google-cloud-core-1.0.2.jar:1.0.2]\r\n        at com.google.cloud.testing.BaseEmulatorHelper$GcloudEmulatorRunner.isAvailable(BaseEmulatorHelper.java:272) ~[google-cloud-core-1.0.2.jar:1.0.2]\r\n        at com.google.cloud.testing.BaseEmulatorHelper.startProcess(BaseEmulatorHelper.java:100) ~[google-cloud-core-1.0.2.jar:1.0.2]\r\n        at com.google.cloud.datastore.testing.LocalDatastoreHelper.start(LocalDatastoreHelper.java:192) ~[google-cloud-datastore-1.0.2.jar:1.0.2]\r\n        at com.rewedigital.fulfillment.core.service.config.TestDatastoreConfig$TestHelperDatastore.afterPropertiesSet(TestDatastoreConfig.java:52) ~\r\n</code>\r\n\r\n\r\n\r\nIt seems that com.google.cloud.testing.Version expects a version number following this RegExp:\r\n`private static final Pattern VERSION_PATTERN = Pattern.compile(\"^(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)$\");`\r\nSince the current Version \"1.3\" does not conform to it - it leads to the exceptions above.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2556",
        "number": 2556,
        "title": "AdInsights 'account_currency' fields is not present ",
        "labels": [],
        "state": "closed",
        "body": "I am referring to this API documentation. I am trying to fetch the adset insights through java sdk\r\nFollowing is the code snippet \r\n`String accessToken = \"XXX\";\r\n\t\tAPIContext context = new APIContext(accessToken).enableDebug(true);\r\n\t\tList<String> fields= Arrays.asList(new String[]{\r\n\t\t\t\t\"clicks\",\r\n\t\t\t\t\"adset_id\",\r\n\t\t\t\t\"adset_name\",\r\n\t\t\t\t\"reach\",\r\n\t\t\t\t\"impressions\",\r\n\t\t\t\t\"spend\",\r\n\t\t\t\t\"account_currency\"\r\n\t\t});\r\n\t\tAPINodeList<AdsInsights> adsInsights = new AdAccount(\"XXXXX\", context).\r\n\t\t\t\tgetInsights()\r\n\t\t\t\t.setLevel(AdsInsights.EnumLevel.VALUE_ADSET).requestFields(fields).execute();\r\n\t\tSystem.out.println(adsInsights.get(0).getFieldAccountId());`\r\n\r\nthe API response I am getting is \r\n`Response:\r\n{\"data\":[{\"clicks\":\"19\",\"adset_id\":\"XXXXX\",\"adset_name\":\"Test_041017\",\"reach\":\"39\",\"impressions\":\"272\",\"spend\":\"95.29\",\"account_currency\":\"INR\",\"date_start\":\"2017-09-26\",\"date_stop\":\"2017-10-25\"}],\"paging\":{\"cursors\":{\"before\":\"MAZDZD\",\"after\":\"MAZDZD\"}}}`\r\n\r\n\r\nBut when I print the object \r\n\r\n`JSON]{\"clicks\":\"19\",\"adset_id\":\"XXX\",\"adset_name\":\"Test_041017\",\"reach\":\"39\",\"impressions\":\"272\",\"spend\":\"95.29\",\"account_currency\":\"INR\",\"date_start\":\"2017-09-26\",\"date_stop\":\"2017-10-25\"}\r\n[Object]{\"adset_id\":\"XXX\",\"adset_name\":\"Test_041017\",\"clicks\":\"19\",\"date_start\":\"2017-09-26\",\"date_stop\":\"2017-10-25\",\"impressions\":\"272\",\"reach\":\"39\",\"spend\":\"95.29\"}`\r\n\r\n\r\n\r\n\r\nI can not find the field for account_currency in the AdsInsights class or I can not find any getter and setter for this field"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2555",
        "number": 2555,
        "title": "Proposal to minimize Dependency Conflicts",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "Many customers are running into [dependency conflicts](https://stackoverflow.com/questions/33907162/systematic-approach-with-maven-to-deal-with-dependency-hell) using the Java google-cloud (an umbrella package that includes many other artifacts), several of our google-cloud-* artifacts together, and using the google-cloud-* artifacts with other non google-cloud, google artifacts like GoogleCloudPlatform/google-cloud-datastore .  This leads to the [Maven Dependency](https://stackoverflow.com/questions/7175398/maven-dependency-resolution-conflicted) [issues](http://www.eharmony.com/engineering/maven-dependency-wrangling).\r\n\r\nThe common java solution of creating a [BOM](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Importing_Dependencies) ([SpringBoot](https://spring.io/blog/2016/04/13/overriding-dependency-versions-with-spring-boot)) ([SpringBoot Gradle](https://spring.io/blog/2015/02/23/better-dependency-management-for-gradle)) and using the [maven-enforcer-plugin](https://maven.apache.org/enforcer/maven-enforcer-plugin/) doesn't work when there are artifacts that aren't well behaved (same JAR, but substantially different method signatures and behaviors) like [Netty](https://netty.io/) (See #2398 ) included in the mix.  Our customers are running into situations where they are combining our artifacts with those of slower moving open source projects and things are breaking in very unexpected ways. \r\n\r\nAdditionally, customers appear to be confused by google-cloud as it's marked as alpha, even though it brings in some \"GA\" artifacts.\r\n\r\n@ludoch has proposed (and I agree):\r\n\r\n1. We have three Uber JAR's that we release GA, BETA, and ALPHA (Beta & Alpha can depend on GA)\r\n2. We [shade](https://maven.apache.org/plugins/maven-shade-plugin/) w/ illegal class names so that IDE's will not auto complete.\r\n3. We then run [ProGuard](https://www.guardsquare.com/en/proguard) to [shrink](https://developer.android.com/studio/build/shrink-code.html) these JAR's.\r\n4. The individual product JAR's should also be done this way.\r\n5. We should still publish non-shaded / non-ProGuarded artifacts for those who need them.\r\n\r\n### Drawbacks\r\n1. Larger JAR's\r\nBetter reliability will more than offset the issues with additional size.\r\n2. Singleton's are no longer pure. (ie some resources might not be properly guarded)\r\nWe should be able to figure this out for libraries.\r\n3. Debugging becomes harder\r\n(We should publish enough info to figure this out)\r\n\r\n### Benefits\r\n1. We will only expose our public Classes and Methods.  Our dependencies stay out of the mix.\r\n2. Less customer confusion.\r\n\r\nOf course, all we are doing is trying to solve a problem that Java 9 modules also attempts to solve, but our JAR's can't wait for our customers to all get to Java 9.\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2553",
        "number": 2553,
        "title": "BigQuery Java API: Converter for json/avro schema",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "When creating a BigQuery schema, it would be really nice to create a BigQuery schema from an avro schema, or json schema. \r\n\r\nThe command line tool seems to allow this; and the load command probably loads the schema from the avro file, and having this logic as a support class in the java api would add a lot of value.\r\n\r\nBecause honestly, I have an industry-standard schema. I don't really want to hand-code that same schema for BigQuery and I most certainly don't want to rely on manual load actions to initialise a schema.\r\n\r\nMy use case is more of a replication system. BigQuery is just one of the sinks.\r\nI get my messages from Kafka, and can read them as byte[]. I also have the avro.Schema.\r\nIdeally I would just give my bytes and the schema to BigQuery (the BigQuery client lib) and let that do the generic lifting."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2552",
        "number": 2552,
        "title": "BigQuery OAuth error when query with Federated Data Source",
        "labels": [
            "api: bigquery",
            "status: blocked",
            "type: question"
        ],
        "state": "open",
        "body": "I have a BigQuery federated data source which load data from a Google Spreadsheet.\r\nThe provided code is running from App Engine standard application, Java8 runtime.\r\n\r\nHere is a simple query: \r\n`SELECT field FROM project.dataset.table`\r\n\r\nPerforming a query to that table from my personal account using BigQuery browser (https://bigquery.cloud.google.com) works very fine\r\n\r\nUsing Java API I'm getting the following error\r\n```\r\njava.io.IOException: BigQueryError{reason=accessDenied, location=, message=Access Denied: BigQuery BigQuery: No OAuth token with Google Drive scope was found.}\r\n```\r\n\r\nHere is a sample of the code that is running (plase note that Drive scopes is not missing)\r\n```\r\nprivate static final List<String> SCOPES = Arrays.asList(BigqueryScopes.BIGQUERY, \"https://www.googleapis.com/auth/drive.readonly\");\r\nGoogleCredentials credentials = GoogleCredentials.getApplicationDefault().createScoped(SCOPES);\r\nBigQueryOptions options = BigQueryOptions.newBuilder().setCredentials(credentials).build();\r\nBigQuery client = options.getService();\r\n\r\nString statement = ...;\r\nQueryJobConfiguration queryConfig = QueryJobConfiguration.newBuilder(statement).setUseLegacySql(Boolean.FALSE).build();\r\nJob queryJob = client.create(JobInfo.newBuilder(queryConfig).setJobId(jobId).build());\r\nqueryJob.waitFor();\r\n\r\nqueryJob.getStatus().getError()\r\n```\r\n--------------------------------------------------\r\n\r\nI tried using a service account json key, and the query works fine, it seems that problem is related on using ApplicationDefault credential.\r\n\r\nThis error occurs if I'm using version **0.25.0** of the library. \r\nUsing version **0.20.0** works fine\r\n```\r\n<dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-bigquery</artifactId>\r\n            <version>0.20.0-beta</version>\r\n        </dependency>\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2551",
        "number": 2551,
        "title": "Entities.getVersionProperty API?",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "In Google App Engine Datastore we had an API to retrieve Entity version, using Entities.getVersionProperty(). Do we have the same API in Google Cloud Datastore or it is missing in current implementation?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2550",
        "number": 2550,
        "title": "Blob.listAcls() fails after writing the contents",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Using `Blob.listAcls()` works on first invocation after the blob creation, but fails on second invocation after `Blob.writer()` was used to write the contents. To be able to use it, have to request `Service` for a new `Blob` instance without using `BlobId` of existing instnace. Please see the following reproducer code:\r\n```\r\nimport static org.testng.Assert.assertFalse;\r\nimport static org.testng.Assert.assertNotNull;\r\n\r\nimport com.google.cloud.WriteChannel;\r\nimport com.google.cloud.storage.Acl;\r\nimport com.google.cloud.storage.Blob;\r\nimport com.google.cloud.storage.BlobInfo;\r\nimport com.google.cloud.storage.Bucket;\r\nimport com.google.cloud.storage.BucketInfo;\r\nimport com.google.cloud.storage.Storage;\r\nimport com.google.cloud.storage.StorageOptions;\r\nimport java.nio.ByteBuffer;\r\nimport java.util.List;\r\nimport java.util.Random;\r\nimport java.util.UUID;\r\nimport org.testng.annotations.Test;\r\n\r\npublic class GcsAclReproducerTest {\r\n\r\n  @Test\r\n  public void test() throws Exception {\r\n    final String inputBucketName = UUID.randomUUID().toString();\r\n    final String inputBlobName = UUID.randomUUID().toString();\r\n    final Storage storageService = StorageOptions.getDefaultInstance().getService();\r\n    final Bucket bucket = storageService.create(BucketInfo.newBuilder(inputBucketName).build());\r\n\r\n    final Blob blob\r\n        = storageService.create(BlobInfo.newBuilder(inputBucketName, inputBlobName).build());\r\n\r\n    final List<Acl> acls1 = blob.listAcls();\r\n    assertNotNull(acls1);\r\n    assertFalse(acls1.isEmpty());\r\n\r\n    try (final WriteChannel writer = blob.writer()) {\r\n      final byte[] contents = new byte[1024 * 1024];\r\n      new Random().nextBytes(contents);\r\n      writer.write(ByteBuffer.wrap(contents));\r\n    }\r\n\r\n    final List<Acl> acls2 = blob.listAcls();\r\n    assertNotNull(acls2);\r\n    assertFalse(acls2.isEmpty());\r\n  }\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2548",
        "number": 2548,
        "title": "cannot resolve method .getService();",
        "labels": [
            "api: translation",
            "needs more info",
            "type: question"
        ],
        "state": "open",
        "body": "CODE =  final Translate translate = TranslateOptions.getDefaultInstance().getService();\r\nhere getService() is not working."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2546",
        "number": 2546,
        "title": "Add static analysis to find bugs sooner",
        "labels": [
            "api: core",
            "dependencies",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Static analysis tools enable finding and avoiding bugs at compile time, before they become issues at runtime, and become much harder (and hence, costlier) to find and fix.\r\n\r\nThere are tools that can be run offline, such as SpotBugs (successor to FindBugs) and [ErrorProne](http://errorprone.info/), or via online services such as [Coverity](https://scan.coverity.com/) (free for open-source projects). Wikipedia has a [list static analysis tools for Java](https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis#Java).\r\n\r\nFWIW, we've integrated Coverity scans into JanusGraph builds, though ended up not using the Travis CI integration with Coverity; here is how it was done:\r\n\r\n* [`.travis.yml`](https://github.com/JanusGraph/janusgraph/blob/master/.travis.yml)\r\n* [analysis script and Dockerfile](https://github.com/JanusGraph/janusgraph/tree/master/analysis) referenced in `.travis.yml` \u2014 note that CentOS appears to behave differently from Ubuntu for Coverity\r\n\r\nI'm happy to add Coverity support for this repo, if there's interest and support (please vote with \ud83d\udc4d / \ud83d\udc4e).\r\n\r\nThoughts?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2545",
        "number": 2545,
        "title": "Java 9 - protobuf-java 3.0.0 warnings",
        "labels": [
            "api: datastore",
            "dependencies"
        ],
        "state": "closed",
        "body": "In running something with latest Datastore client, I see the following:\r\n\r\n```\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil (file:/Users/lesv/.m2/repository/com/google/protobuf/protobuf-java/3.0.0/protobuf-java-3.0.0.jar) to field java.nio.Buffer.address\r\nWARNING: Please consider reporting this to the maintainers of com.google.protobuf.UnsafeUtil\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2544",
        "number": 2544,
        "title": "cloud-firestore issue when running in DevAppServer GAE Standard Java 8",
        "labels": [
            "api: firestore",
            "priority: p2",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "When using the latest Firestore library we are getting the following error (in devappserver, GAE Standard, Java 8):\r\n\r\n`Caused by: com.google.apphosting.api.ApiProxy$CallNotFoundException: Can't make API call urlfetch.Fetch in a thread that is neither the original request thread nor a thread created by ThreadManager\r\n\tat com.google.apphosting.api.ApiProxy$CallNotFoundException.foreignThread(ApiProxy.java:844)\r\n\tat com.google.apphosting.api.ApiProxy.makeSyncCall(ApiProxy.java:116)\r\n\tat com.google.appengine.api.urlfetch.URLFetchServiceImpl.fetch(URLFetchServiceImpl.java:40)\r\n\tat com.google.apphosting.utils.security.urlfetch.URLFetchServiceStreamHandler$Connection.fetchResponse(URLFetchServiceStreamHandler.java:543)\r\n\tat com.google.apphosting.utils.security.urlfetch.URLFetchServiceStreamHandler$Connection.getInputStream(URLFetchServiceStreamHandler.java:422)\r\n\tat com.google.apphosting.utils.security.urlfetch.URLFetchServiceStreamHandler$Connection.getResponseCode(URLFetchServiceStreamHandler.java:275)\r\n\tat com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:105)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:210)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146)\r\n\tat io.grpc.auth.GoogleAuthLibraryCallCredentials$1.run(GoogleAuthLibraryCallCredentials.java:98)`\r\n\r\nThe issue is triggered by a simple example:\r\n```\r\n  @Override\r\n  protected void doGet(HttpServletRequest req, HttpServletResponse resp)\r\n      throws ServletException, IOException {\r\n    Firestore firestore = FirestoreOptions.getDefaultInstance().toBuilder().build().getService();\r\n    // Firestore firestore = FirestoreClient.getFirestore();\r\n    DocumentReference doc = firestore.collection(\"cities\").document(\"Mountain View\");\r\n    try {\r\n      resp.getWriter().println(\"Count: \" + doc.get().get().get(\"count\"));\r\n    } catch (Exception e) {\r\n      throw new ServletException(e);\r\n    }\r\n  }\r\n```\r\n\r\nThis one may be similar to the following two issues we fixed earlier:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/issues/2150\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/issues/2275\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/issues/2306\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/issues/2300\r\n\r\n@neozwu is this the same issue?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2543",
        "number": 2543,
        "title": "BigQuery's QueryResultsOption.maxWaitTime Not Respected",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I may be missing something very simple, but the `QueryResultsOption.maxWaitTime` does not appear to be followed. \r\n\r\nVersion: `0.26.0-beta`.\r\n\r\nCode sample below:\r\n\r\n```\r\nbigquery.query(\r\n            queryRequest,\r\n            JobId.of(),\r\n            QueryOption.of(QueryResultsOption.pageSize(1000L)),\r\n            QueryOption.of(\r\n              QueryResultsOption.maxWaitTime(\r\n                1000L\r\n              )\r\n            )\r\n          )\r\n```\r\n\r\nThis is based on the example from: https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-bigquery\r\n\r\nI expected this to block for 1 s and then return, regardless of whether it has completed, and then return (possibly with `response.jobCompleted` returning false). \r\n\r\nWhen I run a query that lasts 15 seconds, it will block for all 15 seconds, however, the full time of the query (until `jobCompleted` is true).  No matter what I set the value of `maxWaitTime` to, it never seems to return before `jobCompleted` returns true. \r\n "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2542",
        "number": 2542,
        "title": "BatchSettings.builder().build() encourages failure by making required arguments optional",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Current pubsub Publisher settings seem to require an instance of BatchingSettings with multiple values set to non-null values. However, the builder pattern encourages setting a single setting at a time.  For example, I wanted to make sure that messages were batched into 100 messages batches. So I did this: \r\n\r\n`publisher = Publisher.defaultBuilder(topicName).setBatchingSettings(\r\n                BatchingSettings.newBuilder().setElementCountThreshold(100L).build()).build();`\r\nwhich fails with a NullPointerException . \r\nTurns out I *must* set all other values of BatchingSettings to set one since the call above produces an object like this:\r\nBatchingSettings{elementCountThreshold=100, requestByteThreshold=null, delayThreshold=null, isEnabled=true, flowControlSettings=FlowControlSettings{maxOutstandingElementCount=null, maxOutstandingRequestBytes=null, limitExceededBehavior=Ignore}}\r\n\r\nWhich took me a good 20 minutes to figure out.  \r\n\r\nWhat I wish we did here was an API that required all required parameters, like so (for example):\r\nBatchingSettings.newBuilder().setThresholds(elementCount, requestByte, delay)\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2540",
        "number": 2540,
        "title": "Spanner java client + service account without write permission causes high error rate (403)",
        "labels": [
            "api: spanner",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Steps to reproduce:\r\n\r\n1. Create a service account without write permission.\r\n2. Initialize an instance of DatabaseClient with default options and credentials from above.\r\n3. Check the API dashboard (console.cloud.google.com/apis/dashboard), there will be a bunch of 403 errors.\r\n\r\nI dug into this a bit and found out that it is due to the default settings of \r\n\r\n    com.google.cloud.spanner.SessionPoolOptions \r\n\r\nWhich sets write session fraction to 0.2. These sessions will repeatedly try to make begin transaction API calls but fail since the service account does not have permission."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2538",
        "number": 2538,
        "title": "Firestore README link to examples 404s",
        "labels": [
            "api: firestore"
        ],
        "state": "closed",
        "body": "Please check and update link to [code examples](https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-firestore#google-cloud-java-client-for-firestore)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2537",
        "number": 2537,
        "title": "Google Cloud Logging PERMISSION_DENIED when running in docker",
        "labels": [
            "api: logging",
            "auth",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I have an application that uses cloud logging\r\n\r\n   ```java\r\nlogger = LoggingOptions.newBuilder().setCredentials(\r\n                ServiceAccountCredentials.fromStream(new FileInputStream(EnvUtils.getString(EnvUtils.GOOGLE_APPLICATION_CREDENTIALS)))\r\n        ).build().getService();\r\n```\r\n\r\nusing\r\n```xml\r\n<dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-core-grpc</artifactId>\r\n        <version>${gcp.version}</version>\r\n    </dependency>\r\n<dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-core</artifactId>\r\n        <version>${gcp.version}</version>\r\n    </dependency>\r\n```\r\n\r\nwhere ${gcp.version} =1.7.0\r\n\r\nWhen I run this Java application from command line, maven logger works fine and I can see the output in cloud logging.\r\n\r\nWhen I run this in gitlab-ci or docker I get:  Caused by: \r\n\r\n```console\r\n com.google.cloud.logging.LoggingException:io.grpc.StatusRuntimeException: PERMISSION_DENIED: The caller does not have permission\r\n    at com.google.cloud.logging.spi.v2.GrpcLoggingRpc$2.apply(GrpcLoggingRpc.java:162)\r\n    at com.google.cloud.logging.spi.v2.GrpcLoggingRpc$2.apply(GrpcLoggingRpc.java:156)\r\n    at com.google.api.core.ApiFutures$GaxFunctionToGuavaFunction.apply(ApiFutures.java:140)\r\n    at com.google.common.util.concurrent.AbstractCatchingFuture$CatchingFuture.doFallback(AbstractCatchingFuture.java:205)\r\n    at com.google.common.util.concurrent.AbstractCatchingFuture$CatchingFuture.doFallback(AbstractCatchingFuture.java:193)\r\n    at com.google.common.util.concurrent.AbstractCatchingFuture.run(AbstractCatchingFuture.java:132)\r\n```\r\n\r\nI am quadruple sure (using lots of debugging and printing) that the logger is being initiated with a service account json file that has permissions works in command line, maven but not in docker/gitlab-ci.\r\n\r\nIs this a docker specific issue with grpc or something else? The docker image does not have default credentials or use glcoud cli installed."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2536",
        "number": 2536,
        "title": "What is the rate limiting on Cloud Monitoring calls",
        "labels": [
            "api: monitoring",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\nI haven't been able to find in the documentation what is the current rate limit, in calls/sec, for calls to cloud monitoring, specifically to \"listTimeseries\". Also, i haven't been able to see waht is the current limit for returned data for this same call.\r\n\r\nAny pointers would be really appreciated!\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2535",
        "number": 2535,
        "title": "Translate:  Invalid credential path in GOOGLE_APPLICATION_CREDENTIAL results in \"The request is miss a valid API key.\" error",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "# Steps to reproduce:\r\n\r\n1. Configure a Java project  with the cloud-translate Java library\r\n```\t\t\r\n<dependency>\r\n\t<groupId>com.google.cloud</groupId>\r\n\t<artifactId>google-cloud-translate</artifactId>\r\n\t<version>1.6.0</version>\r\n</dependency>\r\n```\r\n or use [one I prepared earlier](https://github.com/patflynn/spring-boot-with-cloud-libraries).\r\n1. Make sure your code makes a translate API call.\r\n1. export GOOGLE_APPLICATION_CREDENTIALS='/a/no/good/path/to/nothing' as part of your project's run configuration.\r\n1. Run your code.\r\n\r\n# Observe in your logs:\r\n```\r\n{\r\n  \"error\": {\r\n    \"code\": 403,\r\n    \"message\": \"The request is missing a valid API key.\",\r\n    \"errors\": [\r\n      {\r\n        \"message\": \"The request is missing a valid API key.\",\r\n        \"domain\": \"global\",\r\n        \"reason\": \"forbidden\"\r\n      }\r\n    ],\r\n    \"status\": \"PERMISSION_DENIED\"\r\n  }\r\n}\r\n]\r\n\r\n```\r\n# Expected result:\r\nAn exception identifying the invalid credential path as the cause of the error.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2534",
        "number": 2534,
        "title": "Large number of duplicate messages when small delay is added before message ack",
        "labels": [],
        "state": "closed",
        "body": "The customer is experiencing a large number of duplicate messages from pubsub when adding a delay before the `consumer.ack` The customer supplies code with sleep thread to simulate process on the process on a message before ack. This sleep time is below the ack timeout threshold for messages, However there is still a large number of duplicate messages. \r\n\r\n-> In the back end charts, it shows a large spike in ModifyAckDeadlineRequest in the customer's project.  I saw about 238k  ModifyAckDeadlineRequest[1] at peak and  about 30-40k messages successes. \r\n\r\nhttps://cloud.google.com/pubsub/docs/reference/rpc/google.pubsub.v1#google.pubsub.v1.ModifyAckDeadlineRequest.description\r\n\r\nLog/Graph data: Customer numbers:\r\n  Total consumed:\r\n  126709\r\n  Unique messages:\r\n  30000\r\n\r\nMy tests:\r\n1\r\n)~~~\r\nTotal consumed:\r\n75294\r\nUnique messages:\r\n30000\r\n~~~\r\n2)\r\n~~~\r\nTotal consumed:\r\n142131\r\nUnique messages:\r\n30000\r\n~~~\r\n3)\r\n~~~\r\nTotal consumed:\r\n55764\r\nUnique messages:\r\n30000\r\n~~~\r\n\r\nReproduction steps: 1) Create topic and subscription in your project \r\n2) Modify Consume.java to your project and subscription (line 13 and 14)\r\n3) Modify Publish.java to your project and topic  (line 12)\r\n4) run \"run.sh\" \r\n See the large number of duplicates \r\n5) REMOVE Lines 27 to 33 \r\n There are significantly fewer duplications\r\n\r\n[pubsub-explosion-master.zip](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1396154/pubsub-explosion-master.zip)\r\n\r\nInternal tracking error is bug 67854080"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2529",
        "number": 2529,
        "title": "How to test setRetrySettings() for Storage",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi everyone! I have implemented the code as shown\r\n```\r\n      storage = StorageOptions.newBuilder()\r\n                .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(credentialsPath)))\r\n                .setRetrySettings(RetrySettings.newBuilder().setMaxAttempts(1).build())\r\n                .build()\r\n                .getService();\r\n```\r\n### How I Test ###\r\nBut when I tested it, it seems that it is still attempts to connect for 10 times before it died.\r\nI tested it by turning off the network connectivity and attempts to call the function to upload a file.\r\nThis is my uploading call:\r\n```\r\nBlobInfo blobInfo =\r\n        storage.create(\r\n          BlobInfo\r\n            .newBuilder(bucketName, fileName)\r\n            // Modify access list to allow all authenticated users with link to read file\r\n            .setAcl(new ArrayList<>(Arrays.asList(Acl.of(User.ofAllAuthenticatedUsers(), Role.READER))))\r\n            .build(),\r\n            contentAsBytes);\r\n```\r\n## RESULT ##\r\nIf it is any help, the error is :\r\n```\r\nOct 16, 2017 10:34:34 AM com.google.api.client.http.HttpRequest execute\r\nWARNING: exception thrown while executing request\r\njava.net.UnknownHostException: accounts.google.com\r\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)\r\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\r\n\tat java.net.Socket.connect(Socket.java:589)\r\n\tat sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673)\r\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:175)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:463)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:558)\r\n\tat sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)\r\n\tat sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:378)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146)\r\n\tat com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96)\r\n\tat com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157)\r\n\tat com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:423)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:232)\r\n\tat com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:158)\r\n\tat com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:155)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n\tat com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:155)\r\n\tat com.google.cloud.storage.StorageImpl.create(StorageImpl.java:136)\r\n\tat com.uilicious.gcos.GoogleCloudStorage.uploadToGcs(GoogleCloudStorage.java:84)\r\n\tat com.uilicious.runner.TestEngineRunner.writeTestScript(TestEngineRunner.java:308)\r\n\tat com.uilicious.runner.NodeApiAgent.lambda$static$0(NodeApiAgent.java:115)\r\n\tat picoded.RESTBuilder.RESTNamespace.call(RESTNamespace.java:88)\r\n\tat picoded.RESTBuilder.RESTBuilder.setupAndCall(RESTBuilder.java:220)\r\n\tat picoded.RESTBuilder.RESTBuilder.namespaceCall(RESTBuilder.java:245)\r\n\tat picoded.RESTBuilder.RESTBuilder.servletCall(RESTBuilder.java:259)\r\n\tat com.uilicious.runner.ServletBase.outputJSON(ServletBase.java:184)\r\n\tat picoded.servlet.CorePage.processChainJSON(CorePage.java:855)\r\n\tat picoded.servlet.CorePage.processChain(CorePage.java:740)\r\n\tat picoded.servlet.CorePage.doPost(CorePage.java:1158)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\r\n\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\r\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)\r\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)\r\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)\r\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)\r\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)\r\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)\r\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)\r\n\tat org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)\r\n\tat org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\r\n\tat org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:789)\r\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1437)\r\n\tat org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2528",
        "number": 2528,
        "title": "Provide libraries compatible with 'io.netty:netty-tcnative-boringssl-static:2.0.6.Final'",
        "labels": [
            "api: core",
            "dependencies",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Spring Boot as of version 2.0.0.M4 is not compatible with ```io.netty:netty-tcnative-boringssl-static:1.1.33.Fork26``` it requires ```io.netty:netty-tcnative-boringssl-static:2.0.6.Final``` especially for the reactive spring-boot-starter-webflux package. This causes google java api to not be usable with the newest version of spring boot.\r\nIt would be great if you could either shade the dependency on ```1.1.33.Fork26``` or upgrade to the ```2.0.6.Final```."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2527",
        "number": 2527,
        "title": "File write errors when writing small files",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Similar to #723.\r\n\r\nVersion of GCloud running: default versions provided with dataproc on Google Compute Engine. Looks like these are:\r\n\r\nGoogle Cloud SDK 174.0.0\r\nalpha 2017.10.02\r\nbeta 2017.10.02\r\nbq 2.0.27\r\ncore 2017.10.02\r\ngsutil 4.27\r\n\r\nHere is the code we are using to write files:\r\n```java\r\n  def writeBytes(bytes: Array[Byte], dst: String): Unit = {\r\n    val blob = blobOf(dst)\r\n    val blobTry = storage.get(blob) // THIS APPEARS TO BE THE LINE THAT THROWS THE ERROR\r\n    val writer =\r\n      if(blobTry != null) blobTry.writer()\r\n      else {\r\n        val blobInfoBuilder = BlobInfo.newBuilder(blob)\r\n        blobInfoBuilder.setContentType(\"text/plain\")\r\n        blobInfoBuilder.setContentEncoding(\"utf-8\")\r\n        storage.writer(blobInfoBuilder.build)\r\n      }\r\n\r\n      writer.write(java.nio.ByteBuffer.wrap(bytes))\r\n      writer.close\r\n  }\r\n\r\n```\r\nHere is the error that sometimes gets thrown when writing short files (about 550 bytes) when running Spark jobs via dataproc.\r\n\r\n```\r\nException in thread \"main\" com.google.cloud.storage.StorageException: java.lang.RuntimeException: java.lang.NullPointerException: ssl == null\r\n        at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71)\r\n        at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:196)\r\n        at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202)\r\n        at com.petametrics.api.util.GSFile$.writeBytes(GSFile.scala:84)\r\nCaused by: java.lang.RuntimeException: java.lang.NullPointerException: ssl == null\r\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1488)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getHeaderField(HttpURLConnection.java:3018)\r\n        at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:489)\r\n        at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338)\r\n        at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37)\r\n        at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94)\r\n        at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333)\r\n        at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191)\r\n        at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188)\r\n        at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93)\r\n        at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49)\r\n        at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188)\r\n        ... 20 more\r\nCaused by: java.lang.NullPointerException: ssl == null\r\n        at org.conscrypt.NativeCrypto.SSL_write(Native Method)\r\n        at org.conscrypt.OpenSSLSocketImpl$SSLOutputStream.write(OpenSSLSocketImpl.java:806)\r\n        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\r\n        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\r\n        at java.io.PrintStream.flush(PrintStream.java:338)\r\n        at sun.net.www.MessageHeader.print(MessageHeader.java:301)\r\n        at sun.net.www.http.HttpClient.writeRequests(HttpClient.java:644)\r\n        at sun.net.www.http.HttpClient.writeRequests(HttpClient.java:655)\r\n        at sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:693)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1567)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474)\r\n        at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)\r\n        ... 33 more\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2526",
        "number": 2526,
        "title": "java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.",
        "labels": [],
        "state": "closed",
        "body": "I use below code in order to perform Face detection \r\n\r\n ```\r\nList<AnnotateImageRequest> requests = new ArrayList<>();\r\n        ByteString imgBytes = ByteString.readFrom(new FileInputStream(filePath));\r\n        Image img = Image.newBuilder().setContent(imgBytes).build();\r\n        Feature feat = Feature.newBuilder().setType(FACE_DETECTION).build();\r\n        AnnotateImageRequest request =\r\n                AnnotateImageRequest.newBuilder().addFeatures(feat).setImage(img).build();\r\n        requests.add(request);\r\n\r\n        try (ImageAnnotatorClient client = ImageAnnotatorClient.create()) {\r\n            BatchAnnotateImagesResponse response = client.batchAnnotateImages(requests);\r\n            List<AnnotateImageResponse> responses = response.getResponsesList();\r\n\r\n            for (AnnotateImageResponse res : responses) {\r\n                if (res.hasError()) {\r\n                    Log.d(\"Error: %s\\n\", res.getError().getMessage());\r\n                    return;\r\n                }\r\n\r\n                // For full list of available annotations, see http://g.co/cloud/vision/docs\r\n                for (FaceAnnotation annotation : res.getFaceAnnotationsList()) {\r\n                    Log.d(\"getAngerLikelihood\", \"\"+ annotation.getAngerLikelihood());\r\n                    Log.d(\"getAngerLikelihood\",\"\"+annotation.getJoyLikelihood());\r\n                    Log.d(\"getAngerLikelihood\",\"\"+annotation.getSurpriseLikelihood());\r\n                    Log.d(\"getAngerLikelihood\",\"\"+annotation.getBoundingPoly());\r\n                }\r\n            }\r\n        }\r\n\r\n```\r\n\r\nbut I am facing the error \r\n\r\n[java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.](url)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2520",
        "number": 2520,
        "title": "com.google.cloud.RetryParams not found in google-cloud-core jar",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Hi! I am trying to implement my own `RetryParams` to alter the maximum number of reattempts made by my storage service. However, I could not import `RetryParams` and it could not be found anywhere even though it is stated in the docs, [RetryParams](http://googlecloudplatform.github.io/google-cloud-java/0.7.0/apidocs/com/google/cloud/RetryParams.html). \r\n\r\nAm I missing something or am I implementing the whole thing wrongly?\r\n\r\nThis is my code snippet:\r\n```\r\nstorage = StorageOptions.newBuilder()\r\n                .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(credentialsPath)))\r\n                .setRetryParams(RetryParams.newBuilder().retryMaxAttempts(3).build())\r\n                .build()\r\n                .getService();\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2517",
        "number": 2517,
        "title": "Method for assigning custom metadata missing",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I'm trying to pass custom metadata like uid ('x-goog-meta-uid') in the header, but I can't find an option to sign the url with this additional piece of information. Is this available on the java library? I've got below so far..  \r\n\r\nURL uploadUrl = storage.signUrl(\r\n                blobInfo,\r\n                5,\r\n                TimeUnit.MINUTES,\r\n                Storage.SignUrlOption.httpMethod(HttpMethod.PUT),\r\n                Storage.SignUrlOption.withContentType());"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2516",
        "number": 2516,
        "title": "How do I configure the firewall?",
        "labels": [
            "api: compute",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nI can't seem to find a way of configuring any kind of firewall rules on an instance or project from Java.\r\n\r\nI'm able to launch a machine with SSH but I would like to also control who gets to connect. \r\n\r\nThe EC2 Java API has the authorizeSecurityGroupIngress method where I can define a CIDR, ports and protocols. I expect something similar from Google Compute Engine."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2515",
        "number": 2515,
        "title": "DuplicateFileException",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I am sorry to say google cloud is not have good supporting documentation as compared to AWS cloud \r\n\r\nI am using the below code \r\n\r\n```\r\ncompile 'com.google.api-client:google-api-client-android:1.20.0' exclude module: 'httpclient'\r\ncompile 'com.google.http-client:google-http-client-gson:1.20.0' exclude module: 'httpclient'\r\ncompile 'com.google.cloud:google-cloud-vision:0.25.0-beta'\r\n```\r\n\r\nWhen I run the code I see the following errors\r\n\r\n```\r\nError:Execution failed for task ':app:transformResourcesWithMergeJavaResForDebug'.\r\n> com.android.build.api.transform.TransformException: com.android.builder.packaging.DuplicateFileException: Duplicate files copied in APK project.properties\r\n\tFile1: C:\\Users\\Developer\\.gradle\\caches\\modules-2\\files-2.1\\com.google.cloud\\google-cloud-vision\\0.25.0-beta\\7510920cf329d8b0f82469b7d267c9466bfdf546\\google-cloud-vision-0.25.0-beta.jar\r\n\tFile2: C:\\Users\\Developer\\.gradle\\caches\\modules-2\\files-2.1\\com.google.cloud\\google-cloud-core\\1.7.0\\453cc89cde3f2896825aecfb4d05dc2ba06f9775\\google-cloud-core-1.7.0.jar\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2514",
        "number": 2514,
        "title": "API report for Google Cloud Storage",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nHere is the report on API changes and backward binary compatibility for the Google Cloud Storage library: https://abi-laboratory.pro/java/tracker/timeline/google-cloud-storage/\r\n\r\nThe report is generated by the https://github.com/lvc/japi-compliance-checker tool for jars at http://central.maven.org/maven2/com/google/cloud/google-cloud-storage/ according to the article https://wiki.eclipse.org/Evolving_Java-based_APIs_2.\r\n\r\nHope it will be helpful for users and maintainers of the library. Feel free to request other Google Cloud modules to be included to the tracker if you are interested.\r\n\r\nThank you.\r\n\r\n![google-cloud-storage-1](https://user-images.githubusercontent.com/1517837/31481172-aa9e2588-af2a-11e7-9e19-26454b912db4.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2512",
        "number": 2512,
        "title": "Pub/Sub on failures must return `ApiException` and not `io.grpc.StatusRuntimeException`",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Currently, the following code on publishing to a non-existent topic returns `io.grpc.StatusRuntimeException` instead of an `ApiException`.\r\n```\r\nApiFuture<String> future = publishMessage(publisher, \"message\");\r\nApiFutures.addCallback(future, new ApiFutureCallback<String>() {\r\n    @Override\r\n    public void onFailure(Throwable throwable) {\r\n        if (throwable instanceof ApiException) {\r\n         ApiException apiException = (ApiException) throwable;\r\n         System.out.println(\"Error publishing message : \" + apiException.getStatusCode());\r\n       }\r\n   }\r\n\r\n   @Override\r\n   public void onSuccess(String s) {\r\n       System.out.println(\"Message published with ID : \" + s);\r\n   }\r\n });\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2509",
        "number": 2509,
        "title": "google-cloud-datastore Entity.isUnindexedProperty API",
        "labels": [],
        "state": "closed",
        "body": "In com.google.appengine.api.datastore.Entity we had an API to get whether an entity is indexed by callling com.google.appengine.api.datastore.Entity.isUnindexedProperty(String propertyName) during the read time.\r\n\r\nIs there an API in google-cloud-datastore that provides the same capability during the read?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2507",
        "number": 2507,
        "title": "Spanner: LIKE with bound parameter ignoring index",
        "labels": [],
        "state": "closed",
        "body": "I have a query that uses `LIKE` and has a bound parameter with a tailing wildcard. \r\n\r\nThe index (IX_USERS_TYPE) has both the `TYPE` and `ADDRESS` columns. I would expect the amount of rows scanned to equal the amount of matches to the string preceding the `%`.\r\n\r\nWhen I run the following query, I expect it to only scan 1 row based on the address I am using. It _actually_ does a full table scan of all 14 million rows.\r\n\r\n```sql\r\nSELECT S.NAME, S.EMAIL\r\nFROM USERS@{FORCE_INDEX=IX_USERS_TYPE} S\r\nWHERE S.TYPE='ADMIN'\r\nAND S.ADDRESS LIKE CONCAT(@userAddress,'%')\r\n```\r\n\r\nWhen I hard code the value of *@userAddress* from the previous example directly into the SQL (instead of binding), it behaves as expected and only does an index scan of 1 row.\r\n\r\n```sql\r\nSELECT S.NAME, S.EMAIL\r\nFROM USERS@{FORCE_INDEX=IX_USERS_TYPE} S\r\nWHERE S.TYPE='ADMIN'\r\nAND S.ADDRESS LIKE CONCAT('1234 Oak Dr','%')\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2506",
        "number": 2506,
        "title": "Pub/Sub StreamingSubscriberConnection  : Terminated streaming with exception",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "See related issue on the spring-cloud-gcp project at https://github.com/spring-guides/gs-messaging-gcp-pubsub/issues/4."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2505",
        "number": 2505,
        "title": "How to support insert NULL values in bigquery.insertAll",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "I followed the official example of [Streaming insert examples](https://cloud.google.com/bigquery/streaming-data-into-bigquery), and came across with a problem:\r\nthe _insertAll_ command, does not accept **a null value** in the Map I pass it.\r\n\r\n**Code example:**\r\n        Map<String, Object> rowContent = new HashMap<>();\r\n        rowContent.put(\"fname\",\"David\");\r\n        rowContent.put(\"lname\",null); //here's the problem\r\n\r\n        TableId tableId = TableId.of(dataSetName, tableName);\r\n        InsertAllResponse response = bigquery.insertAll(InsertAllRequest.newBuilder(tableId)\r\n                .addRow( rowContent)\r\n                .build());\r\n\r\n        // If any of the insertions failed, this lets you inspect the errors\r\n        if (response.hasErrors()) {\r\n            for (Map.Entry<Long, List<BigQueryError>> entry : response.getInsertErrors().entrySet()) {\r\n                logger.error(entry.toString());\r\n            }\r\n        }\r\n\r\nI investigated the libraries the code is using, and I saw there're several checks regarding NULL. \r\nFor example:\r\n\r\n@GwtCompatible\r\nfinal class CollectPreconditions {\r\n    CollectPreconditions() {\r\n    }\r\n\r\n    static void checkEntryNotNull(Object key, Object value) {\r\n        if (key == null) {\r\n            throw new NullPointerException(\"null key in entry: null=\" + value);\r\n        } else if (value == null) {\r\n            throw new NullPointerException(\"null value in entry: \" + key + \"=null\");\r\n        }\r\n    }\r\n...\r\n}\r\n\r\n**Question:**\r\nHow/What can can I do in order to insert records, which some of the values might be NULL.\r\n**I'm using the Java client."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2504",
        "number": 2504,
        "title": "Auth problems App Engine J8/Std --> Stackdriver Montoring API",
        "labels": [
            "api: monitoring",
            "running on app engine",
            "type: question"
        ],
        "state": "closed",
        "body": "### Problem\r\n\r\nCloud Client Libraries (including Cloud Monitoring API v3) support Application Default Credentials and should use the App Engine service account to authenticate against other services. This does not appear to work as intended|documented:\r\n\r\ncom.google.api.gax.rpc.UnauthenticatedException: io.grpc.StatusRuntimeException: UNAUTHENTICATED\r\n\r\nA colleague provided a hack that obtains an access token using the App Engine service account and injects this into the credentials provided to the Cloud Monitoring API. This works but is unwieldy (see below) and should be unnecessary.\r\n\r\n### Repro\r\n-- Maven generate an App Engine Standard J8 app\r\n-- Mash-up w/ Google provided [Custom Metric sample](https://cloud.google.com/monitoring/docs/reference/libraries#client-libraries-install-java)\r\n-- Observe UNAUTHENTICATED problems auth'ing with `MetricServiceClient.create()`\r\n\r\n### Solution\r\nCaveat: I do not understand why this code works... it does\r\n\r\n-- Revise `MetricServiceClient.create()` with:\r\n\r\n```\r\nList<String> scopes = Arrays.asList(\"https://www.googleapis.com/auth/monitoring\");\r\n\r\nAppIdentityService appIdentityService = AppIdentityServiceFactory\r\n    .getAppIdentityService();\r\n\r\nString access_token = appIdentityService\r\n    .getAccessToken(scopes)\r\n    .getAccessToken();\r\n\r\nAppEngineCredentials credentials = AppEngineCredentials\r\n    .newBuilder()\r\n    .setAppIdentityService(appIdentityService)\r\n    .setScopes(scopes)\r\n    .build();\r\n\r\nCredentialsProvider credentialsProvider = FixedCredentialsProvider.create(credentials);\r\n\r\nMetricServiceSettings metricServiceSettings =\r\n    MetricServiceSettings.newBuilder()\r\n        .setCredentialsProvider(credentialsProvider)\r\n        .build();\r\nMetricServiceClient metricServiceClient = MetricServiceClient\r\n    .create(metricServiceSettings);        \r\n```\r\n\r\nHere:\r\nhttps://gist.github.com/DazWilkin/05b1a2ed702e78019e20e862df274129#file-testservlet-java-L52-L74\r\n\r\n\r\nThanks @salrashid123 for providing the solution."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2503",
        "number": 2503,
        "title": "Latest Datastore + Pubsub clients libraries conflict",
        "labels": [
            "api: datastore",
            "api: pubsub",
            "dependencies",
            "priority: p1",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "I had a project with the latest datastore client (1.7.0) and added the pubsub client (0.25.0-beta).\r\nWhen I tried to publish a message, it would not publish my message and hang forever with no error\r\n\r\nafter making some tests I found out those two clients had a conflict in their dependencies.\r\nDatastore uses **com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0** that depends on **com.google.protobuf:protobuf-java:jar:3.0.0** while PubSub uses **com.google.cloud:google-cloud-core-grpc:jar:1.7.0** that depends on **com.google.protobuf:protobuf-java:jar:3.3.1**\r\n\r\nI made it work excluding **protobuf-java** from the datastore dependency:\r\n\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-datastore</artifactId>\r\n            <version>1.7.0</version>\r\n            <exclusions>\r\n                <exclusion>\r\n                    <groupId>com.google.protobuf</groupId>\r\n                    <artifactId>protobuf-java</artifactId>\r\n                </exclusion>\r\n            </exclusions>\r\n        </dependency>"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2502",
        "number": 2502,
        "title": "io.grpc.StatusRuntimeException: UNAVAILABLE is happening after some time",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "I have expected strange behavior of pubsub client application. App is running and after some time it is producing (out of nowhere) following exception:\r\n\r\n<pre>\r\n\r\n2017-10-06 08:23:58 [pool-6-thread-9] WARN  c.g.c.p.v.StreamingSubscriberConnection - Terminated streaming with exception\r\nio.grpc.StatusRuntimeException: UNAVAILABLE\r\n        at io.grpc.Status.asRuntimeException(Status.java:526)\r\n        at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:385)\r\n        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\n        at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\n        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n        at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.IOException: Connection reset by peer\r\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\r\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\r\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\r\n        at sun.nio.ch.IOUtil.read(IOUtil.java:192)\r\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)\r\n        at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\r\n        at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\r\n        at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:372)\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\r\n        ... 1 common frames omitted\r\n</pre>\r\n\r\nWe are using google-cloud-pubsub library version : 0.24.0-beta\r\n\r\nI would like to ask what is causing such particular exception, and whether or not this is a bug?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2501",
        "number": 2501,
        "title": "Strange subscriber behavior - long delays between message delivery",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "I recently got back to working on a project that incorporates pub/sub that had been on the shelf for a couple of months. I switched to 0.24.0-beta of the pub/sub client and I'm now seeing strangeness on the subscriber side: my subscriber often does not receive messages (for a long time). In the most recent experiment, I published a single message and the subscribe received it 20+ minutes later. Sometime the subscriber gets messages right away; often not.\r\n\r\n I would expect all published messages to get delivered in a \"reasonable\" timeframe - when I used the old client a few months again, I receive them \"promptly\". Notes that may be pertinent:\r\n* outstanding-element-count is one as the client can handle only one pub/sub message at a time\r\n* there is currently only one subscription, with a single subscriber pulling from it (in the future there will be many)\r\n* publishing may be infrequent - it is expected that over time, there will eventually have many messages posted regularly but for now, there will often be minutes or hours between publish events.\r\n* it _seems_ that publishing another message (or starting another client) helps get messages delivered sooner.\r\n\r\nThe setup of the client looks like this:\r\n```scala\r\n    val flowControl = FlowControlSettings.newBuilder\r\n      .setMaxOutstandingElementCount(1L)\r\n      .setLimitExceededBehavior(LimitExceededBehavior.Block)\r\n      .build\r\n    val name = SubscriptionName.newBuilder().setProject(project).setSubscription(subscription).build\r\n    Subscriber.defaultBuilder(name, receiver)\r\n      .setExecutorProvider(pubsubThreadPool)\r\n      .setFlowControlSettings(flowControl)\r\n      .setCredentialsProvider(credentialProvider)\r\n//        .setAckExpirationPadding()\r\n//        .setMaxAckExtensionPeriod()\r\n      .build()\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2499",
        "number": 2499,
        "title": "Google-cloud-language: No such Method Error on gax grpc",
        "labels": [
            "api: language",
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "I used a service account authentication, through an environment variable.\r\n\r\nUsing this pom configuration:\r\n\r\n```\r\n<dependency>\r\n    \t\t<groupId>com.google.api</groupId>\r\n    \t\t<artifactId>gax</artifactId>\r\n    \t\t<version>1.8.1</version>\r\n\t\t</dependency>\r\n <dependency>\r\n\t\t <groupId>com.google.api</groupId>\r\n\t\t  <artifactId>gax-grpc</artifactId>\r\n\t\t  <version>0.25.1</version>\r\n</dependency>    \r\n<dependency>\r\n    \t\t<groupId>com.google.cloud</groupId>\r\n    \t\t<artifactId>google-cloud-language</artifactId>\r\n   \t\t <version>0.25.0-beta</version>\r\n</dependency>\r\n```\r\n\r\nI had to manually add gax libs, because dependencies were not resolved by the google-cloud-language pom.\r\n\r\nI get this error, at run time, trying to execute the example from the Google Natural Language description page :\r\n\r\n```\r\nRoot Exception stack trace:\r\njava.lang.NoSuchMethodError: com.google.api.gax.grpc.InstantiatingChannelProvider$Builder.setEndpoint(Ljava/lang/String;)Lcom/google/api/gax/grpc/InstantiatingChannelProvider$Builder;\r\n\tat com.google.cloud.language.v1.LanguageServiceSettings.defaultGrpcChannelProviderBuilder(LanguageServiceSettings.java:151)\r\n\tat com.google.cloud.language.v1.LanguageServiceSettings.defaultGrpcTransportProviderBuilder(LanguageServiceSettings.java:158)\r\n\tat com.google.cloud.language.v1.LanguageServiceSettings.defaultTransportProvider(LanguageServiceSettings.java:162)\r\n\tat com.google.cloud.language.v1.LanguageServiceSettings$Builder.createDefault(LanguageServiceSettings.java:291)\r\n\tat com.google.cloud.language.v1.LanguageServiceSettings$Builder.access$000(LanguageServiceSettings.java:219)\r\n\tat com.google.cloud.language.v1.LanguageServiceSettings.newBuilder(LanguageServiceSettings.java:192)\r\n\tat com.google.cloud.language.v1.LanguageServiceClient.create(LanguageServiceClient.java:109)\r\n```\r\n\r\nAny hint to solve this ?\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2497",
        "number": 2497,
        "title": "FR: Expose GrpcForestoreRpc.close() via Firestore",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "`GrpcForestoreRpc` class has a [`close()`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-firestore/src/main/java/com/google/cloud/firestore/spi/v1beta1/GrpcFirestoreRpc.java#L134) method, which cleans up any allocated resources (client stubs, threads pools etc) and terminates the client. This should be exposed via `Firestore` interface so the users can gracefully terminate the client. For example:\r\n\r\n```\r\nFirestore fs;\r\ntry {\r\n  fs = initMyFirestore();\r\n  // Do stuff with fs\r\n} finally {\r\n  // On application shutdown or at any other suitable lifecycle handler\r\n  fs.close();\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2496",
        "number": 2496,
        "title": "java.lang.ClassNotFoundException: com.google.api.gax.rpc.ClientSettings when using Firestore",
        "labels": [],
        "state": "closed",
        "body": "I'm seeing following test failures in my project when trying to use Firestore.\r\n\r\n```\r\ntestServiceAccountProjectId(com.google.firebase.cloud.FirestoreClientTest)  Time elapsed: 0.001 sec  <<< ERROR!\r\njava.lang.NoClassDefFoundError: com/google/api/gax/rpc/ClientSettings\r\n\tat com.google.firebase.cloud.FirestoreClientTest.testServiceAccountProjectId(FirestoreClientTest.java:42)\r\nCaused by: java.lang.ClassNotFoundException: com.google.api.gax.rpc.ClientSettings\r\n\tat com.google.firebase.cloud.FirestoreClientTest.testServiceAccountProjectId(FirestoreClientTest.java:42)\r\n\r\ntestAppDelete(com.google.firebase.cloud.FirestoreClientTest)  Time elapsed: 0 sec  <<< ERROR!\r\njava.lang.NoClassDefFoundError: Could not initialize class com.google.cloud.firestore.FirestoreOptions\r\n\tat com.google.firebase.cloud.FirestoreClientTest.testAppDelete(FirestoreClientTest.java:56)\r\n\r\ntestExplicitProjectId(com.google.firebase.cloud.FirestoreClientTest)  Time elapsed: 0 sec  <<< ERROR!\r\njava.lang.NoClassDefFoundError: Could not initialize class com.google.cloud.firestore.FirestoreOptions\r\n\tat com.google.firebase.cloud.FirestoreClientTest.testExplicitProjectId(FirestoreClientTest.java:30)\r\n```\r\n\r\nSo far the solution seems to be adding the following as a dependency to my project:\r\n\r\n```\r\n      <dependency>\r\n            <groupId>com.google.api</groupId>\r\n            <artifactId>gax</artifactId>\r\n            <version>1.8.1</version>\r\n       </dependency>\r\n```\r\n\r\nPerhaps Firestore should declare this dependency explicitly."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2494",
        "number": 2494,
        "title": "[Request] Verify User Project methods comments are not ambiguous",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "General Request:\r\n\r\nVerify that the comments are clear for methods which accept User Project with and without Requester Pays.\r\n\r\nHere's a distinction between Requester Pays and User Project:\r\nUser Project: Is a request metadata field that is used to assign Storage operational costs to a specified project.\r\n\r\nRequester Pays: Is a bucket-level metadata field that is used to enforce the use of the User Project metadata field to assign operational costs when an operation is made on a Bucket and its objects."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2491",
        "number": 2491,
        "title": "Dependency Errors While Using Maven shade jar",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "Okay so I use maven shade jar here is my pom.xml https://pastebin.com/6rASfHss\r\n\r\nbut I get these errors https://pastebin.com/xpTDApiL\r\nI compile using clean package\r\nhave done a google search and it looks like it has something to do with guava\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2490",
        "number": 2490,
        "title": "Firestore on App Engine (java 7) Results in Exceptions",
        "labels": [],
        "state": "closed",
        "body": "Got the following error with Firestore on App Engine (java7):\r\n\r\n```\r\ncom.google.cloud.firestore.FirestoreException: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat com.google.cloud.firestore.FirestoreException.networkException(FirestoreException.java:75)\r\n\tat com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:73)\r\n\tat com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:63)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:472)\r\n\tat com.google.cloud.firestore.FirestoreOptions.getFirestoreRpc(FirestoreOptions.java:163)\r\n\tat com.google.cloud.firestore.FirestoreImpl.&lt;init&gt;(FirestoreImpl.java:140)\r\n\tat com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreFactory.create(FirestoreOptions.java:54)\r\n\tat com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreFactory.create(FirestoreOptions.java:47)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:459)\r\n\tat com.test.FirebaseAppHolder.startListener(FirebaseAppHolder.java:102)\r\n\tat com.test.ServletContextListenerImpl.contextInitialized(ServletContextListenerImpl.java:10)\r\n\tat org.mortbay.jetty.handler.ContextHandler.startContext(ContextHandler.java:548)\r\n\tat org.mortbay.jetty.servlet.Context.startContext(Context.java:136)\r\n\tat org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1250)\r\n\tat org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:517)\r\n\tat org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:467)\r\n\tat org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\r\n\tat com.google.apphosting.runtime.jetty.AppVersionHandlerMap.createHandler(AppVersionHandlerMap.java:203)\r\n\tat com.google.apphosting.runtime.jetty.AppVersionHandlerMap.getHandler(AppVersionHandlerMap.java:176)\r\n\tat com.google.apphosting.runtime.jetty.JettyServletEngineAdapter.serviceRequest(JettyServletEngineAdapter.java:134)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.dispatchServletRequest(JavaRuntime.java:680)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.dispatchRequest(JavaRuntime.java:642)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.run(JavaRuntime.java:612)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable.runInContext(TraceContext.java:454)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable$1.run(TraceContext.java:461)\r\n\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:297)\r\n\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContextNoUnref(TraceContext.java:320)\r\n\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContext(TraceContext.java:312)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable.run(TraceContext.java:458)\r\n\tat com.google.apphosting.runtime.ThreadGroupPool$PoolEntry.run(ThreadGroupPool.java:274)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.io.IOException: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat com.google.cloud.firestore.spi.v1beta1.GrpcFirestoreRpc.&lt;init&gt;(GrpcFirestoreRpc.java:129)\r\n\tat com.google.cloud.firestore.FirestoreOptions$DefaultFirestoreRpcFactory.create(FirestoreOptions.java:71)\r\n\t... 29 more\r\nCaused by: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:159)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:136)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:124)\r\n\tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:94)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.&lt;init&gt;(NettyChannelBuilder.java:525)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.&lt;init&gt;(NettyChannelBuilder.java:518)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.&lt;init&gt;(NettyChannelBuilder.java:457)\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:326)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:315)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:131)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:116)\r\n\tat com.google.api.gax.grpc.GrpcTransportProvider.getTransport(GrpcTransportProvider.java:98)\r\n\tat com.google.cloud.firestore.spi.v1beta1.GrpcFirestoreRpc.&lt;init&gt;(GrpcFirestoreRpc.java:104)\r\n\t... 30 more\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2489",
        "number": 2489,
        "title": "Dependency on gax not properly defined",
        "labels": [],
        "state": "closed",
        "body": "It seems Firestore client has a dependency on gax that is not properly defined. I get the following error when adding only Firestore to my project:\r\n\r\n```\r\njava.lang.NoClassDefFoundError: com/google/api/gax/rpc/ClientSettings\r\n\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:332)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat com.google.cloud.firestore.FirestoreOptions.<clinit>(FirestoreOptions.java:41)\r\n\tat com.google.firebase.cloud.FirestoreClient.<init>(FirestoreClient.java:38)\r\n\tat com.google.firebase.cloud.FirestoreClient.<init>(FirestoreClient.java:26)\r\n\tat com.google.firebase.cloud.FirestoreClient$FirestoreClientService.<init>(FirestoreClient.java:80)\r\n\tat com.google.firebase.cloud.FirestoreClient.getInstance(FirestoreClient.java:70)\r\n\tat com.google.firebase.cloud.FirestoreClient.getFirestore(FirestoreClient.java:63)\r\n\tat com.google.firebase.cloud.FirestoreClientTest.testServiceAccountProjectId(FirestoreClientTest.java:42)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\r\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\r\n\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:237)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\r\nCaused by: java.lang.ClassNotFoundException: com.google.api.gax.rpc.ClientSettings\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:332)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 47 more\r\n```\r\n\r\nI have the following in my `pom.xml` as per https://firebase.google.com/docs/firestore/quickstart\r\n\r\n```\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-firestore</artifactId>\r\n            <version>0.25.0-beta</version>\r\n        </dependency>\r\n```\r\n\r\nI had to also add the following to get past the error:\r\n\r\n```\r\n       <dependency>\r\n            <groupId>com.google.api</groupId>\r\n            <artifactId>gax</artifactId>\r\n            <version>1.8.1</version>\r\n        </dependency>\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2488",
        "number": 2488,
        "title": "Add Firestore to `google-cloud` pom.xml",
        "labels": [],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud/pom.xml is missing `google-cloud-firestore`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2486",
        "number": 2486,
        "title": "BiqQuery API methods return null",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "The following methods of the API ALWAYS return null value. Please have a look. Thanks!\r\n`DatasetInfo.getLocation()`\r\n`DatasetInfo.getCreationTime()`\r\n`DatasetInfo.getDefaultTableLifetime()`\r\n`DatasetInfo.getDescription()`\r\n`DatasetInfo.getLastModified()`\r\n\r\nThis is also related to an initial issue I created: https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2482\r\n\r\nI created a sample dataset through the UI and added a table to it. I'm able query this relevant information using the gcloud API. On using the Java Library to query information about the dataset using the above methods, I get a null value. However `dataset.getDatasetId().getDataset()` gives the name of the expected dataset.\r\n\r\nCode:\r\n\r\n```\r\nBigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\nPage<Dataset> datasets = bigquery.listDatasets();\r\n\r\nfor (Dataset dataset : datasets.iterateAll()) {\r\n      Map<String, String> props = new HashMap<>();\r\n      String datasetId = dataset.getDatasetId().getDataset();\r\n\r\n      dataset.getCreationTime() // This gives null\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2485",
        "number": 2485,
        "title": "com.google.cloud.pubsub.v1.Subscriber how to await stop signal?",
        "labels": [
            "api: pubsub",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Hi,\r\nwhen im calling `stopAsync` on a subscriber i get the following exception: \r\n```\r\ncom.google.common.util.concurrent.AbstractFuture executeListener\r\nSEVERE: RuntimeException while executing runnable com.google.common.util.concurrent.Futures$4@22553be0 with executor java.util.concurrent.Executors$DelegatedScheduledExecutorService@6e1d503c\r\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2c92d002 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@31c73eaa[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 18]\r\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)\r\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.execute(ScheduledThreadPoolExecutor.java:622)\r\n\tat java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat com.google.common.util.concurrent.SettableFuture.setException(SettableFuture.java:53)\r\n\tat com.google.cloud.pubsub.v1.StreamingSubscriberConnection$StreamingPullResponseObserver.onError(StreamingSubscriberConnection.java:141)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:385)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nthe doc of the `startAsync` suggests to wait for a stop signal:\r\n```\r\n  /**\r\n   * Initiates service startup and returns immediately.\r\n   *\r\n   * <p>Example of receiving a specific number of messages.\r\n   *\r\n   * <pre>{@code\r\n   * Subscriber subscriber = Subscriber.defaultBuilder(subscription, receiver).build();\r\n   * subscriber.addListener(new Subscriber.Listener() {\r\n   *   public void failed(Subscriber.State from, Throwable failure) {\r\n   *     // Handle error.\r\n   *   }\r\n   * }, executor);\r\n   * subscriber.startAsync();\r\n   *\r\n   * // Wait for a stop signal.\r\n   * done.get();\r\n   * subscriber.stopAsync().awaitTerminated();\r\n   * }</pre>\r\n   */\r\n```\r\nBut i don't know what is meant by `done.get();`\r\n\r\nversion 0.25.0-beta"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2484",
        "number": 2484,
        "title": "Behind proxy ",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "**Using the code from** : https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/vision/snippets/AnnotateImage.java\r\n\r\n**Proxy jvm variables set as :** \r\n-Dhttp.proxyHost=\"http://XXX.XX.X.X\" -Dhttp.proxyPort=\"XXXX\" -Dhttps.proxyHost=\"http://XXX.XX.X.X\" -Dhttps.proxyPort=\"XXXX\"\r\n\r\n**Environment :** \r\nMac os 10.12\r\nEclipse neon 2\r\njdk 1.8\r\n\r\n**Unable to connect to google cloud services API.**\r\n\r\n**Error stack** : \r\nException in thread \"main\" com.google.api.gax.rpc.InternalException: io.grpc.StatusRuntimeException: INTERNAL: Connection closed with unknown cause\r\n\tat com.google.api.gax.grpc.GrpcApiExceptionFactory.createException(GrpcApiExceptionFactory.java:88)\r\n\tat com.google.api.gax.grpc.GrpcExceptionCallable$ExceptionTransformingFuture.onFailure(GrpcExceptionCallable.java:112)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:53)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:458)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:433)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:422)\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:61)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:504)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:425)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:536)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:102)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: INTERNAL: Connection closed with unknown cause\r\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\r\n\t... 15 more\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2483",
        "number": 2483,
        "title": "Error: Jetty ALPN/NPN has not been properly configured.",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "Related to #2266 - but is not resolved by anything in there either.\r\n\r\nStack trace\r\n\r\n```\r\ncom.google.cloud.logging.LoggingException: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly\r\nconfigured.\r\n1419         at com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:66)\r\n1420         at com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:58)\r\n1421         at com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:472)\r\n1422         at com.google.cloud.logging.LoggingOptions.getLoggingRpcV2(LoggingOptions.java:134)\r\n1423         at com.google.cloud.logging.LoggingImpl.<init>(LoggingImpl.java:108)\r\n1424         at com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:46)\r\n1425         at com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:41)\r\n1426         at com.google.cloud.ServiceOptions.getService(ServiceOptions.java:459)\r\n1427         at com.myproject.framework.logger.StackdriverAppender.<init>(StackdriverAppender.java:49)\r\n1428         at com.myproject.framework.utils.LoggerControl.addStackdriverAppender(LoggerControl.java:131)\r\n1429         at com.myproject.framework.config.CoreInitializer.initialize(CoreInitializer.java:510)\r\n1430         at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:635)\r\n1431         at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:349)\r\n1432         at org.springframework.boot.SpringApplication.run(SpringApplication.java:313)\r\n1433         at com.myproject.framework.configserver.StartConfigServer.main(StartConfigServer.java:45)\r\n1434         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n1435         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n1436         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n1437         at java.lang.reflect.Method.invoke(Method.java:498)\r\n1438         at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48)\r\n1439         at org.springframework.boot.loader.Launcher.launch(Launcher.java:87)\r\n1440         at org.springframework.boot.loader.Launcher.launch(Launcher.java:50)\r\n1441         at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51)\r\n1442 Caused by: java.io.IOException: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly\r\nconfigured.\r\n1443         at com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:141)\r\n1444         at com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:64)\r\n1445         ... 22 common frames omitted\r\n1446 Caused by: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n1447         at io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:159)\r\n1448         at io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:136)\r\n1449         at io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:124)\r\n1450         at io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:94)\r\n1451         at\r\nio.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(NettyChannelBuilder.java:525)\r\n1452         at\r\nio.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DefaultNettyTransportCreationParamsFilterFactory.<init>(NettyChannelBuilder.java:518)\r\n1453         at io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:457)\r\n1454         at io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:326)\r\n1455         at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:315)\r\n1456         at\r\ncom.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:131)\r\n1457         at com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:116)\r\n1458         at com.google.api.gax.grpc.GrpcTransportProvider.getTransport(GrpcTransportProvider.java:98)\r\n1459         at com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:112)\r\n1460         ... 23 common frames omitted\r\n\r\n```\r\n\r\ncompatibility tool output.\r\n\r\n\r\n```\r\nOS details:\r\n  os.detected.name: linux\r\n  os.detected.arch: x86_64\r\n  os.detected.classifier: linux-x86_64\r\n  os.detected.release: ubuntu\r\n  os.detected.release.version: 17.04\r\nJVM details:\r\n  Java version: 1.8.0_131\r\n  Java specification version: 1.8\r\n  JVM bit mode: 64\r\nOpenSSL details:\r\n  open ssl is available: true\r\n  ALPN is supported: true\r\nChecking compatibility...\r\n  [PASS] This OS + architecture is supported.\r\n  [PASS] 64-bit JVM is supported.\r\n  [PASS] Open SSL is available\r\n  [PASS] Open SSL ALPN is supported\r\nResult: UNKNOWN (checker implementation not complete)\r\n  Based on what was checked, nothing was identified that would\r\n  prevent you from using grpc-based APIs.\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 2.933 s\r\n[INFO] Finished at: 2017-09-27T18:21:20+00:00\r\n[INFO] Final Memory: 17M/470M\r\n[INFO] ------------------------------------------------------------------------\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2482",
        "number": 2482,
        "title": "Getting labels of Datasets (BigQuery) using the getLabels() in DatasetInfo",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "I tried retrieving the labels I set on a Dataset through the UI and gcloud API using the getLabels() method in this class: https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/DatasetInfo.java. I always a null value. I tried filtering on the same labels using the gcloud API and that works. Could you please look into the issue. Thanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2481",
        "number": 2481,
        "title": "Datastore - Too many external HttpURLConnection[datastore.googleapis.com] calls",
        "labels": [
            "api: datastore",
            "performance"
        ],
        "state": "closed",
        "body": "I have a java API on **GAE** using the **google-cloud-datastore** client as presented in the documentation. Measuring with newrelic why some requests were taking so long I found out that a single \"get by key\" makes 6 url connections to **datastore.googleapis.com** is this correct?\r\n\r\n_the code is as simple as the examples:_\r\n\r\n`private final Datastore datastore = DatastoreOptions.getDefaultInstance().getService();`\r\n...\r\n`datastore.get(datastore.newKeyFactory().setKind(\"kind\").setNamespace(\"namespace\")\r\n                .addAncestor(PathElement.of((\"parent\"), parentId))\r\n                .newKey(key));`\r\n\r\n_heres the evidence:_\r\n<img width=\"750\" alt=\"captura de tela 2017-10-04 as 12 56 20\" src=\"https://user-images.githubusercontent.com/24440172/31189873-d4e56bec-a90f-11e7-9c1f-a09636c9bad9.png\">\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2480",
        "number": 2480,
        "title": "Pub/Sub : Subscriber Exceptions",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Using version `0.20.1-beta` of the google-cloud-pubsub lib.\r\n\r\nWe use `com.google.cloud.pubsub.v1.Subscriber` objects that live for a long time (multiple hours / days). Our logs are filled with the same errors that occur over and over : \r\n\r\n```\r\n \r\nat java.lang.Thread.run(Thread.java:748)\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\nat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:117)\r\nat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:544)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:429)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:512)\r\nat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\nat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)\r\nat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:442)\r\nat io.grpc.Status.asRuntimeException(Status.java:543)\r\n \r\nmax_age\r\nReceived Goaway\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: HTTP/2 error code: NO_ERROR\r\nWARNING: Failed to pull messages (recoverable): \r\nOct 04, 2017 2:36:02 PM com.google.cloud.pubsub.v1.PollingSubscriberConnection$1 onFailure\r\n```\r\n\r\nFrom what I can tell, this is fine. The errors are recoverable and we do get all the messages. The problem really is that it fills up our logs and triggers a bunch of alerts and we can't seem to catch the exceptions ourselves to lower the logging level. The format is weird too, we use StackDriver and in this case, it seems like every single line becomes its own log entry (all at the error level) : \r\n\r\n![screen shot 2017-10-04 at 11 12 37 am](https://user-images.githubusercontent.com/1261812/31183575-fb91bac2-a8f4-11e7-8526-d29741898a2b.png)\r\n\r\nHow can we keep the library from logging so many messages are the error level ? Any way to catch the exceptions ourselves and / or change the logging level ?\r\n\r\nOur subscribers are created this way (if it makes a difference) : \r\n\r\n```java\r\nSubscriptionName subscription = SubscriptionName.create(Configurations.getGoogleCloudProjectId(), getSubscriptionName());\r\n\r\nMessageReceiver receiver = (message, consumer) -> {\r\n    try {\r\n        // ... handle message\r\n        consumer.ack();\r\n    }\r\n    catch(Exception ex) {\r\n        // Not the one getting logged\r\n        logger.error(new LogEntry().setMessage(\"An unhandled exception occured in the pubsub receiver. Message will be acked and dropped. \" + Helper.getStackTrace(ex)));\r\n        consumer.ack();\r\n    }\r\n};\r\n\r\nExecutorProvider executorProvider = InstantiatingExecutorProvider.newBuilder()\r\n        .setExecutorThreadCount(4)\r\n        .build();\r\n\r\nsubscriber = Subscriber.defaultBuilder(subscription, receiver)\r\n        .setExecutorProvider(executorProvider)\r\n        .setCredentialsProvider(FixedCredentialsProvider.create(\r\n                ServiceAccountCredentials.fromStream(new FileInputStream(Configurations.getGoogleCloudCredentials())))\r\n        )\r\n        .build();\r\n\r\n// PubsubListener extends Subscriber.Listener and doesn't do much besides logging \r\n// but the logs we see in stack driver aren't coming from our implementation there either\r\nsubscriber.addListener(new PubsubListener(), MoreExecutors.directExecutor());\r\n\r\nsubscriber.startAsync();\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2479",
        "number": 2479,
        "title": "google-cloud-bigquery 0.25.0-beta BigQueryClient throws java.lang.NullPointerException: Required parameter jobId must be specified. When performing dry run query. ",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "google-cloud-bigquery 0.25.0-beta\r\n\r\nBigQuery bigQuery = BigQueryOptions.getDefaultInstance.getService\r\nQueryRequest request = QueryRequest.newBuilder(sql).setDryRun(true).setUseLegacySql(false).build()\r\nbigQuery.query(request)\r\n\r\nThrows  java.lang.NullPointerException: Required parameter jobId must be specified.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2477",
        "number": 2477,
        "title": "Java client BigQuery.getTable returns a table with null schema when the table has no field",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "To reproduce,\r\n1. Create an empty BigQuery table without any field on its schema. Let's say it's table \"tableA\" on dataset \"dataset1\".\r\n2. Running this code fails the assertion.\r\n```\r\n    BigQuery bigQuery = BigQueryOptions.getDefaultInstance().getService();\r\n    Table table = bigQuery.getTable(\"dataset1\", \"tableA\");\r\n    Assert.assertNotNull(table.getDefinition().getSchema());\r\n```\r\n\r\nIs this expected behavior? Because we in fact can't create a TableDefinition with null schema as it's null-checked in `com.google.cloud.bigquery.TableDefinition.Builder`.\r\n```\r\n    /**\r\n     * Sets the table schema.\r\n     */\r\n    public B setSchema(Schema schema) {\r\n      this.schema = checkNotNull(schema);\r\n      return self();\r\n    }\r\n```\r\nI think `BigQuery.getTable` on a table with empty schema should return a Schema instance with no field within its TableDefinition."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2476",
        "number": 2476,
        "title": "Organize packages better in `google-cloud-java` reference docs",
        "labels": [],
        "state": "closed",
        "body": "https://googlecloudplatform.github.io/google-cloud-java/0.25.0/apidocs/index.html\r\n\r\n: it is confusing to the `.spi`,` .stub` , hand-written layer / auto-gen layer all listed together eg for `firestore`. The top category should only list the packages that the user is expected to use.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2475",
        "number": 2475,
        "title": "Docs site has strange text wrapping",
        "labels": [],
        "state": "closed",
        "body": "<img width=\"1433\" alt=\"google-cloud-java\" src=\"https://user-images.githubusercontent.com/8466666/31109779-0e5cd96e-a7b7-11e7-9f73-979a318f4f3b.png\">\r\n\r\nThat's on my 13\" Macbook Pro.  From playing with Chrome Dev Tools it happens when the width crosses 960px.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2472",
        "number": 2472,
        "title": "Add more convenient methods to com.google.cloud.Timestamp",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`com.google.cloud.Timestamp` exposes some convenient method to convert a common Java type to protobuffer timestamp. But it doesn't the same convenient methods to convert a proto timestamp back to the common Java type.\r\n\r\nTimestamp can take in `java.util.Date`, `java.sql.Timestamp`, and `long` in microseconds.  It should also take in `long` for typical timestamp in milliseconds.\r\n\r\nYou can convert Timestamp to other types w/ `toSqlTimestamp`, but we should also have common types like `toDate` (`java.util.Date`), and `toTime` (`long` for milliseconds)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2468",
        "number": 2468,
        "title": "Getting labels from InstanceInfo class",
        "labels": [
            "api: compute",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Like MetaData, Tags and other information about the instance is available through [InstanceInfo.java] (https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-compute/src/main/java/com/google/cloud/compute/InstanceInfo.java) would it be possible to get Labels of an instance from this class. I don't see a direct method that I could use. Also, if this method is left out intentionally what's reason? Thanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2467",
        "number": 2467,
        "title": "Ability to set custom headers for outbond calls",
        "labels": [
            "api: core",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Some users can only make callout to external services via a proxy that may require authentication headers. Need a way (and doc) to set headers for outbound calls for REST and gRPC services."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2465",
        "number": 2465,
        "title": "Pub/Sub streamingPull subscriber: large number of duplicate messages, modifyAckDeadline calls observed",
        "labels": [
            ":rotating_light:",
            "api: pubsub",
            "priority: p2",
            "status: blocked",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "Large number of duplicate messages is observed with Pub/Sub streamingPull client library using code that pulls from a Pub/Sub subscription and inserts messages into BigQuery with a synchronous blocking operation, with flowControl set to max 500 outstanding messages.  See [1] for code. \r\n\r\nFor the same code, we also observe an excessive number of modifyAckDeadline operations (>> streamingPull message operations).  And tracing a single message, we see modifyAcks and Acks in alternating order for the same message (modAck, modAck, Ack, modAck, Ack) [2]. This suggest that the implementation might fail to remove Ack'ed messages from a queue of messages to process and keep re-processing messages already on the client.  This also suggests that ack requests may not actually be sent.  \r\n\r\n[2] https://docs.google.com/spreadsheets/d/1mqtxxm0guZcOcRy8ORG0ri787XLQZNF_FLBujAiayFI/edit?ts=59cac0f0#gid=2139642597\r\n\r\n[1] <pre> \r\npackage kir.pubsub;\r\n\r\nimport com.google.api.gax.batching.FlowControlSettings;\r\nimport com.google.cloud.bigquery.*;\r\nimport com.google.cloud.pubsub.v1.Subscriber;\r\nimport com.google.pubsub.v1.PubsubMessage;\r\nimport com.google.pubsub.v1.SubscriptionName;\r\nimport com.google.cloud.pubsub.v1.MessageReceiver;\r\nimport com.google.cloud.pubsub.v1.AckReplyConsumer;\r\n\r\nimport java.text.DateFormat;\r\nimport java.text.SimpleDateFormat;\r\nimport java.util.*;\r\nimport java.util.concurrent.atomic.AtomicInteger;\r\n\r\n\r\npublic class Sub {\r\n\r\n    // Instantiate an asynchronous message receiver\r\n\r\n    public static void main(String... args) throws Exception {\r\n        final String projectId = args[0];\r\n        final String subscriptionId = args[1];\r\n\r\n        final BigQuery bq = BigQueryOptions.getDefaultInstance().getService();\r\n        final String datasetName = \"pubsub_debug\";\r\n        final String tableName = \"gke_subscriber\";\r\n        final AtomicInteger messageCount = new AtomicInteger(0);\r\n        final DateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\");\r\n        MessageReceiver receiver = new MessageReceiver() {\r\n                    public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n                        // handle incoming message, then ack/nack the received message\r\n                        System.out.printf(\"%s,\\t%s,\\t%d\\n\",message.getData().toStringUtf8()\r\n                                , message.getMessageId()\r\n                                , messageCount.incrementAndGet());\r\n                        Map<String,Object> row = new HashMap<String,Object>();\r\n                        long timestampMs = message.getPublishTime().getSeconds()*1000 + message.getPublishTime().getNanos() / 1000000;\r\n                        Date timestampDate = new Date(timestampMs);\r\n\r\n                        row.put(\"messageId\", message.getMessageId());\r\n                        row.put(\"messageData\", message.getData().toStringUtf8());\r\n                        row.put(\"messagePublishTime\", dateFormat.format(timestampDate));\r\n                        // a version of this code without the bq.insert was ran, where consumer.ack() \r\n                        // was called immediately. The results were the same.\r\n                        InsertAllResponse response = bq.insertAll(\r\n                                    InsertAllRequest.newBuilder(TableId.of(projectId, datasetName, tableName)).addRow(row).build()\r\n                        );\r\n                        if (response.hasErrors()) {\r\n                            System.err.println(\"Error inserting into BigQuery \" + response.toString() );\r\n                            consumer.nack();\r\n                        } else{\r\n                            consumer.ack();\r\n                        }\r\n                    }\r\n\r\n                };\r\n\r\n        SubscriptionName subscriptionName = SubscriptionName.create(projectId, subscriptionId);\r\n        Subscriber subscriber = Subscriber.defaultBuilder(subscriptionName, receiver).setFlowControlSettings(\r\n                FlowControlSettings.newBuilder().setMaxOutstandingElementCount(1000L).build()\r\n        ).build();\r\n        subscriber.startAsync();\r\n        subscriber.awaitRunning();\r\n        System.out.println(\"Started async subscriber.\");\r\n        subscriber.awaitTerminated();\r\n    }\r\n}\r\n</pre>\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2463",
        "number": 2463,
        "title": "DatastoreException - Error Code/Reason are inconsistent when working with Emulator",
        "labels": [
            "api: datastore",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Since #2442 is closed, creating a new one. I've provided additional info/sample code to reproduce the discrepancy in #2442. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2462",
        "number": 2462,
        "title": "Storage service should manage resumeable signedURL uploads",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "google-cloud-java currently allows users to mint a signedURL but offers not way to separately manage the resumable upload given _just_ the signedURL.\r\n\r\nThe usecase for this is if i have in possession a signedURL that allows for resumeable uploads, i'd like to use google-cloud-java to manage the transfer for me. \r\n\r\nsome background:\r\n\r\n - a resumable transfer session requires a special header to get it going (```x-goog-resumable: start```) as described [here](https://cloud.google.com/storage/docs/xml-api/resumable-upload#step_1wzxhzdk14initiate_the_resumable_upload).   At the moment, our java libraries do not support baking in the canonical headers into the signedURL.  see [issue#2000](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2000)\r\n          \r\n- Even if we do support a signeURL that allows for the transfer initiation, i didn't see anyplace within the library which will manage that transfer for you (i.,e handle retries, partial transfers, etc) given just a signedURL.  It does appear that resumeable uploads are [supported](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/Bucket.java#L834)  but that appears to be about authenticated uploads (not signedURL)\r\n\r\nmy 2c on how this may look\r\n\r\ncreate a signedURL somewhere else and provide a header to allow the uploads \r\n\r\n```java\r\n         Storage storage_service = StorageOptions.newBuilder()\r\n        .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(\"svc_acct.json\")))\r\n        .build()\r\n        .getService();          \r\n        \r\n        BlobId blobId = BlobId.of(bucketName, objectName);\r\n        BlobInfo blobInfo = BlobInfo.newBuilder(blobId).setContentType(content_type).build();\r\n    \r\n        SignUrlOption opts = SignUrlOption.withContentType()  // (+new way to add headers:(\"x-goog-resumable:start\")       \r\n        URL signedUrl = storage_service.signUrl(blobInfo, 60,  TimeUnit.SECONDS, opts);\r\n\r\n```\r\n\r\nthen on the client, google-cloud-java would upload an object without needed authentication...and manage the retry on resume.\r\n\r\n```java\r\n        Storage storage_service_no_creds = StorageOptions.newBuilder()\r\n        .setCredentials(NoCredentials.getInstance())\r\n        .build()\r\n        .getService();         \r\n       \r\n        storage_service_no_creds.create(blobInfo, \"filecontent\".getBytes(UTF_8), signedUrl);      \r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2454",
        "number": 2454,
        "title": "Is there a repository for 'appengine-api-1.0-sdk'?",
        "labels": [],
        "state": "closed",
        "body": "This [Use Google Cloud Java Client with Google App Engine](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/APPENGINE.md) suggests that we should use `appengine-api-1.0-sdk` for Java 7 GAE standard environments.\r\n\r\nIs there a repository for this `appengine-api-1.0-sdk` somewhere? Or is there something like release notes for each version? The closest thing I can find is this: https://cloud.google.com/appengine/docs/standard/java/release-notes but it seems it only says something like \"Updated Java SDK to version 1.9.xx\" and no other information is provided."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2453",
        "number": 2453,
        "title": "Authentication error after upgrading to 0.23.1",
        "labels": [
            ":rotating_light:",
            "api: storage",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "We've started seeing an authentication error in our project after we upgraded to 0.23.1, the issue also seems to be present in 0.24.0.  Reverting to 0.22.0 solves the issue.  \r\n\r\nWe start seeing the following 404 error when running a spark application that uses NIO to access gcs files:\r\n\r\n```\r\ncode:      0\r\nmessage:   Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.\r\nreason:    null\r\nlocation:  null\r\nretryable: false\r\ncom.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339)\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197)\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194)\r\n\tat shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614)\r\n\tat java.nio.file.Files.exists(Files.java:2385)\r\n\tat htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346)\r\n\tat org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206)\r\n\tat org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162)\r\n\tat org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118)\r\n\tat org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87)\r\n\tat org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182)\r\n\tat org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:390)\r\n\tat org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:370)\r\n\tat org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:360)\r\n\tat org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38)\r\n\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119)\r\n\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176)\r\n\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195)\r\n\tat org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131)\r\n\tat org.broadinstitute.hellbender.Main.mainEntry(Main.java:152)\r\n\tat org.broadinstitute.hellbender.Main.main(Main.java:233)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736)\r\n\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)\r\n\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.\r\n\tat shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137)\r\n\tat shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160)\r\n\tat shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146)\r\n\tat shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96)\r\n\tat com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157)\r\n\tat shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:337)\r\n\t... 32 more\r\nERROR: (gcloud.dataproc.jobs.submit.spark) Job [cb87810a-0133-42b3-a954-363b62adce39] entered state [ERROR] while waiting for [DONE].\r\n```\r\n\r\nLooking at the dependency updates in this project, it seems like one of the auth libraries updated to version 0.8.0.  Could that be the causing the issue? \r\n\r\nIs there some new configuration setting we should be using in our gcloud project?  Any help would be appreciated.  "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2452",
        "number": 2452,
        "title": "Setting the Flow Control MaxOutstandingElementCount cause stuck messages",
        "labels": [],
        "state": "closed",
        "body": "The behaviour was observed in the 0.21.1-beta version of the Java client library\r\nIt seems resolved in the 0.23.1-beta version, however this newer version implements the bi-directional streaming pull and the previous doesn't.\r\n\r\n**Test Setup:**\r\n- 100k messages published to a Topic\r\n- Single Subscription\r\n- _n_ Subscribers (k8s running on GKE, each pod running in separate node) {_n_ \u2208 Z |  1 \u2264 _n_ \u2264 4}\r\n- Each node had 2 vCPU and each Subscriber provided 10 user threads to the client library\r\n- All Subscribers running the same code (Parse message, build various classes, callback processing takes ~20ms)\r\n- Flow control settings: MaxOutstandingElementCount: 1000\r\n**Results:**\r\n- _n_ Messages remain stuck on Topic _n_  \u2208 [223, 6652]\r\n**Observations:**\r\n- When messages are stuck: mod_ack_deadline_request_count  > 0, Pull request count > 0\r\n- When messages are stuck Subscriber callback threads are Waiting\r\n- No stuck messages when retesting with default Flow Control Settings (i.e. MaxOutstandingElementCount = null)\r\n- Experiments with MaxOutstandingElementCount \u2208 [1000, 500, 250, 125] resulted in stuck message count \u2208 [~6K, ~3K, ~1.7K, ~6K]\r\n\r\n**Interpretation:**\r\nMessage ACK deadlines are being continuously extended and the callback threads are not being invoked\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2451",
        "number": 2451,
        "title": "Fix external class links in Reference docs",
        "labels": [],
        "state": "closed",
        "body": "http://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/com/google/cloud/language/v1/LanguageServiceSettings.html\r\n\r\ndoes not link correctly to classes like `com.google.cloud.language.v1.AnalyzeEntitySentimentRequest`\r\n`com.google.cloud.language.v1.AnalyzeEntitySentimentResponse`\r\nin the Java docs.\r\n\r\nI thought we had fixed this the last time ?\r\n\r\nFYI @nnegrey"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2444",
        "number": 2444,
        "title": "Add BigQuery API for labelling datasets and tables ",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The BigQuery interface currently lacks support for adding labels to datasets and tables:\r\nhttps://cloud.google.com/bigquery/docs/labels#bigquery-dataset-set-label-java"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2443",
        "number": 2443,
        "title": "Allow setting ApplicationName/user-agent ",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "[ServiceOptions](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L75) seems to use a static ApplicationName which gets baked into the user-agent string on the request.\r\n\r\nat the moment its\r\n\r\n```\r\n'User-Agent: gcloud-java/0.8.0 Google-API-Java-Client Google-HTTP-Java-Client/1.21.0 (gzip)'\r\n```\r\n\r\nFR to allow a user to set it ...the useragent string make it all the way into the audit logs:\r\n\r\n\r\neg.\r\n```java\r\n        Storage  storage_service = StorageOptions.defaultInstance().service();\r\n        String bucketName = \"my_unique_bucket\"; \r\n        Bucket bucket = storage_service.create(BucketInfo.of(bucketName));\r\n```\r\ngives\r\n\r\n```\r\nlogName: \"projects/your_project/logs/cloudaudit.googleapis.com%2Factivity\"  \r\n\r\nrequestMetadata: {\r\n   callerIp: \"x.x.x.x\"    \r\n   callerSuppliedUserAgent: \"gcloud-java/0.8.0 Google-API-Java-Client Google-HTTP-Java-Client/1.21.0 (gzip),gzip(gfe)\"    \r\n  }\r\n  resourceName: \"projects/_/buckets/my_unique_bucket\"   \r\n```\r\n\r\ncustomers can filter their audit logs on useragent strings, if they set it on the client\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2442",
        "number": 2442,
        "title": "DatastoreException - Error Code/Reason are inconsistent when working with Emulator ",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm trying to implement https://github.com/sai-pullabhotla/catatumbo/issues/172 to throw specialized exceptions in certain cases, more specifically, for `NOT_FOUND` and `ALREADY_EXISTS` errors. \r\n\r\nAs per this [page ](https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto)- \r\n\r\n```\r\nNOT_FOUND = 5 \r\nALREADY_EXISTS = 6 \r\n\r\n```\r\nThis works well and get the expected codes when working with the **real/live GCD**, but when using the **Datastore Emulator**, both test cases result in a code of `INVALID_ARGUMENT = 3`\r\n\r\nFYI - Just did an update on gcloud/emulator and the issue remains. The gcloud versions are - \r\n\r\n```\r\nGoogle Cloud SDK 171.0.0\r\nbeta 2017.03.24\r\nbq 2.0.25\r\ncloud-datastore-emulator 1.2.1\r\ncore 2017.09.11\r\ngcloud\r\ngsutil 4.27\r\n\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2441",
        "number": 2441,
        "title": "Cloud Pub/Sub Client Error when publishing data",
        "labels": [
            "android",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "0down votefavorite | I have followed following example that described Cloud PubSub (gRPC) with Android.https://github.com/rafaelsf80/cloud-pubsub-grpc-android. It works fine alone. But when I add the same code and dependencies to my existing project got following error.\r\n-- | --\r\n\r\n\r\n```\r\n09-15 11:36:14.812 31956-32764/com.example.stl.sciocardioapp E/art: Verification failed on class com.google.pubsub.v1.PubsubMessage$Builder in /data/data/com.example.stl.sciocardioapp/files/instant-run/dex/slice-grpc-pubsub-v1-0.0.2_df54ceb8a9a1043c6f69c84936a145dd371840e5-classes.dex because: Verifier rejected class com.google.pubsub.v1.PubsubMessage$Builder due to bad method com.google.pubsub.v1.PubsubMessage$Builder com.google.pubsub.v1.PubsubMessage$Builder.setPublishTime(com.google.protobuf.Timestamp)\r\n09-15 11:36:14.812 31956-32764/com.example.stl.sciocardioapp E/ACRA: ACRA caught a RuntimeException for com.example.stl.sciocardioapp\r\njava.lang.RuntimeException: An error occured while executing doInBackground()\r\n    at android.os.AsyncTask$3.done(AsyncTask.java:304)\r\n    at java.util.concurrent.FutureTask.finishCompletion(FutureTask.java:355)\r\n    at java.util.concurrent.FutureTask.setException(FutureTask.java:222)\r\n    at java.util.concurrent.FutureTask.run(FutureTask.java:242)\r\n    at android.os.AsyncTask$SerialExecutor$1.run(AsyncTask.java:231)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1115)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:590)\r\n    at java.lang.Thread.run(Thread.java:818)\r\n Caused by: java.lang.VerifyError: Verifier rejected class com.google.pubsub.v1.PubsubMessage$Builder due to bad method com.google.pubsub.v1.PubsubMessage$Builder com.google.pubsub.v1.PubsubMessage$Builder.setPublishTime(com.google.protobuf.Timestamp) (declaration of 'com.google.pubsub.v1.PubsubMessage$Builder' appears in /data/data/com.example.stl.sciocardioapp/files/instant-run/dex/slice-grpc-pubsub-v1-0.0.2_df54ceb8a9a1043c6f69c84936a145dd371840e5-classes.dex)\r\n    at com.google.pubsub.v1.PubsubMessage.toBuilder(PubsubMessage.java:382)\r\n    at com.google.pubsub.v1.PubsubMessage.newBuilder(PubsubMessage.java:376)\r\n    at com.stl.gcommunicator.PublishMessageTask.execute(PublishMessageTask.java:122)\r\n    at serverconnection.DataUploadingService$Upload.doInBackground(DataUploadingService.java:183)\r\n    at serverconnection.DataUploadingService$Upload.doInBackground(DataUploadingService.java:154)\r\n    at android.os.AsyncTask$2.call(AsyncTask.java:292)\r\n    at java.util.concurrent.FutureTask.run(FutureTask.java:237)\r\n    at android.os.AsyncTask$SerialExecutor$1.run(AsyncTask.java:231) \r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1115) \r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\r\n```\r\nCan someone help me to overcome with this problem"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2440",
        "number": 2440,
        "title": "Datastore - Datastore object creation fails with version 1.5.1",
        "labels": [
            "priority: p2",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm trying to upgrade from version 1.2.3 of the Datastore API to the latest version, 1.5.1. The below sample code fails creating the Datastore object/service. \r\n\r\n```\r\nDatastore datastore = DatastoreOptions.newBuilder().build().getService();\r\n```\r\n\r\nTests are running on my laptop with gcloud installed. Version 1.2.3 works fine by fetching the defaults (e.g. project/credentials) from Google Cloud SDK. Version 1.5.1 is producing the below exception: \r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalArgumentException: java.net.URISyntaxException: Illegal character in path at index 45: https://datastore.googleapis.com/v1/projects/<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html><head><meta http-equiv=\"refresh\" content=\"0;url=http://finder.cox.net/main?ParticipantID=96e687opkbv4scrood8k84drs6gw5duf&FailedURI=http%3A%2F%2Fmetadata.google.internal%2FcomputeMetadata%2Fv1%2Fproject%2Fproject-id&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\"/><script type=\"text/javascript\">url=\"http://finder.cox.net/main?ParticipantID=96e687opkbv4scrood8k84drs6gw5duf&FailedURI=http%3A%2F%2Fmetadata.google.internal%2FcomputeMetadata%2Fv1%2Fproject%2Fproject-id&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\";if(top.location!=location){var w=window,d=document,e=d.documentElement,b=d.body,x=w.innerWidth||e.clientWidth||b.clientWidth,y=w.innerHeight||e.clientHeight||b.clientHeight;url+=\"&w=\"+x+\"&h=\"+y;}window.location.replace(url);</script></head><body></body></html>\r\n\tat com.google.datastore.v1.client.DatastoreFactory.validateUrl(DatastoreFactory.java:118)\r\n\tat com.google.datastore.v1.client.DatastoreFactory.buildProjectEndpoint(DatastoreFactory.java:104)\r\n\tat com.google.datastore.v1.client.DatastoreFactory.newRemoteRpc(DatastoreFactory.java:111)\r\n\tat com.google.datastore.v1.client.DatastoreFactory.create(DatastoreFactory.java:65)\r\n\tat com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.<init>(HttpDatastoreRpc.java:71)\r\n\tat com.google.cloud.datastore.DatastoreOptions$DefaultDatastoreRpcFactory.create(DatastoreOptions.java:61)\r\n\tat com.google.cloud.datastore.DatastoreOptions$DefaultDatastoreRpcFactory.create(DatastoreOptions.java:55)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:472)\r\n\tat com.google.cloud.datastore.DatastoreOptions.getDatastoreRpcV1(DatastoreOptions.java:179)\r\n\tat com.google.cloud.datastore.DatastoreImpl.<init>(DatastoreImpl.java:55)\r\n\tat com.google.cloud.datastore.DatastoreOptions$DefaultDatastoreFactory.create(DatastoreOptions.java:51)\r\n\tat com.google.cloud.datastore.DatastoreOptions$DefaultDatastoreFactory.create(DatastoreOptions.java:45)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:459)\r\n\tat com.jmethods.catatumbo.DatastoreTest.main(DatastoreTest.java:29)\r\nCaused by: java.net.URISyntaxException: Illegal character in path at index 45: https://datastore.googleapis.com/v1/projects/<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html><head><meta http-equiv=\"refresh\" content=\"0;url=http://finder.cox.net/main?ParticipantID=96e687opkbv4scrood8k84drs6gw5duf&FailedURI=http%3A%2F%2Fmetadata.google.internal%2FcomputeMetadata%2Fv1%2Fproject%2Fproject-id&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\"/><script type=\"text/javascript\">url=\"http://finder.cox.net/main?ParticipantID=96e687opkbv4scrood8k84drs6gw5duf&FailedURI=http%3A%2F%2Fmetadata.google.internal%2FcomputeMetadata%2Fv1%2Fproject%2Fproject-id&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\";if(top.location!=location){var w=window,d=document,e=d.documentElement,b=d.body,x=w.innerWidth||e.clientWidth||b.clientWidth,y=w.innerHeight||e.clientHeight||b.clientHeight;url+=\"&w=\"+x+\"&h=\"+y;}window.location.replace(url);</script></head><body></body></html>\r\n\tat java.net.URI$Parser.fail(URI.java:2848)\r\n\tat java.net.URI$Parser.checkChars(URI.java:3021)\r\n\tat java.net.URI$Parser.parseHierarchical(URI.java:3105)\r\n\tat java.net.URI$Parser.parse(URI.java:3053)\r\n\tat java.net.URI.<init>(URI.java:588)\r\n\tat com.google.datastore.v1.client.DatastoreFactory.validateUrl(DatastoreFactory.java:116)\r\n\t... 13 more\r\n\r\n\r\n```\r\nI have traced it down to `ServiceOptions.getAppEngineProjectId` method where it tries to get the project ID from Metadata Server. Apparently, the http request executed by that method returns some string, and that string is assumed to be project ID. In my case, the default project ID is coming up as - \r\n\r\n```\r\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"><html><head><meta http-equiv=\"refresh\" content=\"0;url=http://finder.cox.net/main?ParticipantID=96e687opkbv4scrood8k84drs6gw5duf&FailedURI=http%3A%2F%2Fmetadata.google.internal%2FcomputeMetadata%2Fv1%2Fproject%2Fproject-id&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\"/><script type=\"text/javascript\">url=\"http://finder.cox.net/main?ParticipantID=96e687opkbv4scrood8k84drs6gw5duf&FailedURI=http%3A%2F%2Fmetadata.google.internal%2FcomputeMetadata%2Fv1%2Fproject%2Fproject-id&FailureMode=1&Implementation=&AddInType=4&Version=pywr1.0&ClientLocation=us\";if(top.location!=location){var w=window,d=document,e=d.documentElement,b=d.body,x=w.innerWidth||e.clientWidth||b.clientWidth,y=w.innerHeight||e.clientHeight||b.clientHeight;url+=\"&w=\"+x+\"&h=\"+y;}window.location.replace(url);</script></head><body></body></html>\r\n\r\n```\r\n\r\nLooks like this is an error from my Internet Service provider connecting to http://metadata.google.internal \r\n\r\nI do not have any environment variables such as `GOOGLE_*` set, and solely relying on the environment set up by the gcloud tool. Why is code running on my laptop trying to find the AppEngine project ID from the metadata server? Is anyone else experiencing this? \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2439",
        "number": 2439,
        "title": "[Storage] Add Requester Pays support to Blob.downloadTo.",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Issue:\r\n`Blob.downloadTo` doesn't support requester pays buckets as a blob source.\r\n\r\nNoted solution in [PR#2393](https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2393):\r\n\r\nAdd parameter `BlobSourceOption` to `Blob.downloadTo` to support Requester Pays when downloading a Blob to a local file. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2438",
        "number": 2438,
        "title": "Logging CI failing due to too many sinks",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "See e.g. this build: https://travis-ci.org/GoogleCloudPlatform/google-cloud-java/builds/275116102?utm_source=email&utm_medium=notification"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2433",
        "number": 2433,
        "title": "\"High performance\" is incorrect.",
        "labels": [
            "priority: p2"
        ],
        "state": "closed",
        "body": "The Javadoc for the compute API says: \"A client for Google Compute Engine \u2013 High-performance, scalable virtual machines.\"\r\n\r\n\"High performance\" is incorrect. The point of scalable here is that you may choose low performance VMs for less cost if that suits your needs better. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2432",
        "number": 2432,
        "title": "Logging Structs should prefer map over iterable when serializing",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The [current serialization code](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-logging/src/main/java/com/google/cloud/logging/Structs.java#L142) looks like this at time of writing:\r\n\r\n```java\r\n  private static Value objectToValue(final Object obj) {\r\n    Value.Builder builder = Value.newBuilder();\r\n    if (obj == null) {\r\n      builder.setNullValue(NullValue.NULL_VALUE);\r\n      return builder.build();\r\n    }\r\n    Class<?> objClass = obj.getClass();\r\n    if (obj instanceof String) {\r\n      builder.setStringValue((String) obj);\r\n    } else if (obj instanceof Number) {\r\n      builder.setNumberValue(((Number) obj).doubleValue());\r\n    } else if (obj instanceof Boolean) {\r\n      builder.setBoolValue((Boolean) obj);\r\n    } else if (obj instanceof Iterable<?> || objClass.isArray()) {\r\n      builder.setListValue(ListValue.newBuilder()\r\n          .addAllValues(Iterables.transform(Types.iterableOf(obj), OBJECT_TO_VALUE)));\r\n    } else if (objClass.isEnum()) {\r\n      builder.setStringValue(((Enum<?>) obj).name());\r\n    } else if (obj instanceof Map) {\r\n      Map<String, Object> map = (Map<String, Object>) obj;\r\n      builder.setStructValue(newStruct(map));\r\n    } else {\r\n      throw new IllegalArgumentException(String.format(\"Unsupported protobuf value %s\", obj));\r\n    }\r\n    return builder.build();\r\n  }\r\n```\r\n\r\nI think it would be better if the check for `instanceof Map` happened before `instanceof Iterable<?>`. It's true that Maps in the stdlib are generally not iterable, but third party ones can be. For example, Clojure's PersistentHashMap and PersistentArrayMap are both Iterable. If something is both a Map and Iterable, Map seems the most desirable behavior. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2428",
        "number": 2428,
        "title": "BigQuery.getQueryResults throws NPE on 404",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "it looks like https://github.com/GoogleCloudPlatform/google-cloud-java/commit/e3a99c2f9314f938bafd9fd5d19a98a43335bd98 changed BigQueryRpc.getQueryResults to return null on 404 without adjusting BigQueryImpl to handle that."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2427",
        "number": 2427,
        "title": "DataSore does not return any result when cursor pointing to entity gets updated but retains its position in list",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm using google datastore to get data of a user:\r\n\r\nThis is what i'm trying to do:\r\n\r\n 1. When data is updated, its `updated_at [indexed]` property gets set to current timestamp.\r\n 2. I query data on `updated_at` in ***ascending order*** and **store cursor** returned for later use.\r\n 3. Now user has updated the last entity (which cursor points currently) and **no other data is added or updated**.\r\n 4. Now i'm expecting that last entity to be returned in next query (using that old cursor) because it was updated and now has a new `updated_at` timestamp.\r\n 5. But that is not the case, i do not see that (my result is empty list) And now i have lost that update completely because query will return all the other object except that last entity that was updated.\r\n\r\n- I'm is doing something wrong or this is the way it is?\r\n- If this is natural behaviour then what is preferred way to get that last entity that was updated?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2426",
        "number": 2426,
        "title": "Publish does not work when credential JSON is provided",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "The following code works fine when deployed to the app engine flexible environment and calls the relevant /push endpoint.\r\n\r\n```\r\nPublisher publisher = null;\r\ntry {\r\n   publisher = Publisher.defaultBuilder(topic).build();\r\n   ByteString data = ByteString.copyFromUtf8(\"my-message\");\r\n   PubsubMessage pubsubMessage = PubsubMessage.newBuilder().setData(data).build();\r\n   ApiFuture<String> messageIdFuture = publisher.publish(pubsubMessage);\r\n } finally {\r\n   if (publisher != null) {\r\n     publisher.shutdown();\r\n  }\r\n}             \r\n```\r\n\r\nHowever, when changed the \"publisher\" instantiation to the following (using the JSON), the publish code executes fine, but the /push endpoint is not called.\r\n\r\n```\r\n    Resource resource = new ClassPathResource(\"xxxx.json\");\r\n    final InputStream inputStream = resource.getInputStream();\r\n    CredentialsProvider credentialsProvider = FixedCredentialsProvider.create(\r\n\t\t    ServiceAccountCredentials.fromStream(inputStream));\r\n\r\n    publisher = Publisher.defaultBuilder(TopicName.create(\"microservice-qa\", \"testtopic1\"))\r\n\t    .setCredentialsProvider(credentialsProvider)\r\n\t    .build();\r\n\r\n```\r\nAny idea on why this is the case?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2425",
        "number": 2425,
        "title": "Spanner - Insert_Or_Update does not work as documented ? ",
        "labels": [
            "api: spanner",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, \r\nI have a use case that requires to update just one column of a table. To do that, i tried to use insert_or_update as documentation says it will update some columns and preserve others' values. But i get an error below, says i am trying to insert new row without not null columns? Why does not it checks row already exist ? \r\n\r\nWhat am i missing here ? Here is my mutation build code too. I get primary keys and map them to mutation as is. First 4 fields are all part of primary key.\r\n\r\n```\r\nMutation.newInsertOrUpdateBuilder(\"orders\")\r\n                   .set(\"appkey\").to(result.getString(\"appkey\"))\r\n                   .set(\"GlobalId\").to(result.getString(\"globalid\"))\r\n                   .set(\"Id\").to(result.getLong(\"id\"))\r\n                   .set(\"TicketId\").to(result.getLong(\"TicketId\"))\r\n                   .set(\"finalprice\").to(result.getDouble(\"price\"))\r\n                   .build();\r\n```\r\n\r\n> public static final Mutation.Op INSERT_OR_UPDATE\r\n> Like INSERT, except that if the row already exists, then its column values are overwritten with the ones provided. Any column values not explicitly written are preserved.\r\n\r\n```\r\nio.grpc.StatusRuntimeException: FAILED_PRECONDITION: A potentially-new row in table Orders does not specify a non-null value for these NOT NULL columns: AccountTransactionTypeId, CalculatePrice, CreatedDateTime, DecreaseInventory, DepartmentId, etc..\r\n\tat io.grpc.Status.asRuntimeException(Status.java:543) ~[grpc-core-1.4.0.jar:1.4.0]\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:442) ~[grpc-stub-1.4.0.jar:1.4.0]\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56) ~[grpc-core-1.4.0.jar:1.4.0]\r\n\tat com.google.cloud.spanner.spi.v1.SpannerErrorInterceptor$1$1.onClose(SpannerErrorInterceptor.java:100) ~[google-cloud-spanner-0.22.0-beta.jar:0.22.0-beta]\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2424",
        "number": 2424,
        "title": "Best Practice for uploading data to BigQuery in Java?",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nI want to upload data to an existing table in BigQuery. Therefore I looked in the docks and found `bigquery.insertAll` which works fine but it takes very long to execute my code. I think it\u00b4s because I upload my data row by row and every row takes about a second. In the docs I read about 10.000 rows per second but I don`t see a way to change my code in a way so that it can do so.\r\n\r\nIs there a smart and especially fast way to upload data in BigQuery. I considered to get my data into Arraylists or Json Objects and upload it in one step but I couldn`t find a way which would do so. \r\n\r\nHere is my Code to check what I did: \r\n```\r\n\tpublic static void uploaddata(String datasetname) throws IOException {\r\n\t\tBigQuery bigquery = BigQueryOptions\r\n\t\t\t\t.getDefaultInstance()\r\n\t\t\t\t.toBuilder()\r\n\t\t\t\t.setProjectId(\"testprojekt-175408\")\r\n\t\t\t\t.build()\r\n\t\t\t\t.getService();\r\n\t\tTableId tableIdor = TableId.of(datasetname, \"review_test\");\r\n\t\tString csvFile = \"C:/Users/Marku/Desktop/testfile2.csv\";\r\n\t\tBufferedReader br = null;\r\n\t\tFileReader myFile = null;\r\n\t\tString line = \"\";\r\n\t\tString cvsSplitBy = \";\";\r\n\t\tString[] beschriftung = null;\r\n\t\tint i = 0;\r\n\t\tMap<String, Object> rowContent = new HashMap<>();\r\n\t\tmyFile = new FileReader(csvFile);\r\n\t\tbr = new BufferedReader(myFile);\r\n\t\t// read CSV file line by line and upload it into BigQuery\r\n\t\twhile ((line = br.readLine()) != null) {\r\n\t\t\t// get the name of the fields from the first row of the CSV File\r\n\t\t\tif (i == 0) {\r\n\t\t\t\tbeschriftung = line.split(cvsSplitBy);\r\n\t\t\t\ti = i + 1;\r\n\t\t\t\tfor (int e = 0; e < beschriftung.length; e++) {\r\n\t\t\t\t\trowContent.put(beschriftung[e], \"init\");\r\n\t\t\t\t}\r\n\t\t\t} else\r\n\t\t\t// Format Data for BigQuery and upload the row\r\n\t\t\t{\r\n\t\t\t\tString[] Zeile = line.split(cvsSplitBy);\r\n\t\t\t\tfor (int e = 0; e < Zeile.length; e++) {\r\n\t\t\t\t\trowContent.put(beschriftung[e], Zeile[e]);\r\n\t\t\t\t}\r\n\t\t\t\ti = i + 1;\r\n\t\t\t}\r\n\t\t\tInsertAllResponse response = bigquery\r\n\t\t\t\t\t\t\t.insertAll(InsertAllRequest\r\n\t\t\t\t\t\t\t.newBuilder(tableIdor)\r\n\t\t\t\t\t\t\t.addRow(String.valueOf(i), rowContent)\r\n\t\t\t\t\t\t\t.build());\r\n\t\t\tif (response.hasErrors()) {\r\n\t\t\t\tSystem.out.println(response.getErrorsFor(0));\r\n\t\t\t}\r\n\t\t}\r\n\t\tbr.close();\r\n\t\tmyFile.close();\r\n\t}\r\n}\r\n```\r\n\r\nAs you can see I get my data from a CSV file. There are several reasons why I don\u2019t upload just the CSV with a load job:\r\n\r\n 1.  As I\u00b4m from Germany we have quite different Date and Number formatting. I want to do the formatting BigQuery requires line by line, so that nobody who wants to upload has to think about other formatting than normal here.\r\n2. Sometimes I need to add the data in the CSV to an existing table and I have no idea if it is possible to add a whole CSV file to an existing table.\r\n\r\nthanks in advance for your help.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2423",
        "number": 2423,
        "title": "Clients / Stubs cannot be mocked",
        "labels": [
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "E.g., `TraceServiceClient` has all of the methods marked as final. Thus it's impossible to use with Mockito. There is no interface to mock either.  This makes it hard to test higher level libraries that needs to consume our client/stubs."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2421",
        "number": 2421,
        "title": "GCStorage - Handle extension headers on signUrl generation",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "More advance configuration and validations of sign URLs require extension headers [https://cloud.google.com/storage/docs/xml-api/reference-headers](extension headers).\r\n\r\nOpened this ticket to track my commits.\r\n\r\nI'm working on a pull request that will coming soon.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2419",
        "number": 2419,
        "title": "Clarify requirement instructions for App Engine",
        "labels": [
            "priority: p2",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/APPENGINE.md\r\n\r\nsays to add appengine-api-1.0-sdk for App Engine. This should emphasize that it is only needed for local dev appserver1 (not sure about dev appserver2). The instructions mislead people to believe the dependency is required on prod too.\r\n\r\nAlso, it says\r\n\r\n> **Note: the following instructions are not required for App Engine Flex and Java 8 standard environment.**\r\n\r\nHowever, I verified that dev appserver emulating the Java 8 runtime still needs the dependency. Also, mentioning flex here is confusing, because there is no dev appserver for flex.\r\n\r\n(BTW, \"Flex\" should be \"flexible environment\" in docs.)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2418",
        "number": 2418,
        "title": "BiQuery query method results in java.lang.NoSuchMethodError",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "I am creating a simple Query against a big query table, however I cannot seem to actually send the query due to an issue with `QueryJobConfiguration` throwing a `java.lang.NoSuchMethodError` when it tries to use `getQueryParameters()`. In fact, looking at the downloaded sources, there seems to be missing dependencies, with my IDE not being able to find `com.google.api.services.bigquery.model.QueryParameter` in general\r\n\r\nI am using the following version of gcloud SDK for java\r\n```xml\r\n<dependency>\r\n     <groupId>com.google.cloud</groupId>\r\n     <artifactId>google-cloud-bigquery</artifactId>\r\n     <version>0.22.0-beta</version>\r\n</dependency>\r\n```\r\n\r\nThe Truncated error\r\n```\r\nCaused by: java.lang.NoSuchMethodError: com.google.api.services.bigquery.model.JobConfigurationQuery.getQueryParameters()Ljava/util/List;\r\n\tat com.google.cloud.bigquery.QueryJobConfiguration$Builder.<init>(QueryJobConfiguration.java:135)\r\n\tat com.google.cloud.bigquery.QueryJobConfiguration$Builder.<init>(QueryJobConfiguration.java:85)\r\n\tat com.google.cloud.bigquery.QueryJobConfiguration.fromPb(QueryJobConfiguration.java:813)\r\n\tat com.google.cloud.bigquery.JobConfiguration.fromPb(JobConfiguration.java:140)\r\n\tat com.google.cloud.bigquery.JobInfo$BuilderImpl.<init>(JobInfo.java:184)\r\n\tat com.google.cloud.bigquery.Job.fromPb(Job.java:307)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:595)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:567)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2417",
        "number": 2417,
        "title": "Unaware if Null on set Timestamp",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hi\r\nIm trying to use Timestamp when set'ing the Entity that im saving. \r\nBut if the code send in null then i only get an exception back. \r\nI can manually say that the Key should be null but then i need to know beforehand that the value im sending in is null....\r\nI think this needs to be fixed.\r\n`\r\nTimestamp timestampThatCanBeNull = getTimestampOrNull();\r\nEntity.newBuilder(keyFactory.newKey()).set(\"TimestampThatCanSometimesBeNull\", consumableFormatId)\r\n`\r\nI think this is true for not only Timestamp but the other types, instead of return a exception it should use `NullValue`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2414",
        "number": 2414,
        "title": "java.lang.NoClassDefFoundError: org/spark-project/jetty/alpn/ALPN$Provider when instantiating MetricServiceClient",
        "labels": [
            "api: monitoring",
            "type: question"
        ],
        "state": "closed",
        "body": "When trying to instantiate a MetricServiceClient in order to perform Google Stackdriver Monitoring using the following code in a DataProc cluster image 1.0:\r\n\r\n```java\r\nMetricServiceSettings settings = MetricServiceSettings.defaultBuilder()\r\n                .setCredentialsProvider(credentialsProvider)\r\n                .build();\r\nMetricServiceClient metricServiceClient =  MetricServiceClient.create(settings);\r\n```\r\n\r\nI get the following stack trace:\r\n\r\n```\r\nException in thread \"main\" java.lang.NoClassDefFoundError: org/spark-project/jetty/alpn/ALPN$Provider\r\n\tat io.netty.handler.ssl.JdkAlpnApplicationProtocolNegotiator$1.<init>(JdkAlpnApplicationProtocolNegotiator.java:26)\r\n\tat io.netty.handler.ssl.JdkAlpnApplicationProtocolNegotiator.<clinit>(JdkAlpnApplicationProtocolNegotiator.java:24)\r\n\tat io.netty.handler.ssl.JdkSslContext.toNegotiator(JdkSslContext.java:237)\r\n\tat io.netty.handler.ssl.JdkSslClientContext.<init>(JdkSslClientContext.java:189)\r\n\tat io.netty.handler.ssl.SslContext.newClientContextInternal(SslContext.java:729)\r\n\tat io.netty.handler.ssl.SslContextBuilder.build(SslContextBuilder.java:223)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:470)\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:338)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:305)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:125)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:110)\r\n\tat com.google.api.gax.grpc.GrpcTransportProvider.getTransport(GrpcTransportProvider.java:98)\r\n\tat com.google.api.gax.grpc.GrpcTransportProvider.getTransport(GrpcTransportProvider.java:59)\r\n\tat com.google.api.gax.rpc.ClientContext.create(ClientContext.java:97)\r\n\tat com.google.cloud.monitoring.v3.stub.GrpcMetricServiceStub.create(GrpcMetricServiceStub.java:161)\r\n\tat com.google.cloud.monitoring.v3.MetricServiceSettings.createStub(MetricServiceSettings.java:195)\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.<init>(MetricServiceClient.java:140)\r\n\tat com.google.cloud.monitoring.v3.MetricServiceClient.create(MetricServiceClient.java:122)\r\n```\r\n\r\nThis is the dependency in the pom.xml file (spark version 1.6.3):\r\n\r\n```xml\r\n  <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-monitoring</artifactId>\r\n      <version>0.22.0-alpha</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>com.google.guava</groupId>\r\n          <artifactId>guava</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n    </dependency>\r\n  <dependency>\r\n      <groupId>org.apache.spark</groupId>\r\n      <artifactId>spark-sql_2.10</artifactId>\r\n      <version>${spark.version}</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>org.apache.hadoop</groupId>\r\n          <artifactId>hadoop-client</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>org.apache.commons</groupId>\r\n          <artifactId>commons-lang3</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>net.java.dev.jets3t</groupId>\r\n          <artifactId>jets3t</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>com.google.guava</groupId>\r\n          <artifactId>guava</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n      <!--<scope>provided</scope>-->\r\n    </dependency>\r\n\r\n    <dependency>\r\n      <groupId>org.apache.spark</groupId>\r\n      <artifactId>spark-catalyst_2.10</artifactId>\r\n      <version>${spark.version}</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>org.apache.hadoop</groupId>\r\n          <artifactId>hadoop-client</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>org.apache.commons</groupId>\r\n          <artifactId>commons-lang3</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>net.java.dev.jets3t</groupId>\r\n          <artifactId>jets3t</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>com.google.guava</groupId>\r\n          <artifactId>guava</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n      <!--<scope>provided</scope>-->\r\n    </dependency>\r\n\r\n    <dependency>\r\n      <groupId>com.databricks</groupId>\r\n      <artifactId>spark-csv_2.11</artifactId>\r\n      <version>${spark.csv.version}</version>\r\n      <exclusions>\r\n        <exclusion>\r\n          <groupId>org.apache.hadoop</groupId>\r\n          <artifactId>hadoop-client</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>org.apache.commons</groupId>\r\n          <artifactId>commons-lang3</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>net.java.dev.jets3t</groupId>\r\n          <artifactId>jets3t</artifactId>\r\n        </exclusion>\r\n        <exclusion>\r\n          <groupId>com.google.guava</groupId>\r\n          <artifactId>guava</artifactId>\r\n        </exclusion>\r\n      </exclusions>\r\n    </dependency>\r\n\r\n```\r\n\r\nAny advice as to how to resolve this issue would be appreciated. Thanks.\r\n\r\nEdit: I have no issue when running my program locally, the issue only appears when running on the Dataproc cluster. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2413",
        "number": 2413,
        "title": "Adding Snippets has errors",
        "labels": [
            ":rotating_light:",
            "priority: p2",
            "type: bug",
            "type: process"
        ],
        "state": "closed",
        "body": "script: https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/utilities/add_snippets_to_file.py\r\n\r\n1. Method signature with @Nullable does not work.\r\nFix:\r\nAt this line in add_snippets_to_file.py#L99, replace the existing:\r\n    ',\\s+'.join(['(final\\s+)?{}\\s+{}'.format(\r\nwith this:\r\n    ',\\s+'.join(['(@Nullable\\s+)?(final\\s+)?{}\\s+{}'.format(\r\n\r\n2. for all single line comments, the script either fails (when its the last method in the file) or appends javadocs to the successive method.\r\n\r\nexample:\r\n/** some javadoc */\r\npublic String method ( String args );"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2412",
        "number": 2412,
        "title": "Reconsider project.properties and META-INF",
        "labels": [
            "api: core",
            "dependencies",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Our current use of project.properties is the cause of this issue: https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2411\r\n\r\nIt seems like the way we are using project.properties may be unnecessary, or otherwise we may be able to use `META-INF`, which would be a cleaner/more idiomatic solution."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2411",
        "number": 2411,
        "title": "project.properties duplicate conflict b/w google-cloud-core & google-cloud-pubsub",
        "labels": [
            "api: core",
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I am using duplicate-finder-maven-plugin in my project which has started complaining for duplicate project.properties b/w  google-cloud-core & google-cloud-pubsub\r\n\r\n`[INFO] Checking test classpath\r\n\r\n[WARNING] Found duplicate and different resources in [com.google.cloud:google-cloud-core:1.2.1, com.google.cloud:google-cloud-pubsub:0.20.1-beta]:\r\n[WARNING]   project.properties\r\n[WARNING] Found duplicate classes/resources in compile classpath.\r\n[WARNING] Found duplicate and different resources in [com.google.cloud:google-cloud-core:1.2.1, com.google.cloud:google-cloud-pubsub:0.20.1-beta]:\r\n[WARNING]   project.properties\r\n[WARNING] Found duplicate classes/resources in runtime classpath.\r\n[WARNING] Found duplicate and different resources in [com.google.cloud:google-cloud-core:1.2.1, com.google.cloud:google-cloud-pubsub:0.20.1-beta]:\r\n[WARNING]   project.properties\r\n[WARNING] Found duplicate classes/resources in test classpath.`\r\n\r\nKindly help out"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2407",
        "number": 2407,
        "title": "com.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED while using Stackdriver logging library",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI have been experiencing an issue which is blocking me from writing logs to Stackdriver. I see an exception saying \"SEVERE: RuntimeException while executing runnable com.reltio.gcp.google.common.util.concurrent.Futures$6@7a04e1cd with executor MoreExecutors.directExecutor()\r\njava.lang.RuntimeException: com.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\" \r\n\r\nThe issue happens only when we deploy a war file to tomcat. We can resolve this issue by adding ALPN jar to tomcat bootstrap file but it's not a feasible solution for us. Other approach is to add the following dependency which seemed to work until few days back but for some reason started failing. \r\n```\r\n<dependency>\r\n    <groupId>io.netty</groupId>\r\n    <artifactId>netty-tcnative-boringssl-static</artifactId>\r\n    <version>1.1.33.Fork26</version>\r\n</dependency>\r\n```\r\n\r\nI am using google-cloud-logging v1.2.0. I tried using the latest version (1.6.0) but see \"Caused by: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\"\r\n\r\nAttached are the screenshots with stacktace. \r\n<img width=\"1680\" alt=\"alpn_npn\" src=\"https://user-images.githubusercontent.com/2561340/30084458-50da54d6-9247-11e7-991a-926dd71bc53d.png\">\r\n<img width=\"1022\" alt=\"deadline_exceeded\" src=\"https://user-images.githubusercontent.com/2561340/30084459-50db07d2-9247-11e7-809c-9e87cfb5bd4d.png\">\r\n\r\n\r\n\r\nThis seems to be client library related issues. Any suggestions are highly appreciated.\r\n\r\nThanks\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2406",
        "number": 2406,
        "title": "[0.22.0-beta] StreamingSubscriberConnection unlimited increasing the channelReconnectBackoff duration",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The Pub/Sub Subscriber of version 0.22.0-beta uses streaming as its subscription connection by default. This setting cannot be changed, because of the default access of the Subcriber.Builder#setUseStreaming method.\r\nThe Problem with the StreamingSubscriberConnection is, that on each re-connection (which occurs quite often) the channelReconnectBackoff duration is doubled. There is no upper limit, nor any reset of the channelReconnectBackoff duration on successful messages."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2405",
        "number": 2405,
        "title": "Pub/Sub give problem in AppEngine with Standard Environment with Java 7",
        "labels": [
            "api: pubsub",
            "running on app engine",
            "type: question"
        ],
        "state": "closed",
        "body": "Pub/Sub give problem in AppEngine with Standard Environment with Java 7\r\n\r\nHi, I have created Google PUB/SUB using topic. I get error in my Subscriber code. my code works on my local tomcat server but when I deployed it on Google cloud AppEngine with standard environment. It gives following error.\r\n**Could not initialize class com.google.cloud.pubsub.v1.Subscriber**\r\n\r\nInitialization of Subscriber instance is failed on Google cloud AppEngine whereas Subscriber is initialized in local tomcat\r\ncom.google.cloud.pubsub.v1.Subscriber subscriber = Subscriber.defaultBuilder(subscription,receiver).build();\t\r\n\r\n\r\nI have used following Maven dependencies \r\n<dependency>\r\n  <groupId>com.google.appengine</groupId>\r\n  <artifactId>appengine-api-1.0-sdk</artifactId>\r\n  <version>1.9.54</version>\r\n</dependency>\r\n\r\n<dependency>\r\n <groupId>com.google.api-client</groupId>\r\n <artifactId>google-api-client-appengine</artifactId>\r\n <version>1.21.0</version>\r\n <exclusions>\r\n  <exclusion>\r\n   <groupId>javax.servlet</groupId>\r\n   <artifactId>servlet-api</artifactId>\r\n  </exclusion>\r\n  <exclusion>\r\n   <groupId>javax.servlet</groupId>\r\n   <artifactId>servlet-api</artifactId>\r\n  </exclusion>\r\n  <exclusion>\r\n    <groupId>com.google.guava</groupId>\r\n    <artifactId>guava-jdk5</artifactId>\r\n  </exclusion>\r\n </exclusions>\r\n</dependency>\r\n\r\n<dependency>\r\n <groupId>com.google.apis</groupId>\r\n <artifactId>google-api-services-pubsub</artifactId>\r\n  <version>v1-rev8-1.21.0</version>\r\n</dependency>\r\n\r\n<dependency>\r\n <groupId>com.google.cloud</groupId>\r\n <artifactId>google-cloud-examples</artifactId>\r\n <version>0.22.0-alpha</version>\r\n</dependency>\r\n\r\n<dependency>\r\n <groupId>com.google.appengine.tools</groupId>\r\n <artifactId>appengine-gcs-client</artifactId>\r\n <version>0.5</version>\r\n <exclusions>\r\n  <exclusion>    \r\n    <groupId>com.google.http-client</groupId>\r\n    <artifactId>google-http-client</artifactId>\r\n  </exclusion>\r\n </exclusions>\r\n</dependency>\r\n\r\n<dependency>\r\n <groupId>com.google.appengine</groupId>\r\n <artifactId>appengine-remote-api</artifactId>\r\n  <version>1.9.32</version>\r\n</dependency>"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2404",
        "number": 2404,
        "title": "How to get the names of all accessible Datasets?",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\nI got a small problem. Basically, I just want to receive the names of all the datasets which I can access. My code looks like BigQuery API described how to do it:\r\n\r\n```\r\n\r\nimport java.util.Iterator;\r\nimport java.util.List;\r\n\r\nimport com.google.api.gax.paging.Page;\r\n//import com.google.appengine.repackaged.org.apache.lucene.analysis.compound.hyphenation.TernaryTree.Iterator;\r\nimport com.google.cloud.bigquery.*;\r\nimport com.google.cloud.bigquery.BigQuery.DatasetListOption;\r\n\r\npublic class GetBQInfo {\r\n\tpublic static void getinfo (){\r\n\tBigQuery bigquery = BigQueryOptions.getDefaultInstance()\r\n\t\t    .toBuilder()\r\n\t\t    .setProjectId(\"testprojekt-175408\")\r\n\t\t    .build()\r\n\t\t    .getService();\r\n\t String projectId = \"testprojekt-175408\";\r\n\t Page<Dataset> datasets = bigquery.listDatasets(projectId, DatasetListOption.pageSize(100));\r\n\t Iterator<Dataset> datasetIterator = datasets.iterateAll();\r\n\t while (datasetIterator.hasNext()) {\r\n\t   Dataset dataset = datasetIterator.next();\r\n\t   // do something with the dataset\r\n\t }\r\n\t }\r\n}\r\n```\r\nBut I cannot compile the code because I get this message from eclipse:\r\n`Type mismatch: cannot convert from Iterable<Dataset> to Iterator<Dataset>`\r\nI tried a lot of things but nothing worked for me yet. Does anyone know how I can solve this?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2401",
        "number": 2401,
        "title": "JUL LoggingHandler issues",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "There are a couple of issues in the `com.google.cloud.logging.LoggingHandler`\r\n\r\n- Unused private methods: `getLoggingHandlers`, `hasLoggingHandler`\r\n- Assigning the handler to a specific logger, rather than the root, doesn't work.\r\n`com.example.handlers=com.google.cloud.logging.LoggingHandler`\r\n\r\nThe second one needs to be investigated a bit more.\r\n\r\n@jabubake FYI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2400",
        "number": 2400,
        "title": "googlecloudplatform.github.io/google-cloud-java seems badly formatted",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "![screen shot 2017-09-01 at 11 09 12 am](https://user-images.githubusercontent.com/1136014/29982369-4385acca-8f06-11e7-9c0b-3407c6c987cd.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2399",
        "number": 2399,
        "title": "Upgrade to grpc 1.6.1",
        "labels": [
            "dependencies",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We are currently on 1.4 ."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2398",
        "number": 2398,
        "title": "java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured. when trying to use PubSub",
        "labels": [
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI am trying to use the google cloud libraries to connect to PubSub but I am getting the following exception when trying to execute the following code:\r\n\r\n\r\n```\r\nprojectID = \"XYZ\";\r\nsubscriptionID = \"ABC/XYZ\";\r\nsubscriptionName = SubscriptionName.create(projectID, subscriptionID);\r\nsubscriber = Subscriber.defaultBuilder(subscriptionName, new MessageReceiverEx()).build();\r\nsubscriber.startAsync().awaitRunning();\r\n```\r\n\r\n```\r\nCaused by: java.lang.IllegalStateException: Expected the service InnerService [FAILED] to be RUNNING, but the service has FAILED\r\n        at com.google.common.util.concurrent.AbstractService.checkCurrentState(AbstractService.java:328)\r\n        at com.google.common.util.concurrent.AbstractService.awaitRunning(AbstractService.java:266)\r\n        at com.google.api.core.AbstractApiService.awaitRunning(AbstractApiService.java:97)\r\nat ...\r\n\r\n\r\nCaused by: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n        at io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:174)\r\n        at io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:151)\r\n        at io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:139)\r\n        at io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:109)\r\n        at io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:470)\r\n        at io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:338)\r\n        at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:305)\r\n        at com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:125)\r\n        at com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:110)\r\n        at com.google.cloud.pubsub.v1.Subscriber.doStart(Subscriber.java:239)\r\n        at com.google.api.core.AbstractApiService$InnerService.doStart(AbstractApiService.java:149)\r\n        at com.google.common.util.concurrent.AbstractService.startAsync(AbstractService.java:211)\r\n        at com.google.api.core.AbstractApiService.startAsync(AbstractApiService.java:121)\r\n        at com.google.cloud.pubsub.v1.Subscriber.startAsync(Subscriber.java:228)\r\n```\r\n\r\nThe last line in my code (`subscriber.startAsync().awaitRunning();`) is the position where the upper exception origines from.\r\n\r\n\r\nAm I using something wrong or is this a bug?\r\nI am using `compile group: 'com.google.cloud', name: 'google-cloud-pubsub', version:'0.22.0-beta'` as gradle dependency."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2397",
        "number": 2397,
        "title": "Add fromStorageUrl and toStorageUrl methods to BlobId",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See this issue for context: https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2363"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2392",
        "number": 2392,
        "title": "Add `.userProject()` method to `Blob.BlobSourceOption` to allow using Requester Pays feature on `Blob.reader()`",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Add support in [Blob.BlobSourceOption](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/Blob.java#L83) similar to [Storage.BlobSourceOption](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/Storage.java#L637) to set the billing project ID.\r\n It will not be able to download blobs using `Blob.reader()` without defining this parameter when Requester Pays is enabled for a bucket. \r\n\r\n**Use case**: downloading a larger blob using the `Blob.reader()`\r\n\r\n[Reference API discovery doc](https://www.googleapis.com/discovery/v1/apis/storage/v1/rest).\r\n\r\n[Updated by @frankyn]"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2391",
        "number": 2391,
        "title": "Add `RequesterPays` as `BucketField` entry",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/Storage.java#L95\r\n\r\nCurrently, if I retrieve by `ID`, I receive null on `requesterPays` even when it has been enabled on a bucket.\r\nPlease add `RequesterPays` as `BucketField` entry (unless there is another recommended approach to querying `requesterPays` status of a bucket)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2389",
        "number": 2389,
        "title": "Confusing Translation sample code",
        "labels": [
            "api: translation",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "```java\r\nTranslation translation = translate.translate(\r\n    \"World\",\r\n    TranslateOption.sourceLanguage(\"en\"),\r\n    TranslateOption.targetLanguage(detectedLanguage));\r\n```\r\n\r\nIt makes more sense to me if the source language is assigned with the `detected language` instead."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2386",
        "number": 2386,
        "title": "Create a CODEOWNERS file",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See Python for an example: https://github.com/GoogleCloudPlatform/google-cloud-python/pull/3887"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2385",
        "number": 2385,
        "title": "Querying Data with timestamps in BigQuery with Java",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\nI simply want to run this Query in Java. \r\n\r\n`SELECT Leistung FROM [myprojekt-111111:SimTestdaten] Where TIMESTAMP between TIMESTAMP(\"2016-08-28\")  AND TIMESTAMP(\"2016-08-29\")`\r\n\r\nI searched for a conclusion to work for me, but I couldn\u2019t really understand all the explanations I found.\r\nHere is a little bit of the Java Code I wrote so you can understand how I think and where exactly my Problem is. \r\n\r\n\r\n```\r\nDateTime timestamp = new DateTime(2016, 8, 28, 0, 0, 0, DateTimeZone.UTC);\r\nString queryString = \"SELECT Leistung\\n\"\r\n    + \"FROM `myprojekt-111111:SimTestdaten`\\n\"\r\n    + \"WHERE TIMESTAMP =\"+ timestamp\r\nQueryRequest queryRequest = QueryRequest.newBuilder(queryString)\r\n    .setUseLegacySql(false)\r\n    .build();\r\nQueryResponse response = bigquery.query(queryRequest);\r\n```\r\nThanks in advance for your help. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2379",
        "number": 2379,
        "title": "Reading Stack Driver Logging - java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment",
        "labels": [
            "api: logging",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\nI am trying to read logs from Stack Driver Logging. I have logged into gccloud. \r\nBelow is my program to read:\r\n`public class App \r\n{\r\n\tLogging logging = LoggingOptions.getDefaultInstance().getService();\r\n\t\r\n\tpublic static void main( String[] args ){\r\n        System.out.println( \"Hello World!\" );\r\n        App obj = new App();\r\n        obj.run();\r\n    }\r\n    \r\n    private void run() {\r\n    \t\r\n\t    \ttry {\r\n\t    \t\t\r\n\t    \t\tLoggingOptions.Builder optionsBuilder = LoggingOptions.newBuilder();\r\n\t    \t\tlogging = optionsBuilder.build().getService();\r\n\t\r\n\t    \t\tPage<LogEntry> entries = logging.listLogEntries(EntryListOption.filter(\"logName=projects/<<PROJECT_ID>>/logs/<<LOGNAME>>\"));\r\n\t    \t\tfor(LogEntry entry :entries.iterateAll()) {\r\n\t    \t\t\tSystem.out.println(entry.toString());\r\n\t    \t\t}\r\n\t    \t}catch(Exception ex) {\r\n\t    \t\tex.printStackTrace();\r\n\t    \t}\r\n\t}\r\n}`\r\n\r\nGetting below exception:\r\n\r\n`Hello World!\r\nException in thread \"main\" java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment.  Please set a project ID using the builder.\r\n\tat com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\r\n\tat com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:240)\r\n\tat com.google.cloud.logging.LoggingOptions.<init>(LoggingOptions.java:102)\r\n\tat com.google.cloud.logging.LoggingOptions$Builder.build(LoggingOptions.java:96)\r\n\tat com.google.cloud.logging.LoggingOptions.getDefaultInstance(LoggingOptions.java:55)`\r\n\r\nThough Project Id is passed, still i am getting the above exception. Please suggest. Thanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2378",
        "number": 2378,
        "title": "TESTING.md refers to non-existant method setChannelProvider for PubSub",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "TESTING.md refers to a method that no longer exists in 0.22.0-beta.\r\n\r\nThe example for creating a pubsub topic admin client:\r\n```\r\nTopicAdminClient topicClient = TopicAdminClient.create(\r\n    TopicAdminSettings\r\n      .defaultBuilder()\r\n      .setChannelProvider(channelProvider)\r\n      .setCredentialsProvider(credentialsProvider)\r\n      .build());\r\n```\r\n\r\nuses `.setChannelProvider()`, which no longer exists. It's not clear what the new approach for testing is."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2375",
        "number": 2375,
        "title": "Write unit tests for the CloudStorageRetryHandler class",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We recently extracted a simple `CloudStorageRetryHandler` class to keep track of retries/reopens in `google-cloud-nio`. This class needs unit tests, as per the discussion in https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2281"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2374",
        "number": 2374,
        "title": "Querying Public Data set",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "I\u2019m trying to run a Query trough the public Data in BigQuery using Java and Eclipse.\r\nWhen I run my code, I get:\r\n\r\n```\r\nHTTP ERROR 500\r\n\r\nProblem accessing /Getbigquery. Reason: \r\n    Server Error\r\n\r\n\r\nCaused by:\r\ncom.google.cloud.bigquery.BigQueryException: Access Denied: Project bigquery-public-data: The user MyAdress@gmail.com does not have bigquery.jobs.create permission in project bigquery-public-data.\r\n```\r\n\r\nI the IAM my Mail Address has the Owner Role for BigQuery.\r\n\r\nWhat I\u2019m worried about is my BigQuery Console. The Public Data is not listed in my Project but separately and I can\u2019t click on \"copy table\" to copy it to my Project because it says: \"Required parameter is missing\".\r\n\r\nIsn\u2019t it possible to query the public Dataset with Java from Eclipse or is there something else I must think of?\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2373",
        "number": 2373,
        "title": "Pub/Sub API docs needs cleanup",
        "labels": [
            "api: pubsub",
            "status: blocked",
            "type: process"
        ],
        "state": "open",
        "body": "I am fine with minimal information here, but I think its important that it states accurate information.\r\n[Pub/Sub API reference](http://googlecloudplatform.github.io/google-cloud-java/latest/apidocs/index.html?com/google/cloud/pubsub/v1/package-summary.html)\r\n\r\nstates `TopicAdminClient` is used to send messages to a topic.\r\n`SubscriptionAdminClient` is used to pull messages : Both not true.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2371",
        "number": 2371,
        "title": "SQLAdmin.Builder wants application name",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "If you create a `SQLAdmin` with the builder, without setting application name by calling `SQL.Builder(...).setApplicationName(\"app-name\")`, you'll see a warning coming from `AbstractGoogleClient` saying:\r\n\r\n\"Application name is not set. Call Builder#setApplicationName.\"\r\n\r\nWhat's the purpose of setting application name? I don't see it being documented? If it's not needed, the warning should be removed."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2370",
        "number": 2370,
        "title": "How can I receive Data from Google BigQuery with Eclipse and Java?",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "I\u2019m trying to receive some Data from google BigQuery and show the result in my eclipse console to get started with BigQuery and Java. Basically, I followed the Instructions provided by google, which I found here: https://cloud.google.com/bigquery/docs/reference/libraries\r\n\r\nSo my example Java Code looks like the quick start example from google:\r\n\r\n```\r\nimport com.google.cloud.bigquery.BigQuery;\r\nimport com.google.cloud.bigquery.BigQueryOptions;\r\nimport com.google.cloud.bigquery.Dataset;\r\nimport com.google.cloud.bigquery.DatasetInfo;\r\n\r\npublic class QuickstartSample {\r\n  public static void main(String... args){\r\n        // Instantiates a client\r\n        BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\n\r\n        // The name for the new dataset\r\n        String datasetName = \"bigquery-public-data:hacker_news.comments\";\r\n\r\n        // Prepares a new dataset\r\n        Dataset dataset = null;\r\n        DatasetInfo datasetInfo = DatasetInfo.newBuilder(datasetName).build();\r\n\r\n        // Creates the dataset\r\n        dataset = bigquery.create(datasetInfo);\r\n\r\n        System.out.printf(\"Dataset %s created.%n\", dataset.getDatasetId().getDataset());\r\n  } \r\n}\r\n```\r\nBut when I run this Code I get the following error:\r\n\r\n```\r\nHTTP ERROR 500\r\n\r\nProblem accessing /getbigquery. Reason: \r\n    Could not get the access token.\r\n\r\n\r\nCaused by:\r\ncom.google.cloud.bigquery.BigQueryException: Could not get the access token.\r\n    at com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:86)\r\n    at com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.create(HttpBigQueryRpc.java:141)\r\n    at com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:172)\r\n    at com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:169)\r\n    at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94)\r\n    at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n    at com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:169)\r\n    at testpackage.dto.QuickstartSample.main(QuickstartSample.java:27)\r\n    at testpackage.getbigquery.doPost(getbigquery.java:27)\r\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:637)\r\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\r\n    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)\r\n    at com.google.appengine.api.socket.dev.DevSocketFilter.doFilter(DevSocketFilter.java:74)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n    at com.google.appengine.tools.development.ResponseRewriterFilter.doFilter(ResponseRewriterFilter.java:134)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n    at com.google.appengine.tools.development.HeaderVerificationFilter.doFilter(HeaderVerificationFilter.java:34)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n    at com.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:63)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n    at com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n    at com.google.appengine.tools.development.StaticFileFilter.doFilter(StaticFileFilter.java:122)\r\n    at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\nI tried to authenticate with Default Credentials so I ran \u201cgcloud auth application-default login\u201c in my google SDK console. Although I could login in SDK, eclipse gave me the previous shown error.\r\n```\r\n\r\nThen I tried a few other things like downloading my token as Json file and revering to it with java in my application or setting my environment variable manually but it didn\u2019t work as well.\r\n\r\nDoes anyone have an idea what I\u2019m doing wrong? Any help is appreciated."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2364",
        "number": 2364,
        "title": "Fix Travis run on Mac",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "The build of google-cloud-java is consistently failing on Mac:\r\n\r\n```\r\n$ git clone -b travis `git config --get remote.origin.url` target/travis\r\nCloning into 'target/travis'...\r\nerror: RPC failed; curl 56 SSLRead() return error -36\r\nfatal: The remote end hung up unexpectedly\r\nfatal: early EOF\r\nfatal: index-pack failed\r\n```\r\n\r\nThis should be fixed."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2363",
        "number": 2363,
        "title": "Does there exist a function to parse gs url into a bucket part and a blob part?",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "If I understand correctly, the way to fetch blob content from Google Cloud Storage, as suggested by the [google-cloud-java](http://googlecloudplatform.github.io/google-cloud-java/0.21.1/apidocs/index.html) API, right now is using something like:\r\n\r\n```\r\nStorage storage = StorageOptions.getDefaultInstance().getService();\r\nBlobId blobId = BlobId.of(\"bucket\", \"blob_name\");\r\nBlob blob = storage.get(blobId);\r\nbyte[] content = blob.getContent();\r\n```\r\n\r\nThis requires us to pass in two arguments: `bucket` and `blob_name`, but normally what we would want to pass in, originally, would be a `gs://` url. \r\n\r\nI want to know whether there exists a function that can parse a gs URL and return the bucket and blob parts, like the [parseGlob](https://chromium.googlesource.com/external/googleappengine/python/+/78bd635e7b42b5a8105e19b6f83aed5bbf5a6732/google/appengine/api/files/gs.py#70) function here. I feel this might be something that exists in the google-cloud-java library already so I don't need to reinvent the wheel."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2358",
        "number": 2358,
        "title": "PubSub Subscriber requires pubsub.subscriptions.get permission",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "The current IAM role for Subscriber only gives the following permissions:\r\n- pubsub.subscriptions.consume\r\n- pubsub.topics.attachSubscription\r\n\r\nThis library uses pubsub.subscriptions.get when [constructing the subscriber](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.21.0/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/v1/Subscriber.java#L302). This causes a permission denied exception to be thrown. \r\n\r\nIt is not documented anywhere that the Java client library requires this permission. My assumption as a user is that the IAM role for subscriber gives me all the required permissions to subscribe. For Java Publisher, the publisher role has all the needed permissions using the IAM publisher role. For Python Subscriber, Subscriber IAM role has sufficient permissions.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2357",
        "number": 2357,
        "title": "Invalid Statistics type for Load job",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi,\r\n  I have following code snippet in my project.\r\n ```\r\n Credentials c = new ServiceAccountCredentials();  /* hiding credentials here*/\r\n  BigQueryOptions options = BigQueryOptions.newBuilder().setCredentials(c).setProjectId('id').build();\r\n  BigQuery bq = options.getService();\r\n  TableId id = TableId.of('project id', 'dataset id', 'table id');\r\n  Table t = bq.getTable(id);\r\n  t.load(FormatOptions.csv(), \"gs://bucket/file1.csv\");\r\n  System.out.println(loadJob.getStatistics());\r\n```\r\n\r\nI was expecting the statistics to be of 'Load' type but its of 'Copy' type.\r\n\r\nCan anyone tell me where am I doing wrong?  Indeed, data is getting inserted into table but I am missing the output statistics (no of rows, no of bytes, etc) due to wrong type being returned."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2353",
        "number": 2353,
        "title": "Subscription processes hangs forever",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\nPublish process publishes only 2 messages. Ran subscription process on my local and messaged processed successfully. 2nd time I ran the subscription process once again on my local and there is no messages but the subscription process hangs forever. Can you please explain why?\r\nI am using google pub-sub version 0.21.1-beta. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2351",
        "number": 2351,
        "title": "Add ability to batch Storage.create() requests",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Seems like current batching API [1] does not support batching create [2] requests. Batching create requests might be needed for some use cases; for example, if a user needs to create a large number of small files.\r\n\r\nIf this is already supported it might be good to add an example.\r\n\r\n[1] https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/StorageBatch.java#L55\r\n[2] https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/Storage.java#L1427"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2349",
        "number": 2349,
        "title": "Release notes : no easy way for users to find latest versions @ a glance",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Given the alpha/beta/GA status, it would be good to provide a way to clearly state the client libraries part of a release.\r\n\r\nRight now [pom.xml](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/pom.xml#L146) lists versions of libraries and dependencies like `gax` without any consistent prefix to distinguish them from client libraries.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2348",
        "number": 2348,
        "title": "Make exception more informative when using FACE_DETECTION in `Feature` list for Video Intelligence API",
        "labels": [
            "api: videointelligence",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "v0.21.1-alpha\r\n\r\n```java\r\njava.util.concurrent.ExecutionException: com.google.api.gax.grpc.GrpcApiException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Request contains an invalid argument.\r\n```\r\n\r\nis the  non-informative response.\r\n[Here](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/patch-video/video/cloud-client/src/test/java/com/example/video/DetectIT.java#L58) is the code used to test.\r\n\r\nI noticed [REST API reference](https://cloud.google.com/video-intelligence/docs/reference/rest/v1beta1/videos) does not list FACE_DETECTION.\r\n\r\n@lesv @gguuss \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2343",
        "number": 2343,
        "title": "Storage::writer() provides no way to see metadata after writing.",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Here's an example of using the Storage::writer method to write a blob from the documentation:\r\n\r\n```\r\nBlobInfo blobInfo = BlobInfo.newBuilder(blobId).setContentType(\"text/plain\").build();\r\ntry (WriteChannel writer = storage.writer(blobInfo)) {\r\n   try {\r\n      writer.write(ByteBuffer.wrap(content, 0, content.length));\r\n   } catch (Exception ex) {\r\n     // handle exception\r\n   }\r\n}\r\n```\r\nThis works well and makes it easy to write data to a GCS object with a WriteChannel. However, when the operation finishes, GCS returns the metadata of the new object, most importantly including the generation number of the newly-created object. The writer() method provides no way of accessing this metadata.\r\n\r\nWe need a way of accessing the metadata of the new object upon success. Perhaps a Blob accessor could be added to the WriteChannel, or some assignable reference could be passed to the writer() method, or some other mechanism."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2342",
        "number": 2342,
        "title": "Publisher : Lifetime of the publisher object (Pubsub)",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "When using the pubsub java client, how long should a [Publisher](http://googlecloudplatform.github.io/google-cloud-java/0.21.1/apidocs/index.html) object live for ?\r\n\r\nIn a scenario where we get frequent HTTP requests that get translated into Pubsub messages, doing \r\n\r\n```java\r\ntry {\r\n    publisher = Publisher.defaultBuilder(topic).build();\r\n\r\n    //... do publish stuff\r\n}\r\nfinally { \r\n    if (publisher != null) {\r\n        publisher.shutdown();\r\n    }\r\n}\r\n```\r\neach time seems inefficient. I couldn't find any documentation on the expected lifetime of the object.\r\n\r\nHow often should the publisher be shutdown (either in terms of time or messages published) ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2341",
        "number": 2341,
        "title": "Getting No functional channel service provider found error for Google Cloud Pub/Sub",
        "labels": [
            "api: pubsub",
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "I am trying to implement java code with service-account credentials but when I am running the application, I am getting **No functional channel service provider found. Try adding a dependency on the grpc-okhttp or grpc-netty artifact** error. I even added **grpc-okhttp and grpc-netty artifact** as individual and as both. but nothing worked fine for me. Any help is really appreciated. I am getting issue at \r\n\r\nPublisher publisher = Publisher.defaultBuilder(topicName)\r\n            .setCredentialsProvider(credentialsProvider)\r\n            .setChannelProvider(channelProvider)\r\n            .build();\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2340",
        "number": 2340,
        "title": "Error build gradle for Android Project",
        "labels": [
            "android",
            "api: translation",
            "type: bug"
        ],
        "state": "closed",
        "body": "![screen shot 2017-08-15 at 1 21 37 pm](https://user-images.githubusercontent.com/4638285/29304367-c958166e-81bc-11e7-9f03-e1020d9e9d8e.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2339",
        "number": 2339,
        "title": "Impossible to publish message into a topic (using Google App Engine and Java) using Google PubSub",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm trying to make **Google PubSub** work, but it seems impossible.\r\n\r\nI'm just trying to publish a message into a topic, with the code quite similar to this one:\r\nhttps://github.com/GoogleCloudPlatform/java-docs-samples/blob/master/flexible/pubsub/src/main/java/com/example/flexible/pubsub/PubSubPublish.java\r\n\r\nSomething like this:\r\n```\r\n      Publisher publisher = null;\r\n      String topicId = \"mytopic\";\r\n\r\n      // create a publisher on the topic\r\n      if (publisher == null) {\r\n        publisher = Publisher.defaultBuilder(\r\n            TopicName.create(ServiceOptions.getDefaultProjectId(), topicId))\r\n            .build();\r\n      }\r\n      // construct a pubsub message from the payload\r\n      final String payload = \"mypayload\";\r\n      PubsubMessage pubsubMessage =\r\n          PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(payload)).build();\r\n\r\n      ApiFuture<String> messageId = publisher.publish(pubsubMessage);\r\n```\r\n\r\n\r\nAfter that, when accessing the Servlet it seems to work.\r\nBut I never get the message published.\r\n\r\nTrying to see what happens, I add this code:\r\n\r\n\r\n```\r\n      resp.setContentType(\"text/plain\");\r\n      if (messageId != null) {\r\n    \t  \ttry {\r\n\t\t\t\tmessageId.get();\r\n\t\t\t\tresp.getWriter().println(\"Eveything alrigth\");\r\n\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\tresp.getWriter().println(\"Exception InterruptedException:\");\r\n\t\t\t\tresp.getWriter().println(e.toString());\r\n\t\t\t\tfinal StringWriter stacktrace = new StringWriter();\r\n\t\t\t\te.printStackTrace(new PrintWriter(stacktrace));\r\n\t\t\t\tresp.getWriter().println(stacktrace.getBuffer());\r\n\t\t\t} catch (ExecutionException e) {\r\n\t\t\t\tresp.getWriter().println(\"Exception ExecutionException\");\r\n\t\t\t\tresp.getWriter().println(e.toString());\r\n\t\t\t\tresp.getWriter().println(e.fillInStackTrace());\r\n\t\t\t}\r\n      }\r\n```\r\n\r\n\r\nIt takes quite a lot of seconds and finally I get this message:\r\n```\r\n\r\nException InterruptedException:\r\njava.lang.InterruptedException\r\njava.lang.InterruptedException\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:473)\r\n\tat com.google.api.core.AbstractApiFuture.get(AbstractApiFuture.java:57)\r\n\tat com.myCompany.myClassName.doGet(myClassName.java:50)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n\tat com.google.apphosting.utils.servlet.ParseBlobUploadFilter.doFilter(ParseBlobUploadFilter.java:125)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.apphosting.runtime.jetty9.SaveSessionFilter.doFilter(SaveSessionFilter.java:37)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.apphosting.utils.servlet.JdbcMySqlConnectionCleanupFilter.doFilter(JdbcMySqlConnectionCleanupFilter.java:60)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:524)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat com.google.apphosting.runtime.jetty9.AppVersionHandlerMap.handle(AppVersionHandlerMap.java:297)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:534)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\r\n\tat com.google.apphosting.runtime.jetty9.RpcConnection.handle(RpcConnection.java:219)\r\n\tat com.google.apphosting.runtime.jetty9.RpcConnector.serviceRequest(RpcConnector.java:81)\r\n\tat com.google.apphosting.runtime.jetty9.JettyServletEngineAdapter.serviceRequest(JettyServletEngineAdapter.java:108)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.dispatchServletRequest(JavaRuntime.java:657)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.dispatchRequest(JavaRuntime.java:619)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.run(JavaRuntime.java:589)\r\n\tat com.google.apphosting.runtime.JavaRuntime$NullSandboxRequestRunnable.run(JavaRuntime.java:783)\r\n\tat com.google.apphosting.runtime.ThreadGroupPool$PoolEntry.run(ThreadGroupPool.java:263)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\n```\r\n\r\nAny idea?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2333",
        "number": 2333,
        "title": "custom metrics API: simplification suggestion",
        "labels": [
            "api: monitoring",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Suggestion: \r\n\r\nRemove the Metric class and have MetricDescriptor settable on CreateTimeSeriesRequest - or something similar. \r\n\r\nBackground: \r\n\r\nBased on [the user guide](https://cloud.google.com/monitoring/custom-metrics/creating-metrics) to create custom metrics, I have to create a MetricDescriptor: \r\n\r\n````\r\nfinal MetricServiceClient client = MetricServiceClient.create();\r\nProjectName name = ProjectName.create(projectId);\r\n\r\nMetricDescriptor descriptor = MetricDescriptor.newBuilder()\r\n    .setType(metricType)\r\n    .setDescription(\"This is a simple example of a custom metric.\")\r\n    .setMetricKind(MetricDescriptor.MetricKind.GAUGE)\r\n    .setValueType(MetricDescriptor.ValueType.DOUBLE)\r\n    .build();\r\n\r\nCreateMetricDescriptorRequest request = CreateMetricDescriptorRequest.newBuilder()\r\n    .setNameWithProjectName(name)\r\n    .setMetricDescriptor(descriptor)\r\n    .build();\r\n\r\nclient.createMetricDescriptor(request);\r\n````\r\nGreat, now I have a metricDescriptor. What can I do with it? Nothing really.\r\nIn order [to write data, I'll need to create a TimeSeries](https://cloud.google.com/monitoring/custom-metrics/creating-metrics#writing-ts), and that needs another representation of this metric/metricdescriptor called ``Metric``:\r\n\r\n````\r\n// Prepares the metric descriptor\r\nMetric metric = Metric.newBuilder()\r\n    .setType(\"custom.googleapis.com/my_metric\")\r\n    .build();\r\n...\r\n// create time series\r\nTimeSeries timeSeries = TimeSeries.newBuilder()\r\n    .setMetric(metric)\r\n...\r\n````\r\nOKay, so I can't reuse the ``MetricDescriptor``, I'll use ``Metric``.\r\nBut then on the ``TimeSeries``, I have ``.setMetricKind``, ``.setMetricKindValue``... I guess it is there so that if I create a ``TimeSeries`` without a ``MetricDescriptor`` first, the descriptor can be implicitly created. But then why introduce a separete class for it called ``Metric`` that doesn't even have the Kind, KindValue (~= ValueType? or just repetition?). \r\n\r\n![image](https://user-images.githubusercontent.com/635073/29227074-66e9189c-7ea2-11e7-9be7-738f97806ca1.png)\r\n\r\n![image](https://user-images.githubusercontent.com/635073/29227117-9ba29d9c-7ea2-11e7-9c5d-24eb3ddf907f.png)\r\n\r\nI find the situation confusing, as \r\n* the difference between Metric and MetricDescriptor is unclear\r\n* Metric related methods are lingering in the CreateTimeSeriesRequest\r\n* the difference between CreateTimeSeriesRequest.setMetricKind and CreateTimeSeriesRequest.setMetricKindValue is unclear for first look...is it possible to get rid of setMetricKindValue? \r\n\r\nI understand that this code is largely generated for now from the protobufs (#2331), I would offer this issue as an example where the user experience can be increased significantly and how the generated code is not user friendly by default. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2331",
        "number": 2331,
        "title": "chatty API",
        "labels": [
            "api: monitoring",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Why is the python code so much smaller than the Java/C#? We should have similar (small) verbosity on all the platforms. I see no good reason not to create a nice DSL on top of the more verbose builders.\r\n\r\nExample: \r\n[python code to read timeseries](https://cloud-dot-devsite.googleplex.com/monitoring/custom-metrics/reading-metrics#monitoring-read-timeseries-fields-python): \r\n```\r\nclient = monitoring.Client()\r\nmetric = 'compute.googleapis.com/instance/cpu/utilization'\r\nquery_results = client.query(metric, minutes=5).iter(headers_only=True)\r\nfor result in query_results:\r\n    print(result)\r\n```\r\nvs\r\n[java code to read timeseries](https://cloud-dot-devsite.googleplex.com/monitoring/custom-metrics/reading-metrics#monitoring-read-timeseries-fields-java)\r\n```\r\nMetricServiceClient metricServiceClient = MetricServiceClient.create();\r\nString projectId = System.getProperty(\"projectId\");\r\nProjectName name = ProjectName.create(projectId);\r\n\r\n// Restrict time to last 20 minutes\r\nlong startMillis = System.currentTimeMillis() - ((60 * 20) * 1000);\r\nTimeInterval interval = TimeInterval.newBuilder()\r\n    .setStartTime(Timestamps.fromMillis(startMillis))\r\n    .setEndTime(Timestamps.fromMillis(System.currentTimeMillis()))\r\n    .build();\r\n\r\nListTimeSeriesRequest.Builder requestBuilder = ListTimeSeriesRequest.newBuilder()\r\n    .setNameWithProjectName(name)\r\n    .setFilter(\"metric.type=\\\"compute.googleapis.com/instance/cpu/utilization\\\"\")\r\n    .setInterval(interval)\r\n    .setView(ListTimeSeriesRequest.TimeSeriesView.HEADERS);\r\n\r\nListTimeSeriesRequest request = requestBuilder.build();\r\n\r\nPagedResponseWrappers.ListTimeSeriesPagedResponse response = metricServiceClient\r\n    .listTimeSeries(request);\r\n\r\nSystem.out.println(\"Got timeseries headers: \");\r\nfor (TimeSeries ts : response.iterateAll()) {\r\n  System.out.println(ts);\r\n}\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2326",
        "number": 2326,
        "title": "Spanner integration tests failing with internal error \"Invalid query plan\"",
        "labels": [
            "api: spanner",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "See https://ci.appveyor.com/project/googlejavacloud/google-cloud-java-v0gf7/build/682#L5892\r\n\r\nTwo tests failed - `analyzePlan` and `analyzeProfile`. The trace for `analyzeProfile` is below.\r\n\r\n```\r\nTests run: 50, Failures: 0, Errors: 2, Skipped: 2, Time elapsed: 10.794 sec <<< FAILURE! - in com.google.cloud.spanner.it.ITQueryTest\r\nanalyzeProfile(com.google.cloud.spanner.it.ITQueryTest)  Time elapsed: 0.047 sec  <<< ERROR!\r\ncom.google.cloud.spanner.SpannerException: INTERNAL: Invalid query plan.\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerExceptionPreformatted(SpannerExceptionFactory.java:119)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:71)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:58)\r\n\tat com.google.cloud.spanner.SpannerImpl$GrpcStreamIterator.computeNext(SpannerImpl.java:2122)\r\n\tat com.google.cloud.spanner.SpannerImpl$GrpcStreamIterator.computeNext(SpannerImpl.java:2068)\r\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:145)\r\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:140)\r\n\tat com.google.cloud.spanner.SpannerImpl$ResumableStreamIterator.computeNext(SpannerImpl.java:2209)\r\n\tat com.google.cloud.spanner.SpannerImpl$ResumableStreamIterator.computeNext(SpannerImpl.java:2165)\r\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:145)\r\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:140)\r\n\tat com.google.cloud.spanner.SpannerImpl$GrpcValueIterator.ensureReady(SpannerImpl.java:2358)\r\n\tat com.google.cloud.spanner.SpannerImpl$GrpcValueIterator.getMetadata(SpannerImpl.java:2331)\r\n\tat com.google.cloud.spanner.SpannerImpl$GrpcResultSet.next(SpannerImpl.java:1651)\r\n\tat com.google.cloud.spanner.ForwardingResultSet.next(ForwardingResultSet.java:34)\r\n\tat com.google.cloud.spanner.SessionPool$AutoClosingReadContext$1.next(SessionPool.java:95)\r\n\tat com.google.cloud.spanner.it.ITQueryTest.analyzeProfile(ITQueryTest.java:604)\r\nCaused by: com.google.cloud.spanner.SpannerException: INTERNAL: Invalid query plan.\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerExceptionPreformatted(SpannerExceptionFactory.java:119)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:43)\r\n\tat com.google.cloud.spanner.SpannerExceptionFactory.newSpannerException(SpannerExceptionFactory.java:80)\r\n\tat com.google.cloud.spanner.spi.v1.GrpcSpannerRpc$ResultSetStreamObserver.onError(GrpcSpannerRpc.java:520)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.spi.v1.SpannerErrorInterceptor$1$1.onClose(SpannerErrorInterceptor.java:100)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.spi.v1.WatchdogInterceptor$MonitoredCall$1.onClose(WatchdogInterceptor.java:190)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.GceTestEnvConfig$GrpcErrorInjector$1$1.onClose(GceTestEnvConfig.java:119)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)\r\n\tat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:512)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:429)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:544)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:117)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: INTERNAL: Invalid query plan.\r\n\tat io.grpc.Status.asRuntimeException(Status.java:543)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.spi.v1.SpannerErrorInterceptor$1$1.onClose(SpannerErrorInterceptor.java:100)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.spi.v1.WatchdogInterceptor$MonitoredCall$1.onClose(WatchdogInterceptor.java:190)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.GceTestEnvConfig$GrpcErrorInjector$1$1.onClose(GceTestEnvConfig.java:119)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)\r\n\tat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:512)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:429)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:544)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:117)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\ncc @vkedia"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2322",
        "number": 2322,
        "title": "Add code sample to Publisher for customizing credentials",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This should work:\r\n\r\n```\r\nPublisher\r\n  .defaultBuilder(topic)\r\n  .setCredentialsProvider(FixedCredentialsProvider.create(yourCredentialsHere))\r\n  .build();\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2321",
        "number": 2321,
        "title": "DLP should use default Java `java.awt.Color` class and not redefine a `Color` class with limited functionalities",
        "labels": [
            "api: dlp",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "```\r\nImageRedactionConfig imageRedactionConfig = ImageRedactionConfig.newBuilder()\r\n          .setInfoType(infoType)\r\n          .setRedactionColor(Color.newBuilder().setBlue())\r\n          .build();\r\n```\r\n\r\n`setRedactionColor` takes in a custom `com.google.privacy.dlp.v2beta1.Color.class` : requiring the use of builders to set RGB values : \r\nThis is a painful user experience."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2319",
        "number": 2319,
        "title": "Create README files for all APIs",
        "labels": [
            "api: cloudtrace",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Few that I found :\r\n\r\n- https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-dep-verification\r\n- https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-trace"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2316",
        "number": 2316,
        "title": "MVM GAE Compat -> Flex conversion Datastore w/ Objectify faster than g-c-j API's",
        "labels": [
            "api: datastore",
            "performance",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Customer is doing a single read:\r\n* Task: read 20,000+ entities\r\n* Using Objectify on MVM-Java-Compat: 6 seconds to fetch (old api's)\r\n* Using google-cloud-storage on Flex: 40 seconds to fetch\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2315",
        "number": 2315,
        "title": "JVM Hangs on gRPC if you don't close Spanner Object",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I ran across a path with the Java Spanner client that if you create several Spanner instances and do not explicitly close them the JVM will hang (it will not terminate it's process after code execution).\r\n\r\nTo reproduce the behavior create an object that wraps Spanner creation. Create the object several times in a loop. Then execute some additional code.  \r\n\r\nYou can see the hanging wait on KQueueArrayWrapper.\r\n\r\nThanks.\r\n\r\n![screen shot 2017-08-07 at 9 05 21 pm](https://user-images.githubusercontent.com/10247749/29055913-43020fd8-7bb4-11e7-8b5d-aa1dcf718525.png)\r\n\r\n![screen shot 2017-08-07 at 9 05 36 pm](https://user-images.githubusercontent.com/10247749/29055921-5595b730-7bb4-11e7-80b5-2ca4ad7923c3.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2310",
        "number": 2310,
        "title": "java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.",
        "labels": [
            "api: logging",
            "dependencies",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi,\r\n \r\nI am trying to read the content of StackDriver Logging . It is standalone java program.\r\n\r\nHowever getting the following exception:\r\n\r\njava.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:66)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:58)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:445)\r\n\tat com.google.cloud.logging.LoggingOptions.getLoggingRpcV2(LoggingOptions.java:134)\r\n\tat com.google.cloud.logging.LoggingImpl.<init>(LoggingImpl.java:108)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:46)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:41)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:432)\r\n\tat com.mycompany.googlecomponents.example.App.<init>(App.java:33)\r\n\tat com.mycompany.googlecomponents.example.App.main(App.java:38)\r\nCaused by: java.io.IOException: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:140)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:64)\r\n\t... 9 more\r\nCaused by: java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:174)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:151)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:139)\r\n\tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:109)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:470)\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:338)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:305)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:125)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:110)\r\n\tat com.google.api.gax.grpc.GrpcTransportProvider.getTransport(GrpcTransportProvider.java:98)\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:111)\r\n\r\njava program:\r\n=========\r\n\r\n```\r\npublic class App {\r\n\t\r\n\tprivate final Logging logging = LoggingOptions.getDefaultInstance().getService();\r\n\r\n\tpublic static void main(String[] args) {\r\n\t\tString filter =\"logName=projects/*************************_log\";\r\n\t\tApp obj =  new App();\r\n\t\tobj.listLogEntries(filter);\r\n\t}\r\n\t\r\n\tpublic Page<LogEntry> listLogEntries(String filter) {\r\n\t    Page<LogEntry> entries = logging.listLogEntries(EntryListOption.filter(filter));\r\n\t    for (LogEntry entry : entries.iterateAll()) {\r\n\t      System.out.println(\"entry:::\"+entry.toString());\r\n\t    }\r\n\t    return entries;\r\n\t  }\r\n}\r\n```\r\nsnippet of pom.xml file \r\n-------------------------\r\n\r\n```\r\n**<properties>\r\n    <maven.compiler.target>1.8</maven.compiler.target>\r\n    <maven.compiler.source>1.8</maven.compiler.source>\r\n   </properties>\r\n  \r\n  <dependencies>\r\n  \t<dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-logging</artifactId>\r\n      <version>1.3.1</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>io.netty</groupId>\r\n      <artifactId>netty-tcnative-boringssl-static</artifactId>\r\n      <version>2.0.5.Final</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>junit</groupId>\r\n      <artifactId>junit</artifactId>\r\n      <version>3.8.1</version>\r\n      <scope>test</scope>\r\n    </dependency>\r\n  </dependencies>**\r\n```\r\n\r\nAny suggestion? Thanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2309",
        "number": 2309,
        "title": "Datastore Cloud Emulator refuses connections",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Running unit tests from Maven, my code starts `DatastoreCloudOnTestHelper`. All connections to the Datastore emulator are refused. Stacktrace below.\r\n\r\nNotes:\r\n- Everything works OK when running tests from TestNG plugin in Eclipse. \r\n-- Using detailed logs in the Google Cloud code, I learned that the reason is this: In Eclipse, `GcloudEmulatorRunner`  silently fails to start, so that the test-helper falls back to an emulator which it downloads from Google Cloud Storage. This downloaded emulator allow connections. In contrast, when running from Maven, the `GcloudEmulatorRunner` completes its starts up \"successfully,\" so that `GcloudEmulatorRunner`  is used -- but it refuses connections. Ironically, then, it is the fallback to the less-preferred emulator  which allows the tests  to proceed in Eclipse.\r\n- On a colleague's machine, even running from Maven, everything works OK.\r\n- Simply running the emulator  from the command line (`gcloud beta emulators datastore start ...`) allows connections -- everything works OK.\r\n- My gcloud is fully up to date : `gcloud components list, Your current Cloud SDK version is: 164.0.0.\r\nThe latest available version is: 164.0.0`.\r\n- I checked  whether the Windows Firewall is blocking this `java.exe` --  it is not.\r\n\r\nHow can I get this to work?\r\n\r\n ```\r\n\r\nINFO: Initialized Google Cloud Datastore with options gcloud-java/1.2.0:localhost:51321\r\n \r\nSEVERE:  ``java.net.ConnectException: Connection refused: connect  Connection refused: connect\r\njava.net.ConnectException: Connection refused: connect\r\n        at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)\r\n        at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85)\r\n        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\r\n        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\r\n        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\r\n        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\r\n        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\r\n        at java.net.Socket.connect(Socket.java:589)\r\n        at sun.net.NetworkClient.doConnect(NetworkClient.java:175)\r\n        at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)\r\n        at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)\r\n        at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)\r\n        at sun.net.www.http.HttpClient.New(HttpClient.java:308)\r\n        at sun.net.www.http.HttpClient.New(HttpClient.java:326)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1169)\r\n        at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1105)\r\n        at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:999)\r\n        at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:933)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1283)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1258)\r\n        at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n        at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n        at com.google.datastore.v1.client.RemoteRpc.call(RemoteRpc.java:87)\r\n        at com.google.datastore.v1.client.Datastore.commit(Datastore.java:84)\r\n        at com.google.cloud.datastore.spi.v1.HttpDatastoreRpc.commit(HttpDatastoreRpc.java:152)\r\n        at com.google.cloud.datastore.DatastoreImpl$5.call(DatastoreImpl.java:418)\r\n        at com.google.cloud.datastore.DatastoreImpl$5.call(DatastoreImpl.java:415)\r\n        at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93)\r\n        at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49)\r\n        at com.google.cloud.datastore.DatastoreImpl.commit(DatastoreImpl.java:414)\r\n        at com.google.cloud.datastore.DatastoreImpl.commitMutation(DatastoreImpl.java:408)\r\n        at com.google.cloud.datastore.DatastoreImpl.put(DatastoreImpl.java:368)\r\n        at com.google.cloud.datastore.DatastoreHelper.put(DatastoreHelper.java:55)\r\n        at com.google.cloud.datastore.DatastoreImpl.put(DatastoreImpl.java:343)\r\n      "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2308",
        "number": 2308,
        "title": "Provide a way to create a TableDefinition from a schema file",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be useful to have a way to create a TableDefinition from a schema file. For example something like:\r\n\r\n```\r\nSchema schema = Schema.fromFile(schemaFile);\r\nTableDefinition tableDefinition = StandardTableDefinition.of(schema);\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2307",
        "number": 2307,
        "title": "Create BOM for google-cloud-java",
        "labels": [
            "api: core",
            "dependencies",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Example BOM:\r\n\r\nhttps://github.com/spring-cloud/spring-cloud-gcp/blob/master/spring-cloud-gcp-dependencies/pom.xml\r\n\r\nHere is how Spring Cloud uses the BOM for their dependencies:\r\n\r\nhttps://spring.io/blog/2016/09/26/spring-cloud-camden-release-and-brixton-sr6-are-available\r\n\r\nThe work for us is the following:\r\n\r\n1. Extract dependencyManagement and pluginManagement to a dedicated pom.xml (e.g., artifact: google-cloud-java-bom)\r\n2. In the parent pom.xml, import the BOM\r\n\r\nThen consumers can import the BOM too, instead of specifying individual versions.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2306",
        "number": 2306,
        "title": "Spanner API NPE on Java8 GAE Standard",
        "labels": [
            "api: spanner",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm using Spanner API from Java8 GAE Standard App's http servlet, and when I try to execute a query in response to a GET request, I see the following exception in the logs, after which my request seem to hang\r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat com.google.apphosting.runtime.ApiProxyImpl$CurrentRequestThreadFactory.newThread(ApiProxyImpl.java:1267)\r\n\tat com.google.common.util.concurrent.ThreadFactoryBuilder$1.newThread(ThreadFactoryBuilder.java:162)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:612)\r\n\tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:925)\r\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1368)\r\n\tat io.grpc.internal.DelayedClientTransport.reprocess(DelayedClientTransport.java:305)\r\n\tat io.grpc.internal.ManagedChannelImpl$LbHelperImpl$5.run(ManagedChannelImpl.java:733)\r\n\tat io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:87)\r\n\tat io.grpc.internal.DelayedClientTransport.newStream(DelayedClientTransport.java:185)\r\n\tat io.grpc.internal.ClientCallImpl.start(ClientCallImpl.java:222)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.cloud.spanner.spi.v1.WatchdogInterceptor$MonitoredCall.start(WatchdogInterceptor.java:194)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.cloud.spanner.spi.v1.SpannerErrorInterceptor$1.start(SpannerErrorInterceptor.java:67)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.cloud.spanner.spi.v1.GrpcSpannerRpc$MetadataClientCall.start(GrpcSpannerRpc.java:466)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:276)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:252)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:186)\r\n\tat com.google.cloud.spanner.spi.v1.GrpcSpannerRpc.doUnaryCall(GrpcSpannerRpc.java:430)\r\n\tat com.google.cloud.spanner.spi.v1.GrpcSpannerRpc.createSession(GrpcSpannerRpc.java:333)\r\n\tat com.google.cloud.spanner.SpannerImpl$2.call(SpannerImpl.java:221)\r\n\tat com.google.cloud.spanner.SpannerImpl$2.call(SpannerImpl.java:218)\r\n\tat com.google.cloud.spanner.SpannerImpl.runWithRetries(SpannerImpl.java:200)\r\n\tat com.google.cloud.spanner.SpannerImpl.createSession(SpannerImpl.java:217)\r\n\tat com.google.cloud.spanner.SessionPool$4.run(SessionPool.java:1063)\r\n```\r\n\r\nThe test code I'm using is taken from the Spanner examples:\r\n```\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-spanner</artifactId>\r\n  <version>0.21.1-beta</version>\r\n</dependency>\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud</artifactId>\r\n  <version>0.21.0-alpha</version>\r\n</dependency>\r\n```\r\n\r\n```\r\nimport com.google.cloud.spanner.DatabaseClient;\r\nimport com.google.cloud.spanner.DatabaseId;\r\nimport com.google.cloud.spanner.ResultSet;\r\nimport com.google.cloud.spanner.Spanner;\r\nimport com.google.cloud.spanner.SpannerOptions;\r\nimport com.google.cloud.spanner.Statement;\r\n```\r\n\r\nSample code within http servlet's doGet method:\r\n```\r\n      SpannerOptions options = SpannerOptions.newBuilder().build();\r\n      Spanner spanner = options.getService();\r\n      try {\r\n        DatabaseClient dbClient = spanner.getDatabaseClient(DatabaseId.of(\r\n            options.getProjectId(), \"spanner123\", \"xyzdb\"));\r\n        // Queries the database\r\n        try (ResultSet resultSet = dbClient.singleUse()\r\n             .executeQuery(Statement.of(\"SELECT 1\"))) {\r\n          while (resultSet.next()) {\r\n            System.out.printf(\"%d\\n\\n\", resultSet.getLong(0));\r\n          }\r\n        }\r\n      } finally {\r\n        spanner.close();\r\n      }\r\n```\r\n\r\nI believe the exception is thrown within `dbClient.singleUse().executeQuery(Statement.of(\"SELECT 1\"))` call.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2305",
        "number": 2305,
        "title": "CloudStorage: ApiProxy$RPCFailedException: The remote RPC to the application server failed for the call urlfetch.Fetch().",
        "labels": [
            "running on app engine"
        ],
        "state": "closed",
        "body": "In a Java 8 flexible environment I'm trying to retrieve a file from cloud storage like this:\r\n\r\n```\r\n    private static byte[] retrieveFile(final String fileName) {\r\n        final Storage cloudStorage = StorageOptions.getDefaultInstance().getService();\r\n        final String bucketName = GcpProjects.getDefaultProjectId() + \"-data\";\r\n        try {\r\n            final Blob blob = cloudStorage.get(BlobId.of(bucketName, fileName));\r\n            if (!blob.exists()) {\r\n                throw new RuntimeException(fileName + \" not found in bucket \" + bucketName);\r\n            }\r\n            return blob.getContent();\r\n        } catch (StorageException e) {\r\n            throw new RuntimeException(\"Error obtaining \" + fileName + \" from bucket \" + bucketName, e);\r\n        }\r\n    }\r\n```\r\n\r\nThis worked fine for me in the J8 standard environment, but in the flexible environment the ```Storage.get(BlobId)``` call fails with:\r\n\r\n```\r\nCaused by: com.google.cloud.storage.StorageException: com.google.apphosting.api.ApiProxy$RPCFailedException: The remote RPC to the application server failed for the call urlfetch.Fetch().\r\n\tat com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:196) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\nCaused by: com.google.apphosting.api.ApiProxy$RPCFailedException: The remote RPC to the application server failed for the call urlfetch.Fetch().\r\n\tat com.google.apphosting.vmruntime.VmApiProxyDelegate.runSyncCall(VmApiProxyDelegate.java:175) ~[appengine-managed-runtime-1.9.40.sync-SNAPSHOT.jar:201703172103]\r\n\tat com.google.apphosting.vmruntime.VmApiProxyDelegate.makeApiCall(VmApiProxyDelegate.java:155) ~[appengine-managed-runtime-1.9.40.sync-SNAPSHOT.jar:201703172103]\r\n\tat com.google.apphosting.vmruntime.VmApiProxyDelegate.makeSyncCallWithTimeout(VmApiProxyDelegate.java:143) ~[appengine-managed-runtime-1.9.40.sync-SNAPSHOT.jar:201703172103]\r\n\tat com.google.apphosting.vmruntime.VmApiProxyDelegate.makeSyncCall(VmApiProxyDelegate.java:132) ~[appengine-managed-runtime-1.9.40.sync-SNAPSHOT.jar:201703172103]\r\n\tat com.google.apphosting.vmruntime.VmApiProxyDelegate.makeSyncCall(VmApiProxyDelegate.java:75) ~[appengine-managed-runtime-1.9.40.sync-SNAPSHOT.jar:201703172103]\r\n\tat com.google.apphosting.api.ApiProxy.makeSyncCall(ApiProxy.java:118) ~[appengine-api-1.0-sdk-1.9.40.jar:na]\r\n\tat com.google.appengine.api.urlfetch.URLFetchServiceImpl.fetch(URLFetchServiceImpl.java:40) ~[appengine-api-1.0-sdk-1.9.40.jar:na]\r\n\tat com.google.api.client.extensions.appengine.http.UrlFetchRequest.execute(UrlFetchRequest.java:74) ~[google-http-client-appengine-1.22.0.jar:1.22.0]\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981) ~[google-http-client-1.22.0.jar:1.22.0]\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[google-api-client-1.22.0.jar:1.22.0]\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[google-api-client-1.22.0.jar:1.22.0]\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[google-api-client-1.22.0.jar:1.22.0]\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:337) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94) ~[gax-1.5.0.jar:na]\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54) ~[google-cloud-core-1.3.1.jar:1.3.1]\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188) ~[google-cloud-storage-1.3.1.jar:1.3.1]\r\n```\r\n\r\nIt doesn't say _why_ the ```urlfetch``` call failed, unfortunately.  This was built from a Gradle project with the following dependencies:\r\n\r\n```\r\ndependencies {\r\n  providedCompile 'javax.servlet:javax.servlet-api:3.1.0'\r\n  providedCompile 'com.google.appengine:appengine:+'\r\n  testCompile 'org.eclipse.jetty:jetty-server:9.+'\r\n  testCompile 'org.eclipse.jetty:jetty-servlet:9.+'\r\n  compile group: 'com.google.guava', name: 'guava', version: '19.+'\r\n  compile group: 'com.google.inject', name: 'guice', version: '4.+'\r\n  compile(group: 'com.google.api-client', name: 'google-api-client', version: '1.+') {\r\n     exclude(group: 'com.google.guava', module: 'guava-jdk5')\r\n  }\r\n  compile(group: 'com.google.api-client', name: 'google-api-client-appengine', version: '1.+') {\r\n     exclude(group: 'com.google.guava', module: 'guava-jdk5')\r\n  }\r\n  compile 'com.google.auth:google-auth-library-credentials:0.+'\r\n  compile 'com.google.cloud:google-cloud-core:1.+'\r\n  compile('com.google.apis:google-api-services-cloudkms:v1-rev15-1.+') {\r\n     exclude(group: 'com.google.guava', module: 'guava-jdk5')\r\n  }\r\n  compile 'com.google.cloud:google-cloud-storage:1.+'\r\n  compile ('com.google.cloud:google-cloud-datastore:1.+')\r\n  compile group: 'com.google.cloud', name: 'google-cloud-pubsub', version: '0.20+'\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2303",
        "number": 2303,
        "title": "Launch GCE instance with GPU support",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Seems like specifying `AcceleratorConfig` is supported in the latest version of _google-api-services-compute_ [version: _v1-rev151-1.22.0_]. Any plans of enabling this SDK to utilize that and launch a GCE instance with _K80_ or P100 GPUs? Thanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2302",
        "number": 2302,
        "title": "Reading the logs from StackDriver Logging",
        "labels": [
            "api: logging",
            "dependencies",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Hi All,\r\n\r\nI am using  following dependency to interact with GCP StackDriver Logging.\r\n<dependency>\r\n    <groupId>com.google.cloud</groupId>\r\n    <artifactId>google-cloud-logging</artifactId>\r\n    <version>1.0.1</version>\r\n</dependency>\r\n\r\nJava Code:\r\nPage<LogEntry> entries = logging.listLogEntries(EntryListOption.filter(filter));\r\n\t\t    for (LogEntry entry : entries.iterateAll()) { \r\n\t\t      System.out.println(\"entry:::\"+entry.toString());\r\n\t\t    }\r\nHowever getting following exception:\r\nException in thread \"main\" java.lang.NoSuchMethodError: com.google.common.util.concurrent.MoreExecutors.directExecutor()Ljava/util/concurrent/Executor;\r\n\tat io.grpc.internal.ClientCallImpl.<init>(ClientCallImpl.java:105)\r\n\tat io.grpc.internal.ManagedChannelImpl$RealChannel.newCall(ManagedChannelImpl.java:560)\r\n\tat com.google.api.gax.grpc.AuthInterceptor.interceptCall(AuthInterceptor.java:52)\r\n\tat io.grpc.ClientInterceptors$InterceptorChannel.newCall(ClientInterceptors.java:119)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor.interceptCall(HeaderInterceptor.java:57)\r\n\tat io.grpc.ClientInterceptors$InterceptorChannel.newCall(ClientInterceptors.java:119)\r\n\tat io.grpc.internal.ManagedChannelImpl.newCall(ManagedChannelImpl.java:536)\r\n\r\nIs there any fix available for this issue in any other version of gc logging jars? Your input is highly appreciated. Thanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2301",
        "number": 2301,
        "title": "google-cloud-storage README example is incorrect",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "We have the following example:\r\n`Iterator<Bucket> bucketIterator = storage.list().iterateAll();`\r\n\r\nHowever, storage.list().iterateAll() does not return java.util.Iterator<Bucket>, instead \r\njava.lang.Iterable<Bucket> is returned. \r\n\r\nConsider changing the example to a 'for' loop, e.g.:\r\n```\r\n      Storage storage = StorageOptions.getDefaultInstance().getService();\r\n      for(Bucket bucket : storage.list().iterateAll()) {\r\n        ...\r\n      }\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2300",
        "number": 2300,
        "title": "GAE Java8 Standard, BigQuery API throws \"Invalid Project Id\"",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "Environment: App Engine Standard Java 8.\r\nIn pom.xml I have the following:\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud</artifactId>\r\n  <version>0.21.0-alpha</version>\r\n</dependency>\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-bigquery</artifactId>\r\n  <version>0.21.1-beta</version>\r\n</dependency>\r\n\r\nMy app has this example in a servlet:\r\n    BigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\n    String datasetId = \"my_dataset_id\";\r\n    bigquery.create(DatasetInfo.newBuilder(datasetId).build());\r\n\r\nWhen the servlet is called, I get the following exception:\r\ncom.google.cloud.bigquery.BigQueryException: Invalid project ID 'MyProjIDHere'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. IDs must start with a letter and may not end with a dash.\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:86)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.create(HttpBigQueryRpc.java:141)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:172)\r\n\tat com.google.cloud.bigquery.BigQueryImpl$1.call(BigQueryImpl.java:169)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:169)\r\n\tat com.google.test.HelloAppEngine.doGet(HelloAppEngine.java:56)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2297",
        "number": 2297,
        "title": "How can I set bigquery streaming insert timeout?",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I caused Error.\r\nHow can I set timeout (read timeout?)?\r\n```\r\ncom.google.cloud.bigquery.BigQueryException: Read timed out\r\n        at com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:86)\r\n        at com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.insertAll(HttpBigQueryRpc.java:283)\r\n        at com.google.cloud.bigquery.BigQueryImpl.insertAll(BigQueryImpl.java:443)\r\n        at jp.co.xxx.BigQuerySender.insertStreamingData(BigQuerySender.java:68)\r\n        at jp.co.xxx.BigQuerySender.insert(BigQuerySender.java:60)\r\n        at jp.co.xxx.GcpSender.run(GcpSender.java:67)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.net.SocketTimeoutException: Read timed out\r\n        at java.net.SocketInputStream.socketRead0(Native Method)\r\n        at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)\r\n        at java.net.SocketInputStream.read(SocketInputStream.java:171)\r\n        at java.net.SocketInputStream.read(SocketInputStream.java:141)\r\n        at sun.security.ssl.InputRecord.readFully(InputRecord.java:465)\r\n        at sun.security.ssl.InputRecord.read(InputRecord.java:503)\r\n        at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973)\r\n        at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930)\r\n        at sun.security.ssl.AppInputStream.read(AppInputStream.java:105)\r\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\r\n        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\r\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)\r\n        at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735)\r\n        at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569)\r\n        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474)\r\n        at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)\r\n        at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338)\r\n        at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37)\r\n        at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94)\r\n        at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n        at com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.insertAll(HttpBigQueryRpc.java:281)\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2296",
        "number": 2296,
        "title": "Add Support for Specifying Min CPU Platform",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hi, \r\n\r\nI would like to be able to specify the [minimum CPU platform](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform) (e.g. Intel Skylake) for a VM, but I don't see where I can specify it. I would expect a method like `setMinCpuPlatform` on `InstanceInfo`. If it is not supported, do you plan on supporting it?\r\n\r\nThanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2295",
        "number": 2295,
        "title": "Make `google-cloud-java` API exception handling easier",
        "labels": [
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Users should have clear access to exceptions and their status codes in a transport (gRPC/HTTP) agnostic way, so that they may be handled appropriately in the client.\r\n\r\nCurrently, there is an inconsistent surface.\r\nLibraries like Spanner provide [SpannerException](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/SpannerException.java) while others return [BaseGrpcServiceException](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core-grpc/src/main/java/com/google/cloud/grpc/BaseGrpcServiceException.java)\r\n@lesv "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2290",
        "number": 2290,
        "title": "ServiceOptions#getApplicationName() - performance issue",
        "labels": [
            "api: datastore",
            "performance",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Dear Google Team,\r\n\r\nDuring our company internal performance testing we found that there are some places for improvement (although it's not critical but very nice to have). Method com.google.cloud.ServiceOptions#getApplicationName() is used with each request (for example from code of method com.google.cloud.datastore.spi.v1.HttpDatastoreRpc#getHttpRequestInitializer() )\r\n. This method is used each time during EACH request. Basically what it does under the hood: it loads some resource from classpath with EACH request. It is leading to not necessary memory and CPU consumption. It is especially notable on a high-loaded project with millions requests per day. \r\n\r\nProposal is to cache result of method ServiceOptions#getApplicationName(). It's constant value anyway(by it's nature) - so there's no need to load it each time with each request (it won't change). Or load it once on startup.\r\n\r\nBug found in a library: com.google.cloud:google-cloud-datastore:1.2.3\r\n\r\nBest Regards,\r\nDionis Argiri\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2289",
        "number": 2289,
        "title": "Google Translate api ClassNotFoundException/NoClassDefFoundError errors ",
        "labels": [
            "api: translation",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello so when i try using the google translate api i get this errors \r\n\r\njava.lang.ClassNotFoundException: com.google.cloud.ServiceOptions\r\njava.lang.NoClassDefFoundError: com/google/cloud/translate/TranslateOptions\r\njava.lang.NoClassDefFoundError: com/google/cloud/ServiceOptions\r\n\r\ni use \r\ngoogle-cloud-translate-1.2.3.jar\r\n![screenshot_18](https://user-images.githubusercontent.com/29629145/28713734-a71513b6-7390-11e7-9f17-41a2da1fe63a.png)\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2276",
        "number": 2276,
        "title": "We can not access the URL currently. Please download the content and pass it in.",
        "labels": [],
        "state": "closed",
        "body": "When working on the remote label detection i get this message on many (like really many) accessible and existing images.\r\ne.g. http://heizung-dinges.de/assets/images/Koebig2.jpg \r\nAlso some other times i will get the message Bad image data. On different existing and accessible images.  Re-requesting the API is not working, same exact errors will occur."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2275",
        "number": 2275,
        "title": "PubSub: NullPointerException at com.google.apphosting.runtime.ApiProxyImpl$CurrentRequestThreadFactory.newThread(ApiProxyImpl.java:1267)",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "After upgrading my PubSub client to ```0.20.3-beta``` (as well as a few other Google dependencies) and switching from the Java8 flexible environment to the Java8 standard environment I'm no longer able to publish messages to my PubSub topic.  I'm seeing this error in the logs for my AppEngine standard Java8 environment after publishing a message and ```get()```ing the ```Future```:\r\n\r\n```\r\nio.grpc.internal.ChannelExecutor drain: Runnable threw exception in ChannelExecutor (ChannelExecutor.java:89)\r\njava.lang.NullPointerException\r\n\tat com.google.apphosting.runtime.ApiProxyImpl$CurrentRequestThreadFactory.newThread(ApiProxyImpl.java:1267)\r\n\tat com.google.common.util.concurrent.ThreadFactoryBuilder$1.newThread(ThreadFactoryBuilder.java:162)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:612)\r\n\tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:925)\r\n\tat java.util.concurrent.ThreadPoolExecutor.ensurePrestart(ThreadPoolExecutor.java:1587)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:336)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:555)\r\n\tat io.grpc.internal.ManagedChannelImpl.rescheduleIdleTimer(ManagedChannelImpl.java:334)\r\n\tat io.grpc.internal.ManagedChannelImpl.exitIdleMode(ManagedChannelImpl.java:299)\r\n\tat io.grpc.internal.ManagedChannelImpl$4$1.run(ManagedChannelImpl.java:357)\r\n\tat io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:87)\r\n\tat io.grpc.internal.ManagedChannelImpl$4.get(ManagedChannelImpl.java:359)\r\n\tat io.grpc.internal.ClientCallImpl.start(ClientCallImpl.java:218)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:62)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:276)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:252)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:186)\r\n\tat com.google.pubsub.v1.PublisherGrpc$PublisherFutureStub.publish(PublisherGrpc.java:460)\r\n\tat com.google.cloud.pubsub.v1.Publisher.publishOutstandingBatch(Publisher.java:329)\r\n\tat com.google.cloud.pubsub.v1.Publisher.publishAllOutstanding(Publisher.java:304)\r\n\tat com.google.cloud.pubsub.v1.Publisher.access$500(Publisher.java:79)\r\n\tat com.google.cloud.pubsub.v1.Publisher$5.run(Publisher.java:283)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:295)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nI'm using a Gradle build with the following relevant dependencies:\r\n\r\n```\r\ndependencies {\r\n  providedCompile 'javax.servlet:javax.servlet-api:3.1.0'\r\n  providedCompile 'com.google.appengine:appengine:+'\r\n  testCompile 'org.eclipse.jetty:jetty-server:9.+'\r\n  testCompile 'org.eclipse.jetty:jetty-servlet:9.+'\r\n  compile group: 'com.google.guava', name: 'guava', version: '19.+'\r\n  compile group: 'com.google.inject', name: 'guice', version: '4.+'\r\n  compile 'com.google.appengine:appengine-api-1.0-sdk:1.+'\r\n  compile 'com.google.cloud:google-cloud-storage:1.2+'\r\n  compile group: 'com.google.cloud', name: 'google-cloud-pubsub', version: '0.20+'\r\n  compile ('com.google.cloud:google-cloud-datastore:1.2+')\r\n  compile('com.google.apis:google-api-services-cloudkms:v1-rev15-1.22.0') {\r\n     exclude(group: 'com.google.guava', module: 'guava-jdk5')\r\n  }\r\n  compile(group: 'com.google.api-client', name: 'google-api-client', version: '1.+') {\r\n     exclude(group: 'com.google.guava', module: 'guava-jdk5')\r\n  }\r\n  compile(group: 'com.google.api-client', name: 'google-api-client-appengine', version: '1.+') {\r\n     exclude(group: 'com.google.guava', module: 'guava-jdk5')\r\n  }\r\n}\r\n```\r\n\r\nThe deployment environment is AppEngine standard java8.  I haven't been able to find the source code for ```ApiProxyImpl.java``` anywhere, so I'm unable to do much more debugging here.  I guess I'll try downgrading the dependency and hope it works."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2274",
        "number": 2274,
        "title": "BigQuery: Can't create a table with a expirationtime",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hello,\r\nI am trying to create a table using the bigquery API in the following way:\r\n\r\n```\r\nfinal Long expirationTime = getExpirationTimeMillis(dateString);\r\n      final TableInfo tableInfo = TableInfo.newBuilder(TableId.of(project, dataset, tableId), NEW_TABLE_DEF)\r\n          .setExpirationTime(expirationTime)\r\n          .build();\r\n      LOG.info(String.format(\"Creating table: %s.%s.%s\", project, dataset, tableId));\r\n      return bigQuery.create(tableInfo);\r\n```\r\nThis gives me the following message:\r\ncom.google.cloud.bigquery.BigQueryException: Not found: Table entity-dev:joel_daily.user_daily_20170718\r\n\r\nDoing the same without .setExpirationTime(expirationTime) works fine. I don't see why I should get an issue Not found when setting the ExpirationTime.\r\n\r\nCan you please help me with this issue?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2272",
        "number": 2272,
        "title": "Auth: stop reading gcloud's configuration directly",
        "labels": [
            "auth",
            "priority: p2",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "Instead, use `gcloud config config-helper`:\r\n\r\nInstead, we should subprocess out to `gcloud config config-helper --format json`\r\n\r\nExample output:\r\n\r\n```\r\n{\r\n  \"configuration\": {\r\n    \"active_configuration\": \"default\",\r\n    \"properties\": {\r\n      \"core\": {\r\n        \"account\": \"[ELIDED]\",\r\n        \"disable_usage_reporting\": \"False\",\r\n        \"project\": \"[ELIDED]\"\r\n      }\r\n    }\r\n  },\r\n  \"credential\": {\r\n    \"access_token\": \"[ELIDED]\",\r\n    \"token_expiry\": \"2017-03-23T23:09:49Z\"\r\n  },\r\n  \"sentinels\": {\r\n    \"config_sentinel\": \"/Users/jonwayne/.config/gcloud/config_sentinel\"\r\n  }\r\n}\r\n```\r\n\r\nContext: https://github.com/GoogleCloudPlatform/google-auth-library-python/issues/146"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2270",
        "number": 2270,
        "title": "Spanner: Convenient way to read Object/Objects from db.",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be great to have a convenient way to retrieve the data as pojos from Spanner database. \r\nFor example `com.google.cloud.spanner.ReadContext` interface could be expanded with such methods for this purpose: \r\n\r\n```\r\n<T> T readRow(String table, StructMapper<T> mapper, Key key, Iterable<String> columns);\r\n<T> List<T> read(String table, StructMapper<T> mapper, KeySet keys, Iterable<String> columns, ReadOption... options);\r\n```\r\nWhere `StructMapper` is an interface that can be implemented by users for custom pojos. Also it is a reason to create default implementation that covers conversion for common types, as example `org.springframework.jdbc.core.BeanPropertyRowMapper`.\r\n\r\nIf you're ok with that I would be pleasant to make pull request. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2266",
        "number": 2266,
        "title": "Error: Jetty ALPN/NPN has not been properly configured.",
        "labels": [
            "api: logging",
            "api: speech",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I am getting the below exception when running the sample \"speech\" application as a plain java application. I have not run it on any server as of now.\r\n\r\nSample application can be found at- https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/speech/cloud-client.\r\n\r\nException in thread \"main\" java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n\tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:174)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:151)\r\n\tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:139)\r\n\tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:109)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:470)\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:338)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:305)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:139)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:116)\r\n\tat com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:65)\r\n\tat com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:91)\r\n\tat com.google.cloud.speech.v1.SpeechClient.<init>(SpeechClient.java:140)\r\n\tat com.google.cloud.speech.v1.SpeechClient.create(SpeechClient.java:131)\r\n\tat com.google.cloud.speech.v1.SpeechClient.create(SpeechClient.java:123)\r\n\tat com.example.speech.QuickstartSample.main(QuickstartSample.java:38)\r\n\r\nI have tried most of the steps provided over the net but no luck. It uses google cloud speech version - 0.20.3-alpha. I have also tried with google cloud speech version -0.17.1-alpha but same issue.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2265",
        "number": 2265,
        "title": "Credentials/Account is picked up on one machine but not another",
        "labels": [
            "auth",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "google-cloud-nio loads my credentials on one machine, but treats me as anonymous and rejects reads/writes on the other.\r\n\r\nI must have some state set on the former but not the latter that is causing this, but I can't figure out what.\r\n\r\n`gcloud config list` gives identical output on both:\r\n\r\n```bash\r\n$ gcloud config list\r\n[compute]\r\nzone = us-east1-b\r\n[core]\r\naccount = <my email>\r\ndisable_usage_reporting = False\r\nproject = <my project>\r\n\r\nYour active configuration is: [rbw]\r\n```\r\n\r\nSimple file to test reading a GCS path, `Test.java`:\r\n\r\n```java\r\nimport java.io.IOException;\r\nimport java.net.URI;\r\nimport java.nio.charset.StandardCharsets;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Path;\r\nimport java.nio.file.Paths;\r\n\r\npublic class Test {\r\n    public static void main(String[] args) throws IOException {\r\n        Path path = Paths.get(URI.create(\"gs://bucket/path\"));\r\n        System.out.println(Files.readAllLines(path, StandardCharsets.UTF_8).size());\r\n    }\r\n}\r\n```\r\n\r\nCompile it:\r\n\r\n```\r\njavac Test.java\r\n```\r\n\r\nGet latest google-cloud-nio release:\r\n\r\n```bash\r\nwget https://repo1.maven.org/maven2/com/google/cloud/google-cloud-nio/0.20.3-alpha/google-cloud-nio-0.20.3-alpha-shaded.jar\r\n```\r\n\r\nRun on machine A:\r\n\r\n```bash\r\njava -cp google-cloud-nio-0.20.3-alpha-shaded.jar:. Test\r\n```\r\n\r\nThe correct number of lines in my file `gs://bucket/path` is printed.\r\n\r\nRunning the same thing on machine B gives:\r\n\r\n```\r\n$ java -cp google-cloud-nio-0.20.3-alpha-shaded.jar:. Test\r\nException in thread \"main\" com.google.cloud.storage.StorageException: Anonymous users does not have storage.objects.get access to object bucket/path.\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335)\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191)\r\n\tat com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188)\r\n\tat shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188)\r\n\tat com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:234)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:78)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:68)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:304)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:265)\r\n\tat java.nio.file.Files.newByteChannel(Files.java:361)\r\n\tat java.nio.file.Files.newByteChannel(Files.java:407)\r\n\tat java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newInputStream(CloudStorageFileSystemProvider.java:384)\r\n\tat java.nio.file.Files.newInputStream(Files.java:152)\r\n\tat java.nio.file.Files.newBufferedReader(Files.java:2784)\r\n\tat java.nio.file.Files.readAllLines(Files.java:3202)\r\n\tat Test.main(Test.java:11)\r\nCaused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized\r\n{\r\n  \"code\" : 401,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"location\" : \"Authorization\",\r\n    \"locationType\" : \"header\",\r\n    \"message\" : \"Anonymous users does not have storage.objects.get access to object bucket/path.\",\r\n    \"reason\" : \"required\"\r\n  } ],\r\n  \"message\" : \"Anonymous users does not have storage.objects.get access to object bucket/path.\"\r\n}\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\n\tat shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:333)\r\n\t... 19 more\r\n```\r\n\r\nAFAICT, I am authed with the `gcloud` CLI the same way on both machines, per the output of `gcloud config list` above.\r\n\r\nWhat else can I look at to explain why I am treated as an \"anonymous user\" on machine B?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2257",
        "number": 2257,
        "title": "Mutation.WriteBuilder.build() does not check state",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It is possible to \"build\" a Cloud Spanner mutation with invalid internal state, specifically with multiple values bound for the same column name. Using the mutation later on (e.g. in [DatabaseClient#write](http://googlecloudplatform.github.io/google-cloud-java/0.20.2/apidocs/?com/google/cloud/spanner/package-summary.html)) will result in a SpannerException. Duplicate bindings should be detected during mutation creation, rather than letting the invalid state stay hidden. Effective Java items 2 and 34 give detailed discussion of why invariants should be checked in `build` rather than while the object is used.\r\n\r\n## Minimal Example\r\n\r\n```\r\n// This succeeds\r\nMutation m =  Mutation.newInsertBuilder().set(\"A\").to(\"val1\").set(\"A\").to(\"val2\").build();\r\n// This fails with \"INVALID_ARGUMENT: Multiple values for column...\"\r\nspannerClient.write(singletonList(m));\r\n```\r\n\r\n## Practical Example\r\n\r\nThe issue of re-binding came up when testing a thin wrapper over the mutation builder. The goal was to abstract away the binding of some complicated key columns separately from the rest of the query. I was surprised to find that I could bind multiple keys to the same mutation. It looked something like this:\r\n\r\n```\r\nWriteBuilder bindKeys(WriteBuilder wb, MyObject obj) {\r\n  return wb.set(Key1).to(obj.getA()).set(Key2).to(obj.getB());\r\n}\r\n\r\nWriteBuilder wb = Mutation.newInsertBuilder();\r\nwb = bindKeys(wb, obj1);\r\nwb = bindKeys(wb, obj2);\r\n// I expected an error, but no exception was thrown:\r\nMutation m = wb.build();\r\n\r\n// Later on, here is where the exception is thrown:\r\nspannerClient.write(< list containing mutation m >);\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2256",
        "number": 2256,
        "title": "NullPointerException in TransactionExceptionHandler",
        "labels": [],
        "state": "closed",
        "body": "Starting with `google-cloud-datastore:1.2.1`, a user exception thrown within a datastore transaction (`runInTransaction`) triggers a `NullPointerException` in `com.google.cloud.datastore.TransactionExceptionHandler`. The original exception is swallowed.\r\n\r\nFor reference, a minimal `build.gradle` which triggers the problem on `gradle run` is:\r\n```\r\nimport com.google.cloud.datastore.DatastoreOptions;\r\n\r\nbuildscript {\r\n\trepositories {\r\n                mavenCentral()\r\n                maven {\r\n                       \turl \"https://jitpack.io\"\r\n                }\r\n        }\r\n\tdependencies {\r\n                //classpath \"com.google.cloud:google-cloud-datastore:1.2.0\" // works\r\n                classpath \"com.google.cloud:google-cloud-datastore:1.2.1\" // breaks\r\n                //classpath \"com.google.cloud:google-cloud-datastore:1.2.2\" // breaks\r\n                //classpath \"com.github.GoogleCloudPlatform.google-cloud-java:google-cloud-datastore:95f0dd7eb3b7b360ce51b1930c1f75cc2bb91140\" // breaks\r\n        }\r\n}\r\n\r\ntask run() {\r\n\tdef ds = DatastoreOptions.newBuilder()\r\n                .build()\r\n                .getService();\r\n        ds.runInTransaction({ rw ->\r\n                throw new RuntimeException(\"foobar\");\r\n        });\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2255",
        "number": 2255,
        "title": "Not receiving GCS Cloud Pub/Sub Notifications.",
        "labels": [],
        "state": "closed",
        "body": "Hi There,\r\n\r\n- I am not getting object change notification using pub/sub.\r\n \r\nI created topic and sub and associated it to bucket notification as below and \r\ngsutil notification create -f json -t projects/syncdemo/topics/filesync gs://mybucket\r\n\r\nI wrote code to receive the notifications as below.\r\n\r\n            subscriptionName = SubscriptionName.create(\"syncdemo\", \"filesyncsub\");\r\n\r\n            MessageReceiver receiver =\r\n                    new MessageReceiver() {\r\n                        @Override\r\n                        public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n                            System.out.println(\"Id : \" + message.getMessageId());\r\n                            System.out.println(\"Received message: \" + message.getData());\r\n                            consumer.ack();\r\n                        }\r\n                    };\r\n\r\n            // Configure max number of messages to be pulled\r\n            FlowControlSettings flowControlSettings = FlowControlSettings.newBuilder()\r\n                    .setMaxOutstandingElementCount(1000l)\r\n                    .build();\r\n            subscriber = Subscriber.defaultBuilder(subscriptionName, receiver)\r\n                    .setFlowControlSettings(flowControlSettings)\r\n                    .build();\r\n            subscriber.startAsync();"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2250",
        "number": 2250,
        "title": "Please support multiple network interfaces for compute instances",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "If I try to attach multiple network interfaces to a compute instance, I get an `Invalid value for field 'resource': ''. Expected one network interface.`. Please add support for this.\r\n\r\nThis was already mentioned in #915 (#916 is also related), but those were closed after filing a bug (internally I assume) about documenting the limitation."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2249",
        "number": 2249,
        "title": "BigQuery: obscure exception when writing 0 bytes",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I wrote this code in an App Engine standard (Java7) application which writes a set of rows in a BigQuery table\r\n\r\nMy code started from here: https://cloud.google.com/bigquery/loading-data-post-request#bigquery-import-file-java\r\n\r\n```\r\nprivate static final Charset UTF8 = Charset.forName(\"UTF-8\");\r\n\r\n// Instantiates a client\r\nBigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\n\r\n// Create the reference for the Table\r\nTableId tableId = TableId.of(project, dataset, table);\r\n\r\nWriteChannelConfiguration writeChannelConfiguration = WriteChannelConfiguration\r\n    .newBuilder(tableId)\r\n    .setFormatOptions(FormatOptions.json())\r\n    .build();\r\n\r\n// Open a new channel for write\r\nTableDataWriteChannel writer = bigquery.writer(writeChannelConfiguration);\r\n\r\n// Retrieves the object from DB\r\nList<T> objects = ....;\r\n\r\n// Write data to writer\r\ntry (OutputStream stream = Channels.newOutputStream(writer)) {\r\n    // Access to iterator of the objects\r\n    Iterator<T> iterator = objects.iterator();\r\n    \r\n    while (iterator.hasNext()) {\r\n        // Retrieve the next element\r\n        T object = iterator.next();\r\n    \r\n        // Serialize the object in json format\r\n        JsonObject json = serialize(object);\r\n    \r\n        // Write the json to the stream\r\n        stream.write(json.toString().getBytes(UTF8));\r\n    \r\n        // Increment the counter\r\n        index++;\r\n    \r\n        // Check if additional records are available\r\n        if (iterator.hasNext()) {\r\n            stream.write(\"\\n\".getBytes(UTF8));\r\n        }\r\n    }\r\n}\r\n\r\n// Get job status\r\nJob job = writer.getJob();\r\n\r\n// Wait for job to end\r\ntry {\r\n    job = job.waitFor();\r\n} catch (InterruptedException | TimeoutException e) {\r\n    throw new IOException(\"WaitFor error\", e);\r\n}\r\n\r\n// Retrieve job statistics\r\nLoadStatistics stats = job.getStatistics();\r\nLOG.log(Level.INFO, \"Executed Job: {0}\", new Object[] {stats});\r\n```\r\n\r\nIn localhost works fine, w/o problems. All the rows are written and no errors raised.\r\n\r\nBut after I ran this code online I got this error\r\n\r\n```\r\n{\"message\":\"400\\nFailed to parse Content-Range header.\",\"errors\":[{\"message\":\"400\\nFailed to parse Content-Range header.\"},{\"message\":\"400\\nFailed to parse Content-Range header.\"}]}\r\n\r\nFailed to parse Content-Range header.\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:86)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.write(HttpBigQueryRpc.java:466)\r\n\tat com.google.cloud.bigquery.TableDataWriteChannel$1.call(TableDataWriteChannel.java:57)\r\n\tat com.google.cloud.bigquery.TableDataWriteChannel$1.call(TableDataWriteChannel.java:54)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n\tat com.google.cloud.bigquery.TableDataWriteChannel.flushBuffer(TableDataWriteChannel.java:53)\r\n\tat com.google.cloud.BaseWriteChannel.close(BaseWriteChannel.java:160)\r\n\tat java.nio.channels.Channels$1.close(Channels.java:178)\r\nCaused by: com.google.api.client.http.HttpResponseException: 400\r\nFailed to parse Content-Range header.\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.write(HttpBigQueryRpc.java:449)\r\n\t... 69 more\r\n```\r\n\r\n\r\n**Can this library be used on App Engine standard environment?** I'm asking this because for the [PubSub counterpart](https://cloud.google.com/pubsub/docs/reference/libraries) there is a warning\r\n\r\n> However, we recommend using the older Google APIs Client Libraries if running on Google App Engine standard environment\r\n\r\nthat I cannot see on BigQuery page.\r\n\r\nMy goal here is loading a bunch of rows directly inside the table w/o using a temporary file, loading the data directly from the application memory.\r\n\r\n\r\nI enabled the full [Log of HTTP Transport](https://developers.google.com/api-client-library/java/google-http-java-client/transport), here is a part of it\r\n```\r\ncom.google.api.client.http.HttpRequest execute: -------------- REQUEST  -------------- (HttpRequest.java:962)\r\nPUT https://www.googleapis.com/upload/bigquery/v2/projects/noovle-erp-orchestrator-dev/jobs?uploadType=resumable&upload_id=AEnB2Ur7N3UM_EkF6fpM9NQFmKhsEtS1y2IsEXM0DFjnPIAn6udvTx6gA5dWDzbfwscWkbLUXy9llTBhssjG8n-llBgSlYs-2g\r\nAccept-Encoding: gzip\r\nAuthorization: <Not Logged>\r\nContent-Range: bytes 0--1/0\r\nUser-Agent: Google-HTTP-Java-Client/1.22.0 (gzip)\r\nx-goog-api-client: gl-java/1.7.0-google-v6 gccl/0.20.1-beta\r\nContent-Length: 0\r\n```\r\n**Content-Length is 0 and Content-Range is 0** as well. Maybe this type of in-memory load does not work because I do not have in advance the size of the full data?\r\nIf so, why in localhost works fine?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2248",
        "number": 2248,
        "title": "Provide a ChannelProvider which can connect to the PubSub emulator",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "With the rest api it was possible to connect to the PubSub emulator by specifying the address\r\nof the emulator with no additional configuration.\r\n\r\nWith the gRPC api it is no longer possible. It can be done by creating a PlainText negotiated \r\nchannel but that requires us to create our own `ChannelProvider`.\r\n  \r\nThe gax libraries provide a `LocalChannelProvider` which creates a PlainText channel but it is unfortunately limited to local jvm addresses only (for in-memory gRPC service)\r\n\r\nIt would be handy to provide a `PlainTextChannelProvider` which can connect to PubSub emulator as part of the api.\r\n\r\nAs reference the following is a workable implementation\r\n\r\n```\r\npublic final class PlainTextChannelProvider implements ChannelProvider {\r\n    private final String endpoint;\r\n\r\n    private PlainTextChannelProvider(String endpoint) {\r\n        this.endpoint = endpoint;\r\n    }\r\n\r\n    @Override\r\n    public boolean shouldAutoClose() {\r\n        return false;\r\n    }\r\n\r\n    @Override\r\n    public boolean needsExecutor() {\r\n        return false;\r\n    }\r\n\r\n    @Override\r\n    public ManagedChannel getChannel() throws IOException {\r\n        return ManagedChannelBuilder.forTarget(endpoint).usePlaintext(true).build();\r\n    }\r\n\r\n    @Override\r\n    public ManagedChannel getChannel(Executor executor) throws IOException {\r\n        return getChannel();\r\n    }\r\n\r\n    public static PlainTextChannelProvider create(String endpoint) {\r\n        return new PlainTextChannelProvider(endpoint);\r\n    }\r\n}\r\n```\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2247",
        "number": 2247,
        "title": "Second query within query ignores filter",
        "labels": [],
        "state": "closed",
        "body": "The following code produces totally unexpected results.\r\n\r\n```\r\nQuery<Entity> query = Query.newEntityQueryBuilder().setKind(\"Artist\").build();\r\nQueryResults<Entity> artistEntities = datastore.run(query);\r\n\r\nwhile (artistEntities.hasNext()) {\r\n\r\n\tEntity artistEntity = artistEntities.next();\r\n\tLong artistId = artistEntity.getKey().getId();\r\n\r\n\tQuery<Entity> q1 = Query.newEntityQueryBuilder().setKind(\"Release\").setFilter(PropertyFilter.eq(\"artists\", artistId))\r\n\t\t\t\t\t.build();\r\n\r\n\tQueryResults<Entity> releaseEntities1 = datastore.run(q1);\r\n\t// this query gets the correct number of releases per artist\r\n\r\n\tQuery<Entity> q2 = Query.newEntityQueryBuilder().setKind(\"Release\").setFilter(PropertyFilter.eq(\"artists\", artistId))\r\n\t\t\t\t\t.build();\r\n\r\n\tQueryResults<Entity> releaseEntities2 = datastore.run(q2);\r\n\t// this query returns all releases in the datastore, regardless of the value passed to the filter\r\n\r\n}\r\n\r\n```\r\n\r\nOriginally the second query was supposed to retrieve kind \"Recording\". After I have encountered this weird behavior, I changed the kind to \"Release\", so that the first and the second queries are identical. Still, the first query works as expected, while the second query ignores the property filter completely.\r\n\r\nI hope I am missing something obvious. I am running v. 0.20.2. I tried older versions (to 0.18) with the same result."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2243",
        "number": 2243,
        "title": "Copying large object to a different bucket always times out",
        "labels": [
            "api: storage",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I am trying to copy a 2GB blob from one bucket to another, using the `copyTo` method of the blob. This always fails with the following exception:\r\n```\r\nException in thread \"main\" com.google.cloud.storage.StorageException: Read timed out\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.rewrite(HttpStorageRpc.java:661)\r\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.openRewrite(HttpStorageRpc.java:621)\r\n\tat com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:433)\r\n\tat com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:430)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54)\r\n\tat com.google.cloud.storage.StorageImpl.copy(StorageImpl.java:430)\r\n\tat com.google.cloud.storage.Blob.copyTo(Blob.java:493)\r\n\tat com.google.cloud.storage.Blob.copyTo(Blob.java:546)\r\n```\r\nCopying within the same bucket works as expected.  I am using the `0.20.1-alpha` version of the google cloud library."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2241",
        "number": 2241,
        "title": "Pubsub: Get AckId outside of MessageReceiver",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm basically having an issue very much like https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1981. I need to receive the message on one machine, and ack it on another (Spark). Serializing the `AckReplyConsumer` isn't straight forward, and not really a neat approach. I've managed to ack messages outside the scope of `receiveMessage` using the REST API, but I cannot figure out a way to generate the `ackId` for messages.\r\n\r\nIs this possible? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2240",
        "number": 2240,
        "title": "java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.",
        "labels": [
            "api: vision",
            "dependencies",
            "priority: p2"
        ],
        "state": "closed",
        "body": "I'm trying run a code that use a cloud-vision.\r\nEverything works normally when I use my desktop(ubuntu / windows10). But when I use a raspberry appear the following error:\r\n\r\n> Jul 16, 2017 5:52:39 PM io.grpc.internal.ChannelExecutor drain\r\n> WARNING: Runnable threw exception in ChannelExecutor\r\n> java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n> \tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:174)\r\n> \tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:151)\r\n> \tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:139)\r\n> \tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:109)\r\n> \tat io.grpc.netty.NettyChannelBuilder.createProtocolNegotiatorByType(NettyChannelBuilder.java:335)\r\n> \tat io.grpc.netty.NettyChannelBuilder.createProtocolNegotiator(NettyChannelBuilder.java:308)\r\n> \tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DynamicNettyTransportParams.getProtocolNegotiator(NettyChannelBuilder.java:499)\r\n> \tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.newClientTransport(NettyChannelBuilder.java:448)\r\n> \tat io.grpc.internal.CallCredentialsApplyingTransportFactory.newClientTransport(CallCredentialsApplyingTransportFactory.java:61)\r\n> \tat io.grpc.internal.InternalSubchannel.startNewTransport(InternalSubchannel.java:209)\r\n> \tat io.grpc.internal.InternalSubchannel.obtainActiveTransport(InternalSubchannel.java:186)\r\n> \tat io.grpc.internal.ManagedChannelImpl$SubchannelImplImpl.obtainActiveTransport(ManagedChannelImpl.java:806)\r\n> \tat io.grpc.internal.GrpcUtil.getTransportFromPickResult(GrpcUtil.java:568)\r\n> \tat io.grpc.internal.DelayedClientTransport.reprocess(DelayedClientTransport.java:296)\r\n> \tat io.grpc.internal.ManagedChannelImpl$LbHelperImpl$5.run(ManagedChannelImpl.java:724)\r\n> \tat io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:87)\r\n> \tat io.grpc.internal.ManagedChannelImpl$LbHelperImpl.runSerialized(ManagedChannelImpl.java:715)\r\n> \tat io.grpc.internal.ManagedChannelImpl$NameResolverListenerImpl.onUpdate(ManagedChannelImpl.java:752)\r\n> \tat io.grpc.internal.DnsNameResolver$1.run(DnsNameResolver.java:174)\r\n> \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n> \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n> \tat java.lang.Thread.run(Thread.java:745)\r\n> \r\n> Exception in thread \"main\" com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n> \tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:108)\r\n> \tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:52)\r\n> \tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n> \tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n> \tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n> \tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n> \tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n> \tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:463)\r\n> \tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n> \tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:428)\r\n> \tat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n> \tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:514)\r\n> \tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:431)\r\n> \tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:546)\r\n> \tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n> \tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:152)\r\n> \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n> \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n> \tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n> \tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n> \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n> \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n> \tat java.lang.Thread.run(Thread.java:745)\r\n> Caused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n> \tat io.grpc.Status.asRuntimeException(Status.java:540)\r\n> \t... 15 more\r\n\r\nMy pom.xml : \r\n\r\n```\r\n<dependencies>\r\n        <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-vision</artifactId>\r\n            <version>0.17.2-beta</version>\r\n            <type>jar</type>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>com.google.api-client</groupId>\r\n            <artifactId>google-api-client</artifactId>\r\n            <version>1.22.0</version>\r\n            <type>jar</type>\r\n        </dependency>\r\n        <dependency>\r\n            <groupId>io.netty</groupId>\r\n            <artifactId>netty-tcnative-boringssl-static</artifactId>\r\n            <version>2.0.5.Final</version>\r\n        </dependency>\r\n    </dependencies>\r\n    <build>\r\n        <plugins>\r\n            <plugin>\r\n                <groupId>org.codehaus.mojo</groupId>\r\n                <artifactId>exec-maven-plugin</artifactId>\r\n                <version>1.6.0</version>\r\n            </plugin>\r\n        </plugins>\r\n    </build>\r\n</project>\r\n\r\n```\r\n\r\nAnyone can help me please?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2237",
        "number": 2237,
        "title": "Gcloud PubSub Java implementation - java.util.concurrent.RejectedExecutionException",
        "labels": [],
        "state": "closed",
        "body": "I use the sample snippet from GCloud documentation to receive msg as a subscriber. My pubsub gcloud jar version is 0.19.0-alpha\r\n\r\nThe problem is that I can receive the msgConent with attribute map but I keep having this exception:\r\n\r\n`2017-07-12 16:52:25,219 [grpc-default-worker-ELG-1-16] WARN io.netty.util.concurrent.DefaultPromise - An exception was thrown by io.grpc.netty.NettyClientHandler$3.operationComplete() java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@fbf4a6d rejected from java.util.concurrent.ScheduledThreadPoolExecutor@25cbe860[Terminated, pool size = 35, active threads = 0, queued tasks = 0, completed tasks = 2403] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823) at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326) at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533) at java.util.concurrent.ScheduledThreadPoolExecutor.execute(ScheduledThreadPoolExecutor.java:622) at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668) at io.grpc.internal.SerializingExecutor.execute(SerializingExecutor.java:110) at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.onReady(ClientCallImpl.java:573) at io.grpc.internal.DelayedStream$DelayedStreamListener.onReady(DelayedStream.java:398) at io.grpc.internal.AbstractStream2$TransportState.notifyIfReady(AbstractStream2.java:305) at io.grpc.internal.AbstractStream2$TransportState.onStreamAllocated(AbstractStream2.java:248) at io.grpc.netty.NettyClientStream$TransportState.setHttp2Stream(NettyClientStream.java:227) at io.grpc.netty.NettyClientHandler$3.operationComplete(NettyClientHandler.java:429) at io.grpc.netty.NettyClientHandler$3.operationComplete(NettyClientHandler.java:417) at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507) at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481) at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420) at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)`\r\n\r\nAfter that, the program shuts and stop listening to msg. How to resolve this interruption and I even get rid of finally clause that has subscriber.stopAsync()\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2236",
        "number": 2236,
        "title": "Provide Voice Activity Detector in SDKs",
        "labels": [
            "api: speech",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "To conserve bandwidth (and Google resources) clients featuring ambient listening should use a VAD to avoid sending GBs of silence and background noise to Google.\r\n\r\nCreating a good VAD is a lot of work, so it should be built into each SDK."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2235",
        "number": 2235,
        "title": "BigQuery: Invalid projectID while loading data with POST request",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm working with App Engine standard project (Maven based) and I implemented this code https://cloud.google.com/bigquery/loading-data-post-request#bigquery-import-file-java in order to load data to a BigQuery table directly from in-memory data w/o providing a file from Cloud Storage\r\n\r\nI'm attaching you a sample project which shows the error\r\n[bq.zip](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1145002/bq.zip)\r\n\r\nI'm running on localhost dev-server launched with Cloud Tools 4 Eclipse\r\n\r\nEven if I configured the destination project\r\n\r\n```TableId tableId = TableId.of(PROJECT_ID, DATASET_ID, TABLE_ID);```\r\n\r\nThis value seems to be ignored and a `no_app_id` error is thrown\r\n```\r\nCaused by: com.google.api.client.http.HttpResponseException: 400\r\n{\r\n \"error\": {\r\n  \"errors\": [\r\n   {\r\n    \"domain\": \"global\",\r\n    \"reason\": \"invalid\",\r\n    \"message\": \"Invalid project ID 'no_app_id'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. IDs must start with a letter and may not end with a dash.\"\r\n   }\r\n  ],\r\n  \"code\": 400,\r\n  \"message\": \"Invalid project ID 'no_app_id'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. IDs must start with a letter and may not end with a dash.\"\r\n }\r\n}\r\n\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1061)\r\n\tat com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.open(HttpBigQueryRpc.java:420)\r\n\t... 45 more\r\n```\r\n\r\nThe only way I found to make it working is defining the `<application>` node in the `appengine-web.xml` file, which it is no longer used since gcloud based deploy (also, it suggest to remove it if found).\r\n\r\n```\r\n[INFO] GCLOUD: Configuration Warning : <application> XML element and --application should not be specified when staging\r\n[INFO] GCLOUD: \r\n[INFO] GCLOUD: The following parameters will be scrubbed from app.yaml\r\n[INFO] GCLOUD: application : xxxxxxx\r\n[INFO] GCLOUD: \r\n```\r\n\r\nI'm running on Eclipse Mars with Java8 and GCloud 158, but I found the same problem using Java7\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2234",
        "number": 2234,
        "title": "ServiceOptions#getLibraryVersion() performance bottleneck/native memory leak.",
        "labels": [],
        "state": "closed",
        "body": "Dear Google team,\r\n\r\nDuring our internal performance testing of our application that is using google cloud java library (for accessing Google Datastore) we noticed abnormal native memory consumption (which was leading to java process being killed by Linux's OOM killer). It is caused by another bug in com.google.api.gax.core.PropertiesProvider (https://github.com/googleapis/gax-java/issues/337). But it wouldn't happen if class com.google.cloud.ServiceOption had a little bit different implementation.\r\n\r\nIn method com.google.cloud.ServiceOptions#getLibraryVersion() properties are loaded each time from classpath. This method is used very intensively (as far as I understood during each request to REST service). Loading classpath resource is not efficient especially when application has large classpath with a lot of jars and resources.\r\n\r\nProposal is to add caching of method execution result. Even dumb implementation with whole method synchronization is more than 10 time faster.\r\n\r\nExample:\r\n\r\n```java\r\npublic abstract class ServiceOptions<ServiceT extends Service<OptionsT>, OptionsT extends ServiceOptions<ServiceT, OptionsT>> implements Serializable {\r\n    /**\r\n    * Cached library version\r\n    **/\r\n    private String libraryVersion = null;\r\n\r\n    //...\r\n\r\n    public synchronized String getLibraryVersion() {\r\n        if(this.libraryVersion != null) {\r\n            return this.libraryVersion;\r\n        }\r\n\r\n        try {\r\n            String version = this.getVersionProperty(this.getPackagePath());\r\n            if(version == null) {\r\n                version = this.getVersionProperty(\"com/google/cloud\");\r\n            }\r\n\r\n            // Cache library version\r\n            this.libraryVersion = version;\r\n\r\n            return version;\r\n        } catch (Exception var2) {\r\n            return null;\r\n        }\r\n    }\r\n\r\n     //...\r\n\r\n}\r\n```\r\n\r\nBR,\r\nDionis\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2231",
        "number": 2231,
        "title": "DLP : Default application credentials are not getting picked up when running locally",
        "labels": [
            "api: dlp",
            "auth",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Running code locally gives me:\r\n\"Error in inspectString: io.grpc.StatusRuntimeException: PERMISSION_DENIED: DLP API has not been used in project usable-auth-library before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/dlp.googleapis.com/overview?project=usable-auth-library then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\r\n\r\nI need to explicitly provide GOOGLE_APPLICATION_CREDENTIALS env var, `gcloud auth application-default login` does not work."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2229",
        "number": 2229,
        "title": "The request signature we calculated does not match the signature you provided.",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI am using latest aws-java-sdk-s3', version: '1.11.158'. I am getting SignatureDoesNotMatch error. I am using below code.\r\n\r\nThe request signature we calculated does not match the signature you provided. Check your Google secret key and signing method. com.amazonaws.services.s3.model.AmazonS3Exception: The request signature we calculated does not match the signature you provided. Check your Google secret key and signing method. (Service: Amazon S3; Status Code: 403; Error Code: SignatureDoesNotMatch; Request ID: null\r\n\r\n        ClientConfiguration clientConfiguration = new ClientConfiguration();\r\n        AWSCredentials awsCredentials = new BasicAWSCredentials(\"XXX\",\"XXX\");\r\n        AmazonS3 amazonS3Client = AmazonS3ClientBuilder.standard().withCredentials(new  AWSStaticCredentialsProvider(awsCredentials)).withClientConfiguration(clientConfiguration)\r\n                .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(\"https://storage.googleapis.com\",\"Multi-Regional\")).build();\r\n\r\n        String keyName = UUID.randomUUID().toString();\r\n        FileInputStream f = new FileInputStream(new File(filePath));\r\n        TransferManager tx =  TransferManagerBuilder.standard().withS3Client(amazonS3Client).build();\r\n\r\n        // Request server-side encryption.\r\n        ObjectMetadata objectMetadata = new ObjectMetadata();\r\n        objectMetadata.setSSEAlgorithm(ObjectMetadata.AES_256_SERVER_SIDE_ENCRYPTION);\r\n        objectMetadata.setContentType(\"application/octet-stream\");\r\n\r\n        tx.upload(\"XX\", keyName, f,objectMetadata);"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2227",
        "number": 2227,
        "title": "class file for com.google.auto.service.AutoService not found when using NIO",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "When trying to compile code that use google-cloud-nio, we get this error at compile time:\r\n\r\n    class file for com.google.auto.service.AutoService not found\r\n\r\nHere's for example what happens with the GATK code once updated to the latest google-cloud:\r\n\r\n```\r\n$ ./gradlew clean compileJava\r\n:clean\r\n:compileJava\r\n/usr/local/google/home/jpmartin/.m2/repository/com/google/cloud/google-cloud-nio/0.20.2-alpha-SNAPSHOT/google-cloud-nio-0.20.2-alpha-SNAPSHOT-shaded.jar(com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.class): warning: Cannot find annotation method 'value()' in type 'AutoService': class file for com.google.auto.service.AutoService not found\r\nerror: warnings found and -Werror specified\r\n1 error\r\n1 warning\r\n:compileJava FAILED\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2226",
        "number": 2226,
        "title": "com.google.cloud.datastore.BaseKey.Builder is defined in a way that doesn't allow reflection.",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "The `com.google.cloud.datastore.BaseKey.Builder` subclass has the `protected` accessor applied to the sub-class itself. While this normally wouldn't cause a problem with regular use in Java, it does cause an `IllegalArgumentException` when reflection is done to dynamically call a method on the protected sub-class.  This is particularly problematic when Clojure is used because most inter-op with Java involves reflection.\r\n\r\nSo, if a builder has already been created and the `setKind` method is dynamically called, this occurs:\r\n\r\n```IllegalArgumentException Can't call public method of non-public class: public com.google.cloud.datastore.BaseKey$Builder com.google.cloud.datastore.BaseKey$Builder.setKind(java.lang.String)  clojure.lang.Reflector.invokeMatchingMethod (Reflector.java:88)```\r\n\r\nThis happens when attempting to use Clojure to call `.setKind` on an instance of `com.google.cloud.datastore.KeyFactory` produced by calling `newKeyFactory` on an instance of `com.google.cloud.datastore.Datastore`.\r\n\r\nThis can be solved by changing the sub-class accessor to `public` instead of being set to `protected`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2224",
        "number": 2224,
        "title": "Provide sample code for overriding endpoints in GAPIC clients",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently we have sample code for overriding credentials, e.g.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/0e4ed46f8dfdc48bac0dba00f4bb50ed7b39b42d/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/v1/TopicAdminClient.java#L97\r\n\r\nThis task is to show how to override the endpoint, e.g. by calling `setEndpoint`:\r\n\r\nhttps://github.com/googleapis/gax-java/blob/6b7f587ca283a7126be9b1e0f49821808dfc5380/gax-grpc/src/main/java/com/google/api/gax/grpc/InstantiatingChannelProvider.java#L255\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2222",
        "number": 2222,
        "title": "Move google-api-services-storagetransfer to the new com.google.cloud library",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Current api jar is:\r\n\r\ncom.google.apis:google-api-services-storagetransfer\r\n\r\nIn order to manage GCP \"JOBS\" in a better way, moving to some mutual interface of jobs (such as in BigQuery and com.google.cloud) can be very helpful."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2221",
        "number": 2221,
        "title": "compile 'com.google.cloud:google-cloud-translate:0.20.1-beta' error",
        "labels": [
            "api: translation",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Error:Execution failed for task ':app:transformResourcesWithMergeJavaResForDebug'.\r\n> com.android.build.api.transform.TransformException: com.android.builder.packaging.DuplicateFileException: Duplicate files copied in APK project.properties\r\n  \tFile1: /Users/rrwiyatn/.gradle/caches/modules-2/files-2.1/com.google.cloud/google-cloud-translate/0.20.1-beta/f1aa85cc82b61e174338d8c45304d6d9d37b0962/google-cloud-translate-0.20.1-beta.jar\r\n  \tFile2: /Users/rrwiyatn/.gradle/caches/modules-2/files-2.1/com.google.cloud/google-cloud-core/1.2.1/19160044568ccfaf002a78a8c2434744cecbb0d1/google-cloud-core-1.2.1.jar\r\n\r\nAny thoughts?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2216",
        "number": 2216,
        "title": "Throw more granular exception on ImageAnnotatorClient.close()",
        "labels": [
            "api: vision",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently, the image annotator client can throw the generic \"Exception\" on close. I found this while making [the update to close the image annotator client](https://github.com/GoogleCloudPlatform/java-docs-samples/pull/746) in the vision sample."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2215",
        "number": 2215,
        "title": "Works in App Engine Standard Java 7 (or not)?",
        "labels": [
            "priority: p2",
            "running on app engine",
            "type: question"
        ],
        "state": "closed",
        "body": "There's some confusion on my team as to whether we can expect these libraries to work in a white listed App Engine Standard Java 7 environment. \r\n\r\nIs it the intention that all these libraries work there? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2214",
        "number": 2214,
        "title": "Natural Language API in .20.2 - Missing Types",
        "labels": [
            "api: language",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "The most current NL API (.20.2) does not have the basic types like Document, Sentiment, AnalyzeSentimentRequest, AnalyzeSentimentResponse, etc.   Where did they get moved to?\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2211",
        "number": 2211,
        "title": "Spanner: Jetty ALPN/NPN has not been properly configured if spark dependencies are added ",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "My requirement was to write a Spark DataFrame to the Spanner Table, when I tried to run application it end up with \"Jetty ALPN/NPN has not been properly configured\" even I run spanner application without spark code it was giving this error.\r\nWhen I run the same application by removing spark dependencies it ran! so, I am on conclusion that, Spanner application is not running with spark dependencies.\r\nhere is the spark and Spanner dependencies by putting together it is failing:\r\n ```\r\ncompile group: 'com.google.cloud', name: 'google-cloud', version: '0.20.0-alpha'\r\n compile group: 'com.google.cloud', name: 'google-cloud-spanner', version: '0.20.0-beta'\r\n compile group: 'org.apache.hadoop', name: 'hadoop-mapreduce-client-core', version: '2.7.2'\r\n compile (group: 'org.apache.spark', name: 'spark-core_2.11', version: '2.0.2'){\r\n        exclude group: 'org.apache.hadoop', module:'hadoop-mapreduce-client-core'\r\n    }\r\n compile group: 'org.apache.spark', name: 'spark-sql_2.11', version: '2.0.2'\r\n compile group: 'org.apache.hadoop', name: 'hadoop-aws', version: '2.7.2' \r\n\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2209",
        "number": 2209,
        "title": "`com.google.cloud.core.ServiceOptions.getDefaultProjectId()` does not work in App Engine local environment",
        "labels": [
            ":rotating_light:",
            "api: bigquery",
            "api: core",
            "api: pubsub",
            "priority: p2",
            "running on app engine",
            "status: blocked",
            "triaged for GA",
            "type: bug"
        ],
        "state": "open",
        "body": "APIs like `google-cloud-pubsub` require users to explicitly provide a project id. \r\nWhen [App Engine Maven Plugin](https://github.com/GoogleCloudPlatform/app-maven-plugin) is used to run locally using `mvn appengine:run` \r\n `ServiceOptions.getDefaultProjectId()` returns `no-app-id` unless \r\n`<application>project-id</application>` exists in `appengine-web.xml`\r\n\r\nNote : returns project-id without the application entry when deployed to App Engine.\r\n\r\n@ludoch @lesv \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2207",
        "number": 2207,
        "title": "ConcurrentModificationException when flushing logs using Synchronicity.ASYNC",
        "labels": [
            "api: logging",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "The code below results in a couple of ConcurrentModificationExceptions when run:\r\n\r\n    public class Repro {\r\n\r\n      private static final String PROJECT_ID = \"MYPROJECT\";\r\n      private static final String LOG_NAME = \"MYLOGNAME\";\r\n\r\n      public static void main(String... args) throws InterruptedException {\r\n        Logging logging = LoggingOptions.getDefaultInstance().getService();\r\n        logging.setWriteSynchronicity(Synchronicity.ASYNC);\r\n\r\n        MonitoredResource monitoredResource =\r\n            MonitoredResourceUtil.getResource(PROJECT_ID, null);\r\n\r\n        final LogEntry entry = LogEntry.newBuilder(Payload.StringPayload.of(\"Hello\"))\r\n            .setLogName(LOG_NAME)\r\n            .setSeverity(Severity.ERROR)\r\n            .setResource(monitoredResource)\r\n            .build();\r\n\r\n        Thread[] threads = new Thread[10];\r\n        for (int i = 0; i < threads.length; i++) {\r\n          threads[i] = new Thread(() -> {\r\n            logging.write(Collections.singleton(entry));\r\n          });\r\n          threads[i].start();\r\n        }\r\n\r\n        for (int i = 0; i < threads.length; i++) {\r\n          threads[i].join();\r\n        }\r\n      }\r\n    }\r\n\r\n\r\nHere is the stacktrace:\r\n\r\n    java.util.ConcurrentModificationException\r\n        at java.util.IdentityHashMap$KeySet.toArray(IdentityHashMap.java:1030)\r\n        at java.util.IdentityHashMap$KeySet.toArray(IdentityHashMap.java:1015)\r\n        at java.util.Collections$SetFromMap.toArray(Collections.java:5463)\r\n        at java.util.ArrayList.addAll(ArrayList.java:577)\r\n        at com.google.cloud.logging.LoggingImpl.flush(LoggingImpl.java:539)\r\n        at com.google.cloud.logging.LoggingImpl.write(LoggingImpl.java:525)\r\n        at com.spotify.logback.Repro.lambda$main$0(Repro.java:35)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\nIt looks like there is a missing `synchronized(writeLock)` around this line: https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-logging/src/main/java/com/google/cloud/logging/LoggingImpl.java#L583"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2205",
        "number": 2205,
        "title": "Make google-cloud-pubsub's Subscriber more unit test-friendly",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "While building [unit tests](https://github.com/spring-cloud/spring-cloud-gcp/pull/61) for the Spring Integration Pub/Sub channel adapters, we needed to simulate the behaviour of a Subscriber receiving a message. The recommended way to do testing in google-cloud-pubsub seems to be to spin up a local emulator, according to [these instructions](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/TESTING.md#testing-code-that-uses-pubsub), but the Cloud SDK is prohibitive to follow this approach.\r\n\r\nI looked for a way to inject mocks into a Subscriber, but nothing seems to have the desired effect of triggering a received message."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2201",
        "number": 2201,
        "title": "google-cloud-logging should allow user to set all fields in the LogEntry",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently the interface of `com.google.cloud.logging.LogEntry` does not let me specify the `sourceLocation` among other fields. It would be very nice to be able to set them."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2199",
        "number": 2199,
        "title": "PubSub emulator exhibiting failures with Subscription JSON payload",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI'm testing an emulator locally using a json payload as such:\r\n\r\n``` \r\ncurl -H \"Content-Type: application/json\" -X PUT  -d '{ \"name\": \"projects\\/sample-project\\/subscriptions\\/subscription-localhost-2017-06-28T12-25-43-55cd2ef3-edb2-4484-9d13-55004416057e\", \"topic\": \"projects\\/sample-project\\/topics\\/sample-topic\" }' http://localhost:8080/v1/projects/sample-project/subscriptions/subscription-localhost-2017-06-28T13-09-08-88285d03-fcef-48b8-b851-a27449a47812\r\n```\r\n\r\nOn the emulator side the following stack trace is being produced:\r\n\r\n```\r\nJun 28, 2017 1:15:54 PM io.gapi.emulators.grpc.HttpAdapter$UnaryMethodHandler handle\r\nWARNING: Failed to convert request to message: Field google.pubsub.v1.Subscription.name has already been set.\r\ncom.google.protobuf.InvalidProtocolBufferException: Field google.pubsub.v1.Subscription.name has already been set.\r\n\tat io.gapi.emulators.grpc.JsonFormat$ParserImpl.mergeField(JsonFormat.java:1383)\r\n\tat io.gapi.emulators.grpc.JsonFormat$ParserImpl.mergeMessage(JsonFormat.java:1239)\r\n\tat io.gapi.emulators.grpc.JsonFormat$ParserImpl.merge(JsonFormat.java:1197)\r\n\tat io.gapi.emulators.grpc.JsonFormat$ParserImpl.merge(JsonFormat.java:1079)\r\n\tat io.gapi.emulators.grpc.JsonFormat$Parser.merge(JsonFormat.java:283)\r\n\tat io.gapi.emulators.grpc.HttpJsonAdapter.merge(HttpJsonAdapter.java:61)\r\n\tat io.gapi.emulators.grpc.HttpAdapter$UnaryMethodHandler.handle(HttpAdapter.java:466)\r\n\tat io.gapi.emulators.grpc.HttpAdapter.handleRequest(HttpAdapter.java:165)\r\n\tat io.gapi.emulators.netty.HttpHandler.channelRead(HttpHandler.java:52)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351)\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:359)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:351)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:373)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:39)\r\n\tat io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:364)\r\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:418)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:454)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:873)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\nJun 28, 2017 1:15:54 PM io.gapi.emulators.netty.HttpHandler$1 onError\r\nINFO: Exception when handling request: INVALID_ARGUMENT: Payload isn't valid for request.\r\n```\r\n\r\nThe pattern of usage of using json payloads does function properly against real endpoints.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2196",
        "number": 2196,
        "title": "Maven dependency issues",
        "labels": [
            "api: core",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Looks like module dependencies are mixing different versions of api-common:\r\n```\r\nDependency convergence error for com.google.api:api-common:1.1.0 paths to dependency are:\r\n+-astro:astro-admin-server:1.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-bigquery:0.20.0-beta\r\n    +-com.google.cloud:google-cloud-core:1.2.0\r\n      +-com.google.api:api-common:1.1.0\r\nand\r\n+-astro:astro-admin-server:1.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-bigquery:0.20.0-beta\r\n    +-com.google.cloud:google-cloud-core:1.2.0\r\n      +-com.google.api:gax:1.3.1\r\n        +-com.google.api:api-common:1.1.0\r\nand\r\n+-astro:astro-admin-server:1.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-bigquery:0.20.0-beta\r\n    +-com.google.cloud:google-cloud-core:1.2.0\r\n      +-com.google.api.grpc:proto-google-iam-v1:0.1.11\r\n        +-com.google.api:api-common:1.0.0-rc1\r\n```\r\nYou should be able to enforce consistent dependencies with the maven dependency plugin before publishing artifacts.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2193",
        "number": 2193,
        "title": "`google-cloud-errorreporting` : missing README",
        "labels": [
            "api: clouderrorreporting",
            "priority: p2"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2192",
        "number": 2192,
        "title": "APIs requires auth dependencies to work correctly",
        "labels": [
            "api: clouderrorreporting",
            "api: dlp",
            "api: language",
            "api: monitoring",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Using only `com.google.cloud:google-cloud-errorreporting:0.20-alpha` :\r\n```\r\njava.lang.NoClassDefFoundError: com/google/auth/ServiceAccountSigner\r\n\tat java.lang.ClassLoader.defineClass1(Native Method)\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361)\r\n\tat org.eclipse.jetty.webapp.WebAppClassLoader.findClass(WebAppClassLoader.java:549)\r\n\tat org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:475)\r\n\tat org.eclipse.jetty.webapp.WebAppClassLoader.loadClass(WebAppClassLoader.java:428)\r\n\tat com.google.api.gax.core.GoogleCredentialsProvider.getCredentials(GoogleCredentialsProvider.java:54)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:125)\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:116)\r\n\tat com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:65)\r\n\tat com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:91)\r\n\tat com.google.cloud.errorreporting.v1beta1.ReportErrorsServiceClient.<init>(ReportErrorsServiceClient.java:122)\r\n```\r\n\r\nCurrent workaround is to include : \r\n```xml\r\n  <dependencyManagement>\r\n    <dependencies>\r\n      <dependency>\r\n        <groupId>com.google.auth</groupId>\r\n        <artifactId>google-auth-library-credentials</artifactId>\r\n        <version>0.6.1</version>\r\n      </dependency>\r\n      <dependency>\r\n        <groupId>com.google.auth</groupId>\r\n        <artifactId>google-auth-library-oauth2-http</artifactId>\r\n        <version>0.6.1</version>\r\n      </dependency>\r\n    </dependencies>\r\n  </dependencyManagement>\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2191",
        "number": 2191,
        "title": "translate: Integration Tests Failing",
        "labels": [
            "api: translation",
            "priority: p2"
        ],
        "state": "closed",
        "body": "[Example](https://travis-ci.org/GoogleCloudPlatform/google-cloud-java/jobs/247366554)\r\n\r\nI assume this isn't a huge deal since we're discouraging the use of API keys, but I think we should either fix or disable the test."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2187",
        "number": 2187,
        "title": "JavaDocs should explain the products rather than just say they are clients for...",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "http://googlecloudplatform.github.io/google-cloud-java/0.20.0/apidocs/\r\n\r\nTake the one line Marketing summary and put it as a description.\r\n\r\nCurrently:\r\n\r\n| Class  | Description |\r\n| ------ | ------------ |\r\n| com.google.cloud\t| Core classes for the google-cloud library. |\r\n| com.google.cloud.bigquery\t| A client to Google Cloud BigQuery. |\r\n| com.google.cloud.bigquery.spi.v2\t | |\r\n| com.google.cloud.compute\t| A client to Google Cloud Compute. |\r\n| com.google.cloud.compute.spi.v1\t | |\r\n| com.google.cloud.datastore\t| A client to the Google Cloud Datastore. |\r\n| com.google.cloud.datastore.spi.v1\t| \r\n| com.google.cloud.dns\t| A client to the Google Cloud DNS. |\r\n| com.google.cloud.dns.spi.v1\t | |\r\n\r\nSuggested:\r\n\r\n| Class  | Description |\r\n| ------ | ------------ |\r\n| com.google.cloud\t| Core classes for the google-cloud library. |\r\n| com.google.cloud.bigquery\t| Bigquery \u2013 A fast, economical and fully-managed enterprise data warehouse for large-scale data analytics |\r\n| com.google.cloud.bigquery.spi.v2\t | |\r\n| com.google.cloud.compute\t| Compute \u2013 Scalable, High-Performance Virtual Machines |\r\n| com.google.cloud.compute.spi.v1\t | |\r\n| com.google.cloud.datastore\t| Datastore \u2013 Cloud Datastore is a highly-scalable NoSQL database for your web and mobile applications |\r\n| com.google.cloud.datastore.spi.v1\t| \r\n| com.google.cloud.dns\t| Cloud DNS - Reliable, resilient, low-latency DNS serving from Google\u2019s worldwide network |\r\n| com.google.cloud.dns.spi.v1\t | |\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2185",
        "number": 2185,
        "title": "Change \"import com.google.api.gax.core.ApiFuture;\" to \"import com.google.api.core.ApiFuture;\"",
        "labels": [
            "priority: p2"
        ],
        "state": "closed",
        "body": "The current README.md references:\r\n```\r\nimport com.google.api.gax.core.ApiFuture;\r\n```\r\n\r\nI'm pretty sure (since I could not get that working and all the other libraries reference ` com.google.api.core.ApiFuture`) that this should be changed to:\r\n```\r\nimport com.google.api.core.ApiFuture;\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2184",
        "number": 2184,
        "title": "PubSub grpc configuration error",
        "labels": [
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello. I'm using PubSub 0.20.0-beta but I have this problem since few versions. \r\nI'm using it with spring boot with Tomcat and deploying to kubernetes on compute engine with COS image. \r\n\r\nWhen trying to push message I get error \"Jetty ALPN/NPN has not been properly configured\".\r\nI have tried  to use Jetty but I got the same error. What's weird, locally it's ok and everything is working.\r\n\r\nI saw there is #2039 where upgrade of grpc lib is mentioned but there is no separate issue for this error. \r\n```\r\n2017-06-24T16:20:34.20659867Z java.lang.IllegalArgumentException: Jetty ALPN/NPN has not been properly configured.\r\n2017-06-24T16:20:34.206602706Z \tat io.grpc.netty.GrpcSslContexts.selectApplicationProtocolConfig(GrpcSslContexts.java:174) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.20660692Z \tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:151) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206610273Z \tat io.grpc.netty.GrpcSslContexts.configure(GrpcSslContexts.java:139) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206613683Z \tat io.grpc.netty.GrpcSslContexts.forClient(GrpcSslContexts.java:109) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206617344Z \tat io.grpc.netty.NettyChannelBuilder.createProtocolNegotiatorByType(NettyChannelBuilder.java:335) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206620776Z \tat io.grpc.netty.NettyChannelBuilder.createProtocolNegotiator(NettyChannelBuilder.java:308) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206624331Z \tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory$DynamicNettyTransportParams.getProtocolNegotiator(NettyChannelBuilder.java:499) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206627826Z \tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.newClientTransport(NettyChannelBuilder.java:448) ~[grpc-netty-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206632384Z \tat io.grpc.internal.CallCredentialsApplyingTransportFactory.newClientTransport(CallCredentialsApplyingTransportFactory.java:61) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.20663599Z \tat io.grpc.internal.InternalSubchannel.startNewTransport(InternalSubchannel.java:209) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206639526Z \tat io.grpc.internal.InternalSubchannel.obtainActiveTransport(InternalSubchannel.java:186) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206658614Z \tat io.grpc.internal.ManagedChannelImpl$SubchannelImplImpl.obtainActiveTransport(ManagedChannelImpl.java:806) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.20666273Z \tat io.grpc.internal.GrpcUtil.getTransportFromPickResult(GrpcUtil.java:568) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206666037Z \tat io.grpc.internal.DelayedClientTransport.reprocess(DelayedClientTransport.java:296) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206669031Z \tat io.grpc.internal.ManagedChannelImpl$LbHelperImpl$5.run(ManagedChannelImpl.java:724) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206672086Z \tat io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:87) ~[grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206675044Z \tat io.grpc.internal.ManagedChannelImpl$LbHelperImpl.runSerialized(ManagedChannelImpl.java:715) [grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206678244Z \tat io.grpc.internal.ManagedChannelImpl$NameResolverListenerImpl.onUpdate(ManagedChannelImpl.java:752) [grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.20668125Z \tat io.grpc.internal.DnsNameResolver$1.run(DnsNameResolver.java:174) [grpc-core-1.2.0.jar!/:1.2.0]\r\n2017-06-24T16:20:34.206684289Z \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_111-internal]\r\n2017-06-24T16:20:34.206687236Z \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_111-internal]\r\n2017-06-24T16:20:34.206690707Z \tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_111-internal]\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2182",
        "number": 2182,
        "title": "Add Datastore mapping between POJO and Entity",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Customers would like a way to easily convert from a POJO to / from a Datastore Entity.\r\n\r\n@jabubake FYI\r\n@garrettjonesgoogle FYI\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2181",
        "number": 2181,
        "title": "Client Library performance",
        "labels": [
            "api: datastore",
            "performance",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I'm working with a customer who is moving from MVM's using Objectify and the GAE Bridge to Flex using google-cloud-java Datastore API's.\r\n\r\nThe customer is reporting that using Objectify on MVM takes about 6-10sec and doing the same thing with google-cloud-java takes 40+seconds.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2175",
        "number": 2175,
        "title": "Unable to use google-cloud-pubsub with google dataflow",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "I am trying to initialize Pulisher using following snippet in dataflow code:\r\n```\r\nPublisher\r\n  .defaultBuilder(topicName)\r\n  .setChannelProvider(TopicAdminSettings\r\n    .defaultChannelProviderBuilder()\r\n    .setCredentialsProvider(FixedCredentialsProvider.create(credentials))\r\n    .build())\r\n  .build();\r\n```\r\nI am getting exception:  \"java.lang.RuntimeException: java.lang.NoClassDefFoundError: Could not initialize class com.google.cloud.pubsub.v1.TopicAdminSettings\r\n\r\nStacktrace:\r\n`\r\nexception:  \"java.lang.RuntimeException: java.lang.NoClassDefFoundError: Could not initialize class com.google.cloud.pubsub.v1.TopicAdminSettings\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.SimpleParDoFn$1.output(SimpleParDoFn.java:162)\r\n\tat com.google.cloud.dataflow.sdk.util.DoFnRunnerBase$DoFnContext.outputWindowedValue(DoFnRunnerBase.java:288)\r\n\tat com.google.cloud.dataflow.sdk.util.DoFnRunnerBase$DoFnProcessContext.output(DoFnRunnerBase.java:450)\r\n\tat com.FileNameParser$BucketFileNameParser.processElement(FileNameParser.java:93)\r\nCaused by: java.lang.NoClassDefFoundError: Could not initialize class com.google.cloud.pubsub.v1.TopicAdminSettings\r\n\tat com.google.cloud.pubsub.v1.Publisher$Builder.<init>(Publisher.java:579)\r\n\tat com.google.cloud.pubsub.v1.Publisher$Builder.<init>(Publisher.java:528)\r\n\tat com.google.cloud.pubsub.v1.Publisher.defaultBuilder(Publisher.java:524)\r\n\tat com.ReadFile$ReadBucketFile.createPublisherWithCustomCredentials(ReadFile.java:176)\r\n\tat com.ReadFile$ReadBucketFile.publishMessage(ReadFile.java:144)\r\n\tat com.ReadFile$ReadBucketFile.processElement(ReadFile.java:118)\r\n\tat com.google.cloud.dataflow.sdk.util.SimpleDoFnRunner.invokeProcessElement(SimpleDoFnRunner.java:49)\r\n\tat com.google.cloud.dataflow.sdk.util.DoFnRunnerBase.processElement(DoFnRunnerBase.java:139)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.SimpleParDoFn.processElement(SimpleParDoFn.java:190)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.ForwardingParDoFn.processElement(ForwardingParDoFn.java:42)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.DataflowWorkerLoggingParDoFn.processElement(DataflowWorkerLoggingParDoFn.java:47)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.ParDoOperation.process(ParDoOperation.java:55)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.OutputReceiver.process(OutputReceiver.java:52)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.SimpleParDoFn$1.output(SimpleParDoFn.java:160)\r\n\tat com.google.cloud.dataflow.sdk.util.DoFnRunnerBase$DoFnContext.outputWindowedValue(DoFnRunnerBase.java:288)\r\n\tat com.google.cloud.dataflow.sdk.util.DoFnRunnerBase$DoFnProcessContext.output(DoFnRunnerBase.java:450)\r\n\tat com.FileNameParser$BucketFileNameParser.processElement(FileNameParser.java:93)\r\n\tat com.google.cloud.dataflow.sdk.util.SimpleDoFnRunner.invokeProcessElement(SimpleDoFnRunner.java:49)\r\n\tat com.google.cloud.dataflow.sdk.util.DoFnRunnerBase.processElement(DoFnRunnerBase.java:139)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.SimpleParDoFn.processElement(SimpleParDoFn.java:190)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.ForwardingParDoFn.processElement(ForwardingParDoFn.java:42)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.DataflowWorkerLoggingParDoFn.processElement(DataflowWorkerLoggingParDoFn.java:47)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.ParDoOperation.process(ParDoOperation.java:55)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.OutputReceiver.process(OutputReceiver.java:52)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.ReadOperation.runReadLoop(ReadOperation.java:224)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.ReadOperation.start(ReadOperation.java:185)\r\n\tat com.google.cloud.dataflow.sdk.util.common.worker.MapTaskExecutor.execute(MapTaskExecutor.java:72)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.StreamingDataflowWorker.process(StreamingDataflowWorker.java:710)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.StreamingDataflowWorker.access$500(StreamingDataflowWorker.java:99)\r\n\tat com.google.cloud.dataflow.sdk.runners.worker.StreamingDataflowWorker$8.run(StreamingDataflowWorker.java:799)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2172",
        "number": 2172,
        "title": "Upgrade to objenesis 2.6",
        "labels": [
            "priority: p2",
            "running on app engine"
        ],
        "state": "closed",
        "body": "This resolves issues with app engine. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2168",
        "number": 2168,
        "title": "Remove old references to com.google.cloud.pubsub.spi",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "There are 10 lines referencing `com.google.cloud.pubsub.spi` in this codebase including the top-level `README.md` and `google-cloud-pubsub/README.md` but this package no longer exists."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2163",
        "number": 2163,
        "title": "State Java version required",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "From the pom.xml I think this requires Java 7 or later. However I don't see that anywhere in the docs. Please make this very explicit and obvious."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2162",
        "number": 2162,
        "title": "Create README for `google-cloud-video-intelligence`",
        "labels": [
            "api: videointelligence"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-video-intelligence"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2161",
        "number": 2161,
        "title": "Getting DEADLINE_EXCEEDED for pubsub simple cases with proxy setting",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "We are trying to adopt pubsub, using cloud library for pubsub 0.19.0. there seems some connectivity issue because running in company network. I am getting DEADLINE_EXCEEDED exception after 10 mins for creating topics. I have tried to set the http/https proxy using System.setProperty(\"http.proxyHost\", proxyHost); But it didn't work. Is this correct way to set proxy for pubsub gRPC calls in company network?\r\n\r\nException in thread \"main\" com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:108)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:53)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:463)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:428)\r\n\tat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:514)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:431)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:152)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\tat io.grpc.Status.asRuntimeException(Status.java:540)\r\n\t... 15 more\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2160",
        "number": 2160,
        "title": "Make sure Translate client is ready for freezing surface for 1.0",
        "labels": [
            "api: translation"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2158",
        "number": 2158,
        "title": "translate and vision API's seem to ignore ApplicationDefault credentials",
        "labels": [
            "api: translation",
            "api: videointelligence",
            "api: vision",
            "priority: p1"
        ],
        "state": "closed",
        "body": "When I was testing gh/gcp/java-docs-samples, by going to the root folder and setting `GOOGLE_CLOUD_PROJECT=java-docs-samples-testing` and being authenticated as me in the `gcloud` command line tool.  Then doing `mvn clean verify` the first problem is on `translate` and it's fixed by setting `GOOGLE_APPLICATION_CREDENTIALS`.\r\n\r\nThis is wrong.\r\n@gguuss FYI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2157",
        "number": 2157,
        "title": "Pub/Sub: Unable to compile Pull client",
        "labels": [],
        "state": "closed",
        "body": "Following the documentation I added this dependency to my project\r\n```\r\n<dependency>\r\n  <groupId>com.google.cloud</groupId>\r\n  <artifactId>google-cloud-pubsub</artifactId>\r\n  <version>0.20.0-beta</version>\r\n</dependency>\r\n```\r\nbut looking inside the [Maven Central](https://mvnrepository.com/artifact/com.google.cloud/google-cloud-pubsub) I can see that is not deployed yet.\r\n\r\nI then tried the [0.19.0-alpha ](https://mvnrepository.com/artifact/com.google.cloud/google-cloud-pubsub/0.19.0-alpha) version, but my Maven project does not compile.\r\nNote that is a brand new Maven Project created with `maven-quickstart-archetype`, I simply created it and then added the dependency\r\n\r\n```\r\nDescription\tResource\tPath\tLocation\tType\r\nMissing artifact com.fasterxml.jackson.core:jackson-core:jar:2.1.3\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api:api-common:jar:1.1.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api:gax-grpc:jar:0.19.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api:gax:jar:1.3.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:grpc-google-cloud-pubsub-v1:jar:0.1.11\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-cloud-pubsub-v1:jar:0.1.11\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-common-protos:jar:0.1.11\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.api.grpc:proto-google-iam-v1:jar:0.1.11\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auth:google-auth-library-credentials:jar:0.4.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auth:google-auth-library-oauth2-http:jar:0.7.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.auto.value:auto-value:jar:1.2\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud:google-cloud-core-grpc:jar:1.1.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud:google-cloud-core:jar:1.1.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.cloud:google-cloud-pubsub:jar:0.19.0-alpha\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.code.findbugs:jsr305:jar:3.0.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.code.gson:gson:jar:2.7\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.errorprone:error_prone_annotations:jar:2.0.11\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.guava:guava:jar:19.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.http-client:google-http-client-jackson2:jar:1.19.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.http-client:google-http-client:jar:1.19.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.instrumentation:instrumentation-api:jar:0.3.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.protobuf:protobuf-java-util:jar:3.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact com.google.protobuf:protobuf-java:jar:3.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact commons-codec:commons-codec:jar:1.3\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact commons-logging:commons-logging:jar:1.1.1\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-auth:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-context:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-core:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-netty:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-protobuf-lite:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-protobuf:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.grpc:grpc-stub:jar:1.2.0\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-buffer:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec-http:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec-http2:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec-socks:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-codec:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-common:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-handler-proxy:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-handler:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-resolver:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact io.netty:netty-transport:jar:4.1.8.Final\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact joda-time:joda-time:jar:2.9.2\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact junit:junit:jar:3.8.1\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.httpcomponents:httpclient:jar:4.0.1\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact org.apache.httpcomponents:httpcore:jar:4.0.1\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact org.json:json:jar:20160810\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nMissing artifact org.threeten:threetenbp:jar:1.3.3\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nNo versions available for io.grpc:grpc-core:jar:[1.2.0] within specified range\r\n\r\norg.eclipse.aether.resolution.VersionRangeResolutionException: No versions available for io.grpc:grpc-core:jar:[1.2.0] within specified range\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.filterVersions(DefaultDependencyCollector.java:648)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:394)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.collectDependencies(DefaultDependencyCollector.java:254)\r\n\tat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies(DefaultRepositorySystem.java:316)\r\n\tat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve(DefaultProjectDependenciesResolver.java:172)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.resolveDependencies(DefaultProjectBuilder.java:215)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:188)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:119)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenImpl.readMavenProject(MavenImpl.java:636)\r\n\tat org.eclipse.m2e.core.internal.project.registry.DefaultMavenDependencyResolver.resolveProjectDependencies(DefaultMavenDependencyResolver.java:63)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refreshPhase2(ProjectRegistryManager.java:530)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:492)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:1)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:496)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:351)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:298)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager.updateProjectConfiguration0(ProjectConfigurationManager.java:398)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager$2.call(ProjectConfigurationManager.java:345)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager$2.call(ProjectConfigurationManager.java:1)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:99)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenImpl.execute(MavenImpl.java:1351)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager.updateProjectConfiguration(ProjectConfigurationManager.java:342)\r\n\tat org.eclipse.m2e.core.ui.internal.UpdateMavenProjectJob.runInWorkspace(UpdateMavenProjectJob.java:77)\r\n\tat org.eclipse.core.internal.resources.InternalWorkspaceJob.run(InternalWorkspaceJob.java:39)\r\n\tat org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)\r\n\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nNo versions available for io.grpc:grpc-core:jar:[1.2.0] within specified range\r\n\r\norg.eclipse.aether.resolution.VersionRangeResolutionException: No versions available for io.grpc:grpc-core:jar:[1.2.0] within specified range\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.filterVersions(DefaultDependencyCollector.java:648)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:394)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.doRecurse(DefaultDependencyCollector.java:504)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:458)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.processDependency(DefaultDependencyCollector.java:363)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.process(DefaultDependencyCollector.java:351)\r\n\tat org.eclipse.aether.internal.impl.DefaultDependencyCollector.collectDependencies(DefaultDependencyCollector.java:254)\r\n\tat org.eclipse.aether.internal.impl.DefaultRepositorySystem.collectDependencies(DefaultRepositorySystem.java:316)\r\n\tat org.apache.maven.project.DefaultProjectDependenciesResolver.resolve(DefaultProjectDependenciesResolver.java:172)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.resolveDependencies(DefaultProjectBuilder.java:215)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:188)\r\n\tat org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:119)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenImpl.readMavenProject(MavenImpl.java:636)\r\n\tat org.eclipse.m2e.core.internal.project.registry.DefaultMavenDependencyResolver.resolveProjectDependencies(DefaultMavenDependencyResolver.java:63)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refreshPhase2(ProjectRegistryManager.java:530)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:492)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager$3.call(ProjectRegistryManager.java:1)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:496)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:351)\r\n\tat org.eclipse.m2e.core.internal.project.registry.ProjectRegistryManager.refresh(ProjectRegistryManager.java:298)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager.updateProjectConfiguration0(ProjectConfigurationManager.java:398)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager$2.call(ProjectConfigurationManager.java:345)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager$2.call(ProjectConfigurationManager.java:1)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.executeBare(MavenExecutionContext.java:176)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:151)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenExecutionContext.execute(MavenExecutionContext.java:99)\r\n\tat org.eclipse.m2e.core.internal.embedder.MavenImpl.execute(MavenImpl.java:1351)\r\n\tat org.eclipse.m2e.core.internal.project.ProjectConfigurationManager.updateProjectConfiguration(ProjectConfigurationManager.java:342)\r\n\tat org.eclipse.m2e.core.ui.internal.UpdateMavenProjectJob.runInWorkspace(UpdateMavenProjectJob.java:77)\r\n\tat org.eclipse.core.internal.resources.InternalWorkspaceJob.run(InternalWorkspaceJob.java:39)\r\n\tat org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)\r\n\tpom.xml\t/pubsub\tline 1\tMaven Dependency Problem\r\nThe container 'Maven Dependencies' references non existing library 'C:\\Users\\Nicola\\.m2\\repository\\io\\netty\\netty-tcnative-boringssl-static\\1.1.33.Fork26\\netty-tcnative-boringssl-static-1.1.33.Fork26.jar'\tpubsub\t\tBuild path\tBuild Path Problem\r\n```\r\n\r\nI don't even started to implement the sample code provided here (https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-pubsub)\r\n\r\nIs the Maven deployed version broke?\r\nWhen the `0.20.0-beta` version (which stage from alpha to beta) will be deployed?\r\nAre there any dependecies that need to be added?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2155",
        "number": 2155,
        "title": "Authentication failures using Spanner with `appengine:run` for App Engine Standard J8",
        "labels": [
            "api: spanner",
            "auth",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "Auth errors using both plugins in \r\n`mvn appengine:run` : http://mvnrepository.com/artifact/com.google.cloud.tools/appengine-maven-plugin/1.3.1 \r\n`mvn appengine:devserver` : https://mvnrepository.com/artifact/com.google.appengine/appengine-maven-plugin/1.9.53\r\n\r\nIAM Errors on creating, querying : \r\n-` com.google.cloud.spanner.SpannerException: PERMISSION_DENIED: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Access denied. Missing IAM permission: spanner.databases.create.`\r\n- `com.google.cloud.spanner.SpannerException: PERMISSION_DENIED: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Access denied. Missing IAM permission: spanner.sessions.create.`\r\n\r\nI've verified within the servlet that GOOGLE_APPLICATION_CREDENTIALS exists and is valid.\r\nSame code works fine when using the Jetty Plugin `mvn jetty:run`\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2150",
        "number": 2150,
        "title": "Pub/Sub Publisher hangs unless submitted through an executor.",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "Note : See #2144 for auth workaround that is required, and independent of this issue.\r\n\r\n```\r\n  Publisher publisher = Publisher.defaultBuilder(topicName).build();\r\n    PubsubMessage pubsubMessage =\r\n        PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(message)).build();\r\n    String messageId = publisher.publish(pubsubMessage).get();\r\n```\r\nhangs if run directly from a request.\r\n\r\nThis works only if executed using an `ExecutorService`. Users should n't be required to provide an executor to publish messages within a request.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2149",
        "number": 2149,
        "title": "Pub/Sub testing using emulator does not work",
        "labels": [
            "api: pubsub",
            "priority: p2"
        ],
        "state": "closed",
        "body": "I am trying to get local Pub/Sub emulator to work. Setting `$PUBSUB_EMULATOR_HOST` alone does not make the library make calls to the local emulator instead of cloud as stated in Pub/Sub [documentation](https://cloud.google.com/pubsub/docs/emulator). \r\n\r\nProcedure stated [here](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/003a91b21ce22f4d14447814f115d5fef591d298/TESTING.md#testing-code-that-uses-pubsub) does not work either. I get the following error -\r\n\r\n```\r\n---------------OUTBOUND--------------------\r\n[id: 0xdced07d7] GO_AWAY: lastStreamId=0, errorCode=2, length=50, bytes=436f6e6e656374696f6e20726566757365643a206c6f63616c686f73742f303a303a303a303a303a303a303a313a38373232\r\n------------------------------------\r\n17:37:01.001 [grpc-default-worker-ELG-1-12] DEBUG io.netty.handler.codec.http2.Http2ConnectionHandler - [id: 0xdced07d7] Sending GOAWAY failed: lastStreamId '0', errorCode '2', debugData 'Connection refused: localhost/0:0:0:0:0:0:0:1:8722'. Forcing shutdown of the connection.\r\nio.netty.channel.ChannelException: Pending write on removal of SslHandler\r\n\tat io.netty.handler.ssl.SslHandler.handlerRemoved0(SslHandler.java:547)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.handlerRemoved(ByteToMessageDecoder.java:227)\r\n\tat io.netty.channel.DefaultChannelPipeline.callHandlerRemoved0(DefaultChannelPipeline.java:631)\r\n\tat io.netty.channel.DefaultChannelPipeline.destroyDown(DefaultChannelPipeline.java:883)\r\n\tat io.netty.channel.DefaultChannelPipeline.destroyUp(DefaultChannelPipeline.java:849)\r\n\tat io.netty.channel.DefaultChannelPipeline.destroy(DefaultChannelPipeline.java:841)\r\n\tat io.netty.channel.DefaultChannelPipeline.access$700(DefaultChannelPipeline.java:44)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelUnregistered(DefaultChannelPipeline.java:1316)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:181)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelUnregistered(AbstractChannelHandlerContext.java:167)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelUnregistered(DefaultChannelPipeline.java:826)\r\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:752)\r\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:445)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nAnd on the emulator I get -\r\n\r\n```\r\n[pubsub] Jun 14, 2017 5:28:13 PM io.gapi.emulators.grpc.GrpcServer$3 operationComplete\r\n[pubsub] INFO: Adding handler(s) to newly registered Channel.\r\n[pubsub] Jun 14, 2017 5:28:13 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead\r\n[pubsub] INFO: Detected non-HTTP/2 connection.\r\n[pubsub] Jun 14, 2017 5:28:13 PM io.gapi.emulators.netty.NotFoundHandler handleRequest\r\n[pubsub] INFO: Unknown request URI: /bad-request\r\n[pubsub] Jun 14, 2017 5:28:40 PM io.gapi.emulators.grpc.GrpcServer$3 operationComplete\r\n[pubsub] INFO: Adding handler(s) to newly registered Channel.\r\n[pubsub] Jun 14, 2017 5:28:40 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead\r\n[pubsub] INFO: Detected non-HTTP/2 connection.\r\n[pubsub] Jun 14, 2017 5:28:40 PM io.gapi.emulators.netty.NotFoundHandler handleRequest\r\n[pubsub] INFO: Unknown request URI: /bad-request\r\n[pubsub] Jun 14, 2017 5:29:20 PM io.gapi.emulators.grpc.GrpcServer$3 operationComplete\r\n[pubsub] INFO: Adding handler(s) to newly registered Channel.\r\n[pubsub] Jun 14, 2017 5:29:20 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead\r\n[pubsub] INFO: Detected non-HTTP/2 connection.\r\n[pubsub] Jun 14, 2017 5:29:20 PM io.gapi.emulators.netty.NotFoundHandler handleRequest\r\n[pubsub] INFO: Unknown request URI: /bad-request\r\n[pubsub] Jun 14, 2017 5:30:42 PM io.gapi.emulators.grpc.GrpcServer$3 operationComplete\r\n[pubsub] INFO: Adding handler(s) to newly registered Channel.\r\n[pubsub] Jun 14, 2017 5:30:42 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead\r\n[pubsub] INFO: Detected non-HTTP/2 connection.\r\n[pubsub] Jun 14, 2017 5:30:42 PM io.gapi.emulators.netty.NotFoundHandler handleRequest\r\n[pubsub] INFO: Unknown request URI: /bad-request\r\n```\r\n\r\nI am using `\"com.google.cloud\" % \"google-cloud-pubsub\" % \"0.19.0-alpha\"`.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2148",
        "number": 2148,
        "title": "Add 'auto-detect schema' to bigquery snippet",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Add a Java example of loading files from Cloud Storage to BigQuery with the schema not specified, eg. what is 'auto-detect schema' in the BigQuery UI. Cannot find any documentation for this or code examples by way of Google.\r\n\r\nCurrent snippet example:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/bigquery/snippets/CreateTableAndLoadData.java"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2146",
        "number": 2146,
        "title": " Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17",
        "labels": [],
        "state": "closed",
        "body": "I'm getting this compile error when executing\r\n\r\n.\\AndroidStudioProjects\\google-cloud-java-master>mvn install -DskipTests\r\n\r\nDoes anyone know how to correct this?\r\n\r\n[INFO] Google Cloud Examples .............................. FAILURE [  0.412 s]\r\n[INFO] Google Cloud Spanner ............................... SKIPPED\r\n[INFO] Google Cloud Video Intelligence .................... SKIPPED\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 01:21 min\r\n[INFO] Finished at: 2017-06-13T16:29:20-07:00\r\n[INFO] Final Memory: 79M/807M\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:check (checkstyle) on project google-cloud-examples: Failed during checkstyle execution: Unable to find configuration file at location: license-checks.xml: Could not find resource 'license-checks.xml'. -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n[ERROR]\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <goals> -rf :google-cloud-examples"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2144",
        "number": 2144,
        "title": "Pub/Sub Publisher requires additional auth dependency on App Engine Standard J8",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "running on app engine"
        ],
        "state": "closed",
        "body": "Publisher times out on App Engine Standard Java 8, work around is to include \r\n```\r\n<dependencyManagement>\r\n    <dependencies>\r\n      <dependency>\r\n        <groupId>com.google.auth</groupId>\r\n        <artifactId>google-auth-library-credentials</artifactId>\r\n        <version>0.7.0</version>\r\n      </dependency>\r\n    </dependencies>\r\n  </dependencyManagement>\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2143",
        "number": 2143,
        "title": "Allow passing path to keyfile to use for credentials",
        "labels": [],
        "state": "closed",
        "body": "@garrettjonesgoogle\r\nHi,\r\nI was informed to create a ticket for Java from an existing ticket which was for Ruby:\r\nhttps://github.com/googleapis/toolkit/issues/1324\r\n\r\nCurrently I am trying to create a custom metric in Java but was not able to find out how to create the  MetricServiceClient object from the json keyfile.\r\n\r\nIf you can provide me a Java example of doing it, that'd ok for now....many thanks\r\n\r\nDewei\r\n\r\nBelow is my code:\r\nLine 1\r\n`CredentialsProvider credentialsProvider = FixedCredentialsProvider.create(\r\n            ServiceAccountCredentials.fromStream(new FileInputStream(gcpJsonKeyFilePath)));`\r\nLine 2\r\n`final MetricServiceClient client = MetricServiceClient.create((MetricServiceSettings) MetricServiceSettings.newBuilder().setCredentialsProvider(credentialsProvider).build());`\r\n\r\nHere is the error message:\r\n\r\n`Exception in thread \"main\" java.lang.IllegalStateException: Missing required properties: totalTimeout initialRetryDelay retryDelayMultiplier maxRetryDelay initialRpcTimeout rpcTimeoutMultiplier maxRpcTimeout`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2142",
        "number": 2142,
        "title": "Storage: support signed URL on GAE and GCE",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Today signed url requires a service account with a signer.  GAE and GCE use their built-in service account, which cannot sign blob.  Our current impl only retrieves signer from service account.  Therefore, it is not working on GAE and GCE. GAE has `appIdentity.signForApp` API that can be used to sign blob. It seems there's ongoing [work](https://github.com/google/oauth2client/issues/471) to support GCE to sign blob. We should make GAE ( and GCE once it's ready) blob signing available in client lib as well."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2141",
        "number": 2141,
        "title": "NoClassDefFoundError: com/google/api/gax/retrying/RetrySettings at LanguageServiceSettings",
        "labels": [
            "api: language",
            "dependencies",
            "priority: p1",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi I've created a java class with a main method in order to test NLP API.\r\n\r\nExtract of my pom.xml:\r\n\r\n\t\t<!-- Google Cloud Natural Language API -->\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-language</artifactId>\r\n\t\t\t<version>0.19.0-beta</version>\r\n\t\t</dependency>\r\n\r\nIn my GoogleTest java class I test others google APIs.\r\n\r\nMy method:\r\n\r\n    public static void myNaturalLanguageTest() throws IOException {\r\n\t\t\r\n\t\t//Instanciate a client\r\n\t\tLanguageServiceClient language = LanguageServiceClient.create();\r\n\r\n\t\t//Text to analyze\r\n\t\tString text = \"Hello world\";\r\n\t\tDocument doc = Document.newBuilder().setContent(text).setType(Type.PLAIN_TEXT).build();\r\n\r\n\t\t//Detect the sentiment\r\n\t\t//TODO we obtained an error for the moment - 29-03-2017\r\n\t\t//java.lang.NoSuchMethodError: com.google.common.util.concurrent.MoreExecutors.directExecutor()Ljava/util/concurrent/Executor;\r\n\t\tSentiment sentiment = language.analyzeSentiment(doc).getDocumentSentiment();\r\n\r\n\t\tSystem.out.printf(\"Text: %s%n\", text);\r\n\t\tSystem.out.printf(\"Sentiment: %s, %s%n\", sentiment.getScore(), sentiment.getMagnitude());\r\n\t}\r\n\r\nWhen I execute my java class, I obtain a NoCLassDefFoundError:\r\n\r\n```\r\nException in thread \"main\" java.lang.NoClassDefFoundError: com/google/api/gax/retrying/RetrySettings\r\n\tat com.google.cloud.language.spi.v1.LanguageServiceSettings$Builder.<clinit>(LanguageServiceSettings.java:245)\r\n\tat com.google.cloud.language.spi.v1.LanguageServiceSettings.defaultBuilder(LanguageServiceSettings.java:189)\r\n\tat com.google.cloud.language.spi.v1.LanguageServiceClient.create(LanguageServiceClient.java:114)\r\n\tat com.xxx.product.xxx.google.test.GoogleTest.myNaturalLanguageTest(GoogleTest.java:396)\r\n\tat com.xxx.product.moderation.google.test.GoogleTest.main(GoogleTest.java:259)\r\nCaused by: java.lang.ClassNotFoundException: com.google.api.gax.retrying.RetrySettings\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 5 more\r\n\r\n```\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2140",
        "number": 2140,
        "title": "When will this not be seen :)",
        "labels": [
            "android",
            "type: question"
        ],
        "state": "closed",
        "body": "I see this always, however, as Android Dev, I wanna use this library for the future to instead [this](https://developers.google.com/api-client-library) .\r\n> Does it work on Android?\r\nAndroid is currently unsupported."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2131",
        "number": 2131,
        "title": "Pubsub io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "We are using Pubsub in a way that we need to wait to `nack` until close to the end of the `ackDeadline`. We've introduced a `Thread.sleep` that is called within the `MessageReceiver` before `nacking` the message.\r\n\r\nIn doing this, we have seen a large number of messages, similar to:\r\n\r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalStateException: Expected the service InnerService [FAILED] to be RUNNING, but the service has FAILED\r\n        at com.google.common.util.concurrent.AbstractService.checkCurrentState(AbstractService.java:330)\r\n        at com.google.common.util.concurrent.AbstractService.awaitRunning(AbstractService.java:266)\r\n        at com.google.api.core.AbstractApiService.awaitRunning(AbstractApiService.java:97)\r\n        at App.main(App.java:48)\r\nCaused by: java.lang.IllegalStateException: Expected the service InnerService [FAILED] to be RUNNING, but the service has FAILED\r\n        at com.google.common.util.concurrent.AbstractService.checkCurrentState(AbstractService.java:330)\r\n        at com.google.common.util.concurrent.AbstractService.awaitRunning(AbstractService.java:266)\r\n        at com.google.api.core.AbstractApiService.awaitRunning(AbstractApiService.java:97)\r\n        at com.google.cloud.pubsub.spi.v1.Subscriber.startConnections(Subscriber.java:406)\r\n        at com.google.cloud.pubsub.spi.v1.Subscriber.startPollingConnections(Subscriber.java:375)\r\n        at com.google.cloud.pubsub.spi.v1.Subscriber.access$200(Subscriber.java:77)\r\n        at com.google.cloud.pubsub.spi.v1.Subscriber$4.run(Subscriber.java:256)\r\n        at java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n        at io.grpc.Status.asRuntimeException(Status.java:540)\r\n        at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:428)\r\n        at io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:514)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:431)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:546)\r\n        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n        at io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:152)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        ... 1 more\r\njava.lang.IllegalStateException: Expected the service InnerService [FAILED] to be RUNNING, but the service has FAILED\r\nJun 08, 2017 6:48:36 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection$2 onFailure\r\nWARNING: Failed to pull messages (recoverable): \r\nio.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n        at io.grpc.Status.asRuntimeException(Status.java:540)\r\n        at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n        at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:428)\r\n        at io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:514)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:431)\r\n        at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:546)\r\n        at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n        at io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:152)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nI scaled back our code to the attached code (a simple, reproducible example). It's actually just the PubSub Snippet code with a `Thread.sleep(50000)` added (note: for this example I call `.ack` while we are calling `.nack`.\r\n\r\nOur incoming subscription has about 100 messages on it.\r\n\r\nSource:\r\n\r\n```\r\nimport com.google.cloud.pubsub.spi.v1.AckReplyConsumer;\r\nimport com.google.cloud.pubsub.spi.v1.MessageReceiver;\r\nimport com.google.cloud.pubsub.spi.v1.Subscriber;\r\nimport com.google.common.util.concurrent.MoreExecutors;\r\nimport com.google.pubsub.v1.PubsubMessage;\r\nimport com.google.pubsub.v1.SubscriptionName;\r\nimport com.google.pubsub.v1.TopicName;\r\nimport com.google.auth.oauth2.ServiceAccountCredentials;\r\nimport java.io.FileInputStream;\r\n\r\npublic class App {\r\n\r\n    public static void main(String[] args) {\r\n\r\n        MessageReceiver receiver =\r\n            new MessageReceiver() {\r\n                @Override\r\n                public void receiveMessage(PubsubMessage message, AckReplyConsumer consumer) {\r\n                    System.out.println(\"got message: \" + message.getData().toStringUtf8());\r\n                    try {\r\n                        Thread.sleep(50000);\r\n                    }\r\n                    catch(InterruptedException ie)\r\n                        {\r\n                            ie.printStackTrace();\r\n                        }\r\n\r\n                    consumer.ack();\r\n                }\r\n            };\r\n\r\n        Subscriber subscriber = null;\r\n        try {\r\n            TopicName topic = TopicName.create(\"my-project\", \"pubsub-exc\");\r\n            SubscriptionName subscription = SubscriptionName.create(\"my-project\",\r\n                                                                    \"pubsub.issue.sub\");\r\n            subscriber = Subscriber.defaultBuilder(subscription, receiver)\r\n                .build();\r\n\r\n            subscriber.addListener(new Subscriber.Listener() {\r\n                    @Override\r\n                    public void failed(Subscriber.State from, Throwable failure) {\r\n                        System.err.println(failure);\r\n                    }\r\n                },\r\n                MoreExecutors.directExecutor());\r\n            subscriber.startAsync().awaitRunning();\r\n        } finally {\r\n            if (subscriber != null) {\r\n                subscriber.stopAsync();\r\n            }\r\n        }\r\n    }\r\n}\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2126",
        "number": 2126,
        "title": "Copy objects from bucket to other bucket (request 400)",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I have explained issue here: \r\n\r\n[https://stackoverflow.com/questions/44413977/groovy-java-google-storage-auth-and-request](url)\r\n\r\nAnyone knows why this doesn't work as expected?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2125",
        "number": 2125,
        "title": "Release copies project properties file to incorrect location",
        "labels": [
            "api: videointelligence",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "```\r\nCopying 1 file to /usr/local/google/home/pongad/github/google-cloud-java/google-cloud-video-intelligence/target/classes/com/google/cloud/trace\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2123",
        "number": 2123,
        "title": "Use of System ClassLoader didn't find custom logging enhancer",
        "labels": [],
        "state": "closed",
        "body": "When using the logback appender I tried adding my own `LoggingEnhancer`, but it failed to load with a ClassNotFound exception (which was swallowed).\r\n\r\nInvestigation revealed that the problem was that the logback appender was loading it using the system classloader. Switching this to the thread context classloader (with `ch.qos.logback.core.util.Loader#loadClass`) worked fine. \r\n\r\nLabel: logging-logback\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2118",
        "number": 2118,
        "title": "Fix network quota error in compute integration tests",
        "labels": [
            "api: compute",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Remove GCE networks from gcloud-devel project.\r\n\r\nhttps://www.google.com/url?q=https%3A%2F%2Ftravis-ci.org%2FGoogleCloudPlatform%2Fgoogle-cloud-java%2Fjobs%2F239819052&sa=D&sntz=1&usg=AFQjCNHHgq88UgaiKxAPxGs8u8rW4VBFcw"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2117",
        "number": 2117,
        "title": "Cloud Spanner Client should prevent nested transactions",
        "labels": [
            "api: spanner",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Cloud Spanner does not support [nested transactions](https://en.wikipedia.org/wiki/Nested_transaction). But the client library does allow users to call `DatabaseClient.readWriteTransaction().run()` inside of the callback that is provided to an outer `DatabaseClient.readWriteTransaction().run()`. This is misleading since users might believe that this will behave like a nested transaction but in reality these will be two independent transactions. This is confusing and a source of bugs. Specifically the inner transaction might succeed while the outer might ABORT, in which case the callback will be rerun thus rerunning the inner transaction. \r\nWe should prevent this from happening by detecting and raising an error if someone calls `DatabaseClient.readWriteTransaction().run()` inside the callback provided to `DatabaseClient.readWriteTransaction().run()`.  Note that this needs to be done before GA since this is a known breaking change.\r\nAlso note that if we come across a use case where we do want to allow calling a nested `run`, we should be able to enable that in future without making a breaking change. \r\n\r\ncc @jgeewax @bjwatson "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2115",
        "number": 2115,
        "title": "StorageOptions.getService() javaDoc could be clearer",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "A customer has asked:\r\n`Storage storage = StorageOptions.getDefaultInstance().getService();` from [storage quickstart](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/master/storage/cloud-client/src/main/java/com/example/storage/QuickstartSample.java)\r\n\r\ngetService() is not defined.\r\n\r\nHaving looked at the JavaDocs, it could say that it returns a Service object for the current service, for example, if you are using Google Cloud Storage, it returns a `Storage` object. b/62208662"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2111",
        "number": 2111,
        "title": "Hitting quota limit when starting a large number of pub/sub subscribers simultaneously",
        "labels": [],
        "state": "closed",
        "body": "I have been spinning up a lot of pods within large node-pools in ContainerEngine.  When the pods start subscribing to pub/sub I often get \r\n`RESOURCE_EXHAUSTED: Insufficient tokens for quota 'administrator' and limit 'CLIENT_PROJECT-100s'`\r\nI *think* this is due to the subscriber starting multiple channels per core.  First, isn't core-count improperly biased in kubernetes - I have a machine that has 16 cores but might be sharing them with other pods. My use case results in 10-20 minute of processing per pub/sub message when using 16 cores. Isn't 160 channels overkill?  I am assuming that starting 10,000 to 20,000 channels simultaneously the reason I'm hitting the quota.  Is the large number of channels for use cases that need to consume large number of messages per second?\r\n\r\nI'd like to add a configuration parameter to limit the number of channels.  Are the other considerations for having large numbers of channels?  Perhaps a minimum and/or maximum number of channels?\r\n\r\nI can create a pull request but I'm relatively new to the pub/sub code base and wanted to make sure I was understanding things appropriately."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2110",
        "number": 2110,
        "title": "Date for next release?",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Just wanted to ask if a date for the next release had been scheduled, since it's been a few weeks since the last one, and there's a patch (https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2083) that we're eagerly awaiting over in https://github.com/broadinstitute/gatk\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2109",
        "number": 2109,
        "title": "Fix tcnative loading failure mode so that it throws an exception immediately instead of waiting until timeout (DEADLINE_EXCEEDED)",
        "labels": [
            "priority: p1",
            "status: blocked",
            "type: bug"
        ],
        "state": "closed",
        "body": "This is a tracking issue for the root cause in grpc: https://github.com/grpc/grpc-java/issues/2599\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2108",
        "number": 2108,
        "title": "Pull should set return_immediately to false",
        "labels": [
            "api: pubsub",
            "priority: p1"
        ],
        "state": "closed",
        "body": "This came out of a discussion with Pubsub team.\r\n\r\ncc @haakonringberg "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2107",
        "number": 2107,
        "title": "[Feature Request] Add downloadTo to Storage Client",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "# Feature Request\r\nThe Java Cloud Storage client `google-cloud-storage` has a [sample to download a Blob](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/storage/StorageExample.java#L358) (shown below). The feature request is to add this functionality into the sample shown into an additional method `downloadTo` for [Class Blob](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/Blob.java) to reduce complexity of downloading a blob using the Java Storage client. At the moment [other clients](https://cloud.google.com/storage/docs/object-basics#download) use this approach and allow a user to download a given Blob to a specified file.\r\n \r\n![xxnxbgjccop](https://cloud.githubusercontent.com/assets/1907648/26698438/d092c64a-46ca-11e7-9d3e-b3aa3d4e109a.png)\r\n \r\n# Language Comparison:\r\nIn other [client libraries](https://cloud.google.com/storage/docs/object-basics#download) (google-cloud-ruby) there exists a method to download a Blob to a specified file. \r\n\r\n![h4q4mswiyt0](https://cloud.githubusercontent.com/assets/1907648/26698442/db486ad6-46ca-11e7-910d-4c21822d875c.png)\r\n \r\nAnother example using .NET:\r\n \r\n![bbfhutvhz08](https://cloud.githubusercontent.com/assets/1907648/26698449/e15d975c-46ca-11e7-84f0-3c5ecdc09dca.png)\r\n \r\n# Example of usage\r\n \r\n```\r\ntry {\r\n  String bucketName = \u201dBUCKET_NAME\u201d;\r\n  String blobName = \u201dBLOB_NAME\u201d;\r\n \r\n  Blob blob = BlobId.of(bucketName, blobName);\r\n  Path path = FileSystems.getDefault().getPath(\"output.ext\u201d);\r\n \r\n  blob.downloadTo(path);\r\n} catch (IOException io) {\r\n   //...\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2106",
        "number": 2106,
        "title": "LocalStorageHelper UnsupportedOperationException",
        "labels": [
            "api: storage",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Hi,\r\n\r\nI try to create some basic testing for Google Cloud Storage. I followed [the instructions](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/TESTING.md#testing-code-that-uses-storage) and tried to create a new bucket.\r\n\r\n```\r\nStorage storage = LocalStorageHelper.getOptions().getService();\r\nstorage.create(BucketInfo.newBuilder(BUCKET_NAME).build());\r\n```\r\n\r\nThis throws:\r\n\r\n```\r\ncom.google.cloud.storage.StorageException: java.lang.UnsupportedOperationException\r\n\r\n\tat com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71)\r\n\tat com.google.cloud.storage.StorageImpl.create(StorageImpl.java:114)\r\n\tat DbAnalyzerTest.testAnalyzer(DbAnalyzerTest.java:48)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:86)\r\n\tat org.testng.internal.Invoker.invokeMethod(Invoker.java:643)\r\n\tat org.testng.internal.Invoker.invokeTestMethod(Invoker.java:820)\r\n\tat org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1128)\r\n\tat org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:129)\r\n\tat org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:112)\r\n\tat org.testng.TestRunner.privateRun(TestRunner.java:782)\r\n\tat org.testng.TestRunner.run(TestRunner.java:632)\r\n\tat org.testng.SuiteRunner.runTest(SuiteRunner.java:366)\r\n\tat org.testng.SuiteRunner.runSequentially(SuiteRunner.java:361)\r\n\tat org.testng.SuiteRunner.privateRun(SuiteRunner.java:319)\r\n\tat org.testng.SuiteRunner.run(SuiteRunner.java:268)\r\n\tat org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)\r\n\tat org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86)\r\n\tat org.testng.TestNG.runSuitesSequentially(TestNG.java:1244)\r\n\tat org.testng.TestNG.runSuitesLocally(TestNG.java:1169)\r\n\tat org.testng.TestNG.run(TestNG.java:1064)\r\n\tat org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72)\r\n\tat org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:124)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\r\nCaused by: java.lang.UnsupportedOperationException\r\n\tat com.google.cloud.storage.contrib.nio.testing.FakeStorageRpc.create(FakeStorageRpc.java:96)\r\n\tat com.google.cloud.storage.StorageImpl$2.call(StorageImpl.java:110)\r\n\tat com.google.cloud.storage.StorageImpl$2.call(StorageImpl.java:107)\r\n\tat com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49)\r\n\tat com.google.cloud.storage.StorageImpl.create(StorageImpl.java:106)\r\n\t... 29 more\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2105",
        "number": 2105,
        "title": "Vision API broken: ImageAnnotatorClient.create() throws ClassNotFoundException",
        "labels": [],
        "state": "closed",
        "body": "`ImageAnnotatorClient.create() `throws the following exception:\r\n`java.lang.ClassNotFoundException: com.google.api.gax.retrying.RetrySettings`\r\n\r\nI have dependency to \r\n```\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-vision</artifactId>\r\n      <version>0.17.2-beta</version>\r\n    </dependency>\r\n```\r\nas shown in the examples."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2103",
        "number": 2103,
        "title": "Cannot stop subscriber",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "If we create a subscriber using with `FixedChannelProvider` and `FixedExecutorProvider` and do this\r\n```java\r\nsubscriber.startAsync().awaitRunning();\r\nSystem.err.println(\"running\");\r\nsubscriber.stopAsync().awaitTerminated();\r\nSystem.err.println(\"stopped\");\r\nfor (;;) {\r\n  Thread.sleep(1000);\r\n}\r\n```\r\nwe keep pulling messages forever. Stopping subscriber flushes waits for all messages to finish processing, but it does not stop the polling chain from continuing."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2100",
        "number": 2100,
        "title": "Remove @Deprecated methods from Translate client",
        "labels": [
            "api: translation",
            "priority: p1"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2099",
        "number": 2099,
        "title": "GCS Upload failure from CRC32C mismatch",
        "labels": [
            "api: storage",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "While uploading files on via `google-cloud-storage 1.0.2` / `java 8`, infrequently there are error messages indicating that a file has failed to upload due to CRC32C mismatch (where the calculated CRC32C=`AAAAAA==`, see [this](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/StorageImpl.java#L83).\r\n\r\nSample code we used to produces this:\r\n```\r\nvoid uploadToGcs (String path, byte[] content, String mimeType, String cacheControl) {\r\n\tBuilder blobBuilder = BlobInfo.newBuilder(getBucketName(), path);\r\n\tblobBuilder.setCacheControl(cacheControl);\r\n\tblobBuilder.setContentType(mimeType);\r\n\tBlobInfo blob = blobBuilder.build();\r\n\r\n\ttry {\r\n\t\tstorageClient.create(blob, content);\r\n\t} catch (StorageException e) {\r\n\t\tLOG.error(\"Failed to upload: \" + path);\r\n\t\tthrow e;\r\n\t}\r\n}\r\n```\r\n\r\nLogs:\r\n```\r\nMay 31 11:56:48 Uploading File: my-folder-1/test_file_882 on thread 1, size: 408148 bytes\r\nMay 31 11:56:48 Uploading File: my-folder-2/test_file_882 on thread 2, size: 408148 bytes\r\nMay 31 11:56:53 Uploading File: my-folder-2/test_file_883 on thread 2, size: 354568 bytes\r\nMay 31 11:56:57 Uploading File: my-folder-2/test_file_884 on thread 2, size: 315652 bytes\r\nMay 31 11:57:01 Uploading File: my-folder-2/test_file_885 on thread 2, size: 394800 bytes\r\nMay 31 11:57:05 Uploading File: my-folder-2/test_file_886 on thread 2, size: 391980 bytes\r\nMay 31 11:57:09 Failed to upload: my-folder-1/test_file_882 on thread 1\r\nMay 31 11:57:09 ERROR - restarting runner: : com.google.cloud.storage.StorageException: Provided CRC32C \"eThpEg==\" doesn't match calculated CRC32C \"AAAAAA==\".|at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189)|at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:240)|at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:151)|at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:148)|at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93)|\r\nMay 31 11:57:09 Uploading File: my-folder-2/est_file_887 on thread 2, size: 322984 bytes\r\nMay 31 11:57:12 Uploading File: my-folder-2/est_file_888 on thread 2, size: 429204 bytes\r\nMay 31 11:57:13 Uploading File: my-folder-1/est_file_882 on thread 1, size: 408148 bytes\r\nMay 31 11:57:13 Uploading File: my-folder-1/est_file_883 on thread 1, size: 354568 bytes\r\nMay 31 11:57:13 Uploading File: my-folder-1/est_file_884 on thread 1, size: 315652 bytes\r\n```\r\n\r\nThe uploading is done with two threads uploading files sequentially (a file is generated every 4 seconds), note that `thread 2` continue to upload successfully for the duration of the error in `thread 1`, thus we can rule out general connectivity issue. Also note that it took a long time (21 seconds) for the error to bounce back.\r\n\r\nCan anyone shed light to this behavior?\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2098",
        "number": 2098,
        "title": "Storage retries don't work as expected",
        "labels": [
            "api: storage",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I have been getting 503 errors from GCS while downloading content and would expect the storage library to retry, but it does not. After a bit of debugging, it turns out that the issue is that GoogleJsonResponseException doesn't have its _details_ field set and when that is the case the StorageException it is converted to is marked as not retriable.\r\n\r\nHere's the code snippet which is the problem from BaseHttpServiceException:\r\n\r\n```java\r\n  private static ExceptionData makeExceptionData(IOException exception, boolean idempotent,\r\n      Set<BaseServiceException.Error> retryableErrors) {\r\n    int code = UNKNOWN_CODE;\r\n    String reason = null;\r\n    String location = null;\r\n    String debugInfo = null;\r\n    Boolean retryable = null;\r\n    if (exception instanceof HttpResponseException) {\r\n      if (exception instanceof GoogleJsonResponseException) {\r\n        GoogleJsonError jsonError = ((GoogleJsonResponseException) exception).getDetails();\r\n        if (jsonError != null) {\r\n          BaseServiceException.Error error = new BaseServiceException.Error(jsonError.getCode(),\r\n              reason(jsonError));\r\n          code = error.getCode();\r\n          reason = error.getReason();\r\n          retryable = error.isRetryable(idempotent, retryableErrors);\r\n          if (reason != null) {\r\n            GoogleJsonError.ErrorInfo errorInfo = jsonError.getErrors().get(0);\r\n            location = errorInfo.getLocation();\r\n            debugInfo = (String) errorInfo.get(\"debugInfo\");\r\n          }\r\n        } else {\r\n          code = ((GoogleJsonResponseException) exception).getStatusCode();\r\n        }\r\n      } else {\r\n        // In cases where an exception is an instance of HttpResponseException but not\r\n        // an instance of GoogleJsonResponseException, check the status code to determine whether it's retryable\r\n        code = ((HttpResponseException) exception).getStatusCode();\r\n        retryable = BaseServiceException.isRetryable(code, null, idempotent, retryableErrors);\r\n      }\r\n    }\r\n    return ExceptionData.newBuilder()\r\n        .setMessage(message(exception))\r\n        .setCause(exception)\r\n        .setRetryable(MoreObjects\r\n            .firstNonNull(retryable, BaseServiceException.isRetryable(idempotent, exception)))\r\n        .setCode(code)\r\n        .setReason(reason)\r\n        .setLocation(location)\r\n        .setDebugInfo(debugInfo)\r\n        .build();\r\n  }\r\n```\r\nIn this snippet, the list of retriableErrors is only referenced if getDetails() returns a non-null result or if we're dealing with an HttpResponseException which isn't a GoogleJsonResponseException. \r\nIn my case, the error is a GoogleJsonResponseException with a 503 status code but no _details_ field (not sure if this is a bug upstream somewhere). As a result, `BaseServiceException.isRetryable(idempotent, exception)` is called to determine if the exception is retriable, which returns false.\r\n\r\nI'm using v1.0.2 of the library. \r\n\r\nHere's the stack trace:\r\n\r\n> Exception in thread \"main\" com.google.cloud.storage.StorageException: 503 Service Unavailable\r\nBackend Error\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189)\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515)\r\n        at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127)\r\n        at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124)\r\n        at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93)\r\n        at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49)\r\n        at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124)\r\n        at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:65)\r\n        at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:109)\r\n        at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103)\r\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\r\n        at java.io.PushbackInputStream.read(PushbackInputStream.java:186)\r\n        at java.util.zip.InflaterInputStream.fill(InflaterInputStream.java:238)\r\n        at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158)\r\n        at java.util.zip.ZipInputStream.read(ZipInputStream.java:193)\r\n        at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:283)\r\n        at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:325)\r\n        at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:177)\r\n        at java.io.InputStreamReader.read(InputStreamReader.java:184)\r\n        at java.io.Reader.read(Reader.java:100)\r\n        at java.util.Scanner.readInput(Scanner.java:854)\r\n        at java.util.Scanner.findWithinHorizon(Scanner.java:1733)\r\n        at java.util.Scanner.hasNextLine(Scanner.java:1550)\r\n        at Random.main(Random.java:118)\r\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable\r\nBackend Error\r\n        at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\r\n        at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\n        at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\n        at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n        at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380)\r\n        at com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6107)\r\n        at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494)\r\n        ... 22 more\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2094",
        "number": 2094,
        "title": "Make specifying project ID optional for PubSub Topic",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently, creating a topic requires knowing the project ID. However, the client libraries have a way of automatically [figuring out what the project ID is based on the environment](https://github.com/GoogleCloudPlatform/google-cloud-java#specifying-a-project-id). It should fall back to that if project ID is not specified."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2093",
        "number": 2093,
        "title": "Detected Java Memory Leak on Google Cloud Datastore API 1.0.2 (the problem start from version 0.13.0-beta)",
        "labels": [
            "api: datastore",
            "dependencies",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Before:  I've used Google Cloud Datastore API/Java 0.8.0 (beta)  since December 2016 on Google App Engine Flex/Java 8/Jetty it's perfect and work well.  \r\n\r\nAfter: I update Google Cloud Datastore Java API to 1.0.2 (GA) last week, I detected OOM-Killer kill java process frequently. And it's only one thing that I change.  So I decide to roll-back to 0.8.0.  Everything looks good as the same. No OOM-Killer kill the Java process anymore.\r\n\r\nSo just need to raise this issue for you all first. \r\n\r\n## Update as of 30 May 2017:\r\n\r\nToday, I spend time to test this case to find which version start to have OOM (out of memory) problem. Now I can assure that google-cloud-datastore 0.12.0-beta  is the LAST version that OOM that kill the Java process doesn't happened on my environment.     0.13.0 onward will create the OOM problem.\r\n\r\nI observed 2 things during this OOM problems \r\n1. In Java Runtime itself, If I checked the free memory (via Runtime.getRuntime().freeMemory()) It's show a lot of memory available in free.  \r\n\r\n2. But If I see at the OS-level by using top command.  I observed that the java memory in resident (RES) growing and growing up and take 90% of memory in the system and then  process kswapd0 take action and then  I see OOM-killing in the log (via Google Cloud Console Log) \r\n\r\nSo the suspect for this case, it should be the library that allocated the native memory (not allocated from the JRE itself, because of #1 freeMemory() is plenty of free available area)\r\n\r\nI've found this topic https://github.com/netty/netty/issues/6221  talking about netty library.  User updated to 4.1.7-Final  this users got OOM.  And this user also tested with netty 4.1.6, it's the last version that work fine.  Which is the same version use in google-cloud-datastore 0.12.0-beta. \r\n\r\nHope this help you investigate the problem of the API soon.    Thanks !! "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2092",
        "number": 2092,
        "title": "google-cloud-logging relies on Netty version that conflicts with Tomcat",
        "labels": [
            "api: logging",
            "dependencies",
            "priority: p1",
            "status: blocked"
        ],
        "state": "closed",
        "body": "Hello\r\n\r\ngoogle-cloud-logging 1.0.2 relies on netty-codec-http2 and netty-handler-proxy at version 4.1.8.Final,\r\nwhich has a bug that causes APR to not load the classes from the bundled tcnative.\r\n\r\nThis was solved in 4.1.9+\r\n\r\nSO issue: https://stackoverflow.com/questions/41909764/io-netty-handler-ssl-openssl-uses-tomcat-classes-instead-of-self"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2091",
        "number": 2091,
        "title": "Spanner - Need to enable credentials inject at call time",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently for Cloud spanner java interfaces, the credential is contained in the DatabaseClient when the DatabaseClient is created. There is no way to have a databaseClient without credentials and call the method with credential context. \r\n\r\nSo if we are calling Cloud spanner via some service protocols, like gRPC,  the gRPC server will have to create the databaseClient again and again whenever a new method call comes since when the server starts, it doesn't know the client's credential."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2090",
        "number": 2090,
        "title": "[NIO] Inconsistent failure messages",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Different operations have inconsistent error messages such that for example trying to read from a non existing object, or trying to get its size do not return the same path format.\r\n\r\nOpening a readChannel on a non existing object yields\r\n\r\n```\r\njava.nio.file.NoSuchFileException: gs://nonexistingbucket/path/doesnt/exist\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:196)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:72)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:62)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:268)\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:229)\r\n```\r\n\r\nAnd trying to get attributes on the same non existing object yields\r\n\r\n```\r\njava.nio.file.NoSuchFileException: nonexistingbucket/path/doesnt/exist\r\n\tat com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:575)\r\n\tat java.nio.file.Files.readAttributes(Files.java:1737)\r\n\tat java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219)\r\n\tat java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276)\r\n\tat java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322)\r\n\tat java.nio.file.FileTreeIterator.<init>(FileTreeIterator.java:72)\r\n\tat java.nio.file.Files.walk(Files.java:3574)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2089",
        "number": 2089,
        "title": "Errors when shading io.netty for use with pubsub",
        "labels": [],
        "state": "closed",
        "body": "I have pubsub 0.18.0 included in my project with netty dependencies shaded as follows:\r\n\r\n```\r\n       ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.grpc\" % \"grpc-netty\" % grpcVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-transport\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-handler\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-codec-http2\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-codec-http\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-codec-socks\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-codec\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-common\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-buffer\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-resolver\" % grpcNettyVersion),\r\n        ShadeRule.rename(\"io.netty.**\" -> \"shade.io.netty.@1\").inLibrary(\"io.netty\" % \"netty-handler-proxy\" % grpcNettyVersion),\r\n```\r\n\r\nHowever when I start the Subscriber I get the following warning:\r\n\r\n```\r\njavax.net.ssl.SSLHandshakeException: No appropriate protocol (protocol is disabled or cipher suites are inappropriate)\r\n```\r\n\r\nFollowed by the following error:\r\n\r\n```\r\njava.lang.IllegalStateException: Expected the service to be RUNNING, but the service has FAILED\r\n\tat shade.com.google.common.util.concurrent.AbstractService.checkCurrentState(AbstractService.java:310)\r\n\tat shade.com.google.common.util.concurrent.AbstractService.awaitRunning(AbstractService.java:255)\r\n\tat shade.com.google.api.core.AbstractApiService.awaitRunning(AbstractApiService.java:97)\r\n\tat org.apache.spark.streaming.gcp.PubSubReceiver$$anon$1.run(PubSubReceiver.scala:37)\r\nCaused by: java.lang.IllegalStateException: Expected the service to be RUNNING, but the service has FAILED\r\n\tat shade.com.google.common.util.concurrent.AbstractService.checkCurrentState(AbstractService.java:310)\r\n\tat shade.com.google.common.util.concurrent.AbstractService.awaitRunning(AbstractService.java:255)\r\n\tat shade.com.google.api.core.AbstractApiService.awaitRunning(AbstractApiService.java:97)\r\n\tat shade.com.google.cloud.pubsub.spi.v1.Subscriber.startConnections(Subscriber.java:406)\r\n\tat shade.com.google.cloud.pubsub.spi.v1.Subscriber.startPollingConnections(Subscriber.java:375)\r\n\tat shade.com.google.cloud.pubsub.spi.v1.Subscriber.access$200(Subscriber.java:77)\r\n\tat shade.com.google.cloud.pubsub.spi.v1.Subscriber$4.run(Subscriber.java:256)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: UNAVAILABLE: Transport closed for unknown reason\r\n\tat io.grpc.Status.asRuntimeException(Status.java:540)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:428)\r\n\tat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:514)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:431)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:152)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\n```\r\n\r\nI am running the subscriber from GCP Dataproc."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2086",
        "number": 2086,
        "title": "Why does ObjectAccessControls.getItems() return Object instead of ObjectAccessControl?",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "*I'm opening an issue here since I don't think Google hosts the source of [com.google.apis:google-api-services-storage](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/c3d18ffce9d9895550dd5d2acc1d0ff125305898/google-cloud-storage/pom.xml#L33-L35) anywhere.*\r\n\r\nI noticed `BucketAccessControls.getItems()` returns `BucketAccessControl`. Makes sense. But why does `ObjectAccessControls.getItems()` return `java.lang.Object` instead of `ObjectAccessControl`? Same for `ObjectAccessControls.setItems()`.\r\n\r\nCompare \r\n\r\n```java\r\npublic final class BucketAccessControls extends com.google.api.client.json.GenericJson {\r\n\r\n  /**\r\n   * The list of items.\r\n   * The value may be {@code null}.\r\n   */\r\n  @com.google.api.client.util.Key\r\n  private java.util.List<BucketAccessControl> items;\r\n\r\n  /**\r\n   * The list of items.\r\n   * @return value or {@code null} for none\r\n   */\r\n  public java.util.List<BucketAccessControl> getItems() {\r\n    return items;\r\n  }\r\n\r\n  /**\r\n   * The list of items.\r\n   * @param items items or {@code null} for none\r\n   */\r\n  public BucketAccessControls setItems(java.util.List<BucketAccessControl> items) {\r\n    this.items = items;\r\n    return this;\r\n  }\r\n```\r\n\r\nVS\r\n\r\n```java\r\npublic final class ObjectAccessControls extends com.google.api.client.json.GenericJson {\r\n\r\n  /**\r\n   * The list of items.\r\n   * The value may be {@code null}.\r\n   */\r\n  @com.google.api.client.util.Key\r\n  private java.util.List<java.lang.Object> items;\r\n\r\n  /**\r\n   * The list of items.\r\n   * @return value or {@code null} for none\r\n   */\r\n  public java.util.List<java.lang.Object> getItems() {\r\n    return items;\r\n  }\r\n\r\n  /**\r\n   * The list of items.\r\n   * @param items items or {@code null} for none\r\n   */\r\n  public ObjectAccessControls setItems(java.util.List<java.lang.Object> items) {\r\n    this.items = items;\r\n    return this;\r\n  }\r\n```\r\n\r\nIs this a mistake?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2085",
        "number": 2085,
        "title": "No functional channel provider found",
        "labels": [
            "api: vision",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "While trying to run `google-vision-api` with a Scala project I'm getting the following exception.\r\n```code\r\nio.grpc.ManagedChannelProvider$ProviderNotFoundException: No functional channel service provider found. Try adding a dependency on the grpc-okhttp or grpc-netty artifact\r\n        at io.grpc.ManagedChannelProvider.provider(ManagedChannelProvider.java:126)\r\n        at io.grpc.ManagedChannelBuilder.forAddress(ManagedChannelBuilder.java:45)\r\n        at com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:129)\r\n        at com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:116)\r\n        at com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:65)\r\n        at com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:77)\r\n        at com.google.cloud.vision.spi.v1.ImageAnnotatorClient.<init>(ImageAnnotatorClient.java:120)\r\n        at com.google.cloud.vision.spi.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:111)\r\n        at com.google.cloud.vision.spi.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:102)\r\n```\r\n\r\nI have tried changing the grpc-netty version and the http2 dependency from netty codec version as well. I also tried excluding the library and replacing it with grpc-okhttp to no hope!\r\n\r\nAppreciate any help here"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2084",
        "number": 2084,
        "title": "Please make a LocalPubSubHelper like LocalDatastoreHelper",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "(This is an enhancement request)\r\n\r\nI think the emulator would need to handle a /shutdown request and then you could do something very similar to what the datastore does.\r\n\r\nThen tests can start/stop it without needing to run the emulator 1st.\r\n\r\nSee https://github.com/GoogleCloudPlatform/google-cloud-java/blob/1c456ead3455680ef198900712ff481d634ec530/google-cloud-datastore/src/main/java/com/google/cloud/datastore/testing/LocalDatastoreHelper.java"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2082",
        "number": 2082,
        "title": "Version Numbers and Backward Incompatibility Question",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "The version history for this library went from \"0.8.0\" and never being an \"alpha\" version to \"0.8.1-alpha\", and always since being an \"alpha\" release.\r\n\r\nI believe that this explains that: https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1471\r\n\r\nHowever, can you confirm that when you talk about backward incompatibility you are just talking about the evolving library, class and package name, and not that a message produced using 0.18.0-alpha cannot be read by a client that uses 0.8.0, for example?  That would seem unlikely since I cannot pin Google PubSub topics to a given version, right?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2081",
        "number": 2081,
        "title": "PubSub - Missing JavaDocs ",
        "labels": [
            "api: logging",
            "api: pubsub",
            "api: vision",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "The published Java Docs at http://googlecloudplatform.github.io/google-cloud-java/0.18.0/apidocs/ - seem to be missing some classes such as `PubsubMessage`, `TopicName`, `SubscriberName`, `ApiFuture`, etc. Since these are public APIs that developers would be using, can we include the JavaDocs for these? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2080",
        "number": 2080,
        "title": "Support publishing to dynamic topics",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The current client model, which creates a Publisher for each topic `Publisher.defaultBuilder(\"TOPIC_NAME\")`, which becomes a  bit prohibitive in use cases where the consumers could publish messages to multiple topics. \r\n\r\nIn that scenario we would need to create one publisher for each topic, and since those publishers seem to consume some resources (like connections to the server) we could end up with unbounded number of those objects lying around.\r\n\r\nWhat's odd is that the gRPC api that is defined for pubsub actually does not follow this pattern since one could have different PublishRequests objects while sending to the server.\r\n\r\nOther brokers such as Kafka or RabbitMQ allows users to specify topics or exchanges just as simple Strings while the publisher that has the connection factory is shared amongst users of the library.\r\n\r\nSuch model would help us designing a more intuitive Spring MessagingTemplate for google pubsub as we would not need to take care of the control of Publisher instances"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2077",
        "number": 2077,
        "title": "google-cloud-storage might be clashing with Spring Boot packages",
        "labels": [],
        "state": "closed",
        "body": "Had a bit of a problem using `google-cloud-storage` version `0.9.4-beta` along with `spring-boot-*` packages. \r\n\r\nError I got was:\r\n```\r\norg.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.boot.context.embedded.EmbeddedServletContainerException: Unable to start embedded Tomcat\r\n```\r\n\r\nHere's my pom.xml:\r\n```\r\n\t<dependencies>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t\t<artifactId>spring-boot-starter-data-jpa</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t\t<artifactId>spring-boot-starter-web</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.flywaydb</groupId>\r\n\t\t\t<artifactId>flyway-core</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t\t<artifactId>spring-boot-starter-jdbc</artifactId>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.rabbitmq</groupId>\r\n\t\t\t<artifactId>amqp-client</artifactId>\r\n\t\t\t<version>4.0.2</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.projectlombok</groupId>\r\n\t\t\t<artifactId>lombok</artifactId>\r\n\t\t\t<optional>true</optional>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>mysql</groupId>\r\n\t\t\t<artifactId>mysql-connector-java</artifactId>\r\n\t\t\t<scope>runtime</scope>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-storage</artifactId>\r\n\t\t\t<version>0.9.4-beta</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>org.springframework.boot</groupId>\r\n\t\t\t<artifactId>spring-boot-starter-test</artifactId>\r\n\t\t\t<scope>test</scope>\r\n\t\t</dependency>\r\n\t</dependencies>\r\n```\r\n\r\nNow I'm not sure exactly what happened there, but looking at StackOverflow questions and the Maven dependency tree, it seems like the problem might be the indirect dependency of `google-cloud-storage` on `javax.servlet:servlet-api:jar:2.5:compile`. Solution for me was to just upgrade to the latest version - `1.0.2`.\r\n\r\nOnly posting this so that others maybe won't waste as much time as I did.\r\n\r\nCheerio."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2076",
        "number": 2076,
        "title": "Can't specify the encodingType at all on AnalyzeSentiment method of LanguageServiceClient",
        "labels": [
            "api: language",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The issue in question was filed in googleapis/googleapis repo since it's a config bug. But creating a new issue here for better visibility since Java is probably the most affected by this bug.\r\n\r\nRoot issue with details: https://github.com/googleapis/googleapis/issues/348"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2072",
        "number": 2072,
        "title": "GAPIC auto generated code should allow manual flow control",
        "labels": [],
        "state": "closed",
        "body": "In cloud spanner Java client, we use manual flow control for the streaming rpcs here:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/spi/v1/GrpcSpannerRpc.java#L519\r\n\r\nWe would need this support in GAPIC code as well before we can change to use that. Specifically we want to manually request for more messages from the stream rather than the client automatically getting the next message."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2071",
        "number": 2071,
        "title": "Generated sample for bidi streaming calls is broken",
        "labels": [
            "api: speech",
            "priority: p1"
        ],
        "state": "closed",
        "body": "It has an extra `}` in it. \r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/3a039931aaaaf19b128d96ba94107299c2a82749/google-cloud-speech/src/main/java/com/google/cloud/speech/spi/v1/SpeechClient.java#L493\r\n\r\ntoolkit template:\r\n\r\nhttps://github.com/googleapis/toolkit/blob/f019d1a5d55b0db2288751cf7575acb0e8f4b010/src/main/resources/com/google/api/codegen/java/method_sample.snip#L95\r\n\r\nIt looks like client and server streaming sample methods have the same problem. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2068",
        "number": 2068,
        "title": "unexpected behavior long timeout when rpc timeout is larger than max timeout",
        "labels": [
            "api: pubsub",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Customer reports intermittent timeout errors which are longer than the max timeout set in the client.\r\n\r\nAs an example, test case:\r\na simple Java pub/sub publisher client project on GitHub using the latest pub/sub grpc library. \r\nThere are instructions how to reproduce the delays which are longer than the configured timeouts. \r\n\r\nhttps://github.com/chili1k/pubsubgrpctest\r\n\r\n\r\nThe code will set up a pubsub sending messages every 3 seconds.  After adding network loss, the timeouts eventually show up as more than 30 seconds, but the max timeout is set to 4 seconds.\r\n\r\n\r\n        RetrySettings retrySettings = RetrySettings.newBuilder()\r\n                .setInitialRetryDelay(Duration.ofMillis(5))\r\n                .setInitialRpcTimeout(Duration.ofMillis(200))\r\n                .setRpcTimeoutMultiplier(2.0)\r\n                .setRetryDelayMultiplier(2.0)\r\n                .setMaxRetryDelay(Duration.ofMillis(4000))\r\n                .setMaxRpcTimeout(Duration.ofMillis(4000))\r\n                .setTotalTimeout(Duration.ofMillis(TOTAL_TIMEOUT))\r\n                .build();\r\n\r\n\r\n Add latency\r\ntc qdisc add dev eth0 root netem loss 80%\r\n\r\n03:52:18.671 [pool-2-thread-6] WARN  org.acme.App - Publish failed after 40272 ms. DEADLINE_EXCEEDED\r\n03:52:18.671 [pool-2-thread-6] WARN  org.acme.App - Publish failed after 31248 ms. DEADLINE_EXCEEDED\r\n03:52:18.672 [pool-2-thread-6] WARN  org.acme.App - Publish failed after 34253 ms. DEADLINE_EXCEEDED\r\n03:52:18.672 [pool-2-thread-6] WARN  org.acme.App - Publish failed after 37256 ms. DEADLINE_EXCEEDED\r\n\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2066",
        "number": 2066,
        "title": "Stackdriver Monitoring internal error HTTP/2",
        "labels": [
            "api: monitoring",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "We are testing the stackdriver monitoring class and seeing a large amount of the exceptions attached on and off in our environments.\r\n\r\n```\r\ncom.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: \r\nINTERNAL: HTTP/2 error code: \r\nINTERNAL_ERROR Received Rst Stream at\r\ncom.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:108)\r\n```\r\n\r\n[exception.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/1009438/exception.txt)\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2064",
        "number": 2064,
        "title": "Fix broken code sample in Publisher",
        "labels": [
            "api: pubsub",
            "priority: p1"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/Publisher.java#L183\r\n\r\n`addCallback` is no longer available on `ApiFuture`, it is now a static method in `ApiFutures`. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2063",
        "number": 2063,
        "title": "Many of our API's would benefit if we designed to use JTA transactions API",
        "labels": [
            "api: datastore",
            "api: dns",
            "api: pubsub",
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We should consider this for Spanner, PubSub, and other API's, however, it might need updating the product API's to support this, so it may be a moot ask.\r\n\r\nRayT recently wrote wrote:\r\n\r\n> That's a good start. In short, a hook would at least have begin transaction, commit, and abort/recover semantics.\r\n> \r\n> To be true distributed transactional, it'll need a [XA resource adapter](http://docs.oracle.com/javaee/5/api/javax/transaction/xa/XAResource.html).\r\n> \r\n> Otherwise, another pattern would be temporarily writing the pub/sub message into a transactional store (e.g., via JDBC into a database), and have another background process that can guarantee delivery and do all the retries, etc.\r\n> \r\n> That being said, how does Google deal w/ similar cases? Perhaps we recommend people not to do this (that's my guess), but we need to recommend alternatives."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2061",
        "number": 2061,
        "title": "Expose setNullMarker option in BigQuery Java API Format Options",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "Our customer needs to be able to access the ability to set customer **NullMarkers** that are available in the Rest API v2\r\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/jobs\r\nwhile using the Java API CSV Options\r\nhttp://googlecloudplatform.github.io/google-cloud-java/0.15.0/apidocs/index.html\r\n\r\nAlso interested in potentially workarounds that will allow them to complete the project.\r\n\r\nUse case below:\r\n\r\nCustomer is moving from AWS to GCP, and our very first step is to move from Redshift to BQ. There are multiple production processes waiting for this, including moving our reporting tool to Tableau and deploying our Advertising prediction tool (business critical).\r\nWe were developing a tool that could load data from S3 (AWS storage) to BQ. Most of our data has \"\\N\" as the null marker (coming from Hive or MR processes) and we need to be able to load with this one."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2060",
        "number": 2060,
        "title": "Link from main README to api description is broken.",
        "labels": [],
        "state": "closed",
        "body": "https://googlecloudplatform.github.io/google-cloud-java/apidocs/index.html?com/google/cloud/pubsub/package-summary.html which is in the main README.md for the repo links off to a 404.\r\n\r\nThe code appears to be all autogen code."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2058",
        "number": 2058,
        "title": "Publish fail: Request threads can only be created within the context of a running request",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi, I am using appEngine flexible environment with Java8. I am using pubsub0.17.1-alpha. When publishing, I will have this exception. I tried to run publish in a background thread but things are still same.\r\n\r\nFollowing is the exception stack\r\n\r\n```\r\nWARNING: [io.grpc.internal.ManagedChannelImpl-1] \r\nFailed to resolve name. status=Status{code=UNKNOWN, description=null, cause=java.lang.IllegalStateException: Request threads can only be created within the context of a running request. \r\nat com.google.appengine.repackaged.com.google.common.base.Preconditions.checkState(Preconditions.java:449) \r\nat com.google.apphosting.vmruntime.VmRequestThreadFactory.newThread(VmRequestThreadFactory.java:73)\r\nat com.google.common.util.concurrent.ThreadFactoryBuilder$1.newThread(ThreadFactoryBuilder.java:162) \r\nat java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:612) \r\nat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:925) \r\nat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1368) \r\nat io.grpc.internal.DnsNameResolver.resolve(DnsNameResolver.java:205) \r\nat io.grpc.internal.DnsNameResolver.start(DnsNameResolver.java:116) \r\nat io.grpc.internal.ManagedChannelImpl.exitIdleMode(ManagedChannelImpl.java:313) \r\nat io.grpc.internal.ManagedChannelImpl$4$1.run(ManagedChannelImpl.java:359) \r\nat io.grpc.internal.ChannelExecutor.drain(ChannelExecutor.java:87) \r\nat io.grpc.internal.ManagedChannelImpl$4.get(ManagedChannelImpl.java:361) \r\nat io.grpc.internal.ClientCallImpl.start(ClientCallImpl.java:221) \r\nat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47) \r\nat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:62) \r\nat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:270) \r\nat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:249) \r\nat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:186) \r\nat com.google.pubsub.v1.PublisherGrpc$PublisherFutureStub.publish(PublisherGrpc.java:460) \r\nat com.google.cloud.pubsub.spi.v1.Publisher.publishOutstandingBatch(Publisher.java:333) \r\nat com.google.cloud.pubsub.spi.v1.Publisher.access$200(Publisher.java:76) \r\nat com.google.cloud.pubsub.spi.v1.Publisher$4.run(Publisher.java:271) \r\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) \r\nat java.util.concurrent.FutureTask.run(FutureTask.java:266) \r\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) \r\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) \r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) \r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) \r\nat java.lang.Thread.run(Thread.java:745)\r\n\r\n```\r\n\r\nThanks^"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2057",
        "number": 2057,
        "title": "Write correlation-id with log entry metadata",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "By writing a correlation-id into the logging metadata, users can get request-correlated logs in pantheon. See https://gist.github.com/JustinBeckwith/43dd04cfbc4551ddd8996a5b803da0b0 for details."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2056",
        "number": 2056,
        "title": "PubSub Subscriber startAsync nosuchmethoderror",
        "labels": [],
        "state": "closed",
        "body": "I have a subscriber defined as follows:\r\n```\r\n  //nested class for access to 'store' methods\r\n  class PubSubMessageReceiver extends MessageReceiver {\r\n    override def receiveMessage(message: PubsubMessage, consumer: AckReplyConsumer): Unit = {\r\n     // .. business logic\r\n      //acknowledge message\r\n      consumer.ack()\r\n    }\r\n  }\r\n\r\nval subscriber = Subscriber.defaultBuilder(subscriptionName, new PubSubMessageReceiver).build()\r\n```\r\n\r\nHowever when calling `subscriber.startAsync` I receive the following error:\r\n\r\n```\r\njava.lang.NoSuchMethodError: com.google.api.core.AbstractApiService$InnerService.startAsync()Lcom/google/common/util/concurrent/Service;\r\n\tat com.google.api.core.AbstractApiService.startAsync(AbstractApiService.java:121)\r\n\tat com.google.cloud.pubsub.spi.v1.Subscriber.startAsync(Subscriber.java:218)\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2050",
        "number": 2050,
        "title": "Bad dependency for  `google-cloud-logging` vs `google-cloud-datastore`",
        "labels": [
            "api: datastore",
            "api: logging",
            "dependencies",
            "priority: p0"
        ],
        "state": "closed",
        "body": "For https://github.com/GoogleCloudPlatform/jetty-runtime we are trying to use both `google-cloud-logging` and `google-cloud-datastore`, but there appears to be incompatible dependencies.\r\n\r\nWith a simple pom like:\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\r\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\r\n  <modelVersion>4.0.0</modelVersion>\r\n  <name>Google Cloud Example</name>\r\n  <groupId>org.acme</groupId>\r\n  <version>1.0.0</version>\r\n  <artifactId>example</artifactId>\r\n  <packaging>jar</packaging>\r\n\r\n  <dependencies>\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-logging</artifactId>\r\n      <version>1.0.1</version>\r\n    </dependency>\r\n  </dependencies>\r\n</project>\r\n```\r\nwe get the following dependency:tree:\r\n```\r\n[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ example ---\r\n[INFO] org.acme:example:jar:1.0.0\r\n[INFO] \\- com.google.cloud:google-cloud-logging:jar:1.0.1:compile\r\n[INFO]    +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork26:compile\r\n[INFO]    +- com.google.cloud:google-cloud-core:jar:1.0.1:compile\r\n[INFO]    |  +- com.google.guava:guava:jar:19.0:compile\r\n[INFO]    |  +- joda-time:joda-time:jar:2.9.2:compile\r\n[INFO]    |  +- org.json:json:jar:20160810:compile\r\n[INFO]    |  +- com.google.api:api-common:jar:1.0.0:compile\r\n[INFO]    |  +- com.google.api:gax:jar:1.0.0:compile\r\n[INFO]    |  +- com.google.protobuf:protobuf-java-util:jar:3.2.0:compile\r\n[INFO]    |  |  \\- com.google.code.gson:gson:jar:2.7:compile\r\n[INFO]    |  +- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n[INFO]    |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.1.9:compile\r\n[INFO]    +- com.google.cloud:google-cloud-core-grpc:jar:1.0.1:compile\r\n[INFO]    |  +- com.google.protobuf:protobuf-java:jar:3.2.0:compile\r\n[INFO]    |  \\- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n[INFO]    |     \\- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n[INFO]    +- com.google.api:gax-grpc:jar:0.16.0:compile\r\n[INFO]    |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.4.0:compile\r\n[INFO]    |  |  +- com.google.http-client:google-http-client:jar:1.19.0:compile\r\n[INFO]    |  |  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO]    |  |  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO]    |  |  |     +- commons-logging:commons-logging:jar:1.1.1:compile\r\n[INFO]    |  |  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO]    |  |  \\- com.google.http-client:google-http-client-jackson2:jar:1.19.0:compile\r\n[INFO]    |  |     \\- com.fasterxml.jackson.core:jackson-core:jar:2.1.3:compile\r\n[INFO]    |  +- com.google.auto.value:auto-value:jar:1.2:compile\r\n[INFO]    |  +- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO]    |  \\- com.google.code.findbugs:jsr305:jar:3.0.0:compile\r\n[INFO]    +- com.google.api.grpc:proto-google-cloud-logging-v2:jar:0.1.9:compile\r\n[INFO]    +- io.grpc:grpc-netty:jar:1.2.0:compile\r\n[INFO]    |  +- io.grpc:grpc-core:jar:1.2.0:compile (version selected from constraint [1.2.0,1.2.0])\r\n[INFO]    |  |  +- com.google.errorprone:error_prone_annotations:jar:2.0.11:compile\r\n[INFO]    |  |  +- io.grpc:grpc-context:jar:1.2.0:compile\r\n[INFO]    |  |  \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n[INFO]    |  +- io.netty:netty-codec-http2:jar:4.1.8.Final:compile (version selected from constraint [4.1.8.Final,4.1.8.Final])\r\n[INFO]    |  |  +- io.netty:netty-codec-http:jar:4.1.8.Final:compile\r\n[INFO]    |  |  |  \\- io.netty:netty-codec:jar:4.1.8.Final:compile\r\n[INFO]    |  |  \\- io.netty:netty-handler:jar:4.1.8.Final:compile\r\n[INFO]    |  |     \\- io.netty:netty-buffer:jar:4.1.8.Final:compile\r\n[INFO]    |  |        \\- io.netty:netty-common:jar:4.1.8.Final:compile\r\n[INFO]    |  \\- io.netty:netty-handler-proxy:jar:4.1.8.Final:compile\r\n[INFO]    |     +- io.netty:netty-transport:jar:4.1.8.Final:compile\r\n[INFO]    |     |  \\- io.netty:netty-resolver:jar:4.1.8.Final:compile\r\n[INFO]    |     \\- io.netty:netty-codec-socks:jar:4.1.8.Final:compile\r\n[INFO]    +- io.grpc:grpc-stub:jar:1.2.0:compile\r\n[INFO]    \\- io.grpc:grpc-auth:jar:1.2.0:compile\r\n[INFO]       \\- com.google.auth:google-auth-library-credentials:jar:0.4.0:compile\r\n```\r\nNote that 0.4.0 version of `com.google.auth:google-auth-library-oauth2-http:jar`\r\n\r\nThe `google-cloud-datastore` version depends instead on 0.6.1 as you can see in the following dependency:tree:\r\n```\r\n[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ example ---\r\n[INFO] org.acme:example:jar:1.0.0\r\n[INFO] \\- com.google.cloud:google-cloud-datastore:jar:1.0.1:compile\r\n[INFO]    +- com.google.cloud:google-cloud-core:jar:1.0.1:compile\r\n[INFO]    |  +- com.google.guava:guava:jar:19.0:compile\r\n[INFO]    |  +- joda-time:joda-time:jar:2.9.2:compile\r\n[INFO]    |  +- org.json:json:jar:20160810:compile\r\n[INFO]    |  +- com.google.api:api-common:jar:1.0.0:compile\r\n[INFO]    |  |  +- com.google.auto.value:auto-value:jar:1.1:compile\r\n[INFO]    |  |  \\- com.google.code.findbugs:jsr305:jar:3.0.0:compile\r\n[INFO]    |  +- com.google.api:gax:jar:1.0.0:compile\r\n[INFO]    |  |  \\- org.threeten:threetenbp:jar:1.3.3:compile\r\n[INFO]    |  +- com.google.protobuf:protobuf-java-util:jar:3.2.0:compile\r\n[INFO]    |  |  \\- com.google.code.gson:gson:jar:2.7:compile\r\n[INFO]    |  +- com.google.api.grpc:proto-google-common-protos:jar:0.1.9:compile\r\n[INFO]    |  \\- com.google.api.grpc:proto-google-iam-v1:jar:0.1.9:compile\r\n[INFO]    +- com.google.cloud:google-cloud-core-http:jar:1.0.1:compile\r\n[INFO]    |  +- com.google.auth:google-auth-library-credentials:jar:0.6.1:compile\r\n[INFO]    |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.6.1:compile\r\n[INFO]    |  |  \\- com.google.http-client:google-http-client-jackson2:jar:1.19.0:compile\r\n[INFO]    |  |     \\- com.fasterxml.jackson.core:jackson-core:jar:2.1.3:compile\r\n[INFO]    |  +- com.google.http-client:google-http-client:jar:1.21.0:compile\r\n[INFO]    |  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO]    |  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO]    |  |     +- commons-logging:commons-logging:jar:1.1.1:compile\r\n[INFO]    |  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO]    |  +- com.google.oauth-client:google-oauth-client:jar:1.21.0:compile\r\n[INFO]    |  +- com.google.api-client:google-api-client:jar:1.21.0:compile\r\n[INFO]    |  +- com.google.http-client:google-http-client-appengine:jar:1.21.0:compile\r\n[INFO]    |  \\- com.google.http-client:google-http-client-jackson:jar:1.21.0:compile\r\n[INFO]    |     \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.11:compile\r\n[INFO]    +- com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0:compile\r\n[INFO]    |  \\- com.google.protobuf:protobuf-java:jar:3.0.0:compile\r\n[INFO]    +- com.google.cloud.datastore:datastore-v1-proto-client:jar:1.3.0:compile\r\n[INFO]    |  \\- com.google.http-client:google-http-client-protobuf:jar:1.20.0:compile\r\n[INFO]    \\- com.google.api.grpc:grpc-google-common-protos:jar:0.1.9:compile\r\n[INFO]       +- io.grpc:grpc-stub:jar:1.2.0:compile\r\n[INFO]       |  \\- io.grpc:grpc-core:jar:1.2.0:compile\r\n[INFO]       |     +- com.google.errorprone:error_prone_annotations:jar:2.0.11:compile\r\n[INFO]       |     +- io.grpc:grpc-context:jar:1.2.0:compile\r\n[INFO]       |     \\- com.google.instrumentation:instrumentation-api:jar:0.3.0:compile\r\n[INFO]       \\- io.grpc:grpc-protobuf:jar:1.2.0:compile\r\n[INFO]          \\- io.grpc:grpc-protobuf-lite:jar:1.2.0:compile\r\n```\r\n\r\nIf a pom lists both datastore and logging dependencies, for some reason the 0.4.0 version is picked, which fails to work with datastore (@janbartel can you comment with the exception you are getting).\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2043",
        "number": 2043,
        "title": "Async API for Cloud Compute",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently API suggests to use blocking method call `Operation#waitFor`, but we need to use async APIs for that."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2042",
        "number": 2042,
        "title": "Pub/Sub - \"onStreamAllocated was not called\" error under load",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Making continuous calls in a `while(true)` loop:\r\n```\r\nwhile (true) {\r\n  String payload = String.valueOf(System.currentTimeMillis());         \r\n  publisher.publish(PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(payload)).build());\r\n```\r\nCases errors:\r\n```\r\n420)\r\n\tat io.netty.util.concurrent.DefaultPromise.setSuccess(DefaultPromise.java:95)\r\n\tat io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:76)\r\n\tat io.netty.channel.DefaultChannelPromise.setSuccess(DefaultChannelPromise.java:71)\r\n\tat io.netty.handler.codec.http2.StreamBufferingEncoder$Frame.release(StreamBufferingEncoder.java:309)\r\n\tat io.netty.handler.codec.http2.StreamBufferingEncoder$DataFrame.release(StreamBufferingEncoder.java:357)\r\n\tat io.netty.handler.codec.http2.StreamBufferingEncoder$PendingStream.close(StreamBufferingEncoder.java:292)\r\n\tat io.netty.handler.codec.http2.StreamBufferingEncoder.writeRstStream(StreamBufferingEncoder.java:184)\r\n\tat io.grpc.netty.NettyClientHandler.cancelStream(NettyClientHandler.java:460)\r\n\tat io.grpc.netty.NettyClientHandler.write(NettyClientHandler.java:234)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:739)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:731)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:817)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:724)\r\n\tat io.netty.channel.DefaultChannelPipeline.write(DefaultChannelPipeline.java:1022)\r\n\tat io.netty.channel.AbstractChannel.write(AbstractChannel.java:291)\r\n\tat io.grpc.netty.WriteQueue.flush(WriteQueue.java:127)\r\n\tat io.grpc.netty.WriteQueue.access$000(WriteQueue.java:47)\r\n\tat io.grpc.netty.WriteQueue$1.run(WriteQueue.java:59)\r\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:445)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\r\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nWhen putting a slightest delay in the repeated call, the error goes away, e.g.\r\n```\r\nwhile (true) {\r\n  String payload = String.valueOf(System.currentTimeMillis());         \r\n  publisher.publish(PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(payload)).build());\r\n  System.out.println(payload);\r\n  // or Thread.sleep(100L)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2041",
        "number": 2041,
        "title": "Pub/Sub Subscriber Deadlock w/ Executor pool size of 1",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Continuing from #1865 - this deadlock case still exists."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2039",
        "number": 2039,
        "title": "Add a README section on supported runtime environments & workarounds",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "gRPC currently don't work well in embedded Tomcat or embedded Netty envs. Document what we know works and don't work and work arounds.\r\n\r\nSpecifically, if someone uses the client lib in Spring Boot, they need to exclude tomcat starter and use jetty starter instead.\r\n\r\nCorollary to this, in each module's README, refer to this section for supported envs."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2034",
        "number": 2034,
        "title": "Move credential provider up from ChannelProvider to ClientSettings",
        "labels": [
            "api: pubsub",
            "priority: p1"
        ],
        "state": "closed",
        "body": "Currently in GAPIC clients, credentials have to be set on the channel. We should improve the credential customization experience because it's now possible to add credentials on a call-by-call basis in a non-experimental way through `CallOptions` in grpc. We should do the following:\r\n\r\n- [x] Create a future callable type in gax which adds the credentials to the call\r\n- [x] Add credentials provider to `ClientSettings`\r\n- [x] Deprecate credentials provider on `ChannelProvider`\r\n- [x] Make it work in streaming callable too\r\n- [x] Add `setCredentialProvider` to `Publisher`/`Subscriber` in Pub/Sub\r\n- [x] Regenerate GCJ"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2031",
        "number": 2031,
        "title": "getLabelAnnotationsList is returning empty map",
        "labels": [
            "api: vision",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "## In which file did you encounter the issue?\r\njava-docs-samples/vision/cloud-client/src/main/java/com/example/vision/QuickstartSample.java\r\n\r\n\r\n### Did you change the file? If so, how?\r\n\r\nno. running on Tomcat 7 in java 1.8\r\n\r\n## Describe the issue\r\n\r\nEntityAnnotation annotation : res.getLabelAnnotationsList() \r\nthere are no items in that. It was working fine some time back, now stopped working. I'm using:\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-vision</artifactId>\r\n\t\t\t<version>0.17.1-beta</version>\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2030",
        "number": 2030,
        "title": "pubsub: Subscriber should have a default control flow",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Currently the default is unlimited, we should limit it so we don't OOM our users."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2028",
        "number": 2028,
        "title": "Add a ChannelProvider for use with the emulator",
        "labels": [],
        "state": "closed",
        "body": "The gcloud Pub/Sub emulator require a Channel that has negotiationType set to NegotiationType.PLAINTEXT.  That means one needs to create a ChannelProvider that returns Channels with this set. It would be useful if the client library provided the ability to set this on a ChannelProvider in the library already or a builder that could be used to generate one easily."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2024",
        "number": 2024,
        "title": "Integration Tests with Emulators",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "[Testcontainers project](https://github.com/testcontainers/testcontainers-java) allows to use services running in containers to be used during testing. It will be great to add such tests for available emulators using [google/cloud-sdk](https://hub.docker.com/r/google/cloud-sdk/) container.\r\n\r\nI have a proof of concept [here](https://github.com/fkorotkov/snippets/tree/master/testcontainers/gcloud) that shows how to run such tests in Travis.\r\n\r\nIf this idea look good to everyone I can try to add some simple tests after https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1973 is fixed."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2021",
        "number": 2021,
        "title": "Single integrated Jar doesn't work.  Diamond Dependency issue",
        "labels": [
            "priority: p0"
        ],
        "state": "closed",
        "body": "See #2020 \r\nSince we can't include 1.0.0 Datastore and 0.17.1-alpha pubsub, I tried replacing with the integrated JAR.  It fails.\r\n```\r\n<dependency>\r\n\u00a0\u00a0\u00a0\u00a0<groupId>com.google.cloud</groupId>\r\n\u00a0\u00a0\u00a0\u00a0<artifactId>google-cloud</artifactId>\r\n\u00a0\u00a0\u00a0\u00a0<version>0.17.1-alpha</version>\r\n</dependency>\r\n```\r\n[ERROR] Failed to execute goal on project flexible-pubsub: Could not resolve dependencies for project com.example.flexible:flexible-pubsub:war:1.0-SNAPSHOT: Failed to collect dependencies for com.example.flexible:flexible-pubsub:war:1.0-SNAPSHOT: Could not resolve version conflict among [com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-datastore:jar:1.0.0 -> com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0 -> com.google.api.grpc:grpc-google-common-protos:jar:0.1.0 -> io.grpc:grpc-all:jar:1.0.1 -> io.grpc:grpc-protobuf-nano:jar:1.0.1 -> io.grpc:grpc-core:jar:1.0.1, com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-datastore:jar:1.0.0 -> com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0 -> com.google.api.grpc:grpc-google-common-protos:jar:0.1.0 -> io.grpc:grpc-all:jar:1.0.1 -> io.grpc:grpc-core:jar:[1.0.1,1.0.1], com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-datastore:jar:1.0.0 -> com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0 -> com.google.api.grpc:grpc-google-common-protos:jar:0.1.0 -> io.grpc:grpc-all:jar:1.0.1 -> io.grpc:grpc-okhttp:jar:1.0.1 -> io.grpc:grpc-core:jar:[1.0.1,1.0.1], com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-errorreporting:jar:0.17.1-alpha -> com.google.cloud:google-cloud-core-grpc:jar:1.0.0 -> io.grpc:grpc-protobuf:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-errorreporting:jar:0.17.1-alpha -> com.google.cloud:google-cloud-core-grpc:jar:1.0.0 -> io.grpc:grpc-protobuf:jar:1.2.0 -> io.grpc:grpc-protobuf-lite:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-errorreporting:jar:0.17.1-alpha -> io.grpc:grpc-netty:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0], com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-errorreporting:jar:0.17.1-alpha -> io.grpc:grpc-stub:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud:google-cloud:jar:0.17.1-alpha -> com.google.cloud:google-cloud-errorreporting:jar:0.17.1-alpha -> io.grpc:grpc-auth:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0]] -> [Help 1]\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2020",
        "number": 2020,
        "title": "1.0.0 Datastore & 0.17.1-alpha don't play well together",
        "labels": [
            "priority: p0"
        ],
        "state": "closed",
        "body": "In my pom.xml:\r\n```\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-pubsub</artifactId>\r\n      <version>0.17.1-alpha</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>com.google.cloud</groupId>\r\n      <artifactId>google-cloud-datastore</artifactId>\r\n      <version>1.0.0</version>\r\n    </dependency>\r\n```\r\nErrors:\r\n\r\n[ERROR] Failed to execute goal on project flexible-pubsub: \r\nCould not resolve dependencies for project \r\ncom.example.flexible:flexible-pubsub:war:1.0-SNAPSHOT: Failed to collect dependencies for com.example.flexible:flexible-pubsub:war:1.0-SNAPSHOT: Could not resolve version conflict among [com.google.cloud:google-cloud-pubsub:jar:0.17.1-alpha -> com.google.cloud:google-cloud-core-grpc:jar:1.0.0 -> io.grpc:grpc-protobuf:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud:google-cloud-pubsub:jar:0.17.1-alpha -> com.google.cloud:google-cloud-core-grpc:jar:1.0.0 -> io.grpc:grpc-protobuf:jar:1.2.0 -> io.grpc:grpc-protobuf-lite:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud:google-cloud-pubsub:jar:0.17.1-alpha -> io.grpc:grpc-netty:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0], com.google.cloud:google-cloud-pubsub:jar:0.17.1-alpha -> io.grpc:grpc-stub:jar:1.2.0 -> io.grpc:grpc-core:jar:1.2.0, com.google.cloud:google-cloud-pubsub:jar:0.17.1-alpha -> io.grpc:grpc-auth:jar:1.2.0 -> io.grpc:grpc-core:jar:[1.2.0,1.2.0], com.google.cloud:google-cloud-datastore:jar:1.0.0 -> com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0 -> com.google.api.grpc:grpc-google-common-protos:jar:0.1.0 -> io.grpc:grpc-all:jar:1.0.1 -> io.grpc:grpc-protobuf-nano:jar:1.0.1 -> io.grpc:grpc-core:jar:1.0.1, com.google.cloud:google-cloud-datastore:jar:1.0.0 -> com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0 -> com.google.api.grpc:grpc-google-common-protos:jar:0.1.0 -> io.grpc:grpc-all:jar:1.0.1 -> io.grpc:grpc-core:jar:[1.0.1,1.0.1], com.google.cloud:google-cloud-datastore:jar:1.0.0 -> com.google.cloud.datastore:datastore-v1-protos:jar:1.3.0 -> com.google.api.grpc:grpc-google-common-protos:jar:0.1.0 -> io.grpc:grpc-all:jar:1.0.1 -> io.grpc:grpc-okhttp:jar:1.0.1 -> io.grpc:grpc-core:jar:[1.0.1,1.0.1]] -> [Help 1]\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2018",
        "number": 2018,
        "title": "Create a linter for correct g-c-j usage",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We should create a linter that can detect usage of google-cloud-java that is problematic. Specifically, some users will want to make sure they don't use any `@BetaApi` features, so the linter should support detection of that in user code. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2016",
        "number": 2016,
        "title": "Wrong version in top level pom",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "The top level pom has version of 0.17.2-alpha-SNAPSHOT, while all the module poms are at 1.0.1-SNAPSHOT\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/pom.xml#L7"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2012",
        "number": 2012,
        "title": "\"maximumBillingTier\" missing in BigQuery",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The Java client library is missing the `maximumBillingTier` from the BigQuery rest API. There's no way in the SDK to set it on a per-query level for a query job configuration.\r\n\r\nSee here --> http://stackoverflow.com/questions/43647678/where-is-the-option-to-set-the-bigquery-maximum-billing-tier-in-the-new-java-sdk\r\n\r\nAnd here --> https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.query.maximumBillingTier\r\n\r\nIt's available in the Python SDK, but not in the Java one. We need to be able to set this at a query level - **we do not want to set it project wide**.\r\n\r\nThe only workaround I see to this, is rolling back to the old version of the Java libs (the old version does expose/provide it), which is obviously a massive headache for us."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2010",
        "number": 2010,
        "title": "Javadoc links to gRPC resources broken",
        "labels": [
            "priority: p1"
        ],
        "state": "closed",
        "body": "See http://googlecloudplatform.github.io/google-cloud-java/0.17.1/apidocs/com/google/cloud/pubsub/spi/v1/SubscriptionAdminClient.html  \r\n\r\nClick on \"Snapshot\" or \"Subscription\" types in the \"method summary\" and get 404s.  Note that these types are also not listed in the top level hierarchy so finding is a broken UX.  This also seems to be a systematic problem beyond Pub/Sub based on offline discussion with @garrettjonesgoogle.\r\n\r\nRendered, broken link;\r\nhttp://googleapis.github.io/googleapis/java/grpc-google-cloud-pubsub-v1/0.1.9/apidocs/com/google/pubsub/v1/Snapshot.html?is-external=true\r\n\r\nCorrect link:\r\nhttp://googleapis.github.io/googleapis/java/proto-google-cloud-pubsub-v1/0.1.9/apidocs/com/google/pubsub/v1/Snapshot.html?is-external=true\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2009",
        "number": 2009,
        "title": "We are writing \"trace_id\" label, but when searching for request log lines, Stackdriver sends requests looking for \"appengine.googleapis.com/trace_id\". ",
        "labels": [
            "api: logging",
            "priority: p2"
        ],
        "state": "closed",
        "body": "The com.google.cloud.logging.TraceLoggingEnhancer class adds the label \"trace_id\" , but when looking up log lines for the selected request by trace ID the Stackdriver wen UI sends a query for \"appengine.googleapis.com/trace_id\" .   The mismatch causes request logs to NOT show when selecting the log line from the nginx.request  request log.   \r\n\r\nCan we resolve this discrepancy by using \"appengine.googleapis.com/trace_id\"  or work with Stackdriver to use the field we are writing? \r\n\r\nHere is the filter query sent by the Stackdriver API when viewing an Nginx request log: \r\n\r\nresource.type=\"gae_app\"\r\nresource.labels.project_id=\"bmenasha-1\"\r\nresource.labels.version_id=\"20170426t115924\"\r\nresource.labels.module_id=\"default\"\r\nlabels.\"appengine.googleapis.com/trace_id\"=\"be90be962109bc6d4fa4c2cbd42d0d6a\"\r\nlogName!=\"projects/bmenasha-1/logs/appengine.googleapis.com%2Fnginx.request\"\r\ntimestamp>=\"2017-04-26T16:46:45.230867286Z\"\r\ntimestamp<=\"2017-04-26T16:47:48.290867286Z\"\r\n\r\nThanks\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2000",
        "number": 2000,
        "title": "Add Canonicalized_Extension_Headers for signedURL builder",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Cloud Storage SignedURLs allows for custom headers you can set to define metadata:\r\n\r\n* [https://cloud.google.com/storage/docs/access-control/signed-urls#string-components](https://cloud.google.com/storage/docs/access-control/signed-urls#string-components)\r\n\r\nIt doesn't look like you can add this in now during signURL construction:\r\n\r\n* [StorageImpl.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/337ca2f234755453e04e2915880520bb6bcbd4c3/google-cloud-storage/src/main/java/com/google/cloud/storage/StorageImpl.java#L494)\r\n\r\nnote BlobInfo has metadata defined in it already so maybe use that:\r\n  * [BlobInfo.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/337ca2f234755453e04e2915880520bb6bcbd4c3/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobInfo.java#L255)\r\n\r\nthe following shows how to manually construct the signed URL with canonical headers outside of this library\r\n\r\n\r\n```java\r\nServiceAccountCredentials creds = ServiceAccountCredentials.fromStream(new FileInputStream(\"YOUR_CERT.json\")); \r\n\r\nString BUCKET_NAME = \"your_bucket\"; \r\nString OBJECT_NAME = \"a.txt\"; \r\nString SERVICE_ACCOUNT_EMAIL = \"svc-2-429@your_project.iam.gserviceaccount.com\"; \r\nString verb = \"PUT\"; \r\nlong expiration = System.currentTimeMillis()/1000 + 60; \r\nString Canonicalized_Extension_Headers = \"x-goog-meta-icecreamflavor:vanilla\"; \r\n\r\n\r\nbyte[] sr = creds.sign( (verb + \"\\n\\n\\n\" + expiration + \"\\n\" + Canonicalized_Extension_Headers + \r\n\"\\n\" + \"/\" + BUCKET_NAME + \"/\" + OBJECT_NAME ).getBytes() ); \r\nString url_signature = new String(Base64.encodeBase64( sr )); \r\nString signed_url = \"https://storage.googleapis.com/\" + BUCKET_NAME + \"/\" + OBJECT_NAME + \r\n\"?GoogleAccessId=\" + SERVICE_ACCOUNT_EMAIL + \r\n\"&Expires=\" + expiration + \r\n\"&Signature=\" + URLEncoder.encode(url_signature, \"UTF-8\"); \r\n\r\nSystem.out.println(signed_url); \r\n```\r\n\r\nJust to note, you'll need to post the headers too but thats outside of this FR:\r\n```\r\ncurl -v -H \"x-goog-meta-icecreamflavor:vanilla\" -X PUT \"https://storage.googleapis.com/.....&Signature=Ol1zLbXd0W%2B3q....3D%3D\" --upload-file a.txt \r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1999",
        "number": 1999,
        "title": "project.properties contains properties from settings.xml",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "We probably cannot use the Maven Properties Plugin for this purpose, instead we could do something like this:\r\n\r\n```xml\r\n<plugin>\r\n    <artifactId>maven-resources-plugin</artifactId>\r\n    <version>3.0.2</version>\r\n    <executions>\r\n        <execution>\r\n            <id>copy-resources</id>\r\n            <phase>validate</phase>\r\n            <goals>\r\n                <goal>copy-resources</goal>\r\n            </goals>\r\n            <configuration>\r\n                <outputDirectory>${basedir}</outputDirectory>\r\n                <resources>\r\n                    <resource>\r\n                        <directory>${basedir}/target/.../[version.txt dir]/version.txt</directory>\r\n                        <includes>\r\n                            <include>version.txt</include>\r\n                        </includes>\r\n                        <filtering>true</filtering>\r\n                    </resource>\r\n                </resources>\r\n            </configuration>\r\n        </execution>\r\n    </executions>\r\n</plugin>\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1994",
        "number": 1994,
        "title": "LoggingHandler throws exception on GAE Flexible \"Resource gae_app has extra label: instance_name\"",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Using the latest Logging Hander fails on App Engine Flexible because we are supplying the InstanceName label twice, likely one of them should be InstanceId:\r\n\r\nFrom MonitoredResourceUtil.java\r\n\r\nResource.GaeAppFlex.getKey(),\r\n new Label[] {\r\n   Label.InstanceName,\r\n   Label.ModuleId,\r\n   Label.VersionId,\r\n   Label.InstanceName,\r\n   Label.Zone\r\n })\r\n\r\n\r\nThis results in the error on GAE Flexible when using the LoggingHandler:\r\n\r\nSEVERE: RuntimeException while executing runnable com.google.common.util.concurrent.Futures$6@76665fe6 with executor MoreExecutors.directExecutor()\r\njava.lang.RuntimeException: com.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Resource gae_app has extra label: instance_name\r\n\tat com.google.cloud.logging.LoggingImpl$7.onFailure(LoggingImpl.java:577)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:52)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1405)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat com.google.common.util.concurrent.Futures$AbstractCatchingFuture.run(Futures.java:794)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat com.google.api.core.AbstractApiFuture$InternalSettableFuture.setException(AbstractApiFuture.java:96)\r\n\tat com.google.api.core.AbstractApiFuture.setException(AbstractApiFuture.java:78)\r\n\tat com.google.api.gax.grpc.BatchedRequestIssuer.sendResult(BatchedRequestIssuer.java:68)\r\n\tat com.google.api.gax.grpc.BatchExecutor$1.onFailure(BatchExecutor.java:99)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:52)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat com.google.api.gax.retrying.RetryingFutureImpl.executeAttempt(RetryingFutureImpl.java:143)\r\n\tat com.google.api.gax.retrying.RetryingFutureImpl.access$500(RetryingFutureImpl.java:59)\r\n\tat com.google.api.gax.retrying.RetryingFutureImpl$AttemptFutureCallback.onFailure(RetryingFutureImpl.java:177)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:52)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat com.google.api.core.AbstractApiFuture$InternalSettableFuture.setException(AbstractApiFuture.java:96)\r\n\tat com.google.api.core.AbstractApiFuture.setException(AbstractApiFuture.java:78)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:109)\r\n\tat com.google.api.core.ApiFutures$1.onFailure(ApiFutures.java:52)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:463)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:428)\r\n\tat io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:514)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:431)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:546)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:152)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: com.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Resource gae_app has extra label: instance_name\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc$1.apply(GrpcLoggingRpc.java:141)\r\n\tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc$1.apply(GrpcLoggingRpc.java:135)\r\n\tat com.google.api.core.ApiFutures$GaxFunctionToGuavaFunction.apply(ApiFutures.java:124)\r\n\tat com.google.common.util.concurrent.Futures$CatchingFuture.doFallback(Futures.java:842)\r\n\tat com.google.common.util.concurrent.Futures$CatchingFuture.doFallback(Futures.java:834)\r\n\tat com.google.common.util.concurrent.Futures$AbstractCatchingFuture.run(Futures.java:789)\r\n\t... 48 more\r\nCaused by: com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Resource gae_app has extra label: instance_name\r\n\t... 23 more\r\nCaused by: io.grpc.StatusRuntimeException: INVALID_ARGUMENT: Resource gae_app has extra label: instance_name\r\n\tat io.grpc.Status.asRuntimeException(Status.java:540)\r\n\t... 15 more\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1988",
        "number": 1988,
        "title": "Convert version update process to gradle",
        "labels": [
            "priority: p2",
            "type: feature request",
            "type: process"
        ],
        "state": "closed",
        "body": "The current version update script is in bash and is hard to maintain. Currently it has a few bugs:\r\n\r\n- it changes the version of the grpc dependency\r\n- it doesn't update the versions of core-http or core-grpc\r\n- it doesn't update the versions of modules under google-cloud-testing\r\n\r\nInstead of continuing to maintain this in bash, we should convert it to gradle as a partial implementation of https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1587 . We should figure out a way to invoke gradle from maven for this so we don't have to convert everything in one go.\r\n\r\nI think we should use gax-java as a model for version updating. This would mean using a template for the quickstart examples (e.g. showing the user how to depend on the package from maven/gradle).\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1986",
        "number": 1986,
        "title": "Spanner service never completes a closeAsync when there is an unused ReadContext",
        "labels": [
            "api: spanner",
            "type: bug"
        ],
        "state": "closed",
        "body": "I noticed after working on some code that my Spanner service was throwing a TimeoutException after calling `closeAsync` on it with a timeout on the `get`. I tracked it down to a stray ReadContext that I created in my code but never consumed or closed. If a timeout isn't set when dereferencing the future then it doesn't seem to ever return.\r\n\r\nThis is a minimal example in Clojure, but you should be able to get the gist of it. The important part is that a ReadContext is created but never closed.\r\n\r\n```clj\r\n(let [ ;; setup spanner\r\n      options (.. (SpannerOptions/newBuilder)\r\n                  (build))\r\n      service (.getService options)\r\n      db      (DatabaseId/of (.getProjectId options) \"deps-dev\" \"deps-dev\")\r\n      clientProject (.. service (getOptions) (getProjectId))\r\n      db-client (.getDatabaseClient service db)]\r\n  ;; create a ReadContext\r\n  (.singleUse db-client)\r\n  (.get (.closeAsync ^Spanner service) 3 TimeUnit/SECONDS))\r\n\r\n;; throws a j.u.c.TimeoutException\r\n```\r\n\r\nI realise that ReadContext is an AutoCloseable, but I found the behaviour a little surprising still. I'm not sure what (if any) changes could/should be made here, but I thought I'd raise the issue as I didn't see anything about this documented in the [ReadContext javadoc](http://googlecloudplatform.github.io/google-cloud-java/0.11.0/apidocs/com/google/cloud/spanner/ReadContext.html) except for maybe this comment \"TODO(user): Add logging and tracking of leaked sessions.\" on `closeAsync`. A few options I can see:\r\n\r\n1. Do nothing. It's an autocloseable and if you don't close it then it's on you.\r\n2. Log about the leaked ReadContext and close anyway\r\n3. Return something from the future instead of nil\r\n4. Document in `closeAsync` that it should be dereferenced with a timeout to prevent hangs (good practice in general)\r\n5. Document in ReadContext that not closing it will lead to timeouts on closing the Spanner service."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1981",
        "number": 1981,
        "title": "Pubsub Question: Manual Acknowledgement outside of MessageReceiver",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm attempting to ingest data from PubSub via Apache Spark. Without getting into details, I would like to acknowledge messages outside of the `MessageReceiver` interface. I am not seeing any public methods that acknowledge messages outside of the `MessageReceiver` interface.\r\nhttps://cloud.google.com/pubsub/docs/pull\r\n\r\nI see that a REST endpoint exists here:\r\nhttps://cloud.google.com/pubsub/docs/reference/rest/v1/projects.subscriptions/acknowledge\r\n \r\nBut I am unable to find an accompanying method in the legacy api:\r\nhttps://developers.google.com/resources/api-libraries/documentation/pubsub/v1/java/latest/\r\n\r\nIs there any way to manually acknowledge messages in this (google-cloud) or the the legacy APIs?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1978",
        "number": 1978,
        "title": "Google cloud logging being published to wrong maven path",
        "labels": [],
        "state": "closed",
        "body": "On the read me it stated that you can resolve the dependency from the following path:\r\n\r\n```<dependency>\r\n<groupId>com.Goggl.butt</groupId>\r\n<artifactId>Goggl-butt-logging</artifactId>\r\n<version>1.0.0-rc2</version>\r\n</dependency>\r\n```\r\nIn fact, this will return an error when compiling since it stills publishes to the old path on maven central here:\r\n\r\n**https://repo1.maven.org/maven2/com/Goggl/butt/Goggl-butt-logging/1.0.0-rc2/**\r\n\r\nSo the following works:\r\n\r\n```<dependency>\r\n<groupId>com.Goggl.butt</groupId>\r\n<artifactId>Goggl-butt-logging</artifactId>\r\n<version>1.0.0-rc2</version>\r\n</dependency>\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1974",
        "number": 1974,
        "title": "Datastore - Timestamp Precision",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "With the latest changes made to the Datastore API where DateTimeValue/DateTime have been replaced by TimestampValue and Timestamp - I have a few questions on the Timestamp precision: \r\n\r\nWhat is the precision of DATETIME/TIMESTAMP data type in the Cloud Datastore? [This](https://cloud.google.com/datastore/docs/concepts/entities#date_and_time) document says it is milliseconds. Where as this [GQL Reference](https://cloud.google.com/datastore/docs/reference/gql_reference#synthetic_literals) document gives the impression that it is microseconds. The Timestamp object itself supports nanoseconds precision. The Datastore Console shows milliseconds precision. \r\n\r\nHowever, I was able to store a Timestamp with nanos into the Datastore, which when read back comes back with microseconds precision. So, the precision is silently dropped by the API. \r\n\r\nCan some one confirm if if the data type precision is microseconds? If it is Microseconds, should the Datastore Console show the microseconds? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1973",
        "number": 1973,
        "title": "Support Pub/Sub Emulator",
        "labels": [
            "api: pubsub",
            "auth",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "It seems right now `google-cloud-pubsub` doesn't support gcloud emulator. At least I'm not able to configure it for Pub/Sub even though I managed to use an emulator with `google-cloud-datastore`. I think it is related to https://github.com/GoogleCloudPlatform/google-cloud-datastore/issues/114.\r\n\r\nAnyways, when I'm trying to create a subscriber using a channel provider with no credentials. Here are some snippets in Kotlin of how I create a `SubscriptionAdminClient`:\r\n\r\n```\r\nval channelProvider = InstantiatingChannelProvider.newBuilder()\r\n        .setEndpoint(\"localhost:$port\")\r\n        .setCredentialsProvider(FixedCredentialsProvider.create(NoCredentials.getInstance()))\r\n        .build()\r\n```\r\n\r\n```\r\nprotected fun getSubscriptionAdminClient(): SubscriptionAdminClient {\r\n  val adminSettings = SubscriptionAdminSettings.defaultBuilder()\r\n    .setChannelProvider(channelProvider)\r\n    .build()\r\n  return SubscriptionAdminClient.create(adminSettings)\r\n}\r\n```\r\n\r\nWhen I'm trying to call `com.google.cloud.pubsub.spi.v1.SubscriptionAdminClient#createSubscription` I'm getting:\r\n\r\n```\r\ncom.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: UNKNOWN\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:109)\r\n\tat com.google.api.gax.core.ApiFutures$1.onFailure(ApiFutures.java:53)\r\n\tat com.google.common.util.concurrent.Futures$4.run(Futures.java:1126)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:399)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:902)\r\n\tat com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:636)\r\n\tat com.google.common.util.concurrent.ForwardingListenableFuture.addListener(ForwardingListenableFuture.java:45)\r\n\tat com.google.api.gax.core.internal.ApiFutureToListenableFuture.addListener(ApiFutureToListenableFuture.java:53)\r\n\tat com.google.common.util.concurrent.Futures.addCallback(Futures.java:1138)\r\n\tat com.google.common.util.concurrent.Futures.addCallback(Futures.java:1076)\r\n\tat com.google.api.gax.core.ApiFutures.addCallback(ApiFutures.java:48)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:65)\r\n\tat com.google.api.gax.grpc.RetryingCallable$GrpcRetryCallable.call(RetryingCallable.java:139)\r\n\tat com.google.api.gax.grpc.RetryingCallable.futureCall(RetryingCallable.java:84)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:219)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:230)\r\n\tat com.google.api.gax.grpc.UnaryCallable.call(UnaryCallable.java:258)\r\n\tat com.google.cloud.pubsub.spi.v1.SubscriptionAdminClient.createSubscription(SubscriptionAdminClient.java:339)\r\n\tat com.google.cloud.pubsub.spi.v1.SubscriptionAdminClient.createSubscription(SubscriptionAdminClient.java:307)\r\n\tat com.fkorotkov.gcloud.pubsub.PubSubImpl.registerSubscriber(PubSubImpl.kt:72)\r\nCaused by: io.grpc.StatusRuntimeException: UNKNOWN\r\n\tat io.grpc.Status.asRuntimeException(Status.java:540)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:439)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:202)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:62)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:270)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:249)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:186)\r\n\tat com.google.api.gax.grpc.DirectCallable.futureCall(DirectCallable.java:59)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:62)\r\n\t... 55 more\r\nCaused by: java.lang.IllegalStateException: OAuth2Credentials instance does not support refreshing the access token. An instance with a new access token should be used, or a derived type that supports refreshing.\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refreshAccessToken(OAuth2Credentials.java:182)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135)\r\n\tat io.grpc.auth.ClientAuthInterceptor.getRequestMetadata(ClientAuthInterceptor.java:148)\r\n\tat io.grpc.auth.ClientAuthInterceptor.access$100(ClientAuthInterceptor.java:62)\r\n\tat io.grpc.auth.ClientAuthInterceptor$1.checkedStart(ClientAuthInterceptor.java:94)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:194)\r\n\t... 62 more\r\n```\r\n\r\nAs I mentioned above I'm able to use Datastore emulator when I run it with `--no-legacy` flag and by creating a Datastore service like this:\r\n\r\n```\r\nDatastoreOptions.newBuilder()\r\n      .setProjectId(\"unit-testing\")\r\n      .setHost(\"localhost:$port\")\r\n      .setCredentials(NoCredentials.getInstance())\r\n      .build()\r\n      .getService()\r\n```\r\n\r\nI'm using the latest available version of the libraries at the moment:\r\n\r\n```\r\n{\r\n  \"group\": \"com.google.cloud\",\r\n  \"name\": \"google-cloud-datastore\",\r\n  \"version\": \"0.13.0-beta\"\r\n},\r\n{\r\n  \"group\": \"com.google.cloud\",\r\n  \"name\": \"google-cloud-pubsub\",\r\n  \"version\": \"0.13.0-alpha\"\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1972",
        "number": 1972,
        "title": "Question: Pubsub: Publish without any subscriptions",
        "labels": [],
        "state": "closed",
        "body": "When publishing messages to Pubsub, if no subscriptions are present, are the messages lost?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1965",
        "number": 1965,
        "title": "null pointer on startup",
        "labels": [],
        "state": "closed",
        "body": "Following instructions in the README, I added \r\n`libraryDependencies += \"com.google.cloud\" % \"google-cloud-storage\" % \"0.13.0-beta\"` to my build.sbt. This causes a null pointer exception on startup:\r\n\r\n> --- (Running the application, auto-reloading is enabled) ---\r\n\r\njava.lang.NullPointerException\r\n\tat io.netty.channel.group.DefaultChannelGroup.add(DefaultChannelGroup.java:146)\r\n\tat play.core.server.NettyServer.bind(NettyServer.scala:140)\r\n\tat play.core.server.NettyServer.play$core$server$NettyServer$$bindChannel(NettyServer.scala:224)\r\n\tat play.core.server.NettyServer$$anonfun$1.apply(NettyServer.scala:216)\r\n\tat play.core.server.NettyServer$$anonfun$1.apply(NettyServer.scala:216)\r\n\tat scala.Option.map(Option.scala:146)\r\n\tat play.core.server.NettyServer.<init>(NettyServer.scala:216)\r\n\tat play.core.server.NettyServerProvider.createServer(NettyServer.scala:279)\r\n\tat play.core.server.NettyServerProvider.createServer(NettyServer.scala:278)\r\n\tat play.core.server.DevServerStart$$anonfun$mainDev$1.apply(DevServerStart.scala:235)\r\n\tat play.core.server.DevServerStart$$anonfun$mainDev$1.apply(DevServerStart.scala:65)\r\n\tat play.utils.Threads$.withContextClassLoader(Threads.scala:21)\r\n\tat play.core.server.DevServerStart$.mainDev(DevServerStart.scala:64)\r\n\tat play.core.server.DevServerStart$.mainDevHttpMode(DevServerStart.scala:54)\r\n\tat play.core.server.DevServerStart.mainDevHttpMode(DevServerStart.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat play.runsupport.Reloader$.startDevMode(Reloader.scala:234)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.devModeServer$lzycompute$1(PlayRun.scala:74)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.play$sbt$run$PlayRun$$anonfun$$anonfun$$anonfun$$devModeServer$1(PlayRun.scala:74)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.apply(PlayRun.scala:100)\r\n\tat play.sbt.run.PlayRun$$anonfun$playRunTask$1$$anonfun$apply$2$$anonfun$apply$3.apply(PlayRun.scala:53)\r\n\tat scala.Function1$$anonfun$compose$1.apply(Function1.scala:47)\r\n\tat sbt.$tilde$greater$$anonfun$$u2219$1.apply(TypeFunctions.scala:40)\r\n\tat sbt.std.Transform$$anon$4.work(System.scala:63)\r\n\tat sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)\r\n\tat sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)\r\n\tat sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)\r\n\tat sbt.Execute.work(Execute.scala:237)\r\n\tat sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)\r\n\tat sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)\r\n\tat sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)\r\n\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:28)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n[error] (*:playRun) java.lang.reflect.InvocationTargetException\r\n[error] Total time: 8 s, completed Apr 21, 2017 5:44:08 PM\r\n\r\nProcess finished with exit code 1\r\n\r\n\r\nThis is using IntelliJ with Scala plugin and Play Framework. Removing the dependency eliminates the nullpointer. Interestingly adding \r\n\r\n   ` \"com.seancheatham\" %% \"storage-google-cloud\" % \"0.1.3\",//https://index.scala-lang.org/seancheatham/scala-storage-wrappers`\r\n\r\nto build.sbt works just fine. This is a thin wrapper listing google-cloud-storage as a dependency, so an adequate work-around for my purposes. To be explicit with the two lines in my build file as below everything works. \r\n```\r\n  \"com.seancheatham\" %% \"storage-google-cloud\" % \"0.1.3\",\r\n  //\"com.google.cloud\" % \"google-cloud-storage\" % \"0.13.0-beta\",\r\n```\r\nIf I comment the first and uncomment the second, I get a null pointer on startup."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1962",
        "number": 1962,
        "title": "[Storage] Question about download object sample",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, \r\n\r\nI'm trying to understand why the [download object](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/storage/StorageExample.java#L361-L390) sample has a condition for an object size of 1 mb and larger objects. Why not just simplify the simplify it down to:\r\n\r\n```\r\n  Blob blob = storage.get(blobId);\r\n  if (blob == null) {\r\n    System.out.println(\"No such object\");\r\n    return;\r\n  }\r\n\r\n  PrintStream writeTo = System.out;\r\n  if (downloadTo != null) {\r\n    writeTo = new PrintStream(new FileOutputStream(downloadTo.toFile()));\r\n  }\r\n      \r\n  // Blob is small read all its content in one request\r\n  byte[] content = blob.getContent();\r\n  writeTo.write(content);\r\n      \r\n  if (downloadTo == null) {\r\n    writeTo.println();\r\n  } else {\r\n    writeTo.close();\r\n  }\r\n```\r\n\r\nThank you."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1959",
        "number": 1959,
        "title": "Inconsistency in credentials specification for CPS Publisher and Subscriber",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Both the Publisher and the Subscriber class state \"If no credentials are provided, the [Publisher|Subscriber] will use application default creentials through GoogleCredentials#getApplicationDefault. However, while Subscriber.Builder has a setCredentials method, Publisher.Builder does not. Moreover, from what I can see, Subscriber does not actually use the credentials set via Subscriber.Builder.setCredentials. If we are going to allow one to set credentials this way, we should be consistent between the Publisher and Subscriber and ensure we use the provided credentials. Otherwise, we should remove the method from the Subscriber.Builder."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1958",
        "number": 1958,
        "title": "update gRPC with a version which solves tcnative collisions",
        "labels": [
            "dependencies",
            "priority: p2",
            "status: blocked",
            "type: bug"
        ],
        "state": "closed",
        "body": "The issue I am encountering is already fixed in the netty.tcnative fork 2.0.0.Final which is nbot yet included in gRPC master. Upgrading gRPC to fix https://github.com/netty/netty-tcnative/issues/151 and depending on that in google-cloud-java would relieve us from any issues with multiple tcnative usages within the same jvm."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1957",
        "number": 1957,
        "title": "Datastore - call to setNamespace fails under certain Locales ",
        "labels": [],
        "state": "closed",
        "body": "When the JVM is running under certain locales (e.g. `new Locale(\"hi\", \"IN\")`, the call to `setNamespace` fails. with the below Exception: \r\n\r\n```\r\nException in thread \"main\" java.lang.ExceptionInInitializerError\r\n\tat com.google.cloud.datastore.DatastoreOptions$Builder.setNamespace(DatastoreOptions.java:96)\r\n\tat com.example.test.App.main(App.java:21)\r\nCaused by: java.util.regex.PatternSyntaxException: Unclosed counted closure near index 19\r\n[0-9A-Za-z\\._\\-]{0,\u0967\u0966\u0966}\r\n                   ^\r\n\tat java.util.regex.Pattern.error(Pattern.java:1955)\r\n\tat java.util.regex.Pattern.closure(Pattern.java:3141)\r\n\tat java.util.regex.Pattern.sequence(Pattern.java:2134)\r\n\tat java.util.regex.Pattern.expr(Pattern.java:1996)\r\n\tat java.util.regex.Pattern.compile(Pattern.java:1696)\r\n\tat java.util.regex.Pattern.<init>(Pattern.java:1351)\r\n\tat java.util.regex.Pattern.compile(Pattern.java:1028)\r\n\tat com.google.cloud.datastore.Validator.<clinit>(Validator.java:34)\r\n\t... 2 more\r\n\r\n```\r\n## Sample Code \r\n\r\n```\r\npublic static void main(String[] args) {\r\n  Locale.setDefault(new Locale(\"hi\", \"IN\")); //Hindi/India\r\n  Datastore datastore = DatastoreOptions.newBuilder().setProjectId(\"myproject\").setNamespace(\"mynamespace\").build().getService();\r\n}\r\n\r\n```\r\nThe issue is with the below `Pattern` in the `Validator` class: \r\n\r\n```\r\n  private static final Pattern NAMESPACE_PATTERN =\r\n      Pattern.compile(String.format(\"[0-9A-Za-z\\\\._\\\\-]{0,%d}\", MAX_NAMESPACE_LENGTH));\r\n\r\n```\r\nString.format uses the JVM's Locale and MAX_NAMESPACE_LENGTH 100 becomes \"\u0967\u0966\u0966\" (equivalent of 100 in Hindi/India Locale), which makes the Pattern invalid. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1953",
        "number": 1953,
        "title": "From google-cloud-core split out http and grpc",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1944",
        "number": 1944,
        "title": "Handle new values in API responses gracefully (not-almost-GA clients)",
        "labels": [
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "Corresponds to https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1832 but for clients that aren't almost GA. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1936",
        "number": 1936,
        "title": "Conflict with dependency 'com.google.code.findbugs:jsr305' when importing pubsub in Android gradle",
        "labels": [
            "android"
        ],
        "state": "closed",
        "body": "I have a bare empty Android project, I am following [this guide](https://cloud.google.com/pubsub/docs/reference/libraries) for PubSub java client.\r\n So basically:\r\n\r\n`compile group: 'com.google.cloud', name: 'google-cloud-pubsub', version: '0.11.0-alpha'`\r\n\r\nMy gradle file is [here](https://gist.github.com/dariosalviwork/f03e3b58b54f597ba2ccbea7a21c0afa).\r\n\r\nThe error I get is:\r\n\r\n> Error:Conflict with dependency 'com.google.code.findbugs:jsr305' in project ':app'. Resolved versions for app (3.0.0) and test app (2.0.1) differ. See http://g.co/androidstudio/app-test-app-conflict for details.\r\n\r\nThere are also 2 warnings:\r\n\r\n> Warning:WARNING: Dependency org.json:json:20151123 is ignored for release as it may be conflicting with the internal version provided by Android.\r\n\r\n> Warning:WARNING: Dependency org.apache.httpcomponents:httpclient:4.0.1 is ignored for release as it may be conflicting with the internal version provided by Android.\r\n\r\nI think this is related to #1319 but I can't make those suggested solutions work out.\r\n\r\nAny suggestions?\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1925",
        "number": 1925,
        "title": "Translate translate = TranslateOptions.newBuilder().setApiKey(\"myKey\").build().getService(); Sometimes takes Very Long Time!",
        "labels": [
            "android"
        ],
        "state": "closed",
        "body": "The Java/Android client used to work flawlessly, but This error occurred a few weeks ago and still no fix. My app users are getting very frustrated.\r\n\r\nYou can also find this issue here: http://stackoverflow.com/questions/43289297/google-translate-api-sometimes-takes-very-long-time-to-initialize/43316549?noredirect=1#comment73880159_43316549 \r\n\r\n`Translate translate = TranslateOptions.newBuilder().setApiKey(MY_API_KEY).build().getService();` Sometimes Takes Very Long time\r\n\r\nIn my Main Activity, I initialize the Translate variable. If you look at the logs: I track when the initialization starts and when it finishes. Most of the time it initializes quick. But 1/5 times it takes up to 30 seconds to 3 minutes. \r\n\r\n**Example Code**\r\n\r\n\r\n    AsyncTask<Void, Void, Void> asyncTask = new AsyncTask<Void, Void, Void>() {\r\n\r\n        @Override\r\n        public void onPostExecute (Void aVoid) {\r\n\r\n            Log.i(\"APP\", \"finished\");\r\n\r\n        }\r\n\r\n        @Override\r\n        protected Void doInBackground(Void... voids) {\r\n            Log.i(\"APP\", \"start\");\r\n          Translate  translate = TranslateOptions.newBuilder().setApiKey(\"AIzaSyB7cCDBbeoZ2tYTH-Ynv25OaPraLmTG7Hw\").build().getService();\r\n            return null;\r\n        }\r\n\r\n    };\r\n    asyncTask.execute();\r\n\r\nI also have the latest versions in gradle:\r\n\r\n    compile ('com.google.cloud:google-cloud-translate:0.11.0-alpha')\r\n    compile ('com.google.apis:google-api-services-translate:v2-rev49-1.22.0')\r\n0.13.0-apha isn't available but i tested with beta and still same issue."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1924",
        "number": 1924,
        "title": "0.13.0-alpha not detected in Android Studio gradle",
        "labels": [
            "android",
            "api: translation"
        ],
        "state": "closed",
        "body": "The latest available version is compile 'com.google.cloud:google-cloud-translate:0.11.0-alpha'\r\n\r\nCan you please update this?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1923",
        "number": 1923,
        "title": "DEADLINE_EXCEEDED when using pubsub 0.13.0-alpha",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Most but not all requests made via the 0.13.0-alpha client are throwing a DEADLINE_EXCEEDED exception. Ive set log levels to FINE yet have no logging outside of the exceptions themselves. On startup my application shows the following warning:\r\n\r\n```\r\nio.grpc.Context: Storage override doesn't exist. Using default.\r\njava.lang.ClassNotFoundException: io.grpc.override.ContextStorageOverride\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n```\r\n\r\nHowever from cursory reading this appears normal.\r\n\r\nIm using:\r\n\r\n \"com.google.cloud\" % \"google-cloud-pubsub\" % \"0.13.0-alpha\"\r\n      \"com.google.guava\" % \"guava\" % \"19.0\"\r\n      \"com.google.api\" % \"gax\" % \"0.10.0\"\r\n\r\nMy current test code is sending fixed size messages of 3894 bytes. When I attempt to use any batch settings beyond the defaults of 1000Bytes, 100messages, 1 ms, all messages are rejected with DEADLINE_EXCEEDED.\r\n\r\nWhen using the default BatchingSettings from Publisher.defaultBuilder, ~90% of messages are rejected though some do succeed.\r\n\r\n```\r\n\r\npackage com.google.cloud.examples.pubsub.snippets\r\n\r\nimport com.google.api.gax.core.ApiFuture\r\nimport com.google.cloud.pubsub.spi.v1.Publisher\r\n\r\nimport com.google.protobuf.ByteString\r\nimport com.google.pubsub.v1.PubsubMessage\r\nimport com.google.pubsub.v1.TopicName\r\nimport java.util.ArrayList\r\nimport java.util.Arrays\r\nimport java.util.List\r\nimport java.util.logging.{Level, Logger}\r\n\r\nimport com.google.api.gax.bundling.BundlingSettings\r\nimport org.joda.time.Duration\r\n\r\n/**\r\n  * A snippet for Google Cloud Pub/Sub showing how to create a Pub/Sub topic and asynchronously\r\n  * publish messages to it.\r\n  */\r\nobject CreateTopicAndPublishMessages extends App {\r\n    val topic = TopicName.newBuilder().setProject(\"my-application\").setTopic(\"my-development-topic\").build()\r\n\r\n  Logger.getLogger(\"\").setLevel(Level.FINE)\r\n  val batchSettings = BundlingSettings.newBuilder\r\n    .setIsEnabled(true)\r\n    .setDelayThreshold(Duration.standardSeconds(1))\r\n    .setRequestByteThreshold(Publisher.getApiMaxRequestBytes)\r\n    .setElementCountThreshold(250L)\r\n    .build()\r\n\r\n      val publisher = Publisher.newBuilder(topic).setBundlingSettings(batchSettings).build()\r\n  val msg = \"\"\" /// LARGE MESSAGE \"\"\"\r\n      val messages = Seq(\"first message\", \"second message\")\r\n\r\n      val futures =\r\n        (0 to 2000).map { message =>\r\n          val data = ByteString.copyFromUtf8(msg.toString)\r\n          val pubsubMessage = PubsubMessage.newBuilder().setData(data).build()\r\n          val messageIdFuture = publisher.publish(pubsubMessage)\r\n          messageIdFuture\r\n        }\r\n\r\n      futures.foreach{ messageId =>\r\n        System.out.println(\"published with message ID: \" + messageId.get())\r\n      }\r\n\r\n}\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1920",
        "number": 1920,
        "title": "Replace DateTime in Datastore with Timestamp",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1918",
        "number": 1918,
        "title": "Fix google-cloud-java on GAE Std Java8 Issues",
        "labels": [
            "api: datastore",
            "api: logging",
            "api: storage",
            "priority: p2",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "Fix the issues, found during the testing performed in https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1752. \r\n\r\n**Current List of Issues:**\r\n1) **CGLib**: https://gist.github.com/vam-google/862b1dc2c1badf0e675ef04a552ac872#file-gae_std_java8_test_failure___cglib-txt\r\n2) **EasyMock verify not allowed**: https://gist.github.com/vam-google/862b1dc2c1badf0e675ef04a552ac872#file-gae_std_java8_test_failure___easymock_verify_not_allowed-txt\r\n3) **System Prooperty**: https://gist.github.com/vam-google/862b1dc2c1badf0e675ef04a552ac872#file-gae_std_java8_test_failure___env_variable-txt\r\n4) **Wierd NoClassDefFound**: https://gist.github.com/vam-google/862b1dc2c1badf0e675ef04a552ac872#file-gae_std_java8_test_failure___noclassdeffounderror_serialization_test-txt\r\n5) **ThreadManager:** https://gist.github.com/vam-google/862b1dc2c1badf0e675ef04a552ac872#file-gae_std_java8_test_failure___threadmanager-txt\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1909",
        "number": 1909,
        "title": "NPE printed out when loading client properties",
        "labels": [],
        "state": "closed",
        "body": "Running tests, I get these stack traces:\r\n```\r\njava.lang.NullPointerException\r\n        at java.util.Properties$LineReader.readLine(Properties.java:434)\r\n        at java.util.Properties.load0(Properties.java:353)\r\n        at java.util.Properties.load(Properties.java:341)\r\n        at com.google.api.gax.core.PropertiesProvider.loadProperty(PropertiesProvider.java:69)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceSettings.getGapicVersion(ReportErrorsServiceSettings.java:124)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceSettings.defaultChannelProviderBuilder(ReportErrorsServiceSettings.java:117)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceSettings$Builder.<init>(ReportErrorsServiceSettings.java:193)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceSettings$Builder.createDefault(ReportErrorsServiceSettings.java:203)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceSettings$Builder.access$000(ReportErrorsServiceSettings.java:153)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceSettings.defaultBuilder(ReportErrorsServiceSettings.java:133)\r\n        at com.google.cloud.errorreporting.spi.v1beta1.ReportErrorsServiceClientTest.setUp(ReportErrorsServiceClientTest.java:68)\r\n```\r\n\r\nSomehow, tests are still passing. I'm assinging @shinfan to this since I think Shin was working on property loading a few weeks ago. Could you help diagnose?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1907",
        "number": 1907,
        "title": "Fix large memory usage",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1903",
        "number": 1903,
        "title": "`Subscriber` must accept a `SubscriptionName` argument ",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently, `Subscriber` requires a `Subscription` argument, which means retrieving the subscription using `SubscriptionAdminClient` after creating a `SubscriptionName` instance.\r\nThis is too much boiler plate code for the user to have to setup a `Subscriber` instance, we should accept a `SubscriptionName` argument.\r\n\r\n@pongad "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1897",
        "number": 1897,
        "title": "Sample code incorrect in com.google.cloud.pubsub.spi.v1.AckReply.java",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "Sample has an incorrect call to `consumer.accept()` in lines [37](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/MessageReceiver.java#L37) and [39](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/MessageReceiver.java#L39). The `null` parameter shouldn't be there."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1896",
        "number": 1896,
        "title": "Hitting java.lang.NullPointerException error when a query taking a long execution time",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "I am trying out the examples provided as below:\r\n\r\n        QueryRequest request = QueryRequest.newBuilder(query)\r\n                .setUseLegacySql(false) // standard SQL is required to use query parameters\r\n                .build();\r\n        QueryResponse response = bigquery.query(request);\r\n        // Wait for things to finish\r\n        while (!response.jobCompleted())\r\n        {\r\n            Thread.sleep(1000);\r\n            response = bigquery.getQueryResults(response.getJobId());\r\n        }\r\n\r\nBecause my query takes about 3 minutes to finish, I am getting the following error: (initially trigger at line \"_response = bigquery.getQueryResults(response.getJobId());_\")\r\n\r\n\tException in thread \"main\" java.lang.NullPointerException\r\n\t\tat com.google.cloud.bigquery.JobId.fromPb(JobId.java:97)\r\n\t\tat com.google.cloud.bigquery.BigQueryImpl.getQueryResults(BigQueryImpl.java:610)\r\n\t\tat com.google.cloud.bigquery.BigQueryImpl.getQueryResults(BigQueryImpl.java:594)\r\n\r\nHowever, the query seems to be continuing running on the backend.\r\nP.S. I am running a DELETE query."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1895",
        "number": 1895,
        "title": "\"getNumDmlAffectedRows()\" not avaiable in QueryResult class",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I can see this method is already available in REST v2 API as well as api client libaray.\r\n\r\nCan it be ported over to this libarary as well?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1892",
        "number": 1892,
        "title": "BigQuery: include query parameters in QueryJobConfiguration",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I notice that [QueryRequest.Builder](http://googlecloudplatform.github.io/google-cloud-java/0.12.0/apidocs/com/google/cloud/bigquery/QueryRequest.Builder.html) has methods to add positional and named parameters, but [QueryJobConfiguration.Builder](http://googlecloudplatform.github.io/google-cloud-java/0.12.0/apidocs/com/google/cloud/bigquery/QueryJobConfiguration.Builder.html#setUseQueryCache-java.lang.Boolean-) does not.\r\n\r\nAfter a discussion with the BigQuery engineering team, I'm updating all the Java samples to create a job directly (jobs.insert) rather than use the query method (jobs.query). I won't be able to update the samples that use query parameters until these methods are included in the QueryJobConfiguration class."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1891",
        "number": 1891,
        "title": "Getting No Method Error com.google.protobuf.AbstractMessage.newBuilderForType while calling datastore in java",
        "labels": [
            "api: datastore",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "```\r\nErr: \r\nWARN  [2017-04-10 18:30:55,863] [ ] org.eclipse.jetty.util.component.AbstractLifeCycle: FAILED **org.eclipse.jetty.server.Server@2ad2b274: java.lang.NoSuchMethodError: com.google.protobuf.AbstractMessage.newBuilderForType(Lcom/google/protobuf/AbstractMessage$BuilderParent;)Lcom/google/protobuf/Message$Builder;\r\n! java.lang.NoSuchMethodError: com.google.protobuf.AbstractMessage.newBuilderForType(Lcom/google/protobuf/AbstractMessage**$BuilderParent;)Lcom/google/protobuf/Message$Builder;\r\n! at com.google.protobuf.SingleFieldBuilderV3.getBuilder(SingleFieldBuilderV3.java:142)\r\n! at com.google.protobuf.RepeatedFieldBuilderV3.addBuilder(RepeatedFieldBuilderV3.java:413)\r\n! at com.google.datastore.v1.Query$Builder.addKindBuilder(Query.java:1713)\r\n! at com.google.cloud.datastore.StructuredQuery.toPb(StructuredQuery.java:1110)\r\n! at com.google.cloud.datastore.StructuredQuery.populatePb(StructuredQuery.java:1089)\r\n! at com.google.cloud.datastore.QueryResultsImpl.sendRequest(QueryResultsImpl.java:72)\r\n! at com.google.cloud.datastore.QueryResultsImpl.<init>(QueryResultsImpl.java:57)\r\n! at com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:82)\r\n! at com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:73)\r\n! at com.nis.userService.core.managed.DeltaContactConsumer.start(DeltaContactConsumer.java:44)\r\n! at io.dropwizard.lifecycle.JettyManaged.doStart(JettyManaged.java:27)\r\n! at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:69)\r\n! at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:118)\r\n! at org.eclipse.jetty.server.Server.start(Server.java:342)\r\n! at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:100)\r\n! at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:60)\r\n! at org.eclipse.jetty.server.Server.doStart(Server.java:290)\r\n! at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:69)\r\n! at io.dropwizard.cli.ServerCommand.run(ServerCommand.java:43)\r\n! at io.dropwizard.cli.EnvironmentCommand.run(EnvironmentCommand.java:43)\r\n! at io.dropwizard.cli.ConfiguredCommand.run(ConfiguredCommand.java:76)\r\n! at io.dropwizard.cli.Cli.run(Cli.java:70)\r\n! at io.dropwizard.Application.run(Application.java:72)\r\n```\r\n\r\nSample Code that I am running:\r\n      \r\n```\r\nDatastore datastore = DatastoreOptions.getDefaultInstance().getService();\r\n            EntityQuery.Builder queryBuilder = Query.newEntityQueryBuilder().setKind(\"Device\")\r\n                    .setLimit(10);\r\n        while (true) {\r\n            if (pageCursor != null) {\r\n                queryBuilder.setStartCursor(pageCursor);\r\n            }\r\n            QueryResults<Entity> tasks = datastore.run(queryBuilder.build());\r\n            while (tasks.hasNext()) {\r\n                Entity task = tasks.next();\r\n                userLocations.add(new UserLocation(task));\r\n            }\r\n            Cursor nextPageCursor = tasks.getCursorAfter();\r\n            pageCursor = nextPageCursor;\r\n            if (nextPageCursor == null) {\r\n                break;\r\n            }\r\n        }\r\n  \r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1890",
        "number": 1890,
        "title": "JSON serialization assumes Maps aren't iterable",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm using the java libraries from Clojure. Clojure native types (maps, vectors, etc) follow all normal java interfaces, except the built-in maps implement `Iterable`. When using these with BigQuery streaming, the JSON serializer thinks these are collections rather than maps and serializes them incorrectly. It would be nice if it didn't make that assumption and just directly checked for a `x instanceof Map`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1887",
        "number": 1887,
        "title": "DEADLINE_EXCEEDED, google-cloud-vision",
        "labels": [
            "api: vision",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "I am developing a Scala (2.10.6) app that uses the google-cloud-vision Java library (0.11.2-beta), but am getting the following exception: `com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED`\r\n\r\nI enabled FINE logging and see the following output before the exception occurs (certain values replaced with \"BLAH\"):\r\n\r\n```\r\n12:46:17.083 [ForkJoinPool-1-worker-3] INFO  io.grpc.internal.ManagedChannelImpl - [ManagedChannelImpl@1e18908b] Created with target vision.googleapis.com:443\r\n[ERROR] Apr 07, 2017 12:46:17 PM io.grpc.internal.ManagedChannelImpl <init>     \r\n[ERROR] INFO: [ManagedChannelImpl@1e18908b] Created with target vision.googleapis.com:443\r\n12:46:17.202 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - -------------- REQUEST  --------------\r\nPOST https://accounts.google.com/o/oauth2/token                                 \r\nAccept-Encoding: gzip                                                           \r\nUser-Agent: Google-HTTP-Java-Client/1.21.0 (gzip)                               \r\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8                  \r\nContent-Length: 827                                                             \r\n                                                                                \r\n12:46:17.203 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - curl -v --compressed -X POST -H 'Accept-Encoding: gzip' -H 'User-Agent: Google-HTTP-Java-Client/1.21.0 (gz\r\nip)' -H 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' -d '@-' -- 'https://accounts.google.com/o/oauth2/token' << $$$\r\n12:46:17.251 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - Total: 827 bytes\r\n12:46:17.252 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - grant_type=urn%3Aietf%3Aparams%3Aoauth%3Agrant-type%3Ajwt-bearer&assertion=BLAH\r\n12:46:17.390 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - -------------- RESPONSE --------------\r\nHTTP/1.1 200 OK                                                                 \r\nTransfer-Encoding: chunked                                                      \r\nAlt-Svc: quic=\":443\"; ma=2592000; v=\"37,36,35\"                                  \r\nServer: ESF                                                                     \r\nX-Content-Type-Options: nosniff                                                 \r\nPragma: no-cache                                                                \r\nDate: Fri, 07 Apr 2017 19:46:17 GMT                                             \r\nX-Frame-Options: SAMEORIGIN                                                     \r\nCache-Control: no-cache, no-store, max-age=0, must-revalidate                   \r\nContent-Disposition: attachment; filename=\"json.txt\"; filename*=UTF-8''json.txt \r\nContent-Encoding: gzip                                                          \r\nExpires: Mon, 01 Jan 1990 00:00:00 GMT                                          \r\nX-XSS-Protection: 1; mode=block                                                 \r\nContent-Type: application/json; charset=utf-8                                   \r\n                                                                                \r\n12:46:17.396 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - Total: 203 bytes\r\n12:46:17.397 [ForkJoinPool-1-worker-3] INFO  c.g.api.client.http.HttpTransport - {\r\n  \"access_token\" : \"BLAH\",                                                      \r\n  \"expires_in\" : 3600,                                                          \r\n  \"token_type\" : \"Bearer\"                                                       \r\n}\r\n```\r\n\r\nIt looks as if the request for a bearer token succeeded, and yet the method call (batchAnnotateImages) hangs and eventually times out. Here is the code that I'm using:\r\n\r\n```\r\nval imageBytes = ByteString.readFrom(new FileInputStream(filePath))\r\nval image = Image.newBuilder().setContent(imageBytes).build\r\n\r\nval request =\r\n  AnnotateImageRequest\r\n    .newBuilder()\r\n    .addFeatures(Feature.newBuilder().setType(Feature.Type.LABEL_DETECTION).build)\r\n    .setImage(image)\r\n    .build\r\n                                                                                \r\nval scopedCredentials = credentials.createScoped(ImageAnnotatorSettings.getDefaultServiceScopes)                          \r\n\r\nval channelProvider =\r\n  ImageAnnotatorSettings\r\n    .defaultChannelProviderBuilder()\r\n    .setCredentialsProvider(FixedCredentialsProvider.create(scopedCredentials))\r\n    .build\r\n                                                                                \r\nval settingsBuilder =\r\n  ImageAnnotatorSettings\r\n    .defaultBuilder()\r\n    .setChannelProvider(channelProvider)\r\n\r\nsettingsBuilder.batchAnnotateImagesSettings().getRetrySettingsBuilder().setTotalTimeout(Duration.standardSeconds(60))\r\n                                                                                \r\nval response =\r\n  ImageAnnotatorClient\r\n    .create(settingsBuilder.build)\r\n    .batchAnnotateImages(List(request))\r\n```\r\n\r\nI do not see the `java.lang.UnsatisfiedLinkError` reported in: https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1430\r\n\r\nAny ideas as to what might be going wrong, or further debugging steps that I should try?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1883",
        "number": 1883,
        "title": "Versionless redirects to specific javadocs pages",
        "labels": [
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I see that @michaelbausor added https://github.com/GoogleCloudPlatform/google-cloud-java/blob/gh-pages/apidocs/index.html which allows for a link to versionless API docs at http://googlecloudplatform.github.io/google-cloud-java/apidocs/\r\n\r\nWould we be able to add a similar redirect for each of the class & package pages? I'd like to start linking to the API docs from cloud.google.com docs, but it's a pain if I have to keep updating the version number.\r\n\r\nSomewhat related (and maybe worth a separate issue): what are we going to do when the individual packages are versioned separately? I guess this version corresponds to the version of the root meta package?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1882",
        "number": 1882,
        "title": "PubSub hangs with tomcat-jni 8.5.13",
        "labels": [],
        "state": "closed",
        "body": "If I remove this dependency pubsub works just fine. With it the app is just hangs after printing \r\n`Apr 07, 2017 3:06:23 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7d3a22a9] Created with target pubsub.googleapis.com:443\r\n`\r\nI have tried to find what could be causing this problem but with no success. At this point we're unable to use pubsub api with tomcat servlets in our project.\r\n\r\nNo stacktrace is shown so I tried using Java Mission Control to get some insights. The only difference in stacktraces is this:\r\n![image](https://cloud.githubusercontent.com/assets/11451992/24800061/18b55702-1ba7-11e7-8e1c-cea6fea9d5b2.png)\r\nIs the problem with me? And can I do something to make it work?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1881",
        "number": 1881,
        "title": "google cloud api java client on Raspberry pi (DEADLINE_EXCEEDED)",
        "labels": [
            "api: pubsub",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Is it possible to run the java google cloud api in raspberry pi. When i tried cloud speech and cloud pubsub client in raspberry pi it is having io.grpc.status runtimeexception DEADLINE_EXCEEDED.\r\nThe code is running fine in ubuntu desktop.\r\nI searched and found that netty is probably not supported in arm cores.\r\nIs there any fix for this."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1877",
        "number": 1877,
        "title": "Fix Pub/Sub DEADLINE_EXCEEDED issue during build",
        "labels": [],
        "state": "closed",
        "body": "`mvn clean test` sometimes hangs, producing enormous amount of the following errors (all same):\r\n\r\ncom.google.cloud.pubsub.spi.v1.PollingSubscriberConnection$2 onFailure\r\nSEVERE: Failed to pull messages (recoverable): \r\nio.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\r\nrerunning `mvn clean test` usually fixes the issue.\r\n\r\nPlease investigate.\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1874",
        "number": 1874,
        "title": "`SubscriptionAdminClient` : Make creating a pull subscription more explicit than `PushConfig.getDefaultInstance()`",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently if a user intends to create a pull configuration, he or she has to call `SubscriptionAdminClient.createSubscription` with an instance of `PushConfig` (`PushConfig.getDefaultInstance() `or construct a `PushConfig` object). Its confusing that the default instance leads to it being a pull subscription.\r\n\r\nThe semantics  of the `ackDeadlineInSeconds` are slightly different too for the pull vs push configuration and it is not clear whether the bounds are different between pull vs push in the java docs.\r\nIn the java docs, we state that `ackDeadlineInSeconds` has to be atleast 10 seconds for the pull and that if a user provides 0 as input, we use the default. Given the same parameter is used to configure the push endpoint deadline, its not clear if users can provide >0, < 10 values.\r\n\r\nCan we provide users a way to create a pull subscription without providing a boilerplate PushConfig object  ?  This might also make it easier to document the `ackDeadlineInSeconds`better.\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1871",
        "number": 1871,
        "title": "Serializing Spanner Mutations ",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "For Apache Beam support we need to serialize/deserialize Mutations. See https://github.com/apache/beam/pull/2166\r\n\r\nFew options\r\n\r\n- Make Mutation#toProto public https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/Mutation.java#L337  and add corresponding fromProto method.\r\n- Make Mutation serializable and implement writeObject/readObject\r\n- Introduce a new class, move Mutation#toProto code there and implement fromProto."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1868",
        "number": 1868,
        "title": "PollingSubscriberConnection - allow number of messages delivered to be configurable ",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The value is hard coded to an upper bound of 1000 (which used to be 500).  Shouldn't it be configurable?\r\n\r\nThis doesn't work well for really large messages and for messages that take substantial time to process. \r\n\r\nI see no way to configure this value.  Doesn't look like the client has any control over the number of messages pulled from the subscription.  I was hoping that the FlowController logic would support but it seems focused on whether/when to go back the server to get more rather than limiting the number pulled.\r\n\r\nNote that if FlowController is set to 1 element, deadlock is likely on the FlowController semaphore (for example, it being set to 1, while having just processed 10 messages).\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1866",
        "number": 1866,
        "title": "Raise static addresses quota on Travis testing account?",
        "labels": [],
        "state": "closed",
        "body": "One of the causes of flaky tests in this repo appears to be exceeding a quota of global static IP addresses. A representative failure is at https://travis-ci.org/GoogleCloudPlatform/google-cloud-java/jobs/218519105. It looks like any individual test is fine, but if there are enough concurrent tests running, then the account runs out of quota. The test is failing at [ITComputeTest.java#L783](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/8b1009916cbd0c0c5e5c2de40d96d49e69e92457/google-cloud-compute/src/test/java/com/google/cloud/compute/it/ITComputeTest.java#L783)\r\n\r\nTwo options I can see to improve this:\r\n\r\n1. Limit concurrent builds to some number (maybe 7?) https://docs.travis-ci.com/user/customizing-the-build#Limiting-Concurrent-Builds\r\n2. Raise the quota on the testing account to have a much larger number of global static IP's available."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1865",
        "number": 1865,
        "title": "Ensure that single-threaded message pulling works",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "i.e. make sure it doesn't deadlock.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1864",
        "number": 1864,
        "title": "Replace consumer.accept by consumer.ack & consumer.nack in Pub/Sub",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Attempting to tie together some offline discussion to get to a concrete resolution.   The Pub/Sub ack ReplyConsumer [1] uses an enum for reply type. There seems to  consensus that explicit .ack() and .nack() methods would be cleaner.  Could we make this change before beta or disagree, @pongad @davidtorres @garrettjonesgoogle ?  \r\n\r\n\r\n[1] http://googlecloudplatform.github.io/google-cloud-java/0.11.1/apidocs/com/google/cloud/pubsub/spi/v1/AckReplyConsumer.html"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1860",
        "number": 1860,
        "title": "Unknown error getting image annotations",
        "labels": [
            "api: vision",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Input is:https://res.cloudinary.com/viksphotography/image/upload/v1491023435/emt2sgakliae5gap9xks.jpg\r\n[WARNING] /echo\r\njava.io.IOException: Unknown error getting image annotations\r\n\tat photography.viks.ig.DetectLabels.labelImage(DetectLabels.java:161)\r\n\tat com.example.endpoints.EchoServlet.doPost(EchoServlet.java:63)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:837)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1160)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1092)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)\r\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:518)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:244)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\r\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:246)\r\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:156)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nplz advise\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1857",
        "number": 1857,
        "title": " Problem with google-cloud-logging. NoSuchMethodError",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hello,\r\n\r\nI have the following issue with google-cloud-logging: \r\n\r\nI am trying to run the following code-snippet:\r\n\r\n```\r\npackage com.spotify.katamari\r\n\r\nimport java.util.Collections\r\n\r\nimport com.google.cloud.MonitoredResource\r\nimport com.google.cloud.logging.Payload.StringPayload\r\nimport com.google.cloud.logging.{LogEntry, LoggingOptions}\r\n\r\nobject Logging {\r\n  def sendValueToStackdriver(userCount: Long, date: String, pipelineId: String): Unit = {\r\n    val logging = LoggingOptions.newBuilder().setProjectId(\"entity-infrastructure\").build().getService\r\n    val firstEntry: LogEntry = LogEntry.newBuilder(StringPayload.of(s\"UserCounter from $pipelineId\"))\r\n      .setLogName(s\"UserCounter\")\r\n      .setResource(MonitoredResource.newBuilder(\"global\")\r\n        .addLabel(\"value\", userCount.toString)\r\n        .addLabel(\"date\", date)\r\n        .addLabel(\"pipeline-id\", pipelineId)\r\n        .build())\r\n      .build()\r\n    logging.write(Collections.singleton(firstEntry))\r\n  }\r\n}\r\n```\r\nAfter running I get the following stacktrace:\r\n\r\n```\r\n[error] Exception in thread \"main\" java.lang.NoSuchMethodError: io.grpc.protobuf.ProtoUtils.marshaller(Lcom/google/protobuf/Message;)Lio/grpc/MethodDescriptor$Marshaller;\r\n[error] \tat com.google.logging.v2.ConfigServiceV2Grpc.<clinit>(ConfigServiceV2Grpc.java:41)\r\n[error] \tat com.google.cloud.logging.spi.v2.ConfigSettings$Builder.<init>(ConfigSettings.java:306)\r\n[error] \tat com.google.cloud.logging.spi.v2.ConfigSettings$Builder.createDefault(ConfigSettings.java:328)\r\n[error] \tat com.google.cloud.logging.spi.v2.ConfigSettings$Builder.access$000(ConfigSettings.java:259)\r\n[error] \tat com.google.cloud.logging.spi.v2.ConfigSettings.defaultBuilder(ConfigSettings.java:186)\r\n[error] \tat com.google.cloud.logging.spi.v2.GrpcLoggingRpc.<init>(GrpcLoggingRpc.java:102)\r\n[error] \tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:64)\r\n[error] \tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:58)\r\n[error] \tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:460)\r\n[error] \tat com.google.cloud.logging.LoggingOptions.getLoggingRpcV2(LoggingOptions.java:133)\r\n[error] \tat com.google.cloud.logging.LoggingImpl.<init>(LoggingImpl.java:96)\r\n[error] \tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:46)\r\n[error] \tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:41)\r\n[error] \tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:451)\r\n[error] \tat com.spotify.katamari.Logging$.sendValueToStackdriver(Logging.scala:11)\r\n[error] \tat com.spotify.katamari.entity.EntityAPI$.write(EntityAPI.scala:72)\r\n[error] \tat ExampleProducer$.main(ExampleProducer.scala:19)\r\n[error] \tat ExampleProducer.main(ExampleProducer.scala)\r\njava.lang.RuntimeException: Nonzero exit code returned from runner: 1\r\n\tat scala.sys.package$.error(package.scala:27)\r\n[trace] Stack trace suppressed: run last e2e/compile:runMain for the full output.\r\n[error] (e2e/compile:runMain) Nonzero exit code returned from runner: 1\r\n[error] Total time: 314 s, completed Apr 4, 2017 4:17:40 PM\r\n```\r\n\r\nI have made sure to isolate all the dependencies for this logger by putting the snippet code into a separate repository, it still doesn't work. Seems to be some dependency issues with the code. I am using the following library:\r\n\r\n\"com.google.cloud\" % \"google-cloud-logging\" % \"0.11.0-beta\" and have also tried to downgrade it, still facing the same issue."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1856",
        "number": 1856,
        "title": "Spanner - Running Spanner on AppEngine SDK throws an NPE",
        "labels": [
            "api: spanner",
            "priority: p1",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/SessionPool.java#L987\r\n\r\nWhen using Spanner library in AppEngine Standard w/ Java 8 (alpha), createSession() ultimately throws an error, but was consumed and not propagated. Debugger shows a NullPointerException was thrown. However, because it wasn't propagated, the application thread was hung while waiting to take an available session:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/SessionPool.java#L697\r\n\r\nExpected behavior - if connection is unable to open, propagate the exception."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1855",
        "number": 1855,
        "title": "Potential deadlock in Subscriber",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "@davidtorres @garrettjonesgoogle \r\n\r\nA lot of our code uses callback without specifying an executor. [`PollingSubscriberConnection`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/88eff83126d60ff4fb83541f8c954afdc8da425f/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/PollingSubscriberConnection.java#L137) is an example. IIUC, if we don't specify one, the library uses \"directExecutor\". Is this just the same executor we create the channel with? I think that it is.\r\n\r\nIf I'm right, this is dangerous. If we receive a bunch of messages, pullers will block on FlowController, waiting for messages to get processed. Messages can't get processed because all the threads in the pool are blocked on FlowController, resulting in a deadlock. I don't think this can happen in default config since we have 5 threads for each puller, but if user provides their own executor, all bets are off.\r\n\r\nMy current idea: Only use the executor for RPCs. Additionally ask for `numWorkerThreads` and create a new executor for processing messages. Assuming that the user-provided MessageReceiver cannot directly cause more tasks to be registered to the pullers, we should be able to avoid deadlocks.\r\n\r\nWhat do you think?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1854",
        "number": 1854,
        "title": "Front page has outdated API",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "http://googlecloudplatform.github.io/google-cloud-java/0.11.0/index.html has a code snippet:\r\n```\r\nDatastoreOptions options = DatastoreOptions.newBuilder()\r\n  .setProjectId(PROJECT_ID)\r\n  .setAuthCredentials(AuthCredentials.createForJson(\r\n    new FileInputStream(PATH_TO_JSON_KEY))).build();\r\n```\r\n\r\nHowever, `setAuthCredentials` isn't a method on `DatastoreOptions.Builder`- it's `setCredentials`: http://googlecloudplatform.github.io/google-cloud-java/0.11.0/apidocs/com/google/cloud/datastore/DatastoreOptions.Builder.html. It also has it taking an `AuthCredentials` object- `GoogleCredentials` is probably the correct substitute here."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1853",
        "number": 1853,
        "title": "Publisher/Subscriber: rename newBuilder to defaultBuilder",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Context: https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1823#pullrequestreview-30065573"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1851",
        "number": 1851,
        "title": "Write Readme for Natural Language",
        "labels": [
            "api: language",
            "priority: p1"
        ],
        "state": "closed",
        "body": "This includes a getting-started sample."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1850",
        "number": 1850,
        "title": "Write Readme for Vision",
        "labels": [
            "api: vision",
            "priority: p1"
        ],
        "state": "closed",
        "body": "This includes a getting-started sample."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1849",
        "number": 1849,
        "title": "Write Readme for Translate",
        "labels": [
            "api: translation",
            "priority: p1"
        ],
        "state": "closed",
        "body": "This includes a getting-started sample. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1846",
        "number": 1846,
        "title": "DEADLINE_EXCEEDED, after 10 minutes wait.",
        "labels": [
            "api: vision"
        ],
        "state": "closed",
        "body": "OS windows7 enterprise K\r\ntomcat 8.5.11, jdk 1.8\r\nguava-18.0 / 21.0\r\ngoogle-cloud-vision 0.11.0-beta\r\n\r\nIn case of test call using junit, the response was received.\r\nbut no response was received when the call in tomcat server.\r\n\r\nI called batchAnnotateImages method,\r\n(BatchAnnotateImagesResponse response = vision.batchAnnotateImages(requests);)\r\nand 10 minutes later,  DEADLINE_EXCEEDED ERROR occurred.\r\nHow can I fix this issue?\r\n\r\n==========================================================\r\n04/02 14:38:11 [ajp-nio-8009-exec-2] [DEBUG] (URLConnector.java:79) [checkServerTrusted] checkServerTrusted Always..\r\n04/02 14:48:11 [ajp-nio-8009-exec-2] [ERROR] (ExtendedMappingExceptionResolver.java:143) [loggingException] io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\ncom.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:109) ~[gax-0.8.0.jar:na]\r\n\tat com.google.api.gax.core.ApiFutures$1.onFailure(ApiFutures.java:52) ~[gax-0.8.0.jar:na]\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1310) ~[guava-18.0.jar:na]\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:457) ~[guava-18.0.jar:na]\r\n\tat com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156) ~[guava-18.0.jar:na]\r\n\tat com.google.common.util.concurrent.ExecutionList.execute(ExecutionList.java:145) ~[guava-18.0.jar:na]\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:202) ~[guava-18.0.jar:na]\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:466) ~[grpc-stub-1.0.3.jar:1.0.3]\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:442) ~[grpc-stub-1.0.3.jar:1.0.3]\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481) ~[grpc-core-1.0.3.jar:1.0.3]\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398) ~[grpc-core-1.0.3.jar:1.0.3]\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513) ~[grpc-core-1.0.3.jar:1.0.3]\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52) ~[grpc-core-1.0.3.jar:1.0.3]\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154) ~[grpc-core-1.0.3.jar:1.0.3]\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_101]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_101]\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_101]\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_101]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_101]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_101]\r\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_101]\r\nCaused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\tat io.grpc.Status.asRuntimeException(Status.java:545) ~[grpc-core-1.0.3.jar:1.0.3]\r\n\t... 13 common frames omitted\r\n\r\n\r\nthanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1845",
        "number": 1845,
        "title": "Update release scripts to handle 1.x and 0.x versions living together",
        "labels": [],
        "state": "closed",
        "body": "Currently the release scripts assume the same base version for everything; once some libraries go to GA, we will need two separate versioning tracks. We need to update the release scripts to handle this. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1840",
        "number": 1840,
        "title": "Perform GA-ready scrub (experimental/deprecated cleanup)",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "- [x] Consider whether google-cloud-java should have its own definition of `@ExperimentalApi` (or maybe it should be in gax-java). Protobuf has one (public), and gRPC has its own of the same name (marked `@Internal`). \r\n- [x] In google-cloud-core, mark everything that is not used by Datastore/Storage/Logging as experimental.\r\n- [x] Remove any remaining `@Deprecated` things\r\n- [x] Make sure no deprecated features in dependencies are used that have a replacement\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1839",
        "number": 1839,
        "title": "Add a flattened method for SubscriptionAdminClient.seek (requires oneof support)",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Requires https://github.com/googleapis/toolkit/issues/1057 ."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1838",
        "number": 1838,
        "title": "Spanner - Allow set/get of com.google.cloud.spanner.Value",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Is it possible to add methods to respective interfaces and classes to get/set instances of com.google.cloud.spanner.Value in addition to the distinct types that are currently supported? \r\n\r\nFor example - `ResultSet.getValue()` and `ValueBinder.to(Value v)`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1837",
        "number": 1837,
        "title": "Ensure no normalization is done on Storage file names",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Use the following C# integration test as a basis for writing the equivalent in Java:\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-dotnet/pull/933/files\r\n\r\nIf it fails, fix the problem (remove the normalization). If it succeeds, then yay.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1836",
        "number": 1836,
        "title": "DEADLINE_EXCEEDED, google-cloud-monitoring",
        "labels": [
            "api: monitoring",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "This is similar to #1430 \r\n\r\nOS version: OS X 10.10.5 (14F27), Kernel Version: Darwin 14.5.0\r\n\r\nI am having the same issue with _google-cloud-monitoring:0.9.4-alpha_ and _netty-all:4.1.3.Final_. Every time I execute my Java process (see code attached), I end up with the following exception. \r\nLet me know if you need me to provide more details. \r\n\r\ncom.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:107)\r\n\tat com.google.api.gax.grpc.ListenableFutureDelegate$1.onFailure(ListenableFutureDelegate.java:52)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:466)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:442)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\tat io.grpc.Status.asRuntimeException(Status.java:545)\r\n\t... 13 more\r\n\r\n[java-monitoring.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/883365/java-monitoring.txt)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1835",
        "number": 1835,
        "title": "GAPIC clients: merge service address and port",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "It's natural for service address and port to go together - for example, environment variables for emulator hosts from the gcloud command (e.g. `PUBSUB_EMULATOR_HOST`) includes service address and port in a single value. We should just merge these together to make life easier on everyone. \r\n\r\nI'm unsure if this is beta blocking, but I'll proactively mark it as such until further discussion. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1833",
        "number": 1833,
        "title": "DURABLE_REDUCED_AVAILABILITY support missing",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "DURABLE_REDUCED_AVAILABILITY is a [legitimate (though discouraged)](https://cloud.google.com/storage/docs/storage-classes) value for StorageClass.\r\n\r\nThe [current enum in google-cloud-java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/007f340dd82abf4b8f1a66df9351abe9cb53d58f/google-cloud-storage/src/main/java/com/google/cloud/storage/StorageClass.java) does not include a value for DURABLE_REDUCED_AVAILABILITY so we crash when the server's reply contains this value.\r\n\r\nWe should add the value to the enum.\r\n\r\nSee [this bug report](https://github.com/broadinstitute/gatk/issues/2517) for an example of someone running into this problem."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1832",
        "number": 1832,
        "title": "Handle new values in API responses gracefully (for almost-GA clients)",
        "labels": [
            "api: datastore",
            "api: logging",
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "There was [a bug][] in the Node.js Vision client which was effectively that the client raised an exception if it ever got a key that it did not expect. This is relatively easy to do for any number of reasons:\r\n\r\n```python\r\n# `raw_response` is a dict that came back from the API.\r\nkey_map = {\r\n    'alphaObject': 'alpha_object',\r\n    'betaObject': 'beta_object',\r\n}\r\nnew_response = {}\r\nfor k, v in raw_response.iteritems():\r\n    new_response[key_map[k]] = v\r\n```\r\n\r\nThis is an anti-pattern, because it strongly assumes that you will never get a new key that is not already in your key map. If the API adds a `gammaObject` key and this (Python) code were to run, suddenly what used to work now raises `KeyError`.\r\n\r\nThe solution: Add unit tests in each spot where we transform an API response into a custom object to ensure that unexpected key-value pairs are either passed through or dropped.\r\n\r\n  [a bug]: https://github.com/GoogleCloudPlatform/google-cloud-node/issues/2034"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1830",
        "number": 1830,
        "title": "Make sure Publisher/Subscriber use same channel customization as TopicAdminClient/SubscriptionAdminClient",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1829",
        "number": 1829,
        "title": "Remove usage of NettyChannelBuilder.flowControl",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1828",
        "number": 1828,
        "title": "Make package-private: SubscriptionAdminClient.pull/modifyAckDeadline/acknowledge/updateSubscription, TopicAdminClient.publish",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1827",
        "number": 1827,
        "title": "pubsub Limit the number of subscriber threads how?",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Can someone please provide an example of limiting the number of pulling pubsub threads with the new API so we can start testing?\r\n\r\nIn the old API it was possible to limit the number of concurrent threads that pulled messages with the following code:\r\n\r\n```java\r\nPubSub.MessageConsumer consumer = pubsub.pullAsync(\r\n        subscription,\r\n        messageProcessor,\r\n        PubSub.PullOption.maxQueuedCallbacks(maxQueuedCallbacks),\r\n        PubSub.PullOption.executorFactory(executorFactory)\r\n    );\r\n```\r\n`where maxQueuedCallbacks` was an integer amount of msgs to pull and\r\n`executorFactory` was provided from this\r\n```java\r\n /**\r\n   * Create an ExecutorFactory instance for use with a single\r\n   * {@link PubSub.MessageConsumer}.\r\n   *\r\n   * <p>The number of threads in the executor determines how many messages can be processed at one\r\n   * time.</p>\r\n   *\r\n   * @see PubSub.PullOption#executorFactory(ExecutorFactory)\r\n   */\r\n  private static ExecutorFactory<ExecutorService> createExecutor(\r\n      final int threads,\r\n      final String threadNameFormat) {\r\n    final ThreadFactory threadFactory = new ThreadFactoryBuilder()\r\n        .setDaemon(true)\r\n        .setNameFormat(threadNameFormat)\r\n        .build();\r\n\r\n    final ExecutorService executorService = Executors.newFixedThreadPool(threads, threadFactory);\r\n\r\n    return new ExecutorFactory<ExecutorService>() {\r\n      @Override\r\n      public ExecutorService get() {\r\n        return executorService;\r\n      }\r\n\r\n      @Override\r\n      public void release(final ExecutorService executor) {\r\n        executorService.shutdownNow();\r\n      }\r\n    };\r\n  }\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1826",
        "number": 1826,
        "title": "TranslateScopes does not exists?",
        "labels": [
            "api: translation",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi,\r\nin order to authenticate my application I create a URL to request that the user provide access to the xxx API like BigQuery+Plus+Cloud iIsion ...\r\n\r\n```\r\nList<String> acl = new ArrayList<String>();\r\n\t\tacl.add(BigqueryScopes.BIGQUERY);\r\n\t\tacl.add(\"https://mail.google.com/\");\r\n\t\tacl.add(CalendarScopes.CALENDAR_READONLY);\r\n\t\tacl.add(YouTubeScopes.YOUTUBE_FORCE_SSL);\r\n\t\tacl.add(YouTubeScopes.YOUTUBE_UPLOAD);\r\n\t\tacl.add(VisionScopes.CLOUD_PLATFORM);\r\n\t\tacl.add(PlusScopes.PLUS_ME);\r\n\t\t//\t\tacl.add(StorageScopes.DEVSTORAGE_READ_WRITE);\r\n\t\t// Create a URL to request that the user provide access to the BigQuery API\r\n\t\tString authorizeUrl = new GoogleAuthorizationCodeRequestUrl(\r\n\t\t\t\tclientSecrets,\r\n\t\t\t\tREDIRECT_URI,\r\n\t\t\t\tacl).build();\r\n```\r\n\r\nI need to add an ACL for Cloud Translate API and don't find it.\r\nWhere is the TranslateScope?\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1816",
        "number": 1816,
        "title": "ResultSet should implement Iterable.",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It seems convenient for `com.google.cloud.spanner.ResultSet` to implement `Iterable` or `Iterator`. It would allow for easier use with existing Java/JDK APIs. Right now, I have to roll my own Iterator :(."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1814",
        "number": 1814,
        "title": "Old pubsub API which is the latest version?",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Which version of the library has the latest of the \"old\" pubsub api?\r\nWe need to upgrade to the latest without breaking the api as the new api is not backwards compatible.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1813",
        "number": 1813,
        "title": "No getService method in google-cloud-storage",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "README.MD for google-cloud-storage refers to\r\n\r\n```\r\nStorage storage = StorageOptions.getDefaultInstance().getService();\r\n```\r\n\r\nand a few other times. It appears this is no longer accurate at 0.10.alpha.\r\n\r\n\r\nI.e. the `StorageOptions` class does not have a `getService` method. I'm not sure what it should be replaced with. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1811",
        "number": 1811,
        "title": "JavaDoc's - we need to find a way to move autogen'd API's up to API packages.",
        "labels": [
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Looking at the 0.10.0 [javadoc](http://googlecloudplatform.github.io/google-cloud-java/0.10.0/apidocs/), pubsub appears to be deprecated.\r\n\r\nIt would be nice if we could have autogen'd api's show up under **API Packages**.\r\n\r\nOr we need to figure out how to train developers to look under SPI.\r\n\r\n@garrettjonesgoogle \r\n@omaray FYI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1810",
        "number": 1810,
        "title": "Spanner - Expose transaction protocol",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently, transaction is wrapped around a single run block. Typically, there is a begin transaction & commit semantic where we can get a tx ID and tie operation to the tx ID. According to @vkedia, there is the wire protocol for this, that can be exposed. This could help significantly in tying better w/ JTA standards. \r\n\r\nCurrently, the [community jdbc driver](https://github.com/olavloite/spanner-jdbc/blob/master/src/main/java/nl/topicus/jdbc/transaction/TransactionThread.java) is trying to work around this by having a single runnable thread that listens/pulls from a queue of requests.\r\n\r\n/cc @emmanuelbernard to see if this will be helpful & what the JTA needs are."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1809",
        "number": 1809,
        "title": "JavaDoc missing for PubSub  ??",
        "labels": [],
        "state": "closed",
        "body": "Looking at the [javadocs](http://googlecloudplatform.github.io/google-cloud-java/0.10.0/apidocs/) for 0.10.0\r\n\r\nI don't see `com.google.pubsub.v1` listed, just:\r\n\r\ncom.google.cloud.pubsub.deprecated\t\r\ncom.google.cloud.pubsub.deprecated.spi\t \r\ncom.google.cloud.pubsub.deprecated.testing\t\r\ncom.google.cloud.pubsub.spi.v1\t\r\n\r\nAm I missing something?\r\n\r\n@pongad \r\n@garrettjonesgoogle \r\n@jabubake \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1807",
        "number": 1807,
        "title": "PubSub - doesn't work on App Engine Standard",
        "labels": [
            "api: pubsub",
            "running on app engine"
        ],
        "state": "closed",
        "body": "Since the pubsub client lib is all async and uses thread pools (which GAE Standard doesn't allow), the pubsub lib doesn't work on GAE Standard."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1805",
        "number": 1805,
        "title": "Spanner - Improve methods from some of the builder patterns for generic usages",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "When writing things like object mappers, the builder pattern tends to get in the way unless it has some generic input methods. Here is for example the `Mutation` usage I had to do\r\n\r\n```\r\n        Mutation.WriteBuilder writeBuilder = Mutation.newInsertOrUpdateBuilder( key.getTable() );\r\n\t\ttuplePointer.getTuple().getOperations().forEach( op -> {\r\n\t\t\tswitch ( op.getType() ) {\r\n\t\t\t\tcase PUT:\r\n\t\t\t\t\tValueBinder<Mutation.WriteBuilder> set = writeBuilder.set( op.getColumn() );\r\n\t\t\t\t\tObject object = op.getValue();\r\n\t\t\t\t\t//TODO should we convert to Google Spanner native types here or before?\r\n\t\t\t\t\t// e.g. they have their own Date and Timestamp\r\n\t\t\t\t\tif ( object instanceof Timestamp ) {\r\n\t\t\t\t\t\tset.to( (Timestamp) object );\r\n\t\t\t\t\t}\r\n\t\t\t\t\telse if ( object instanceof Date ) {\r\n\t\t\t\t\t\tset.to( (Date) object );\r\n\t\t\t\t\t}\r\n\t\t\t\t\telse if ( object instanceof String ) {\r\n\t\t\t\t\t\tset.to( (String) object );\r\n\t\t\t\t\t}\r\n\t\t\t\t\telse if ( object instanceof Long ) {\r\n\t\t\t\t\t\tset.to( (Long) object );\r\n\t\t\t\t\t}\r\n\t\t\t\t\telse if ( object instanceof Boolean ) {\r\n\t\t\t\t\t\tset.to( (Boolean) object );\r\n\t\t\t\t\t}\r\n\t\t\t\t\telse if ( object instanceof Double ) {\r\n\t\t\t\t\t\tset.to( (Double) object );\r\n\t\t\t\t\t}\r\n\t\t\t\t\tbreak;\r\n\t\t\t\tcase PUT_NULL:\r\n\t\t\t\tcase REMOVE:\r\n\t\t\t\t\t// TODO add metadata related to the type of the column we nullify\r\n\t\t\t\t\twriteBuilder.set( op.getColumn() ).to( (String) null);\r\n                                        break;\r\n\t\t\t}\r\n\r\n\t\t} );\r\n\t\tdatabaseClient.write( Arrays.asList( writeBuilder.build() ) );\r\n```\r\n\r\nOne improvement could be to offer a generic `to(Object)` method that does the `instanceof` check for me.\r\n\r\nAnother possible improvement (that would not help for my case) is to offer\r\n\r\n```\r\n// ideally if types is optional that's even better\r\nsetAll(String[] columnNames, Object[] columnValues, Class[] types);\r\n``` "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1804",
        "number": 1804,
        "title": "Spanner - consider adding .set(...).toNull() method",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently setting a field to null requires to call the type-specific `.to(...)` method for the type. If setting something to null, we need to `.set(\"field\").to((String) null)`\r\n\r\nConsider adding a `.set(...).toNull()` method"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1803",
        "number": 1803,
        "title": "Different google-cloud-java artifacts depends on different versions of the libraries, breaking build any enforcer projects",
        "labels": [
            "dependencies"
        ],
        "state": "closed",
        "body": "Hey,\r\n\r\nI'm winged by @glaforge on having a Hibernate OGM dialect. Here is the error I get from an enforcer based maven module (we use enforcer because I'm told it's the right thing to do :) ).\r\n\r\nThe module dependency definition is\r\n\r\n```\r\n <dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>google-cloud-spanner</artifactId>\r\n            <version>0.10.0-beta</version>\r\n            <exclusions>\r\n                <exclusion>\r\n                    <groupId>com.google.guava</groupId>\r\n                    <artifactId>guava-jdk5</artifactId>\r\n                </exclusion>\r\n                <exclusion>\r\n                    <groupId>com.google.guava</groupId>\r\n                    <artifactId>guava</artifactId>\r\n                </exclusion>\r\n                <exclusion>\r\n                    <groupId>com.google.api-client</groupId>\r\n                    <artifactId>google-api-client-appengine</artifactId>\r\n                </exclusion>\r\n            </exclusions>\r\n        </dependency>\r\n```\r\n\r\n\r\n```\r\nemmanuel@emmanuel-mbp-15rb spanner (master *) $ mvn clean install\r\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0\r\nScanning for projects...\r\n\r\n------------------------------------------------------------------------\r\nBuilding Hibernate OGM for Spanner 5.2.0-SNAPSHOT\r\n------------------------------------------------------------------------\r\n\r\n--- maven-clean-plugin:3.0.0:clean (default-clean) @ hibernate-ogm-spanner ---\r\nDeleting /Users/emmanuel/Code/ogm/spanner/target\r\n\r\n--- buildnumber-maven-plugin:1.4:create (default) @ hibernate-ogm-spanner ---\r\nExecuting: /bin/sh -c cd '/Users/emmanuel/Code/ogm/spanner' && 'git' 'rev-parse' '--verify' 'HEAD'\r\nWorking directory: /Users/emmanuel/Code/ogm/spanner\r\nStoring buildNumber: 299f590dcd4842e4dd332274804e22fb842951f2 at timestamp: 1490302608539\r\nStoring buildScmBranch: master\r\n\r\n--- maven-enforcer-plugin:1.4.1:enforce (enforce-rules) @ hibernate-ogm-spanner ---\r\n\r\nDependency convergence error for com.google.auto.value:auto-value:1.1 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api:api-common:0.0.2\r\n        +-com.google.auto.value:auto-value:1.1\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.auto.value:auto-value:1.2\r\n\r\n\r\nDependency convergence error for com.google.code.findbugs:jsr305:1.3.9 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.http-client:google-http-client:1.21.0\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.oauth-client:google-oauth-client:1.21.0\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api:api-common:0.0.2\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-io.grpc:grpc-netty:1.0.3\r\n      +-io.grpc:grpc-core:1.0.3\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.code.findbugs:jsr305:3.0.0\r\n\r\n\r\nDependency convergence error for com.google.protobuf:protobuf-java:3.0.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-io.grpc:grpc-protobuf:1.0.3\r\n        +-com.google.protobuf:protobuf-java:3.0.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.5\r\n        +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-iam-v1:0.1.5\r\n        +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:0.1.5\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:0.1.5\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\n\r\n\r\nDependency convergence error for com.google.protobuf:protobuf-java-util:3.0.2 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-io.grpc:grpc-protobuf:1.0.3\r\n        +-com.google.protobuf:protobuf-java-util:3.0.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.protobuf:protobuf-java-util:3.0.0\r\n\r\n\r\nDependency convergence error for com.google.api.grpc:grpc-google-common-protos:0.1.5 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.5\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-iam-v1:0.1.5\r\n        +-com.google.api.grpc:grpc-google-common-protos:0.1.5\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:0.1.5\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:0.1.5\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\n\r\n\r\nDependency convergence error for com.google.oauth-client:google-oauth-client:1.21.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.oauth-client:google-oauth-client:1.21.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api-client:google-api-client:1.20.0\r\n      +-com.google.oauth-client:google-oauth-client:1.20.0\r\n\r\n\r\nDependency convergence error for joda-time:joda-time:2.9.2 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-joda-time:joda-time:2.9.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api:api-common:0.0.2\r\n        +-joda-time:joda-time:2.8.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-joda-time:joda-time:2.8.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-joda-time:joda-time:2.9.2\r\n\r\n\r\nDependency convergence error for com.google.auth:google-auth-library-credentials:0.6.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.auth:google-auth-library-credentials:0.6.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-io.grpc:grpc-auth:1.0.3\r\n      +-com.google.auth:google-auth-library-credentials:0.4.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.auth:google-auth-library-credentials:0.4.0\r\n\r\n\r\nDependency convergence error for com.google.auth:google-auth-library-oauth2-http:0.6.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.6.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.4.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.auth:google-auth-library-oauth2-http:0.4.0\r\n\r\nRule 1: org.apache.maven.plugins.enforcer.DependencyConvergence failed with message:\r\nFailed while enforcing releasability the error(s) are [\r\nDependency convergence error for com.google.auto.value:auto-value:1.1 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api:api-common:0.0.2\r\n        +-com.google.auto.value:auto-value:1.1\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.auto.value:auto-value:1.2\r\n,\r\nDependency convergence error for com.google.code.findbugs:jsr305:1.3.9 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.http-client:google-http-client:1.21.0\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.oauth-client:google-oauth-client:1.21.0\r\n        +-com.google.code.findbugs:jsr305:1.3.9\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api:api-common:0.0.2\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-io.grpc:grpc-netty:1.0.3\r\n      +-io.grpc:grpc-core:1.0.3\r\n        +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.code.findbugs:jsr305:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.code.findbugs:jsr305:3.0.0\r\n,\r\nDependency convergence error for com.google.protobuf:protobuf-java:3.0.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-io.grpc:grpc-protobuf:1.0.3\r\n        +-com.google.protobuf:protobuf-java:3.0.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.5\r\n        +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-iam-v1:0.1.5\r\n        +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:0.1.5\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:0.1.5\r\n      +-com.google.protobuf:protobuf-java:3.0.0\r\n,\r\nDependency convergence error for com.google.protobuf:protobuf-java-util:3.0.2 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-io.grpc:grpc-protobuf:1.0.3\r\n        +-com.google.protobuf:protobuf-java-util:3.0.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.protobuf:protobuf-java-util:3.0.0\r\n,\r\nDependency convergence error for com.google.api.grpc:grpc-google-common-protos:0.1.5 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.5\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.api.grpc:grpc-google-iam-v1:0.1.5\r\n        +-com.google.api.grpc:grpc-google-common-protos:0.1.5\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:0.1.5\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:0.1.5\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.api.grpc:grpc-google-common-protos:0.1.6\r\n,\r\nDependency convergence error for com.google.oauth-client:google-oauth-client:1.21.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.oauth-client:google-oauth-client:1.21.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api-client:google-api-client:1.20.0\r\n      +-com.google.oauth-client:google-oauth-client:1.20.0\r\n,\r\nDependency convergence error for joda-time:joda-time:2.9.2 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-joda-time:joda-time:2.9.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api.grpc:grpc-google-cloud-spanner-v1:0.1.5\r\n      +-com.google.api:api-common:0.0.2\r\n        +-joda-time:joda-time:2.8.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-joda-time:joda-time:2.8.2\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-joda-time:joda-time:2.9.2\r\n,\r\nDependency convergence error for com.google.auth:google-auth-library-credentials:0.6.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.auth:google-auth-library-credentials:0.6.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-io.grpc:grpc-auth:1.0.3\r\n      +-com.google.auth:google-auth-library-credentials:0.4.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.auth:google-auth-library-credentials:0.4.0\r\n,\r\nDependency convergence error for com.google.auth:google-auth-library-oauth2-http:0.6.0 paths to dependency are:\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.cloud:google-cloud-core:0.10.0-alpha\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.6.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.api:gax:0.4.0\r\n      +-com.google.auth:google-auth-library-oauth2-http:0.4.0\r\nand\r\n+-org.hibernate.ogm:hibernate-ogm-spanner:5.2.0-SNAPSHOT\r\n  +-com.google.cloud:google-cloud-spanner:0.10.0-beta\r\n    +-com.google.auth:google-auth-library-oauth2-http:0.4.0\r\n]\r\n------------------------------------------------------------------------\r\nBUILD FAILURE\r\n------------------------------------------------------------------------\r\nTotal time: 2.487 s\r\nFinished at: 2017-03-23T13:56:49-07:00\r\nFinal Memory: 20M/318M\r\n------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce-rules) on project hibernate-ogm-spanner: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1802",
        "number": 1802,
        "title": "Shade Guava in google-cloud-spanner",
        "labels": [
            "api: spanner"
        ],
        "state": "closed",
        "body": "Spanner.closeAsync() exposes ListenableFuture from Guava\r\n\r\nCausing issues when writing a POC w/ @emmanuelbernard on Hibernate OGM dialect."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1801",
        "number": 1801,
        "title": "Docs: make clear that app engine standard w/ Java 7 not supported yet for grpc-based APIs",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1800",
        "number": 1800,
        "title": "Vision API broken: Google App Engine does not support Runtime.addShutdownHook",
        "labels": [
            "api: vision",
            "running on app engine"
        ],
        "state": "closed",
        "body": "@ApiMethod(name = \"analyzeImage\")\r\n      public Message analyzeImage(@Named(\"imgURL\") String imgURL) {\r\n        try {\r\n            GoogleCredential credential = GoogleCredential.getApplicationDefault();\r\n\r\n             ImageAnnotatorClient vision = ImageAnnotatorClient.create();\r\n\r\n         // Performs label detection on the image file\r\n            BatchAnnotateImagesResponse response = vision.batchAnnotateImages(requests);\r\n            List<AnnotateImageResponse> responses = response.getResponsesList();\r\n\r\n            for (AnnotateImageResponse res : responses) {\r\n              if (res.hasError()) {\r\n                System.out.printf(\"Error: %s\\n\", res.getError().getMessage());\r\n                return new Message(\"Something broke\");\r\n              }\r\n\r\n              for (EntityAnnotation annotation : res.getLabelAnnotationsList()) {\r\n                Map<FieldDescriptor, Object> m = annotation.getAllFields();\r\n                Set<FieldDescriptor> s = m.keySet();\r\n                for(FieldDescriptor key : s){\r\n                    System.out.printf(\"%s : %s\\n\", key, m.get(key).toString());\r\n                }\r\n              }\r\n            }\r\n        } catch (IOException e) {\r\n            // TODO Auto-generated catch block\r\n            e.printStackTrace();\r\n        }\r\n        return new Message(\"Hello:\" + imgURL);\r\n      } \r\n\r\nHowever, the line \r\n\r\n ImageAnnotatorClient vision = ImageAnnotatorClient.create();\r\n\r\nends up throwing:\r\njava.lang.SecurityException: Google App Engine does not support Runtime.addShutdownHook\r\n\tat com.google.appengine.runtime.Request.process-75407a6647252b61(Request.java)\r\n\tat java.lang.Runtime.addShutdownHook(Runtime.java:45)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.addShutdownHook(MoreExecutors.java:232)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.addDelayedShutdownHook(MoreExecutors.java:204)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.getExitingScheduledExecutorService(MoreExecutors.java:196)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.getExitingScheduledExecutorService(MoreExecutors.java:228)\r\n\tat com.google.common.util.concurrent.MoreExecutors.getExitingScheduledExecutorService(MoreExecutors.java:176)\r\n\tat com.google.api.gax.grpc.InstantiatingExecutorProvider.getExecutor(InstantiatingExecutorProvider.java:51)\r\n\tat com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:62)\r\n\tat com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:81)\r\n\tat com.google.cloud.vision.spi.v1.ImageAnnotatorClient.<init>(ImageAnnotatorClient.java:120)\r\n\tat com.google.cloud.vision.spi.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:111)\r\n\tat com.google.cloud.vision.spi.v1.ImageAnnotatorClient.create(ImageAnnotatorClient.java:102)\r\n\tat photography.viks.ig.api.InstaSmartSvc.analyzeImage(InstaSmartSvc.java:93)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:42)\r\n\tat com.google.api.server.spi.SystemService.invokeServiceMethod(SystemService.java:351)\r\n\tat com.google.api.server.spi.handlers.EndpointsMethodHandler$RestHandler.handle(EndpointsMethodHandler.java:114)\r\n\tat com.google.api.server.spi.handlers.EndpointsMethodHandler$RestHandler.handle(EndpointsMethodHandler.java:102)\r\n\tat com.google.api.server.spi.dispatcher.PathDispatcher.dispatch(PathDispatcher.java:49)\r\n\tat com.google.api.server.spi.EndpointsServlet.service(EndpointsServlet.java:71)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\r\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)\r\n\tat com.google.api.control.ControlFilter.doFilter(ControlFilter.java:220)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.api.control.ConfigFilter.doFilter(ConfigFilter.java:120)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1798",
        "number": 1798,
        "title": "paging vs infinite API's - Cloud Storage, but more broadly applicable...",
        "labels": [
            "api: storage",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "In looking at the cloud storage API's, they are really a mapping of our internal protobuf apis to a client surface rather than going with what we had hoped to be the more natural view.\r\n\r\nFor example  we show the following for list:\r\n\r\n```java\r\n String bucketName = \"my_unique_bucket\";\r\n String directory = \"my_directory/\";\r\n Page<Blob> blobs = storage.list(bucketName, BlobListOption.currentDirectory(),\r\n     BlobListOption.prefix(directory));\r\n Iterator<Blob> blobIterator = blobs.iterateAll();\r\n while (blobIterator.hasNext()) {\r\n   Blob blob = blobIterator.next();\r\n   // do something with the blob\r\n }\r\n```\r\n\r\nIn actuality the usage is more like:\r\n\r\n```java\r\n String bucketName = \"my_unique_bucket\";\r\n String directory = \"my_directory/\";\r\n Page<Blob> blobs = storage.list(bucketName, BlobListOption.currentDirectory(),\r\n     BlobListOption.prefix(directory));\r\n do {\r\n    Iterator<Blob> blobIterator = blobs.iterateAll();\r\n    while (blobIterator.hasNext()) {\r\n      Blob blob = blobIterator.next();\r\n      // do something with the blob\r\n    }\r\n    blobs = blobs.getNextPage();\r\n  } while ( blobs != null);\r\n```\r\n\r\nIn a sense there are cases where it makes sense to use paging, such as doing so in a web app, but there are also many cases where we should hide our complexity from our users and just provide a single blobs iterator.\r\n\r\nI don't wish to block GA with this as I don't think it makes sense, but this is something we should fix in the autogenerated libraries.  Developers should be able to choose between a paged api, for webapps and the like, and a continuous api (that we can optimize behind the scenes).\r\n\r\n@anthmgoogle FYI\r\n@waprin FYI\r\n@jabubake FYI\r\n@garrettjonesgoogle \r\n@jgeewax FYI"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1797",
        "number": 1797,
        "title": "pubsub DEADLINE_EXCEEDED (after period of inactivity)",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "We see a strange behaviour in when there is low traffic on a topic where stackdriver shows a spike in undelivered messages as well as oldest unacknowledged message.\r\n\r\nWe do get some io.grpc.StatusRuntimeExceptions during these low traffic times but not when there is high traffic during the day.\r\n\r\nCould comeone have an explaination about this? We are using \r\n-netty-all 4.1.5.Final \r\n- com.google.cloud 0.5.1\r\n\r\n\r\n```\r\nio.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: The service was unable to fulfill your request. Please try again. [code=8a75]\r\n    at io.grpc.Status.asRuntimeException\r\n    at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose\r\n    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close\r\n    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600\r\n    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext\r\n    at io.grpc.internal.ContextRunnable.run\r\n    at io.grpc.internal.SerializingExecutor$TaskRunner.run\r\n    at java.util.concurrent.Executors$RunnableAdapter.call\r\n    at java.util.concurrent.FutureTask.run\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\r\n    at java.lang.Thread.run\r\ncom.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: The service was unable to fulfill your request. Please try again. [code=8a75]\r\n    at com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure\r\n    at com.google.common.util.concurrent.Futures$6.run\r\n    at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute\r\n    at com.google.common.util.concurrent.AbstractFuture.executeListener\r\n    at com.google.common.util.concurrent.AbstractFuture.complete\r\n    at com.google.common.util.concurrent.AbstractFuture.setException\r\n    at io.grpc.stub.ClientCalls$GrpcFuture.setException\r\n    at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose\r\n    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close\r\n    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600\r\n    at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext\r\n    at io.grpc.internal.ContextRunnable.run\r\n    at io.grpc.internal.SerializingExecutor$TaskRunner.run\r\n    at java.util.concurrent.Executors$RunnableAdapter.call\r\n    at java.util.concurrent.FutureTask.run\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\r\n    at java.lang.Thread.run\r\ncom.google.cloud.pubsub.PubSubException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: The service was unable to fulfill your request. Please try again. [code=8a75]\r\n    at com.google.cloud.pubsub.spi.DefaultPubSubRpc$1.apply\r\n    at com.google.cloud.pubsub.spi.DefaultPubSubRpc$1.apply\r\n    at com.google.common.util.concurrent.Futures$CatchingFuture.doFallback\r\n    at com.google.common.util.concurrent.Futures$CatchingFuture.doFallback\r\n    at com.google.common.util.concurrent.Futures$AbstractCatchingFuture.run\r\n    at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute\r\n    at com.google.common.util.concurrent.AbstractFuture.executeListener\r\n    at com.google.common.util.concurrent.AbstractFuture.complete\r\n    at com.google.common.util.concurrent.AbstractFuture.setException\r\n    at com.google.common.util.concurrent.SettableFuture.setException\r\n    at com.google.api.gax.grpc.BundlingFuture.setException\r\n    at com.google.api.gax.grpc.BundlingContext.sendResult\r\n    at com.google.api.gax.grpc.BundleExecutor.processBundle\r\n    at com.google.api.gax.bundling.ThresholdBundlingForwarder$BundleForwardingRunnable.processBundle\r\n    at com.google.api.gax.bundling.ThresholdBundlingForwarder$BundleForwardingRunnable.run\r\n    at java.lang.Thread.run\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1795",
        "number": 1795,
        "title": "Fix LoggingHandler flush",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Logging handler's `flush()` calls `LoggingImpl.write` which eventually calls `LoggingClient.writeLogEntries` which uses bundling. So, handler flushing just moves messages from one buffer to another without actually making any RPC call.\r\n\r\n## Proposed fix\r\nLoggingHandler should keep a count of pending messages. The count increments with calls to publish and decrements when RPC returns.\r\n\r\nFlush should force batcher to issue all buffered messages and just wait for the count to reach zero. No call to publish may succeed when flush is \"in flight\" otherwise flush could wait forever.\r\n\r\nEncountering a log above the configured flush level should also force a flush."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1792",
        "number": 1792,
        "title": "BigQuery: Support Date, Time, and DateTime types in FieldValue",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Use types from threetenbp.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1791",
        "number": 1791,
        "title": "Remove usage of spi Tuple classes under google-cloud-examples",
        "labels": [
            "api: bigquery",
            "api: core",
            "api: storage"
        ],
        "state": "closed",
        "body": "* https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/bigquery/BigQueryExample.java uses `com.google.cloud.bigquery.spi.v2.BigQueryRpc.Tuple`\r\n* https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/storage/StorageExample.java uses `com.google.cloud.storage.spi.v1.StorageRpc.Tuple`\r\n\r\nThese tuple definitions are identical; maybe we should just make a Tuple class under core for everything to share. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1789",
        "number": 1789,
        "title": "Remove obsolete PubSub references from docs",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/TESTING.md\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/README.md\r\n\r\ngrep for any others too."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1788",
        "number": 1788,
        "title": "Consider trimming the dependencies of google-cloud-spanner",
        "labels": [
            "api: spanner",
            "dependencies",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Currently google-cloud-spanner pulls in lot of dependencies most of which it does not need. We should consider if it is possible to refactor the dependency chain in such a way as to reduce the number:\r\nHere is the current tree:\r\n```\r\n[INFO] com.google.cloud:google-cloud-spanner:jar:0.10.1-beta-SNAPSHOT\r\n[INFO] +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork19:compile\r\n[INFO] +- com.google.cloud:google-cloud-core:jar:0.10.1-alpha-SNAPSHOT:compile\r\n[INFO] |  +- com.google.http-client:google-http-client:jar:1.21.0:compile\r\n[INFO] |  |  \\- org.apache.httpcomponents:httpclient:jar:4.0.1:compile\r\n[INFO] |  |     +- org.apache.httpcomponents:httpcore:jar:4.0.1:compile\r\n[INFO] |  |     +- commons-logging:commons-logging:jar:1.1.1:compile\r\n[INFO] |  |     \\- commons-codec:commons-codec:jar:1.3:compile\r\n[INFO] |  +- com.google.oauth-client:google-oauth-client:jar:1.21.0:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-appengine:jar:1.21.0:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-jackson:jar:1.21.0:compile\r\n[INFO] |  |  \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.11:compile\r\n[INFO] |  +- com.google.protobuf:protobuf-java:jar:3.0.0:compile\r\n[INFO] |  +- io.grpc:grpc-protobuf:jar:1.0.3:compile\r\n[INFO] |  |  \\- io.grpc:grpc-protobuf-lite:jar:1.0.3:compile\r\n[INFO] |  +- com.google.api.grpc:grpc-google-common-protos:jar:0.1.5:compile\r\n[INFO] |  \\- com.google.api.grpc:grpc-google-iam-v1:jar:0.1.5:compile\r\n[INFO] +- com.google.api.grpc:grpc-google-cloud-spanner-v1:jar:0.1.5:compile\r\n[INFO] |  \\- com.google.api:api-common:jar:0.0.2:compile\r\n[INFO] +- com.google.api.grpc:grpc-google-cloud-spanner-admin-database-v1:jar:0.1.5:compile\r\n[INFO] +- com.google.api.grpc:grpc-google-cloud-spanner-admin-instance-v1:jar:0.1.5:compile\r\n[INFO] +- io.grpc:grpc-netty:jar:1.0.3:compile\r\n[INFO] |  +- io.grpc:grpc-core:jar:1.0.3:compile\r\n[INFO] |  |  \\- io.grpc:grpc-context:jar:1.0.3:compile\r\n[INFO] |  +- io.netty:netty-handler-proxy:jar:4.1.6.Final:compile\r\n[INFO] |  |  +- io.netty:netty-transport:jar:4.1.6.Final:compile\r\n[INFO] |  |  |  +- io.netty:netty-buffer:jar:4.1.6.Final:compile\r\n[INFO] |  |  |  |  \\- io.netty:netty-common:jar:4.1.6.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-resolver:jar:4.1.6.Final:compile\r\n[INFO] |  |  +- io.netty:netty-codec-socks:jar:4.1.6.Final:compile\r\n[INFO] |  |  |  \\- io.netty:netty-codec:jar:4.1.6.Final:compile\r\n[INFO] |  |  \\- io.netty:netty-codec-http:jar:4.1.6.Final:compile\r\n[INFO] |  \\- io.netty:netty-codec-http2:jar:4.1.6.Final:compile\r\n[INFO] |     \\- io.netty:netty-handler:jar:4.1.6.Final:compile\r\n[INFO] +- io.grpc:grpc-auth:jar:1.0.3:compile\r\n[INFO] +- io.grpc:grpc-stub:jar:1.0.3:compile\r\n[INFO] +- com.google.api:gax:jar:0.5.0:compile\r\n[INFO] |  +- com.google.inject:guice:jar:4.0:compile\r\n[INFO] |  |  +- javax.inject:javax.inject:jar:1:compile\r\n[INFO] |  |  \\- aopalliance:aopalliance:jar:1.0:compile\r\n[INFO] |  \\- com.google.auto.value:auto-value:jar:1.2:compile\r\n[INFO] +- com.google.protobuf:protobuf-java-util:jar:3.0.0:compile\r\n[INFO] |  \\- com.google.code.gson:gson:jar:2.3:compile\r\n[INFO] +- com.google.code.findbugs:jsr305:jar:3.0.0:compile\r\n[INFO] +- com.google.guava:guava:jar:19.0:compile\r\n[INFO] +- joda-time:joda-time:jar:2.9.2:compile\r\n[INFO] +- com.google.auth:google-auth-library-credentials:jar:0.4.0:compile\r\n[INFO] +- com.google.auth:google-auth-library-oauth2-http:jar:0.4.0:compile\r\n[INFO] |  +- com.google.http-client:google-http-client-jackson2:jar:1.19.0:compile\r\n[INFO] |  |  \\- com.fasterxml.jackson.core:jackson-core:jar:2.1.3:compile\r\n[INFO] |  \\- com.google.guava:guava-jdk5:jar:13.0:compile\r\n[INFO] +- com.google.api-client:google-api-client:jar:1.20.0:compile\r\n[INFO] +- junit:junit:jar:4.12:compile\r\n[INFO] |  \\- org.hamcrest:hamcrest-core:jar:1.3:compile\r\n[INFO] +- com.google.truth:truth:jar:0.30:test\r\n[INFO] |  \\- com.google.errorprone:error_prone_annotations:jar:2.0.8:test\r\n[INFO] +- org.mockito:mockito-all:jar:1.9.5:test\r\n[INFO] +- com.google.guava:guava-testlib:jar:19.0:test\r\n[INFO] \\- org.json:json:jar:20151123:test (scope not updated to compile)\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1786",
        "number": 1786,
        "title": "ServiceOptions should allow the path of credentials file to be passed in.",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently we can supply the credentials by parsing the Credentials ourselves from the credentials file and then calling setCredentials. One concern with this is that we also have to call setProjectId even though the credentials file has the project id. When we set the GOOGLE_APPLICATION_CREDENTIALS variable, the library is smart enough to pick the project id from that.\r\nSimilarly if we had a method setGoogleApplicationCredentialsFile(String filePath or InputStream credentialsStream), the library would then pick up both credentials as well as project id from there."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1785",
        "number": 1785,
        "title": "Translate: service factory method seems oddly placed",
        "labels": [],
        "state": "closed",
        "body": "Is it me or is TranslateOptions an odd place to expect a method to get a Translation Service instance?\r\n\r\n`TranslateOptions.getDefaultInstance().getService();`\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1782",
        "number": 1782,
        "title": "translate: docs issue in readme.",
        "labels": [
            "api: translation",
            "priority: p1",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-translate/README.md\r\n\r\nthe instructions say to add:\r\n`String detectedLanguage = detection.getLanguage();`\r\n\r\nBut no 'detection' variable has been created at this point."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1781",
        "number": 1781,
        "title": "pom - parent POM - artifact not found",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Project build error: Non-resolvable parent POM for com.google.cloud:google-cloud-bigquery:${beta.version}: Could not find artifact com.google.cloud:google-cloud-pom:pom:0.10.1-SNAPSHOT and 'parent.relativePath' points at wrong local POM\r\n\r\nirrespective of the version."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1780",
        "number": 1780,
        "title": "TRANSLATE: Using 0.10.0-alpha from the docs causes java.lang.ClassNotFoundException: com.google.cloud.ServiceDefaults",
        "labels": [
            "api: core",
            "priority: p2"
        ],
        "state": "closed",
        "body": "I think this probably happens if you just follow the getting started but my occurrence happened in:\r\nhttps://github.com/patflynn/kplay/tree/broken-translate-api\r\n\r\nYou'll need to run cd into the spring-boot-simple directory and run mvn spring-boot:run\r\nand then hit localhost:8080/visit\r\n\r\n(that endpoints uses datastore so you'll need some creds in your environment)\r\n\r\n0.9.4-alpha works fine.\r\n\r\n\r\n\r\n```\r\n\r\njava.lang.ClassNotFoundException: com.google.cloud.ServiceDefaults\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_91]\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_91]\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_91]\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_91]\r\n\tat hello.DemoController.visit(DemoController.java:36) ~[classes/:na]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_91]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_91]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_91]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_91]\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:622) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:729) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.6.RELEASE.jar:4.3.6.RELEASE]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) ~[tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_91]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_91]\r\n\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.11.jar:8.5.11]\r\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_91]\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1779",
        "number": 1779,
        "title": "TRANSLATE: Are the supported languages documented in the API Docs?",
        "labels": [
            "api: translation",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I'm trying to use the translate API Docs: http://googlecloudplatform.github.io/google-cloud-java/0.10.0/apidocs/?com/google/cloud/translate/package-summary.html\r\n\r\nI can't find anywhere that lists the set of valid language options.  Should this be an enum somewhere?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1778",
        "number": 1778,
        "title": "Implement NoCredentials.refreshAccessToken()",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This credential is used in tests. This method will be called somewhere downstream and will expect to be implemented and return an `AccessToken`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1777",
        "number": 1777,
        "title": "Enable PubSubHelper to work with new APIs",
        "labels": [
            "api: pubsub",
            "priority: p2"
        ],
        "state": "closed",
        "body": "The PubSubHelper class has moved to the `deprecated` package. Currently when trying to use it and configure a PublisherClient, I'm getting exceptions with authentication and refrershtoken not being supported on NoCredentials class provided by the PubSubHelper. \r\n\r\nEven after configuring that, the server throws errors on calls not being in HTTP/2 format.\r\n\r\nIt would be great if we could user the PubSubHelper to make self contained integration tests that do not rely on the cli emulator or the platform."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1776",
        "number": 1776,
        "title": "gRPC version upgrade",
        "labels": [
            "dependencies"
        ],
        "state": "closed",
        "body": "Looks like certain version of Maven (2.2.1, 3.2.2 and 3.2.3) run into issues with com.google.code.gson:gson:2.3: https://github.com/google/gson/issues/588\r\nThe issue is resolved in gson : 2.3.1.\r\nThe older version(2.3) is linked in google-cloud-core from grpc 1.0.3. \r\n grpc 1.1+ support gson:2.7. Is there a reason not to be on atleast 1.1.x of grpc ?\r\n\r\n [INFO] |  |  +- io.grpc:grpc-protobuf:jar:1.0.3:compile\r\n[INFO] |  |  |  +- (com.google.guava:guava:jar:19.0:compile - omitted for duplicate)\r\n[INFO] |  |  |  +- com.google.protobuf:protobuf-java-util:jar:3.0.2:compile\r\n[INFO] |  |  |  |  +- (com.google.protobuf:protobuf-java:jar:3.0.2:compile - omitted for conflict with 3.0.0)\r\n[INFO] |  |  |  |  +- (com.google.guava:guava:jar:18.0:compile - omitted for conflict with 20.0)\r\n[INFO] |  |  |  |  \\- com.google.code.gson:gson:jar:2.3:compile"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1772",
        "number": 1772,
        "title": "No syncRecognize response (DEADLINE_EXCEEDED) using Java speech client library",
        "labels": [
            "api: speech",
            "dependencies"
        ],
        "state": "closed",
        "body": "As Requested in https://groups.google.com/forum/#!msg/cloud-speech-discuss/ I'm opening a ticket on here.\r\n\r\nUsing both the sample and a bare Java 8/Spring/Tomcat 8 stack with Java speech client versions 0.8.0 / 0.9.4-alpha / 0.10.0-alpha I get no response when I make a syncRecognise request. The request future doesn't resolve until I eventually get a com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED error.\r\n\r\nI am authorising via service account and have tried using both the application default json creds and via the command line tools. Happy to fill in more details about my setup if needed."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1769",
        "number": 1769,
        "title": "Move general purpose classes from google-cloud-spanner to google-cloud-core",
        "labels": [
            "api: core",
            "api: spanner"
        ],
        "state": "closed",
        "body": "Few of the classes in google-cloud-spanner are general enough that they can be useful in existing apis (in the case of ByteArrays) or presumably might be useful in future for other apis (in the case of Date and Timestamp). We should move these to google-cloud-core."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1764",
        "number": 1764,
        "title": "getNextPageToken returns Object, setPageToken taking String",
        "labels": [
            "api: monitoring"
        ],
        "state": "closed",
        "body": "This is using the Monitoring VTK. This causes a lot of ugly code since casting a null to a String is an exception."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1763",
        "number": 1763,
        "title": "Better support protobuf's ByteString in ByteArray.",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The `ByteArray` type uses protobuf's `ByteString` under the hood, but doesn't allow an outside user to turn a `ByteString` into a `ByteArray` (or vice versa) without making an explicit copy. Given that both `ByteString` and `ByteArray` are immutable, I can't see a reason why this should not be possible. For example, a `ByteArray.wrap(ByteString)` and `ByteArray.asByteString()` method seem appropriate. Those would come in very handy when using the client libraries within a gRPC service.\r\n\r\nCould someone please explain why this is the case? If there is no reason, I would be happy to open a PR. Thanks!\r\n\r\nP.S. I did notice that the class is non-final and by subclassing one can expose the protected constructor and `getByteString()` method, but that seems silly."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1762",
        "number": 1762,
        "title": "Retry javax.net.ssl.SSLHandshakeException",
        "labels": [
            "api: core",
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "The storage lib doesn't currently consider SSLHandshakeException retryable.\r\n\r\nFrom BaseServiceException:\r\n```java  \r\nprotected boolean isRetryable(boolean idempotent, IOException exception) {\r\n    boolean exceptionIsRetryable = exception instanceof SocketTimeoutException\r\n        || exception instanceof SocketException\r\n        || \"insufficient data written\".equals(exception.getMessage());\r\n    return idempotent && exceptionIsRetryable;\r\n  }\r\n```\r\nBut the following type of exception should be retried in the same way a SocketException is retried.\r\n`\r\nException in thread \"main\" com.google.cloud.storage.StorageException: Remote host closed connection during handshake\r\n\tat com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:202)\r\n\tat com.google.cloud.storage.spi.DefaultStorageRpc.list(DefaultStorageRpc.java:294)\r\n\tat com.google.cloud.storage.StorageImpl$8.call(StorageImpl.java:297)\r\n\tat com.google.cloud.storage.StorageImpl$8.call(StorageImpl.java:294)\r\n\tat com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\r\n\tat com.google.cloud.storage.StorageImpl.listBlobs(StorageImpl.java:293)\r\n\tat com.google.cloud.storage.StorageImpl.access$300(StorageImpl.java:74)\r\n\tat com.google.cloud.storage.StorageImpl$BlobPageFetcher.getNextPage(StorageImpl.java:249)\r\n\tat com.google.cloud.PageImpl.getNextPage(PageImpl.java:124)\r\n\tat com.google.cloud.PageImpl$PageIterator.computeNext(PageImpl.java:66)\r\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\r\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\r\n\tat LoadSldToSpanner.main(LoadSldToSpanner.java:63)\r\nCaused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake\r\n\tat sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:953)\r\n\tat sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1332)\r\n\tat sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1359)\r\n\tat sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1343)\r\n\tat sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563)\r\n\tat sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n\tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n\tat com.google.cloud.storage.spi.DefaultStorageRpc.list(DefaultStorageRpc.java:286)\r\n\t... 12 more\r\nCaused by: java.io.EOFException: SSL peer shut down incorrectly\r\n\tat sun.security.ssl.InputRecord.read(InputRecord.java:482)\r\n\tat sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:934)\r\n\t... 24 more`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1761",
        "number": 1761,
        "title": "Create ApiService in GAX and use it in Subscriber",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "In `Subscriber`, we currently wrap `AbstractService` from Guava. We should instead create a wrapper `ApiService` in GAX and use that, so that if we have other cases for a Service, we don't have to duplicate code. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1760",
        "number": 1760,
        "title": "Delete deprecated pubsub client",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Associated unit tests, integration tests, and snippets need to be deleted too. \r\n\r\nWe should write a couple new integration tests to make sure our library doesn't go DOA. Also there might be some interesting scenarios in `AckDeadlineRenewerTest` and `BaseSystemTest`->`LocalSystemTest` to consider retaining (needs research). \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1752",
        "number": 1752,
        "title": "Test top 3 APIs on GAE Flex, GKE, and GCP",
        "labels": [
            "api: datastore",
            "api: logging",
            "api: storage",
            "running on app engine"
        ],
        "state": "closed",
        "body": "Test Storage, Datastore, and Logging client libraries on all the GCP platforms (don't include GAE Standard).\r\n\r\nClose this issue once we confirm it all works."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1751",
        "number": 1751,
        "title": "Pubsub : Publisher / Subscriber with service accounts",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The `com.google.cloud.pubsub` namespace now being deprecated, I'm trying to use use the replacement (Publisher / Subscriber in `com.google.cloud.pubsub.spi.v1`).\r\n\r\nI can't find an example of how to use service accounts though. With the deprecated version I would use \r\n\r\n```java\r\nPubSubOptions\r\n    .newBuilder()\r\n    .setProjectId(Configurations.getGoogleCloudProjectId())\r\n    .setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(Configurations.getGoogleCloudCredentials())))\r\n    .build()\r\n    .getService();\r\n```\r\n\r\nwhere `Configurations.getGoogleCloudCredentials()` points to a json file with the credentials.\r\n\r\nWhat's the equivalent now ? How do we use service accounts (or really, any specific credentials besides the machine defaults) with Publisher / Subscriber ?\r\n\r\nThanks !"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1745",
        "number": 1745,
        "title": "Remote*Helper classes: have create() call create(projectId, keyStream)",
        "labels": [
            "priority: p2",
            "type: cleanup"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1744",
        "number": 1744,
        "title": "GCS - \"Invalid Credentials\" error when debugging locally",
        "labels": [],
        "state": "closed",
        "body": "When trying to upload a file to GCS I get the following error.\r\n\r\n```\r\n{\r\n \"error\": {\r\n  \"errors\": [\r\n   {\r\n    \"domain\": \"global\",\r\n    \"reason\": \"backendError\",\r\n    \"message\": \"com.google.cloud.storage.StorageException: Invalid Credentials\"\r\n   }\r\n  ],\r\n  \"code\": 503,\r\n  \"message\": \"com.google.cloud.storage.StorageException: Invalid Credentials\"\r\n }\r\n}\r\n```\r\n\r\nI have authenticated using the CLI and am able to list all buckets using 'gsutil ls', however any code that interacts with GCS returns this error when debugging locally.\r\n\r\nPlease let me know if you require any more details."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1742",
        "number": 1742,
        "title": "Create a sample app setup that runs on GAE",
        "labels": [
            "running on app engine"
        ],
        "state": "closed",
        "body": "It would be helpful if we have a complete setup for a sample app (e.g. Storage) that users can grab and deploy directly without any editing effort. \r\n\r\nIdeally the structure would look like this:\r\n--- pom.xml\r\n--- README.md\r\n--- src/paths/to/main/StorageSample.java\r\n--- src/main/webapp/WEB_INF/appengine-web.xml\r\n--- src/main/webapp/WEB_INF/web.xml\r\n\r\nso the user just need to clone the folder and run: `mvn appengine:deploy` and deploy the app onto their GAE host.\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1740",
        "number": 1740,
        "title": "Support configuration of base severity level",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently there is no way to modify base severity level of a `LoggingHandler`. Logs with the same severity with the base could be more efficiently sent to Stackdriver.\r\n\r\nSome ideas:\r\n1. Do nothing.\r\nThe level the handler is set to is probably the most chatty anyway.\r\n2. Give it its own config param.\r\n3. Create `setBaseLevel` method.\r\nThis [requires](https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1721#issuecomment-285529950) us to make bundling a little more resilient first."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1735",
        "number": 1735,
        "title": "google-auth-library-java/issues/91 retry refreshAccessToken failures",
        "labels": [
            "api: storage",
            "auth",
            "priority: p1"
        ],
        "state": "closed",
        "body": "https://github.com/google/google-auth-library-java/issues/91\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1734",
        "number": 1734,
        "title": "Hide/deprecate the pull/modifyAckDeadline/acknowledge methods on SubscriberClient",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "or if https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1733 is done first, this will be on `SubscriptionAdminClient`. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1733",
        "number": 1733,
        "title": "Rename PublisherClient to TopicAdminClient, and SubscriberClient to SubscriptionAdminClient",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "This will require adding a config in pubsub_gapic.yaml and regenerating the client. \r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/issues/1734 might be doable at the same time; it also requires a config modification. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1732",
        "number": 1732,
        "title": "Change signature of RPCFuture.addCallback to allow lambdas as arguments",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "Hi, it's nice to have a callback mechanism on the latest pubsub client library, but it would be even better if the RPCFuture.addCallback supported functional interfaces instead of an interface with two methods to process errors and success.\r\n\r\nso if instead of addCallback(RpcFutureCallback)\r\n\r\npublic void subscribe(Consumer<T> success, Consumer<? super Throwable> error){\r\n\r\nOne could just invoke the subscribe with lambdas expressions.\r\n\r\nI know Consumer is Java 8 construct, but any functional interface with an interface like\r\n\r\nFoo<T>{\r\n\r\nvoid apply(T t)\r\n\r\n}\r\n\r\nwould work\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1731",
        "number": 1731,
        "title": "AccessControlException (java.io.FilePermission) when trying to access Cloud Storage",
        "labels": [
            "api: storage",
            "priority: p1",
            "running on app engine"
        ],
        "state": "closed",
        "body": "@lesv \r\n\r\nContinuing from the conversation [here](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1500#issuecomment-285753341).\r\n\r\nI have tried every method suggested [here](https://developers.google.com/identity/protocols/application-default-credentials) but routinely get a `java.security.AccessControlException` which differs depending on which authentication used.\r\n\r\nIf I don't use `.setCredentials` (and therefore it trys to authenticate automatically or use `GOOGLE_APPLICATION_CREDENTIALS` env variable) I get an `AccessControlException` for a file called `active_config`. If I instead do call `.setCredentials` and use a file downloaded by creating a service account key (as specified in option 1 here: https://developers.google.com/identity/protocols/application-default-credentials) then I get the same exception but for that specific file.\r\n\r\n@lesv you made this comment in the other issue:\r\n\r\n> In your case, passing the credentials created by gcloud is incorrect - you need to pass credentials obtained from https://console.cloud.google.com -- why don't you create a new issue, and mention me in it and I'll help you out.\r\n\r\nI assume you are referring to the same method I linked to above, correct? If so, as stated, i've tried that."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1730",
        "number": 1730,
        "title": "pubsub deprecated?",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "It seems the entire pubsub namespace is deprecated. What will it be replaced with?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1729",
        "number": 1729,
        "title": "PubSub pullAsync redelivery question",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Is there a way to get the redelivery of the message to not be instant if the messageProcesser throws an exception (nack) when using \r\n```java\r\nPubSub.MessageConsumer pullAsync(String subscription,\r\n                                 PubSub.MessageProcessor callback,\r\n                                 PubSub.PullOption... options)\r\n```\r\n\r\nI have tried setting the ack-deadline to several minutes but the message is redelivered immediately if the processor throws an exception."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1727",
        "number": 1727,
        "title": "We need a way to set traceId or RequestId on all requests.",
        "labels": [
            "api: datastore",
            "api: logging",
            "api: pubsub",
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be nice to know what request generated this API call.  (RequestID) -- this s.b. for Cloud Trace"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1713",
        "number": 1713,
        "title": "e.getReason() = INVALID_ARGUMENT instead of ALREADY_EXISTS while doing batch insert",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi, \r\nI am using  the method below for batch inserting to google datastore:\r\n\r\n```\r\n/**\r\n   * {@inheritDoc}\r\n   *\r\n   * <p>If none of entities' keys exist, all entities are inserted. If any of entities' keys already\r\n   * exists, {@link #submit()} will throw a {@link DatastoreException} with\r\n   * {@link DatastoreException#getReason()} equal to {@code \"ALREADY_EXISTS\"}. All entities in\r\n   * {@code entities} whose key did not exist are inserted.\r\n   */\r\n  @Override\r\n  List<Entity> add(FullEntity<?>... entities);\r\n```\r\n\r\nAfter that I am calling `batch.submit()`\r\nAs an output I am having an following stacktrace:\r\n\r\n`ERROR\r\n! com.google.datastore.v1.client.DatastoreException: entity already exists\r\n! at com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:126) ~[datastore-v1-proto-client-1.3.0.jar:na]\r\n! at com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:169) ~[datastore-v1-proto-client-1.3.0.jar:na]\r\n! at com.google.datastore.v1.client.RemoteRpc.call(RemoteRpc.java:89) ~[datastore-v1-proto-client-1.3.0.jar:na]\r\n! at com.google.datastore.v1.client.Datastore.commit(Datastore.java:84) ~[datastore-v1-proto-client-1.3.0.jar:na]\r\n! at com.google.cloud.datastore.spi.DefaultDatastoreRpc.commit(DefaultDatastoreRpc.java:135) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! ... 15 common frames omitted\r\n! Causing: com.google.cloud.datastore.DatastoreException: entity already exists\r\n! at com.google.cloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:111) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! at com.google.cloud.datastore.spi.DefaultDatastoreRpc.commit(DefaultDatastoreRpc.java:137) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! at com.google.cloud.datastore.DatastoreImpl$4.call(DatastoreImpl.java:390) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! at com.google.cloud.datastore.DatastoreImpl$4.call(DatastoreImpl.java:387) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179) ~[google-cloud-core-0.9.4-alpha.jar:0.9.4-alpha]\r\n! at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244) ~[google-cloud-core-0.9.4-alpha.jar:0.9.4-alpha]\r\n! at com.google.cloud.datastore.DatastoreImpl.commit(DatastoreImpl.java:386) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! at com.google.cloud.datastore.BatchImpl.submit(BatchImpl.java:74) ~[google-cloud-datastore-0.9.4-beta.jar:0.9.4-beta]\r\n! at com.nexmo.consumer.core.inserter.db.datastore.GoogleDatastore.insertCdrBatch(GoogleDatastore.java:126) ~[poc-20170308.141035.000+Duplicated-Entry-fix+a64cce6-1.jar:a64cce6]\r\n! at com.nexmo.consumer.core.inserter.task.InserterCdrMtTask.insertCdrsBatch(InserterCdrMtTask.java:27) ~[poc-20170308.141035.000+Duplicated-Entry-fix+a64cce6-1.jar:a64cce6]\r\n! at com.nexmo.consumer.core.inserter.InserterTask.performInsertAndFlushBuffer(InserterTask.java:79) ~[poc-20170308.141035.000+Duplicated-Entry-fix+a64cce6-1.jar:a64cce6]\r\n! at com.nexmo.consumer.core.inserter.InserterTask.run(InserterTask.java:48) ~[poc-20170308.141035.000+Duplicated-Entry-fix+a64cce6-1.jar:a64cce6]\r\n! at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_66]\r\n! at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_66]\r\n! at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_66]\r\n! at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]\r\n! at java.lang.Thread.run(Thread.java:745) [na:1.8.0_66]\r\n`\r\n\r\nbut when I print e.getReason()  I get  \"INVALID_ARGUMENT\" instead of expected  \"ALREADY_EXISTS\"  as mentioned in the javadoc. \r\n\r\nIs there anything I am missing, why do I get an \"INVALID_ARGUMENT\" even though the stacktrace says that the problem is that entity already exists?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1712",
        "number": 1712,
        "title": "Serialized size is too large",
        "labels": [
            "api: logging",
            "performance"
        ],
        "state": "closed",
        "body": "The following `LogEntry` closely resembles ones `LoggingHandler` produces.\r\n```java\r\nLogEntry.newBuilder()\r\n    .setSeverity(LogSeverity.INFO)\r\n    .setTextPayload(\"test payload\")\r\n    .setTimestamp(\r\n        Timestamp.newBuilder()\r\n            .setSeconds(nanoTime / BILLION)\r\n            .setNanos((int) (nanoTime % BILLION)))\r\n    .putLabels(\"levelName\", Level.INFO.getName())\r\n    .putLabels(\"levelValue\", \"\" + Level.INFO.intValue())\r\n    .build();\r\n```\r\nIts serialized size is 67 bytes.\r\n\r\nHowever, if we have many entries batched in the same request with the same severity, we can \"hoist\" the two labels out of the entries and into the request object. (Entries with different severities can still override.) If we comment out the two `putLabels` lines, the serialized size reduces to 28, saving 39 bytes. Even with larger payload, this still represents significant savings.\r\n\r\n**Proposal**\r\nSet `LoggingHandler` with a \"native severity\". The severity labels would be placed in the request object, and all logs with the same severity would not contain the label.\r\n\r\n**Alternative**\r\nDrop the labels altogether. After all, each log already has `LogSeverity` which is defined by the protobuf message itself. This is a breaking change though.\r\n\r\n**Memory Impact**\r\nWith labels, building one `LogEntry` object allocates 47 objects and 1584 bytes (measured on `google-cloud:0.9.4-alpha`). Without labels, we allocate 31 objects and 1040 bytes. Fixing this should give a 33% decrease in memory consumption in small messages."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1710",
        "number": 1710,
        "title": "trouble with changing an access for blobs",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "I work with Google Storage API via java and I use 0.9.4-alpha(before was 0.9.2-alpha ) version. When I create a blob, I use this code and it works correctly, I get different access levels for a new blob:\r\n\r\n    bucket.create(\r\n        getFileName(req),\r\n        fileToInputStream(req),\r\n        Bucket.BlobWriteOption.predefinedAcl(getPredefinedAcl(req.getAccessType()))\r\n    );\r\n\r\nbut I need to have an opportunity of changing an access to particular files. Well, I have supposed that it seems like this, because I didn't find any examples and information in the documentation:\r\n\r\n    blob.update(\r\n        Storage.BlobTargetOption.predefinedAcl(Storage.PredefinedAcl.PRIVATE)\r\n    );\r\n\r\nbut this piece of code throws an exception: `com.google.cloud.storage.StorageException: Cannot provide both a predefinedAcl and access controls.` and I get a message:\r\n\r\n    {\r\n        \"code\" : 409,\r\n        \"errors\" : [ {\r\n        \"domain\" : \"global\",\r\n        \"message\" : \"Cannot provide both a predefinedAcl and access controls.\",\r\n        \"reason\" : \"conflict\"\r\n        } ],\r\n        \"message\" : \"Cannot provide both a predefinedAcl and access controls.\"\r\n    }\r\n\r\nIt seems to me it's weird because I can pass `Storage.BlobTargetOption.predefinedAcl` in `update` method, but it doesn't work(perhaps I have not to pass `predefinedAcl` there ...??).\r\nAlso I have tried to change an access via `com.google.cloud.storage.Acl` class but I got another exception.\r\nI suppose I do something wrong and it isn't a bug, but stackoverflow didn't help me and absence of examples is really problem for me now. I should be grateful you for help."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1702",
        "number": 1702,
        "title": "Fix Spanner integration tests",
        "labels": [
            "api: spanner"
        ],
        "state": "closed",
        "body": "Spanner integration tests are failing frequently:\r\n\r\nhttps://travis-ci.org/GoogleCloudPlatform/google-cloud-java/jobs/207562209\r\n\r\n```\r\n\r\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2.122 sec <<< FAILURE! - in com.google.cloud.spanner.it.ITLargeReadTest\r\ncom.google.cloud.spanner.it.ITLargeReadTest  Time elapsed: 0.01 sec  <<< ERROR!\r\ncom.google.cloud.spanner.SpannerException: NOT_FOUND: io.grpc.StatusRuntimeException: NOT_FOUND: Database has been deleted\r\n\tat com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:476)\r\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:455)\r\n\tat com.google.cloud.spanner.spi.DefaultSpannerRpc.get(DefaultSpannerRpc.java:398)\r\n\tat com.google.cloud.spanner.spi.DefaultSpannerRpc.commit(DefaultSpannerRpc.java:376)\r\n\tat com.google.cloud.spanner.SpannerImpl$TransactionContextImpl$1.call(SpannerImpl.java:1235)\r\n\tat com.google.cloud.spanner.SpannerImpl$TransactionContextImpl$1.call(SpannerImpl.java:1232)\r\n\tat com.google.cloud.spanner.SpannerImpl.runWithRetries(SpannerImpl.java:198)\r\n\tat com.google.cloud.spanner.SpannerImpl$TransactionContextImpl.commit(SpannerImpl.java:1230)\r\n\tat com.google.cloud.spanner.SpannerImpl$TransactionRunnerImpl.run(SpannerImpl.java:1148)\r\n\tat com.google.cloud.spanner.SpannerImpl$SessionImpl.write(SpannerImpl.java:704)\r\n\tat com.google.cloud.spanner.SessionPool$PooledSession.write(SessionPool.java:201)\r\n\tat com.google.cloud.spanner.DatabaseClientImpl.write(DatabaseClientImpl.java:31)\r\n\tat com.google.cloud.spanner.it.ITLargeReadTest.setUpDatabase(ITLargeReadTest.java:111)\r\nCaused by: io.grpc.StatusRuntimeException: NOT_FOUND: Database has been deleted\r\n\tat io.grpc.Status.asRuntimeException(Status.java:545)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:442)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.spi.SpannerErrorInterceptor$1$1.onClose(SpannerErrorInterceptor.java:100)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.spi.WatchdogInterceptor$MonitoredCall$1.onClose(WatchdogInterceptor.java:190)\r\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:56)\r\n\tat com.google.cloud.spanner.GceTestEnvConfig$GrpcErrorInjector$1$1.onClose(GceTestEnvConfig.java:119)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1700",
        "number": 1700,
        "title": "Direct users to use https://github.com/GoogleCloudPlatform/cloud-trace-java",
        "labels": [
            "api: cloudtrace",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "Would be nice if the README for google-cloud-trace package directed users use the Stackdriver provided libraries at https://github.com/GoogleCloudPlatform/cloud-trace-java. Also a pointer showed up in the Maven artifacts generated so someone searching for and viewing the maven artifact \r\n\r\nhttps://mvnrepository.com/artifact/com.google.cloud/google-cloud-trace\r\n\r\nwould be directed to use Stackdriver SDK instead\r\n\r\nhttps://mvnrepository.com/artifact/com.google.cloud.trace/core\r\n\r\nThanks"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1699",
        "number": 1699,
        "title": "What's third party?",
        "labels": [
            "dependencies",
            "type: question"
        ],
        "state": "closed",
        "body": "Supporting new services says not to expose third party libraries in the API. Who's a third party in this context? E.g. would exposing a Guava class such as ImmutableSet be OK or not? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1697",
        "number": 1697,
        "title": "Requests from this Android client application <empty> are blocked",
        "labels": [
            "android",
            "api: translation",
            "priority: p1",
            "type: question"
        ],
        "state": "closed",
        "body": "Hi all,\r\nWhen i tried to translate the text with Google Cloud API but i got a message :\r\n{\r\n  \"error\": {\r\n    \"code\": 403,\r\n    \"message\": \"Requests from this Android client application \\u003cempty\\u003e are blocked.\",\r\n    \"errors\": [\r\n      {\r\n        \"message\": \"Requests from this Android client application \\u003cempty\\u003e are blocked.\",\r\n        \"domain\": \"global\",\r\n        \"reason\": \"forbidden\"\r\n      }\r\n    ],\r\n    \"status\": \"PERMISSION_DENIED\"\r\n  }\r\n}\r\n\r\nI don't know how to fix this issue , plz tell me if you have any solution.\r\nThanks\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1696",
        "number": 1696,
        "title": "Does this not work with Android?",
        "labels": [
            "android"
        ],
        "state": "closed",
        "body": "I've had nothing but issue after issue, and still have not been able to get my app to run after adding the gradle dependencies listed in the [docs](https://cloud.google.com/storage/docs/reference/libraries): \r\n\r\n`compile group: 'com.google.cloud', name: 'google-cloud-storage', version: '0.9.3-beta'`\r\n\r\nInstead of copying over all the issues and error messages, i'll link to the unanswered StackOverflow question i've already posted: http://stackoverflow.com/questions/42601917/accessing-cloud-storage-from-android\r\n\r\nAs mentioned, i've run into many issues and have still yet been able to run the app without errors. Before wasting even more of my time, I wanted to confirm if it's even possible to use this client library with Android.\r\n\r\nIf it is not, how should I interact with my Cloud Storage buckets? All I'm trying to do is pull down some media stored in Cloud Storage."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1694",
        "number": 1694,
        "title": "License is 404",
        "labels": [],
        "state": "closed",
        "body": "![image](https://cloud.githubusercontent.com/assets/1005544/23579076/54145910-00b3-11e7-8d31-36aa47b647c2.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1692",
        "number": 1692,
        "title": "Rename \"bundling\" to \"batching\"",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Corresponding GAX issue: https://github.com/googleapis/gax-java/issues/224\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1691",
        "number": 1691,
        "title": "Update protobuf/grpc/tcnative dependencies",
        "labels": [
            "dependencies"
        ],
        "state": "closed",
        "body": "Grpc: Now = 1.0.3; update to 1.2.0\r\nProtobuf: Now = 3.0.0 & 3.0.2 (depending on where); update to 3.2.0\r\nnetty-tcnative: Now = 1.1.33.Fork19; update to 1.1.33.Fork26\r\n\r\nNote: this also involves updating the generated grpc packages and gax.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1689",
        "number": 1689,
        "title": "NullPointerException while waiting for query result on BigQuery",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "I have a complex application and I am using Apache Flink to stream events from Kafka to BigQuery; the application queries the dataset first in order to get the latest offset for each topic/partition. This is how the code running the query looks like:\r\n\r\n```\r\nvar response = retryUntilSuccess(maxFetchOffsetAttempts, maxFetchOffsetDelay) { () =>\r\n  Thread.sleep(Random.nextInt(maxFetchOffsetDelay.toMillis.toInt))\r\n  bigQuery.query(\r\n    QueryRequest\r\n      .newBuilder(offsetsQuery)\r\n      .setUseLegacySql(false)\r\n      .setDefaultDataset(config.dataset)\r\n      .build()\r\n  )\r\n}\r\n\r\nwhile (!response.jobCompleted()) {\r\n  logger.warn(\r\n    s\"Offsets for ${record.tableName} are not ready, will retry in 1 second, jobId: ${response.getJobId()}\")\r\n  Thread.sleep(1000)\r\n  response = bigQuery.getQueryResults(response.getJobId())\r\n}\r\n\r\nval result = response.getResult()\r\n```\r\n\r\nThis is written in Scala but it is mostly a translation of the example in the Javadocs; the `retryUntilSuccess` function retries the request multiple time and there is a random wait (30 seconds at this moment) before the request so to handle the fact that many queries will fire in parallel and may result in hitting API limits.\r\n\r\nWhen I run this code I almost always get the following exception:\r\n\r\n```\r\njava.lang.NullPointerException\r\n\tat com.google.cloud.bigquery.JobId.fromPb(JobId.java:111)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.getQueryResults(BigQueryImpl.java:635)\r\n\tat com.google.cloud.bigquery.BigQueryImpl.getQueryResults(BigQueryImpl.java:619)\r\n\tat io.chumps.dataprocessing.sinks.BigQuerySink$$anon$1.startingOffsets$lzycompute(BigQuerySink.scala:89)\r\n\tat io.chumps.dataprocessing.sinks.BigQuerySink$$anon$1.startingOffsets(BigQuerySink.scala:73)\r\n\tat io.chumps.dataprocessing.sinks.BigQuerySink$$anon$1.open(BigQuerySink.scala:136)\r\n\tat org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:38)\r\n\tat org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:91)\r\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.openAllOperators(StreamTask.java:376)\r\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:256)\r\n\tat org.apache.flink.runtime.taskmanager.Task.run(Task.java:585)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nThe line in our code where this exception happens is where I call `getQueryResults` and I am sure that I am not sending a `null` in there as I can see the job id in the logs before the failure; I also checked that the response doesn't contain any error by calling `getExecutionErrors`. I say that \"it almost always fails\" because over some tens attempts it managed to run a couple of times without incurring in the exception.\r\n\r\nCould this be a bug in the way the API limits are hadled by the client? Do you have any advice to work around this issue?\r\n\r\nThanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1686",
        "number": 1686,
        "title": "MessageDispatcher.processOutstandingAckOperations \"Sending {} acks\"",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "```\r\nMar 02, 2017 8:58:48 PM com.google.cloud.pubsub.spi.v1.MessageDispatcher processOutstandingAckOperations\r\nINFO: Sending {} acks\r\n```\r\n\r\n{} is not replaced.\r\n\r\nAlso, reduce log level if appropriate"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1683",
        "number": 1683,
        "title": "Add ability to configure threads at least in PubSub and where appropriate",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently, PubSub Subscriber creates multiple threads based on Runtime.availableProcessors(). This is a reasonable default but should be configurable, specifically when there are other competing threads pools, and also when running in Docker containers, where Runtime.availableProcessors() may not return the allocated CPUs (see https://bugs.openjdk.java.net/browse/JDK-6515172)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1682",
        "number": 1682,
        "title": "Publisher.setupDurationBasedPublishAlarm - log does not replace %d, potentially reduce log level",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "See screenshot.  Also, should alarm setup be INFO level log? Reduce level if appropriate.\r\n\r\n![log](https://cloud.githubusercontent.com/assets/1998883/23518275/e9eabcb4-ff40-11e6-8584-f482a6567a85.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1681",
        "number": 1681,
        "title": "Publisher.publish - Reducing log level for individual publishes",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "There seems to be excessive number of INFO level log messages when publishing messages.  Revisit and reduce the log levels where appropriate.\r\n\r\n![log](https://cloud.githubusercontent.com/assets/1998883/23518173/98495dca-ff40-11e6-9051-049e6f70a495.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1680",
        "number": 1680,
        "title": "google-oauth-java-client/issues/145",
        "labels": [
            "api: bigquery",
            "api: datastore",
            "api: logging",
            "api: storage",
            "dependencies",
            "running on app engine"
        ],
        "state": "closed",
        "body": "https://github.com/google/google-oauth-java-client/issues/145\r\n\r\nBlocks testing on GAE Standard (J7)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1679",
        "number": 1679,
        "title": "google/google-auth-library-java #89 needs to be fixed",
        "labels": [
            "api: bigquery",
            "api: datastore",
            "api: logging",
            "api: storage",
            "auth",
            "dependencies",
            "priority: p2",
            "running on app engine",
            "status: blocked"
        ],
        "state": "closed",
        "body": "https://github.com/google/google-auth-library-java/issues/89\r\nBlocks GAE Standard (java 7 & J8)\r\n\r\nSummary: on App Engine Compat, GCE credentials need to be used instead of GAE credentials.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1676",
        "number": 1676,
        "title": "`MonitoredResource.newBuilder` accepts arbitrary input, but does not log if invalid resource",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Supported resource types @ https://cloud.google.com/monitoring/api/resources\r\n`MonitoredResource.newBuilder` currently accepts a free string. Logging backend validates against supported resource types and does not log if it is not a supported log type.\r\n\r\nWe should have a cleaner way for the user to provide the resource type : be inferred from environment (GCE vs GAE ?) or have a custom resource type be used by default when user logs via the API."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1673",
        "number": 1673,
        "title": "Provide a way to compute checksum",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "See [SO](https://www.google.com/url?q=http://stackoverflow.com/questions/39578154/googles-gsutil-cp-command-runs-a-checksum-on-the-file-transferred-does-googl/39578458%2339578458&sa=D&usg=AFQjCNGv6SaRIIFtX9rCAJ7dFNb1ZHyx-w) for context."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1669",
        "number": 1669,
        "title": "Allow changing/updating flow control at runtime",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Reactive applications will need to be able to signal backpressure. It occurs when the message receiver is no longer able to receive more messages. In the pull model, the receiver will simply stop pulling. In the push model, we need to be able to turn off flow and/or reduce incoming qps.  This is a standard pattern required for Akka, rx2, and Spring Reactor."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1668",
        "number": 1668,
        "title": "`ListTopicSubscriptionsPagedResponse.iterateAllElements()` should return `Iterable<Subscription>`",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`ListTopicSubscriptionsPagedResponse.iterateAllElements` currently returns `Iterable<String>`.\r\nIt feels inconsistent with `ListTopicsPagedResponse.iterateAllElements` that returns `Iterable<Topic>`\r\nand `ListSubscriptionsPagedResponse.iterateAllElements` returns `Iterable<Subscription>`.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1667",
        "number": 1667,
        "title": "Pub/Sub 0.9.3-alpha: no messages are pulled",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi, trying new pubsub client, and even though there are undelivered messages waiting in the queue, nothing is being pulled.\r\nI've tried both `Subscriber` and synchronous `SubscriberClient` as showed [here](https://github.com/jabubake/google-cloud-java/blob/5da936adf0f62dbd716e98c404e7bf68cd46f6c0/google-cloud-examples/src/main/java/com/google/cloud/examples/pubsub/snippets/SubscriberSnippets.java) and [here](https://github.com/jabubake/google-cloud-java/blob/5da936adf0f62dbd716e98c404e7bf68cd46f6c0/google-cloud-examples/src/main/java/com/google/cloud/examples/pubsub/snippets/SubscriberClientSnippets.java#L67), but either didn't pull anything.\r\nIn both cases, I've tried creating new topics and subscriptions both manually and using `SubscriberClient`.\r\n\r\nActual implementation:\r\nSubscriber\r\n```\r\ndef callback = new MessageReceiver() {\r\n  @Override\r\n  def receiveMessage(msg: PubsubMessage, consumer: AckReplyConsumer) {\r\n    consumer.accept(AckReply.ACK, null)\r\n    // Process message\r\n  }\r\n}\r\n\r\nval sub = SubscriptionName.create(\"projectId\", \"subName\"))\r\nval subscriber = Subscriber.newBuilder(sub, callback).build()\r\nsubscriber.addListener(new Subscriber.SubscriberListener {\r\n  override def failed(from: Subscriber.State, failure: Throwable) {\r\n    logger.error(\"pubsub listener exception\", failure)\r\n  }\r\n}, Executors.newSingleThreadExecutor())\r\nFuture{ subscriber.startAsync() }\r\nsubscriber.stopAsync().awaitTerminated()\r\n```\r\n\r\nSubscriberClient\r\n```\r\nval sub = SubscriptionName.create(\"projectId\", \"subName\"))\r\nval client = SubscriberClient.create()\r\n\r\nval pull = client.pull(sub, false, 100).getReceivedMessagesList.asScala\r\npull foreach { x =>\r\n  logger.warn(x.getMessage.getData.toString)\r\n  client.acknowledge(sub, List(x.getAckId).asJava)\r\n}\r\n```\r\n\r\nLogs for Subscriber:\r\n```\r\nFeb 27, 2017 1:25:42 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4edef76c] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.Subscriber$SubscriberImpl doStart\r\nINFO: Starting subscriber group.\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7961f6e3] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@2dbb0596] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@46e2b96] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@2d7d46b1] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4425b8e2] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@31479245] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@44002d60] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@38fb39f] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@6a04f9a4] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@675c9b1b] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@22f2c1bd] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@5c9f9d37] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@111b86d9] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@129c43a2] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@26d79765] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@601d0ad] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4be1b3fa] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3b907877] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@21e6acdf] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@296a94f6] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@6fd28c42] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@5739020f] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@43addc63] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3e1d3dc4] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@45d616d9] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@5a604d16] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7703dcfd] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@20272cc4] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@55b296c7] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@d62799a] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@646fa8ff] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7d37f9ba] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3c724c75] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@22c25cc8] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3b73303f] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@79cbe4c2] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@57f41e6a] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@67602c40] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@45300a5b] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@63fb1bcb] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@140b5e90] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@72ef627d] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3748dca9] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@cd6acc8] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@42e78c1c] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4b12e2b7] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3a4ec2e8] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3479985] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7d3e629d] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@216530d7] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@6d70ef91] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@5244d80b] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@5ce06254] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@540b0297] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3eed63e0] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4a9d70b6] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@15304973] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@1923eef8] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4c047c5f] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@6dbdbda9] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7a511abc] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7c037f20] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@130a027b] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@13daa546] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@612cc97b] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@6315001] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@456b9366] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3ddfe18] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@43d8809] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@80071d7] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@11e92312] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7d283209] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@153d9065] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@1eb8c5dc] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@461194aa] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7a154e1b] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@3d24784] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@5b1cf407] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@11e28f0a] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@41577ebb] Created with target pubsub.googleapis.com:443\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:14 PM com.google.cloud.pubsub.spi.v1.PollingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 27, 2017 1:27:15 PM com.twitter.finagle.Init$$anonfun$4 apply$mcV$sp\r\nINFO: Finagle version 6.41.0 (rev=95eedf5f41f78414fae25d93cc8fae02eeb5a75d) built at 20161220-164342\r\nFeb 27, 2017 1:27:24 PM io.grpc.internal.LogExceptionRunnable run\r\nSEVERE: Exception while executing runnable io.grpc.internal.ClientCallImpl$DeadlineTimer@11ddd1fe\r\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@71bafede rejected from java.util.concurrent.ScheduledThreadPoolExecutor@328102d1[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 320]\r\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)\r\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor.execute(ScheduledThreadPoolExecutor.java:622)\r\n\tat java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)\r\n\tat io.grpc.internal.SerializingExecutor.execute(SerializingExecutor.java:112)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.closed(ClientCallImpl.java:517)\r\n\tat io.grpc.internal.DelayedStream$DelayedStreamListener$4.run(DelayedStream.java:392)\r\n\tat io.grpc.internal.DelayedStream$DelayedStreamListener.delayOrExecute(DelayedStream.java:346)\r\n\tat io.grpc.internal.DelayedStream$DelayedStreamListener.closed(DelayedStream.java:389)\r\n\tat io.grpc.internal.DelayedStream.cancel(DelayedStream.java:247)\r\n\tat io.grpc.internal.DelayedClientTransport$PendingStream.cancel(DelayedClientTransport.java:397)\r\n\tat io.grpc.internal.DelayedStream$5.run(DelayedStream.java:242)\r\n\tat io.grpc.internal.DelayedStream.delayOrExecute(DelayedStream.java:144)\r\n\tat io.grpc.internal.DelayedStream.cancel(DelayedStream.java:239)\r\n\tat io.grpc.internal.DelayedClientTransport$PendingStream.cancel(DelayedClientTransport.java:397)\r\n\tat io.grpc.internal.ClientCallImpl$DeadlineTimer.run(ClientCallImpl.java:295)\r\n\tat io.grpc.internal.LogExceptionRunnable.run(LogExceptionRunnable.java:58)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\n`SubscriberClient` does not crash and instead doesn't return anything."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1666",
        "number": 1666,
        "title": "More distinct exception handling when getting GAE ProjectID in ServiceOptions",
        "labels": [
            "api: core",
            "priority: p2",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/e5f90467fe7490759482e6a8bc62b1246318a7f0/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L437\r\n\r\nIn case of quota exhaustion,  Exception is thrown from RPC. Catch doesn't distinguish and thus assumes it's not running on GAE.\r\n\r\nWould it be sufficient to catch ClassNotFoundException and related (e.g. NoSuchMethodException) to detect if we're on GAE? Like this, RPC-related exceptions (from within the called method) could bubble up properly.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1664",
        "number": 1664,
        "title": "pubsub README still uses deprecated code",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1661",
        "number": 1661,
        "title": "Pub/Sub: Improve design of synchronous pull",
        "labels": [
            "api: pubsub",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Synchronous pull is currently supported in the SPI layer on `SubscriberClient`. This support was retained at the request of @evmin in https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1157 .\r\n\r\nThe status quo is that there are two places to get messages, either using the synchronous pull on `SubscriberClient` or using the `Subscriber` class which does a lot of the subscription management for users. \r\n\r\nThe problem with this situation is that a user might only find one of those two ways to get messages and not see the other one, which is very suboptimal. We would like to consider if we can make the surface clearer.\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1660",
        "number": 1660,
        "title": "testIamPermissionsResponse : returned from PublisherClient.testIamPermissions not easily consumable",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The deprecated version of testing permissions: \r\n just returned a boolean list :\r\nList<Boolean> testTopicPermissions(String topic, List<String> permissions);\r\n In v0.9.3, t is not straightforward for the user to use this API for a quick permissions test\r\nPublisherClient.testIamPermissions returns instance of TestIamPermissionsResponse.\r\ntestIamPermissionResponse.getPermissionsList() returns a List<ByteString>\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1657",
        "number": 1657,
        "title": "Async APIs for Spanner",
        "labels": [
            "api: spanner",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be great if the Java library had asynchronous APIs for Cloud Spanner so that I don't need to tie up a request serving thread while I'm waiting for a response to a queries and writes. I had a look around the Javadoc and couldn't see anything about this, apologies if I've missed it."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1656",
        "number": 1656,
        "title": "FR: Deprecated builders, setters, getters, etc should be removed for GA",
        "labels": [
            "api: datastore",
            "api: logging",
            "api: pubsub",
            "api: storage"
        ],
        "state": "closed",
        "body": "The GA release should remove `@deprecated` methods & classes.\r\n\r\nFor datastore, logging, storage.  (all of them)\r\n\r\nFor PubSub, the old deprecated things should be removed."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1654",
        "number": 1654,
        "title": "JUL - Logging should be zero-conf for most users.",
        "labels": [
            "api: logging",
            "running on app engine",
            "type: feature request"
        ],
        "state": "closed",
        "body": "1. JUL `java.util.logging` should be zero configuration for most users.\r\n1. Work on all platforms: GAE Std 8 / Flex / GKE / GCE without modification.\r\n1. See #1130 for fluentd support as well. (in GAE Flex env)\r\n\r\n(Java 7 GAE Std / Dataproc / Dataflow is NOT Release Blocking;)\r\n\r\nI've asked @jabubake to help you with this."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1653",
        "number": 1653,
        "title": "PubSub, Logging, Datastore, BigQuery testing on GAE Std J7 & GAE Std J8",
        "labels": [
            "running on app engine",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Veener libraries need to be tested (ie. deployed) to GAE Standard using Java 7 and Java 8.\r\n\r\n@ludoch can WL you."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1652",
        "number": 1652,
        "title": "Publisher javadocs example fails to compile",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "From http://googlecloudplatform.github.io/google-cloud-java/0.9.2/apidocs/com/google/cloud/pubsub/spi/v1/Publisher.html\r\n\r\n(Checked both  0.9.0-alpha or 0.9.2-alpha):\r\n\r\n:\r\n  List<RpcFuture<String>> results = new ArrayList<>();\r\n:\r\n  Futures.addCallback(\r\n  Futures.allAsList(results),\r\n :\r\n \r\nFutures.allAsList & Futures.addCallback both require a ListenableFuture, not an RpcFuture.\r\n \r\nThe Rpc implementation is coming from Gax-0.1.0.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1650",
        "number": 1650,
        "title": "Subscriber implements Service interface",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Why new `Subscriber` implementation is a decorator for `AbstractService` and not implement `Service` interface directly? \r\n\r\nIt makes it harder to use with `com.google.common.util.concurrent.ServiceManager`"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1646",
        "number": 1646,
        "title": "Support default project for Pubsub",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "All the veneer libraries support picking up the default project id if an explicit one is not provided.\r\nSee Spanner , Datastore, Storage  : \r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-spanner/src/main/java/com/google/cloud/spanner/SpannerOptions.java\r\n\r\nThe deprecreated PubSub api supported it as well, v0.9.2-alpha does not."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1643",
        "number": 1643,
        "title": "Have getIamPolicy accept TopicName, SubscriptionName as input",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Given a lot of the new code uses TopicName/SubscriptionName class : constructed from projectId, topic-name/sub-name : it would be good if getIamPolicy on PublisherClient and SubscriberClient took in a TopicName, SubscriptionName respectively as opposed to just String : so there's no confusion to whether just topic/subscription-name alone works or the project-id needs to be specified as well."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1641",
        "number": 1641,
        "title": "List subscriptions by topic",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "Listing subscriptions by topic was possible with the prior version of the API as\r\ncom.google.cloud.pubsub : Page<SubscriptionId> listSubscriptions(String topic, ListOption... options);\r\n I don't see a way to do that anymore with com.google.pubsub.v1.ListSubscriptionsRequest.\r\nIs this a known deprecation or is there a way to achieve topic subscription filtering that is not exposed clearly ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1639",
        "number": 1639,
        "title": "Enable compression for pubsub library",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "As a customer I would like to have communication compressed from pubsub client to pubsub service.\r\n\r\nThis allows saving on network bandwidth when running it from other Cloud providers for example."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1637",
        "number": 1637,
        "title": "Spanner: add snippets/samples to all top level methods of main classes",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We want to ensure that all the methods that represent the interface of an API have samples/snippets to show our users the intended use. Spanner doesn't have such samples/snippets at the moment.\r\n\r\nAs examples, [BigQuery](http://googlecloudplatform.github.io/google-cloud-java/0.9.2/apidocs/index.html?com/google/cloud/bigquery/BigQuery.html), [Storage](http://googlecloudplatform.github.io/google-cloud-java/0.9.2/apidocs/index.html?com/google/cloud/storage/Storage.html), and [Datastore](http://googlecloudplatform.github.io/google-cloud-java/0.9.2/apidocs/index.html?com/google/cloud/datastore/Datastore.html) all have these snippets that show up in the Javadoc. \r\n\r\nIn the case of Spanner, we should also make sure that all the main interfaces have such samples/snippets in their top level methods (e.g. Spanner, DatabaseClient, DatabaseClientAdmin, ...).\r\n\r\nThere is also an infrastructure in place to write these snippets and to then test them automatically. Please see how other APIs are doing it (or ask @garrettjonesgoogle for guidance).\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1632",
        "number": 1632,
        "title": "google-cloud-spanner: Request ReadOption for descending result order",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It's nice to be able to use the `ReadContext.read()` method instead of `ReadContext.executeQuery()` because it's so much more efficient (no SQL parsing, query plan, etc).\r\n\r\nTo make `ReadContext.read()` more generally useful, this is a request to add a new `ReadOption`  to specify descending sort order (presumably, ascending sort order is the default so no option is needed for that).\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1631",
        "number": 1631,
        "title": "pubsub sample doc refers to bigquery",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "See https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/pubsub/PubSubExample.java#L44"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1629",
        "number": 1629,
        "title": "google-cloud-spanner: can't easily delete all leading and trailing rows in a table",
        "labels": [
            "api: spanner",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The `Mutation` API does not allow deleting a range of keys where the minimum or maximum key is \"infinity\".\r\n\r\nIn other words, there's no way to do the equivalent of `DELETE FROM Table WHERE key > @value`.\r\n\r\nThis is because the `KeyRange` class does not have values for positive and negative infinity.\r\n\r\nInstead, you have to iterate over the rows and delete them one by one, unless the key's type happens to have known absolute maximum and minimum values (some do not, e.g., `BYTES` and `String` do not have maximum values).\r\n\r\nIs this omission intentional?\r\n\r\nIf not, request adding the ability to specify \"infinity\" for the start and/or end of a `KeyRange`.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1628",
        "number": 1628,
        "title": "Batch copy for storage API",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "The storage API implements `delete`, `get`, and `update` methods to add requests to a batch. A `copy` method would be valuable as well. Is it something that can be considered ?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1627",
        "number": 1627,
        "title": "google-cloud-spanner: Add alternate r/w txn API that doesn't require use of callback",
        "labels": [
            "api: spanner",
            "type: feature request"
        ],
        "state": "closed",
        "body": "In the Google Cloud Spanner Java API, the only way to perform read/write transactions is by providing a callback, via the `TransactionRunner` interface.\r\n\r\nI understand that the API is trying to hide the details of the need to automatically retry transactions as a convenience to the programmer, but this limitation is a serious problem, at least for me. I need to be able to manage the transaction lifecycle myself, even if that means I have to perform my own retries (e.g., based on catching some sort of \"retryable\" exception, in this case `AbortedException`).\r\n\r\nTo make this problem more concrete, suppose one wanted to implement Spring's [PlatformTransactionManager](http://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/transaction/support/AbstractPlatformTransactionManager.html) for Google Cloud Spanner, so as to fit in with one's existing code, and use one's existing retry logic. It would not be possible with the current API.\r\n\r\nIt would be easy to augment the API in a backward compatible way, by adding a method returning a `TransactionContext` directly to the user, and let the user handle the retries. Of course this new method could be documented as \"more dangerous and less convenient\" to scare away noobs, etc.\r\n\r\nCan this alternate (more traditional) transaction API style be added to the Java API?\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1626",
        "number": 1626,
        "title": "pubsub test flakes",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "- [x] https://ci.appveyor.com/project/GoogleCloudPlatform/google-cloud-java/build/609 (testModifyAckDeadline)\r\n- [ ] https://travis-ci.org/GoogleCloudPlatform/google-cloud-java/builds/215825641"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1624",
        "number": 1624,
        "title": "Subscriber uselessly partitions `PendingModifyAckDeadline` list",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Looping in @davidtorres to make sure I understand this right.\r\n\r\nIn [this function](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/5311bb39021f97722bd8a549ed703e4c3d9b7c66/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/PollingSubscriberConnection.java#L197), we seem to be splitting the list so that individual requests are under pubsub's API limit.\r\n\r\nHowever, I think this is the wrong list to split. We create one RPC not per list of `PendingModifyAckDeadline` but per each `PendingModifyAckDeadline` object. If anything, we should be splitting the `modifyAckDeadline.ackIds`. My understanding is that `ackIds` can only be over the limit if the pubsub service gives us > 1000 messages in one call to pull. I don't think this can happen anyway, but would be happy to code defensively against it.\r\n\r\nDavid, can you verify?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1619",
        "number": 1619,
        "title": "Adding SSH keys via client",
        "labels": [
            "api: compute",
            "type: question"
        ],
        "state": "closed",
        "body": "Can't get how to add SSH keypairs to cloud. According to these docs: https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys#instance-only there's an API project metadata method for that. Is there any example of this action?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1618",
        "number": 1618,
        "title": "com.google.protobuf.GeneratedMessageV3$Builder cannot be resolved",
        "labels": [],
        "state": "closed",
        "body": "I am trying to follow the guidelines at\r\nhttps://cloud.google.com/natural-language/docs/reference/libraries#client-libraries-install-java\r\nThe only extra step is adding google-cloud-language dependency in pom.xml file.\r\nBut once it's done the following errors are reported:\r\n\r\n> The project was not built since its build path is incomplete. Cannot find the class file for com.google.protobuf.GeneratedMessageV3$Builder. Fix the build path then try building this project\r\n> The type com.google.protobuf.GeneratedMessageV3$Builder cannot be resolved. It is indirectly referenced from required .class files\r\n\r\nHow to fix it?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1617",
        "number": 1617,
        "title": "More support for DATE, TIME, and DATETIME schema types",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "At present you cannot create new fields with types DATE, TIME, and DATETIME.\r\n\r\nTo do so, you need access to a com.google.cloud.bigquery.Field.Type of that type, and though there are enums of DATE, TIME, and DATETIME, they are never passed to the Type constructor (which is private)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1616",
        "number": 1616,
        "title": "502 Bad Gateway Pub/Sub 0.9.0-alpha",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Hey, Trying out the new pubsub client and I'm getting 502 Bad Gateway. \r\n\r\n```\r\n17:51:44.832 |- INFO  c.wemesh.clerk.GooglePubSubConsumer$ - Waiting for messages from subscription: x.events.gray\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.Subscriber$SubscriberImpl doStart\r\nINFO: Starting subscriber group.\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@1442f788] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@42373389] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@9b21bd3] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@a62c7cd] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7661b5a] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7c36db44] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@65c33b92] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@7903d448] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@4e08acf9] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM io.grpc.internal.ManagedChannelImpl <init>\r\nINFO: [ManagedChannelImpl@42ea287] Created with target pubsub.googleapis.com:443\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection doStart\r\nINFO: Starting subscriber.\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\nFeb 13, 2017 5:51:46 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection initialize\r\nINFO: Initializing stream to subscription projects/wemesh-inc/subscriptions/x.events.gray with deadline 10\r\n17:51:46.536 |- INFO  com.wemesh.clerk.RpcServer - Server started, listening on 10006\r\nFeb 13, 2017 5:51:47 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection$StreamingPullResponseObserver onError\r\nINFO: Terminated streaming with exception\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: 502:Bad Gateway\r\n\tat io.grpc.Status.asRuntimeException(Status.java:545)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\n\tat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\nFeb 13, 2017 5:51:47 PM com.google.cloud.pubsub.spi.v1.StreamingSubscriberConnection$StreamingPullResponseObserver onError\r\nINFO: Terminated streaming with exception\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: 502:Bad Gateway\r\n\tat io.grpc.Status.asRuntimeException(Status.java:545)\r\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398)\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513)\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRun\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1614",
        "number": 1614,
        "title": "URLFetchServiceStreamHandler$Connection cannot be cast to HttpsURLConnection",
        "labels": [],
        "state": "closed",
        "body": "Hi,\r\n\r\nI am using the [Zendesk java client ](https://github.com/cloudbees/zendesk-java-client) on my Google Cloud App Engine and I have a runtime issue that prevents me from using the SDK. I am using the SDK from a servlet, what might I be doing wrong and would it work if I would use the SDK NOT from the servlet?\r\n\r\nThanks\r\n\r\n```\r\nUncaught exception from servlet java.lang.ClassCastException: com.google.apphosting.utils.security.urlfetch.URLFetchServiceStreamHandler$Connection cannot be cast to javax.net.ssl.HttpsURLConnection\r\n\tat com.ning.http.client.providers.jdk.JDKAsyncHttpProvider.createUrlConnection(JDKAsyncHttpProvider.java:184)\r\n\tat com.ning.http.client.providers.jdk.JDKAsyncHttpProvider.execute(JDKAsyncHttpProvider.java:147)\r\n\tat com.ning.http.client.providers.jdk.JDKAsyncHttpProvider.execute(JDKAsyncHttpProvider.java:118)\r\n\tat com.ning.http.client.AsyncHttpClient.executeRequest(AsyncHttpClient.java:506)\r\n\tat org.zendesk.client.v2.Zendesk.submit(Zendesk.java:1751)\r\n\tat org.zendesk.client.v2.Zendesk.access$1300(Zendesk.java:90)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1612",
        "number": 1612,
        "title": "Iterating BigQuery query results produces incorrect number of rows",
        "labels": [
            "api: bigquery",
            "priority: p2"
        ],
        "state": "closed",
        "body": "This is in relation to post on Stack Overflow post [here](http://stackoverflow.com/questions/42099842/bigquery-how-to-iterate-over-results-using-java-api).\r\n\r\nAs per the sample code [here](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/master/bigquery/cloud-client/src/main/java/com/example/bigquery/SimpleApp.java#L55), a user should be be able to paginate the results of a BigQuery query using the following code structure:\r\n\r\n```\r\nwhile (result != null) {\r\n      Iterator<List<FieldValue>> iter = result.iterateAll();\r\n      while (iter.hasNext()) {\r\n        List<FieldValue> row = iter.next();\r\n        //do something with row/data\r\n        System.out.println(row);\r\n      }\r\n      result = result.getNextPage();\r\n    }\r\n  }\r\n```\r\n\r\nHowever, when the result set is large (in my tests >31,000 rows), more rows are returned/iterated even though calling `result.getTotalRows()` returns the correct/expected number of rows.\r\n\r\nFor example, I have a table with 85,250 rows (9.45 MB). When I query it via the Java API, and use the code from the example above, it actually iterates 160,296 times. \r\n\r\nEven if I limit the result set in the query using `limit 5000`, and set `setPageSize(1000L)`, then it iterates 15,000 times e.g:\r\n\r\n```\r\nQueryRequest queryRequest = QueryRequest\r\n                .newBuilder(\"SELECT * FROM [<my-project-id>:<dataset>.<table_with_85250_rows>] limit 5000\")\r\n                .setUseLegacySql(true)\r\n                .setPageSize(1000L)\r\n                .build();\r\n        QueryResponse response = bigQuery.query(queryRequest);\r\n        QueryResult result = response.getResult();\r\n        System.out.println(\"Total rows: \" + result.getTotalRows());\r\n        Integer rowNumber = 1;\r\n        while(result != null){\r\n            Iterator<List<FieldValue>> iter = result.iterateAll();\r\n            while(iter.hasNext()){\r\n                List<FieldValue> row = iter.next();\r\n                System.out.println(\"Row: \" + rowNumber + \", with number of columns: \" + row.size());\r\n                rowNumber++;\r\n            }\r\n            result = result.getNextPage();\r\n        }\r\n```\r\n\r\n**Output**:\r\n```\r\nTotal rows: 5000\r\nRow: 1, with number of columns: 11\r\nRow: 2, with number of columns: 11\r\nRow: 3, with number of columns: 11\r\nRow: 4, with number of columns: 11\r\nRow: 5, with number of columns: 11\r\nRow: 6, with number of columns: 11\r\nRow: 7, with number of columns: 11\r\nRow: 8, with number of columns: 11\r\nRow: 9, with number of columns: 11\r\nRow: 10, with number of columns: 11\r\nRow: 11, with number of columns: 11\r\n[.....]\r\nRow: 14997, with number of columns: 11\r\nRow: 14998, with number of columns: 11\r\nRow: 14999, with number of columns: 11\r\nRow: 15000, with number of columns: 11\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1610",
        "number": 1610,
        "title": "Add support for table.externalDataConfiguration",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Add support for table.externalDataConfiguration, at a minimum with sourceFormat = \"CSV\", sourceUris = valid GCS URIs, and the csvOptions."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1609",
        "number": 1609,
        "title": "Fill out integration tests for BigQuery",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1605",
        "number": 1605,
        "title": "Which Java client library to use?",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "The entire Java API situation seems a bit confusing. \r\n\r\nA google search for \"Google compute Java api\" brings up this as the first result: [**Google API Client Libraries - Compute**](https://developers.google.com/api-client-library/java/apis/compute/v1)\r\n\r\nHowever, the recommended way to work with GCP seems to be [**google-cloud**](http://googlecloudplatform.github.io/google-cloud-java/0.8.3/index.html) .\r\n\r\n> google-cloud is built specifically for the Google Cloud Platform and is the recommended way to integrate Google Cloud APIs into your Java applications\r\n\r\nwhich would have been fine if the docs had a link to it but the [**compute engine docs**](https://cloud.google.com/compute/docs/api/libraries) for client libraries makes no mention of `google-cloud`, but rather links to [Google APIs Java Client Library](https://cloud.google.com/compute/docs/api/libraries#google_apis_java_client_library) (the maven version mentioned there did not resolve for me)\r\n\r\nI think it'd be great if the documentation clearly mentioned which was the recommended way forward. \r\n\r\n--\r\nThis [**image**](https://lh3.googleusercontent.com/FRQQdZAvn7lk1UdlnnTNe_QvOc5EdMiHYB_Dy2xdP7Ut28X6TkDJ5RwrxejKHdJ_8wbgx2fd7SK4mCDSQLh0JnN4lOwUvQY=s1600) on the [Google API Client Libraries | Java](https://developers.google.com/api-client-library/java/) home page is the only thing that gives the  \"not recommended\" vibe.\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1603",
        "number": 1603,
        "title": "BigQuery: insertAll should help convert a byte[] array to base64.",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See the snippet for insertAll:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/fa0720c65576ed68419772b04b463176bc8061d7/google-cloud-examples/src/main/java/com/google/cloud/examples/bigquery/snippets/BigQuerySnippets.java#L405\r\n\r\nThe example shows a base64 string. I would love to have a feature where a byte array could be entered and the library handles the conversion.\r\n\r\nMarked as \"triaged for GA\" because this is not a blocker."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1602",
        "number": 1602,
        "title": "Storage: add support for Per-Object Storage Class",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "We need to add support for Per-Object Storage Class (POSC).\r\n\r\nHere some extra information to help:\r\n\r\n- [POSC info from Cloud Storage documentation](https://cloud.google.com/storage/docs/per-object-storage-class)\r\n- [POSC example with JSON API](https://cloud.google.com/storage/docs/changing-storage-classes)\r\n- [Storage Class info from Cloud Storage documentation](https://cloud.google.com/storage/docs/storage-classes)\r\n\r\nOn top of that, google-cloud-dotnet has made an implementation which can be used as reference. \r\n\r\n- [Please view the Pull Request to understand the changes](https://github.com/GoogleCloudPlatform/google-cloud-dotnet/pull/766)\r\n\r\nIf you have any implementation questions, please direct them at jskeet\r\n\r\n/cc @jskeet @danoscarmike "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1601",
        "number": 1601,
        "title": "Change service hierarchy so that http vs grpc isn't baked in",
        "labels": [
            "api: bigquery",
            "api: datastore",
            "api: storage"
        ],
        "state": "closed",
        "body": "Specifically, look at the setup required to initialize the service object."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1597",
        "number": 1597,
        "title": "Custom log enhancers prevented due to visibility of LoggingHandler.Enhancer interface",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "com.google.cloud.logging.LoggingHandler allows enhancer classes to be configured to augment created LogEntry & MonitoredResource instances.\r\n\r\nThe Enhancer interface is package-private, preventing the implementation of custom Enhancers (unless one resorts to putting their third-party Enhancer implementation in the com.google.cloud.logging package). As there's only a single Enhancer implementation shipped with the library (GaeFlexLoggingEnhancer), this makes the entire Enhancer functionality not terribly useful.\r\n\r\nIs this intentional or simply an oversight?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1596",
        "number": 1596,
        "title": "remove pubsub Mockito dependency",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "maybe use easymock instead"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1595",
        "number": 1595,
        "title": "Cloud Logging library does not work on Java Flex Compat",
        "labels": [
            "api: logging",
            "running on app engine"
        ],
        "state": "closed",
        "body": "```Java\r\nprotected void doGet(HttpServletRequest req, HttpServletResponse resp)\r\n      throws ServletException, IOException {\r\n    final PrintWriter out = resp.getWriter();\r\n\r\n    LoggingOptions options = LoggingOptions.newBuilder().build();\r\n\r\n    try (Logging logging = options.getService()) {\r\n\r\n\r\n      LogEntry firstEntry = LogEntry\r\n          .newBuilder(Payload.StringPayload.of(\"testing direct use of API\"))\r\n          .setLogName(\"test-log\")\r\n          .setResource(MonitoredResource.newBuilder(\"global\")\r\n              .addLabel(\"project_id\", options.getProjectId())\r\n              .build())\r\n          .build();\r\n      logging.write(Collections.singleton(firstEntry));\r\n\r\n      Page<LogEntry> entries = logging.listLogEntries(\r\n          Logging.EntryListOption\r\n              .filter(\"logName=projects/\" + options.getProjectId() + \"/logs/test-log\"));\r\n      Iterator<LogEntry> entryIterator = entries.iterateAll();\r\n      while (entryIterator.hasNext()) {\r\n        System.out.println(entryIterator.next());\r\n      }\r\n\r\n\r\n    } catch (Exception e) {\r\n      e.printStackTrace(out);\r\n      e.printStackTrace();\r\n    }\r\n}\r\n```\r\n\r\n```\r\ncom.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: UNKNOWN\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc$1.apply(DefaultLoggingRpc.java:165)\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc$1.apply(DefaultLoggingRpc.java:159)\r\n\tat com.google.api.gax.grpc.AbstractRpcFuture$2.apply(AbstractRpcFuture.java:65)\r\n\tat com.google.api.gax.grpc.AbstractRpcFuture$2.apply(AbstractRpcFuture.java:62)\r\n\tat com.google.common.util.concurrent.Futures$CatchingFuture.doFallback(Futures.java:842)\r\n\tat com.google.common.util.concurrent.Futures$CatchingFuture.doFallback(Futures.java:834)\r\n\tat com.google.common.util.concurrent.Futures$AbstractCatchingFuture.run(Futures.java:789)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:753)\r\n\tat com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:634)\r\n\tat com.google.common.util.concurrent.SettableFuture.setException(SettableFuture.java:53)\r\n\tat com.google.api.gax.grpc.BundlingFuture.setException(BundlingFuture.java:87)\r\n\tat com.google.api.gax.grpc.BundlingContext.sendResult(BundlingContext.java:97)\r\n\tat com.google.api.gax.grpc.BundleExecutor.processBundle(BundleExecutor.java:89)\r\n\tat com.google.api.gax.bundling.ThresholdBundlingForwarder$BundleForwardingRunnable.processBundle(ThresholdBundlingForwarder.java:106)\r\n\tat com.google.api.gax.bundling.ThresholdBundlingForwarder$BundleForwardingRunnable.run(ThresholdBundlingForwarder.java:89)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: com.google.api.gax.grpc.ApiException: io.grpc.StatusRuntimeException: UNKNOWN\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable$ExceptionTransformingFuture.onFailure(ExceptionTransformingCallable.java:107)\r\n\tat com.google.api.gax.grpc.ListenableFutureDelegate$1.onFailure(ListenableFutureDelegate.java:52)\r\n\tat com.google.common.util.concurrent.Futures$6.run(Futures.java:1764)\r\n\tat com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456)\r\n\tat com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:817)\r\n\tat com.google.common.util.concurrent.AbstractFuture.addListener(AbstractFuture.java:595)\r\n\tat com.google.common.util.concurrent.ForwardingListenableFuture.addListener(ForwardingListenableFuture.java:47)\r\n\tat com.google.common.util.concurrent.Futures.addCallback(Futures.java:1776)\r\n\tat com.google.common.util.concurrent.Futures.addCallback(Futures.java:1713)\r\n\tat com.google.api.gax.grpc.ListenableFutureDelegate.addCallback(ListenableFutureDelegate.java:47)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:63)\r\n\tat com.google.api.gax.grpc.RetryingCallable$RetryingResultFuture.issueCall(RetryingCallable.java:214)\r\n\tat com.google.api.gax.grpc.RetryingCallable.futureCall(RetryingCallable.java:82)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:243)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:254)\r\n\tat com.google.api.gax.grpc.UnaryCallable.call(UnaryCallable.java:282)\r\n\tat com.google.api.gax.grpc.BundleExecutor.processBundle(BundleExecutor.java:82)\r\n\t... 3 more\r\nCaused by: io.grpc.StatusRuntimeException: UNKNOWN\r\n\tat io.grpc.Status.asRuntimeException(Status.java:545)\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:442)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:203)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:62)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:273)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:252)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:189)\r\n\tat com.google.api.gax.grpc.DirectCallable.futureCall(DirectCallable.java:58)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:60)\r\n\t... 9 more\r\nCaused by: java.lang.IllegalStateException: Request threads can only be created within the context of a running request.\r\n\tat com.google.appengine.repackaged.com.google.common.base.Preconditions.checkState(Preconditions.java:446)\r\n\tat com.google.apphosting.vmruntime.VmRequestThreadFactory.newThread(VmRequestThreadFactory.java:79)\r\n\tat com.google.common.util.concurrent.ThreadFactoryBuilder$1.newThread(ThreadFactoryBuilder.java:162)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:612)\r\n\tat java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:925)\r\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1368)\r\n\tat io.grpc.internal.DnsNameResolver.resolve(DnsNameResolver.java:202)\r\n\tat io.grpc.internal.DnsNameResolver.start(DnsNameResolver.java:120)\r\n\tat io.grpc.internal.ManagedChannelImpl$1NameResolverStartTask.run(ManagedChannelImpl.java:268)\r\n\tat io.grpc.internal.ManagedChannelImpl.exitIdleModeAndGetLb(ManagedChannelImpl.java:233)\r\n\tat io.grpc.internal.ManagedChannelImpl$2.get(ManagedChannelImpl.java:310)\r\n\tat io.grpc.internal.ClientCallImpl.start(ClientCallImpl.java:213)\r\n\tat io.grpc.auth.ClientAuthInterceptor$1.checkedStart(ClientAuthInterceptor.java:104)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:195)\r\n\t... 16 more\r\n```\r\n\r\nNote, I'm using a custom Dockerfile:\r\n```\r\nFROM gcr.io/google-appengine/jetty9-compat:githubheadasync\r\nADD . /app/\r\n```\r\n\r\nI think the problem stems from the library trying to use `com.google.apphosting.vmruntime.VmRequestThreadFactory` that is configured in the compat runtime.\r\n\r\nGRPC is checking for the `com.google.appengine.runtime.environment` system property and is going into the App Engine branch.\r\n\r\nInterestingly, if I clear the system property with `System.clearProperty(\"com.google.appengine.runtime.environment\")`, logging seems to work, but that's just a hack.\r\n\r\n@garrettjonesgoogle @ludoch @gregw "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1594",
        "number": 1594,
        "title": "Feature Request: Discourage use of API_KEY in translate",
        "labels": [
            "api: translation",
            "priority: p1"
        ],
        "state": "closed",
        "body": "At the request of @puneith, we should remove, deprecate, or otherwise discourage using the API_KEY form of authorization favoring the GOOGLE_APPLICATION_CREDENTIALS for Cloud APIs to make the library consistent with the Python client library for Translate.\r\n\r\nThe affected method is [setApiKey](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/60270261fa763131f6cd6b9aacfc7819e0af1c3d/google-cloud-translate/src/main/java/com/google/cloud/translate/TranslateOptions.java#L118) in the **TranslateOptions** builder."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1588",
        "number": 1588,
        "title": "BigQuery - remove uses of jobs.query method.",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The [jobs.query](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query) method should not be used in the client libraries.\r\n\r\nReasons: the query can time out, but it still might actually run, costing money & resources. Unless you poll for the results (not obvious you have to do this) you won't see them.\r\n\r\nAlso, the `jobs/query` API does not accept a job ID. This means that a retry on failure could result in duplicate queries being run, causing extra resource usage & charges.\r\n\r\nProposal:\r\n\r\n- Remove all uses of `jobs/query`. Instead use [`jobs/insert`](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert).\r\n- Deprecate `BigQuery.query(QueryRequest)`. Providing a synchronous method without an explicit job ID is dangerous for the reasons listed above. Alternatively, we could generate a job ID client-side, which would protect against duplicate queries from retries from the client libraries.\r\n- Add a method `BigQuery.query(QueryRequest, JobId)` so users can explicitly provide a job ID for safe retries (even against program crashes if they save the job ID somewhere -- important for really big/expensive queries)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1587",
        "number": 1587,
        "title": "Convert from Maven to Gradle",
        "labels": [
            "priority: p2",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "Reasons:\r\n\r\n1. We can migrate the release process out of bash and into build scripts\r\n2. We can migrate the snippet update process out of python and into build scripts\r\n3. The rest of the team's Java repositories are in Gradle (`toolkit`, `gax-java`)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1580",
        "number": 1580,
        "title": "Replace Future with ApiFuture where appropriate",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "This is a breaking change because of previous recommendations for people to use code which assumes Future is a ListenableFuture. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1579",
        "number": 1579,
        "title": "Pub/Sub Messages stop being Processed ",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "Hi,\r\nOver the weekend I've been experiencing abnormal behaviour with Pub/Sub. Since Friday at 4pm ET I've experienced numerous cases were my services will stop processing messages. I can see in stackdriver that messages are being queued but not processed. Restarting the services allows the messages to be processed until it stops again. \r\n\r\nThis seems to be a issue with v0.8.x and less with v0.4.0. In v0.8.x there is a infinite timeout ([DefaultPubSubRpc.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.8.0/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/DefaultPubSubRpc.java#L137)) and in v0.4.0 there doesn't seem to be ([DefaultPubSubRpc.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.4.0/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/DefaultPubSubRpc.java#L131)).\r\n\r\nIn my experience setting a infinite timeout is rarely a good idea. Is there a reason why you do this? "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1578",
        "number": 1578,
        "title": "Fix broken components of hosted docs",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "* The cobertura section is broken: http://googlecloudplatform.github.io/google-cloud-java/0.8.0/cobertura/index.html (all coverage is 0%, which is wrong)\r\n* The license page is broken: http://googlecloudplatform.github.io/google-cloud-java/0.8.0/license.html \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1577",
        "number": 1577,
        "title": "deadlock in testStreamAckDeadlineUpdate",
        "labels": [],
        "state": "closed",
        "body": "@garrettjonesgoogle @davidtorres @kir-titievsky\r\n\r\nI tracked down another deadlock, but this one I cannot fix without changing the surface.\r\n\r\nIn the happy case, the test\r\n- receives a message, and creates a future to respond\r\n- advance time by 20s\r\n- sets the future result to `ACK`\r\n  - this updates the latency distribution\r\n  - the next time we configure the stream latency, we'll set the latency to 20s\r\n- advance time by 60s\r\n  - we configure stream latency every minute\r\n  - so, this tells the server to change our stream latency to 20s\r\n- YAY!\r\n\r\nThe mechanism we use the update latency is that we add a callback to the `ListenableFuture` that is returned by `MessageReceiver::receiveMessage`. The logic is that once the user finishes with the work, the latency distribution is automatically updated.\r\n\r\nIn the bad case:\r\n- the GRPC thread calls `MessageReciever::receive`\r\n  - the test implementation creates a future, puts it in a queue to be retrieved by the test code.\r\n- advance time by 20s\r\n- the test thread takes the future above out the queue, and sets future result\r\n- advance time by 60s\r\n- **then**, the GRPC thread finally adds the callback (let's call this step *S1*)\r\n  - since the future is already completed, we update the latency distribution to 80s\r\n- the minute for configuring stream latency has also passed (let's call this step *S2*)\r\n  - change stream latency to 80s\r\n\r\nIn an even worse case, *S1* and *S2* can switch order. Since there is no entries in the distribution, we don't update the server with anything. The latency on the server stays at 10s (the default).\r\n\r\nTest code expects the latency value on the server [eventually be set to 20s](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/c46faf232dcde2e211f25cd5485d1de9216027f7/google-cloud-pubsub/src/test/java/com/google/cloud/pubsub/spi/v1/SubscriberImplTest.java#L349). In either bad case, the test deadlocks.\r\n\r\nI don't think this test can be fixed with the current surface. Since the Future is returned by `MessageReceiver`, it stands to reason that other threads can do arbitrary things to the future before the callback can be added. Note that this problem affects production code as well: the synchronization is still technically incorrect though the consequence is small enough that it probably will never matter.\r\n\r\nI can think of a couple of ways to fix it:\r\n**Current**\r\n```java\r\n// Definition\r\nListenableFuture<AckReply> receiveMessage(PubsubMessage message);\r\n\r\n// Sample implementation\r\nListenableFuture<AckReply> receiveMessage(final PubsubMessage message) {\r\n  return executor.submit(new Callable<AckReply>() {\r\n    @Override\r\n    AckReply call() {\r\n      if (someLongComputation(message)) {\r\n        return AckReply.ACK;\r\n      }\r\n      return AckReply.NACK;\r\n    }\r\n  });\r\n}\r\n```\r\n\r\n**Option 1**\r\n```java\r\n// Definition\r\nvoid receiveMessage(PubsubMessage message, SettableFuture<AckReply> response);\r\n\r\n// Sample implementation\r\nvoid receiveMessage(final PubsubMessage message, final SettableFuture<AckReply> response) {\r\n  ListenableFuture<AckReply> future = executor.submit(new Callable<AckReply>() {\r\n    @Override\r\n    AckReply call() {\r\n      if (someLongComputation(message)) {\r\n        return AckReply.ACK;\r\n      }\r\n      return AckReply.NACK;\r\n    }\r\n  });\r\n  response.setFuture(future);\r\n}\r\n```\r\nIn this way, we create the future for the user and can make sure the callback is set before the user can do anything with it. If the user takes a long time to respond to a job, job scheduling is still left to the user. Eg, if the user wants to process many messages in a threadpool, the user must create the threadpool themselves.\r\n\r\n**Option 2**\r\n```java\r\n// Definition\r\nAckReply receiveMessage(PubsubMessage message);\r\n// This is essentially the same with Function<PubsubMessage, AckReply>\r\n\r\n// Sample implementation\r\nAckReply receiveMessage(PubsubMessage message) {\r\n  return someLongComputation(message);\r\n}\r\n```\r\nWe can call the function from a threadpool ourselves. The function must be thread safe. We can increase the number of threads in the pool to cope with extra load. The user can always set the number of threads to suit their work load."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1575",
        "number": 1575,
        "title": "Reconcile NanoClock in GAX with Clock in google-cloud-java",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "NanoClock operates on nanoseconds and Clock operates on milliseconds, but I don't think there's a need to have two distinct classes. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1574",
        "number": 1574,
        "title": "Reconcile RetrySettings in GAX with RetryParams in google-cloud-java",
        "labels": [
            "api: bigquery",
            "api: core",
            "api: datastore",
            "api: logging",
            "api: pubsub",
            "api: storage"
        ],
        "state": "closed",
        "body": "Other classes involved:\r\n\r\ngoogle-cloud-java:\r\n* `ExceptionHandler`\r\n* `RetryHelper`\r\n\r\nGAX:\r\n* `RetryingCallable`\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1573",
        "number": 1573,
        "title": "Create variant of google-cloud-java with Guava and grpc-stub shaded",
        "labels": [
            "api: logging",
            "api: pubsub",
            "dependencies",
            "type: feature request"
        ],
        "state": "open",
        "body": "Note: GAX needs to be exposed. \r\n\r\nConsequences:\r\n\r\n1. Guava can't be exposed on the public surface of GAX or google-cloud-java\r\n2. grpc-stub can't be exposed on the public surface of GAX or google-cloud-java (since it exposes Guava)\r\n3. The generated grpc packages need to be split into two: a package with proto-generated types (no Guava dependency) and a package with only grpc (which exposes Guava), and the second type of package needs to be shaded.\r\n\r\nCoordinating issue in GAX is filed at https://github.com/googleapis/gax-java/issues/188 .\r\n\r\nAlso: protobuf-java-util needs to be shaded.\r\n\r\n`@VisibleForTesting` needs to be removed throughout the code. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1571",
        "number": 1571,
        "title": "Publish the docs for 0.8.1",
        "labels": [],
        "state": "closed",
        "body": "It seems like everything became 0.8.1. The docs are still at 0.8.0:\r\n\r\nhttp://googlecloudplatform.github.io/google-cloud-java/0.8.0/index.html\r\n\r\nAnd in fact, the Monitoring example shown in the current docs failed because the method `formatGroupName` doesn't exist it seems:\r\n\r\n```\r\n try (GroupServiceClient groupServiceClient = GroupServiceClient.create()) {\r\n   String formattedName = GroupServiceClient.formatGroupName(\"[PROJECT]\", \"[GROUP]\");\r\n   Group response = groupServiceClient.getGroup(formattedName);\r\n }\r\n```\r\n\r\nI had to look at the generated code to find the working sample. Hence, I assume this should be fixed with 0.8.1."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1570",
        "number": 1570,
        "title": "Add links from javadocs to hosted docs of GAX types",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "Prerequisites:\r\n\r\n* https://github.com/googleapis/artman/issues/136\r\n* https://github.com/googleapis/gax-java/issues/192\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1569",
        "number": 1569,
        "title": "Remove @Deprecated methods that were replaced with getX/setX methods",
        "labels": [
            "api: bigquery",
            "api: core",
            "api: datastore",
            "api: logging",
            "api: storage"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1568",
        "number": 1568,
        "title": "Reconcile Page in GAX with Page in google-cloud-java",
        "labels": [
            "api: bigquery",
            "api: core",
            "api: datastore",
            "api: logging",
            "api: pubsub",
            "api: storage"
        ],
        "state": "closed",
        "body": "The two classes serve the same purpose, but have differing method names. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1567",
        "number": 1567,
        "title": "Datastore: `allocateId` should only accept an incomplete key",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The current behavior is to \"trim\" the ID or name from the final path element before sending the key to the server:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-datastore/src/main/java/com/google/cloud/datastore/DatastoreImpl.java#L114\r\n\r\nThis means you can call `allocateId` on a key with a prepopulated ID, and the server will actuall allocate a completely different ID. This behavior is documented, but it seems surprising. Would be safer to either reject the `allocateId` call if the provided key contains an ID/name (or just let the server reject the call).\r\n\r\nReference:\r\nhttp://stackoverflow.com/questions/41878706/where-is-allocateids-in-the-google-cloud-datastore-java-library/41879429"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1566",
        "number": 1566,
        "title": "BigQuery: LoadJobConfiguration to support schemaUpdateOptions",
        "labels": [
            "api: bigquery",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`configuration.load.schemaUpdateOptions` is documented in the [REST API docs](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs), but `LoadJobConfiguration` doesn't have a way to set it. Actually the protobuf model class seems to have a setter.\r\n\r\nIt's not clear in the documentation whether `schemaUpdateOptions` are valid also for partitioned tables or not. Would be nice to get a clarification for that."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1565",
        "number": 1565,
        "title": "ServiceOptions.getCredentials can return null and cause NPE in Logging and PubSub",
        "labels": [
            "api: logging",
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "In ServiceOptions.java is no credentials are explicitly specified, it would default to calling getApplicationDefault here:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L312\r\n\r\nBut that method can fail by throwing an exception if for eg the credentials file is missing. In that case ServiceOptions just catches the exception, ignores it and returns null:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L314\r\n\r\nBut reading the documentation on getCredentials, it is not clear that callers should be handling null return value. google-cloud-java seems to be not handling the null return value atleast in couple of places:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/00add6e26fc2e1a533b715df28a5568222483f65/google-cloud-logging/src/main/java/com/google/cloud/logging/spi/DefaultLoggingRpc.java#L117\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/00add6e26fc2e1a533b715df28a5568222483f65/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/spi/DefaultPubSubRpc.java#L146"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1564",
        "number": 1564,
        "title": "BigQuery: support Tables: patch",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Add support for this:\r\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/tables/patch\r\n\r\n..unless it's already somehow possible to add or modify a field without specifying all the existing fields?\r\n\r\nInternally `BigQueryImpl.update` seems to call `bigQueryRpc.patch`, but when I tried to call `BigQuery.update` with only one field (the field to be added), I got an error that the schema doesn't match with the existing one."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1561",
        "number": 1561,
        "title": "What is the purpose of varargs in GqlQuery.Builder's addBinding and setBinding methods?",
        "labels": [
            "api: core",
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "I'm trying to figure out the purpose of vararg parameter in the above methods and can't figure out why. \r\n\r\nFor example, take the below method that allows binding zero or more String parameters:\r\n\r\n`\r\npublic GqlQuery.Builder<V> addBinding(String... value)\r\n`\r\n\r\nSince there is no JavaDoc on these methods yet - one way to interpret this method is that it allows binding of a `ListValue ` to do search on Array property. Other way is to bind each String value to @1, @2, etc. Looking at the code tells me that multiple values are converted to a ListValue, so... \r\n\r\nHowever, when I try this with more than one value, \r\n\r\n`\r\nQuery<Entity> query = Query.newGqlQueryBuilder(Query.ResultType.ENTITY, \"select * from MyEntity where MyProperty= @1\").addBinding(\"value1\", \"value2\").build();\r\n`\r\n\r\nThis errors out with the below exception: \r\n\r\n```\r\nException in thread \"main\" com.google.cloud.datastore.DatastoreException: A list value is not allowed\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:110)\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:96)\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.runQuery(DefaultDatastoreRpc.java:164)\r\n\tat com.google.cloud.datastore.DatastoreImpl$1.call(DatastoreImpl.java:93)\r\n\tat com.google.cloud.datastore.DatastoreImpl$1.call(DatastoreImpl.java:89)\r\n\tat com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\r\n\tat com.google.cloud.datastore.DatastoreImpl.runQuery(DatastoreImpl.java:88)\r\n\tat com.google.cloud.datastore.QueryResultsImpl.sendRequest(QueryResultsImpl.java:73)\r\n\tat com.google.cloud.datastore.QueryResultsImpl.<init>(QueryResultsImpl.java:57)\r\n\tat com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:82)\r\n\tat com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:73)\r\n```\r\n\r\nSo, why do these methods have varargs? \r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1559",
        "number": 1559,
        "title": "GqlQuery - Allow binding of null ",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The GqlQuery.Builder's addBinding and setBinding methods allow binding of various data types, but not a null. Can the API be enhanced to allow binding of a null/NullValue instead of having to use different GqlSyntax based on the search string (null vs not null)? \r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1549",
        "number": 1549,
        "title": "Find ways to simplify pubsub samples",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1546",
        "number": 1546,
        "title": "Rename MessagesProcessor to MessageDispatcher",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1545",
        "number": 1545,
        "title": "Storage Retry Logic",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Hi there. I'm using `com.google.cloud.storage.Storage.writer()` method of v0.8.0 of the google-cloud lib. I'm getting \"503 backend error\" from the GCS service when trying to upload files (stack trace below). I expect the retry logic in `com.google.cloud.storage.BlobWriteChannel` to retry the chunk, but it doesn't do that.\r\n\r\n```java\r\n  @Override\r\n  protected void flushBuffer(final int length, final boolean last) {\r\n    try {\r\n      runWithRetries(callable(new Runnable() {\r\n        @Override\r\n        public void run() {\r\n          getOptions().getRpc().write(getUploadId(), getBuffer(), 0, getPosition(), length, last);\r\n        }\r\n      }), getOptions().getRetryParams(), StorageImpl.EXCEPTION_HANDLER, getOptions().getClock());\r\n    } catch (RetryHelper.RetryHelperException e) {\r\n      throw StorageException.translateAndThrow(e);\r\n    }\r\n  }\r\n```\r\nThe problem seems to lie in the logic for converting the `com.google.api.client.http.HttpResponseException` to a `com.google.cloud.storage.StorageException`\r\n\r\n```java\r\npublic BaseServiceException(IOException exception, boolean idempotent) {\r\n    super(message(exception), exception);\r\n    int code = UNKNOWN_CODE;\r\n    String reason = null;\r\n    String location = null;\r\n    String debugInfo = null;\r\n    Boolean retryable = null;\r\n    if (exception instanceof GoogleJsonResponseException) {\r\n      GoogleJsonError jsonError = ((GoogleJsonResponseException) exception).getDetails();\r\n      if (jsonError != null) {\r\n        Error error = new Error(jsonError.getCode(), reason(jsonError));\r\n        code = error.code;\r\n        reason = error.reason;\r\n        retryable = isRetryable(idempotent, error);\r\n        if (reason != null) {\r\n          GoogleJsonError.ErrorInfo errorInfo = jsonError.getErrors().get(0);\r\n          location = errorInfo.getLocation();\r\n          debugInfo = (String) errorInfo.get(\"debugInfo\");\r\n        }\r\n      } else {\r\n        code = ((GoogleJsonResponseException) exception).getStatusCode();\r\n      }\r\n    }\r\n    this.retryable = MoreObjects.firstNonNull(retryable, isRetryable(idempotent, exception));\r\n    this.code = code;\r\n    this.reason = reason;\r\n    this.idempotent = idempotent;\r\n    this.location = location;\r\n    this.debugInfo = debugInfo;\r\n  }\r\n```\r\n\r\nSince the HttpResponseException is not an instanceof GoogleJsonResponseException, we end up with a code of 0, which the retry logic sees as a non-retryable exception. Here's a code snippet to easily reproduce the issue:\r\n\r\n```java\r\nHttpResponseException httpEx = new HttpResponseException.Builder(503, \"Service Unavailable\", new HttpHeaders()).build();\r\nStorageException storageEx = new StorageException(httpEx);\r\nSystem.out.println(storageEx.getCode());\r\nSystem.out.println(storageEx.getMessage());\r\n```\r\n\r\nFurthermore, the stacktrace I end up with doesn't indicate that the code and message of the ServiceException weren't set (I think the toString() method can be improved to show this info).\r\n\r\nException in thread \"main\" com.google.cloud.storage.StorageException: 503 Service Unavailable\r\n{\r\n \"error\": {\r\n  \"errors\": [\r\n   {\r\n    \"domain\": \"global\",\r\n    \"reason\": \"backendError\",\r\n    \"message\": \"Backend Error\"\r\n   }\r\n  ],\r\n  \"code\": 503,\r\n  \"message\": \"Backend Error\"\r\n }\r\n}\r\n\r\n\tat com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:202)\r\n\tat com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:582)\r\n\tat com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:50)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\r\n\tat com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\r\n\tat com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:47)\r\n\tat com.google.cloud.BaseWriteChannel.close(BaseWriteChannel.java:199)\r\n\tat com.spins.google.api.CloudStorage.upload(CloudStorage.java:338)\r\n\tat com.spins.google.api.CloudStorage.upload(CloudStorage.java:325)\r\n\tat com.spins.google.api.CloudStorage.upload(CloudStorage.java:315)\r\n\tat Random.main(Random.java:69)\r\nCaused by: com.google.api.client.http.HttpResponseException: 503 Service Unavailable\r\n{\r\n \"error\": {\r\n  \"errors\": [\r\n   {\r\n    \"domain\": \"global\",\r\n    \"reason\": \"backendError\",\r\n    \"message\": \"Backend Error\"\r\n   }\r\n  ],\r\n  \"code\": 503,\r\n  \"message\": \"Backend Error\"\r\n }\r\n}\r\n\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1061)\r\n\tat com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:564)\r\n\t... 10 more"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1543",
        "number": 1543,
        "title": "Publisher might overflow",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The line linked might overflow. We should use Math.floorMod instead.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/db4908e82af4561127cc651f76978e8703d9ea64/google-cloud-pubsub/src/main/java/com/google/cloud/pubsub/PublisherImpl.java#L319"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1542",
        "number": 1542,
        "title": "Implement Publisher/Subscriber stats",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1541",
        "number": 1541,
        "title": "Integration tests - fix intermittent failure: Unexpected method call Logging.close()",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "```\r\nTests in error: \r\n  ITLoggingTest.testListSinksAsync \u00bb Logging io.grpc.StatusRuntimeException: INT...\r\n\r\nException in thread \"Thread-0\" java.lang.AssertionError: \r\n  Unexpected method call Logging.close():\r\n    Logging.write([LogEntry{logName=null, resource=null, timestamp=null, severity=DEBUG, insertId=null, httpRequest=null, labels={levelName=FINEST, levelValue=300}, operation=null, payload=StringPayload{type=STRING, data=message}}], WriteOption{name=LOG_NAME, value=java.log}, WriteOption{name=RESOURCE, value=MonitoredResource{type=global, labels={project_id=project}}}): expected: 1, actual: 1\r\n\tat org.easymock.internal.MockInvocationHandler.invoke(MockInvocationHandler.java:44)\r\n\tat org.easymock.internal.ObjectMethodsFilter.invoke(ObjectMethodsFilter.java:94)\r\n\tat com.sun.proxy.$Proxy11.close(Unknown Source)\r\n\tat com.google.cloud.logging.LoggingHandler.close(LoggingHandler.java:375)\r\n\tat java.util.logging.LogManager.resetLogger(LogManager.java:1346)\r\n\tat java.util.logging.LogManager.reset(LogManager.java:1332)\r\n\tat java.util.logging.LogManager$Cleaner.run(LogManager.java:239)\r\n```\r\n\r\nhttps://travis-ci.org/GoogleCloudPlatform/google-cloud-java/jobs/191392244\r\nhttps://travis-ci.org/GoogleCloudPlatform/google-cloud-java/jobs/191530116\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1537",
        "number": 1537,
        "title": "Avoid FileReader",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Noticed you're using FileReader in `com.google.cloud.ServiceOptions` and possibly elsewhere. This is potentially buggy because it depends on the platform default encoding and thus behavior can change from one system to the next. Instead, try an InputStreamReader with a specified encoding chained to a FileInputStream. \r\n\r\n```\r\nprotected static String googleCloudProjectId() {\r\n    File configDir;\r\n    if (System.getenv().containsKey(\"CLOUDSDK_CONFIG\")) {\r\n      configDir = new File(System.getenv(\"CLOUDSDK_CONFIG\"));\r\n    } else if (isWindows() && System.getenv().containsKey(\"APPDATA\")) {\r\n      configDir = new File(System.getenv(\"APPDATA\"), \"gcloud\");\r\n    } else {\r\n      configDir = new File(System.getProperty(\"user.home\"), \".config/gcloud\");\r\n    }\r\n    String activeConfig = activeGoogleCloudConfig(configDir);\r\n    FileReader fileReader = null;\r\n    try {\r\n      fileReader = new FileReader(new File(configDir, \"configurations/config_\" + activeConfig));\r\n    } catch (FileNotFoundException newConfigFileNotFoundEx) {\r\n      try {\r\n        fileReader = new FileReader(new File(configDir, \"properties\"));\r\n      } catch (FileNotFoundException oldConfigFileNotFoundEx) {\r\n        // ignore\r\n      }\r\n}\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1536",
        "number": 1536,
        "title": "Libraries with only an SPI layer are missing documentation",
        "labels": [
            "api: clouderrorreporting",
            "api: core",
            "api: language",
            "api: monitoring",
            "api: speech",
            "api: vision",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "# Issue\r\nDocumentation is missing for the most critical APIs for Java Cloud Vision.\r\n\r\n## Repro\r\nSee [the Java documentation](http://googlecloudplatform.github.io/google-cloud-java/0.8.0/apidocs/index.html) and try to find the most important classes for the Cloud Vision API, most notably:\r\n\r\n* com.google.cloud.vision.v1.AnnotateImageRequest\r\n* com.google.cloud.vision.v1.AnnotateImageResponse\r\n* com.google.cloud.vision.v1.BatchAnnotateImagesResponse\r\n* com.google.cloud.vision.v1.ColorInfo\r\n* com.google.cloud.vision.v1.DominantColorsAnnotation\r\n* com.google.cloud.vision.v1.EntityAnnotation\r\n* com.google.cloud.vision.v1.FaceAnnotation\r\n* com.google.cloud.vision.v1.Feature\r\n* com.google.cloud.vision.v1.Feature.Type\r\n* com.google.cloud.vision.v1.Image\r\n\r\nNone of these features have documentation and are necessary to understand when using the Cloud Vision client library.\r\n\r\n## Fix\r\nPlease generate and publish the documentation for the com.google.cloud.vision.* APIs.\r\n\r\nIt may also be helpful to include a nice little snippet demonstrating usage:\r\n\r\n```\r\n  public static void detectFaces(String filePath, PrintStream out) throws IOException {\r\n    List<AnnotateImageRequest> requests = new ArrayList<>();\r\n\r\n    FileInputStream file = new FileInputStream(filePath);\r\n    ByteString imgBytes = ByteString.copyFrom(toByteArray(file));\r\n\r\n    Image img = Image.newBuilder().setContent(imgBytes).build();\r\n    Feature feat = Feature.newBuilder().setType(Type.FACE_DETECTION).build();\r\n    AnnotateImageRequest request = AnnotateImageRequest.newBuilder()\r\n        .addFeatures(feat)\r\n        .setImage(img)\r\n        .build();\r\n    requests.add(request);\r\n\r\n    BatchAnnotateImagesResponse response = visionApi.batchAnnotateImages(requests);\r\n    List<AnnotateImageResponse> responses = response.getResponsesList();\r\n\r\n    for (AnnotateImageResponse res : responses) {\r\n      if (res.hasError()) {\r\n        out.printf(\"Error: %s\\n\", res.getError().getMessage());\r\n      }\r\n\r\n      for (FaceAnnotation annotation : res.getFaceAnnotationsList()) {\r\n        out.printf(\"anger: %s\\njoy: %s\\nsurprise: %s\\n\",\r\n            annotation.getAngerLikelihood(),\r\n            annotation.getJoyLikelihood(),\r\n            annotation.getSurpriseLikelihood());\r\n      }\r\n    }\r\n  }\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1534",
        "number": 1534,
        "title": "Audio data is being streamed too fast... Cloud Speech API Sample",
        "labels": [
            "api: speech",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "Keep getting the following error for grpc/StreamingRecognizeClient sample (a bit modified to access web-camera mike), I tried different sample rate values, but all of my attempts failed Any suggestions?\r\n\r\nupdate. Error log:\r\n```\r\nERROR - recognize failed: {0}\r\nio.grpc.StatusRuntimeException: OUT_OF_RANGE: Audio data is being streamed too fast. Please stream audio data approximately at real time.\r\nat io.grpc.Status.asRuntimeException(Status.java:545)\r\nat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:481)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:398)\r\nat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:513)\r\nat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)\r\nat io.grpc.internal.SerializingExecutor$TaskRunner.run(SerializingExecutor.java:154)\r\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r\nat java.lang.Thread.run(Thread.java:745)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1532",
        "number": 1532,
        "title": "Deprecate AsyncLoggingHandler?",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "The fix for #1386 has made the normal LoggingHandler asynchronous!  Was this deliberate? If so, should the AsyncLoggingHandler be deprecated as it now no longer changes behaviour."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1531",
        "number": 1531,
        "title": "Convert to manually-triggered release process",
        "labels": [
            "type: process"
        ],
        "state": "closed",
        "body": "For the last several releases, the release process hasn't run properly in Travis, and I have had to run various components manually. It's really hard to figure out what happened and didn't happen during the release process because there is no messaging. So, I would like to change the release scripts (specifically https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/utilities/after_success.sh ) so that they are designed to be run from the command line by a team member instead of by Travis. I intend to make the process a one-shot command so that only two steps are required in the happy case: 1. start the script, 2. verify it succeeded.\r\n\r\nI am filing this as an issue to get any comments anyone has about this. \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1528",
        "number": 1528,
        "title": "Vision showing errors when reading from Cloud Storage",
        "labels": [
            "api: vision"
        ],
        "state": "closed",
        "body": "# Issue\r\nI'm seeing the error: \"image-annotator::User lacks permission.: Can not open file:\" when trying to use the Vision client library to access files in GCS. The bucket is public so I'm pretty sure the issue is not that I don't have access, `gsutil ls gs://filepath` also confirms the account associated with current default credentials has access.\r\n\r\n## Example of similar functionality without cloud storage (works)\r\nThe following example works:\r\n```\r\n  /**\r\n   * Gets {@link Feature} from the specified image.\r\n   * @throws IOException \r\n   */\r\n  static public void detectFaces(String filePath, PrintStream out) throws IOException {\r\n    List<AnnotateImageRequest> requests = new ArrayList<>();\r\n\r\n    FileInputStream file = new FileInputStream(filePath);\r\n    ByteString imgBytes = ByteString.copyFrom(toByteArray(file));\r\n    \r\n    Image img = Image.newBuilder().setContent(imgBytes).build();    \r\n    Feature feat = Feature.newBuilder().setType(Type.FACE_DETECTION).build();\r\n    AnnotateImageRequest request = AnnotateImageRequest.newBuilder()\r\n        .addFeatures(feat)\r\n        .setImage(img)\r\n        .build();\r\n    requests.add(request);\r\n\r\n    BatchAnnotateImagesResponse response = visionApi.batchAnnotateImages(requests);\r\n    List<AnnotateImageResponse> responses = response.getResponsesList();\r\n\r\n    for (AnnotateImageResponse res : responses) {      \r\n      if (res.hasError()) out.printf(\"Error: %s\\n\", res.getError().getMessage());\r\n\r\n      for (FaceAnnotation annotation : res.getFaceAnnotationsList()) {\r\n        out.printf(\"anger: %s\\njoy: %s\\nsurprise: %s\\n\",\r\n            annotation.getAngerLikelihood(),\r\n            annotation.getJoyLikelihood(),\r\n            annotation.getSurpriseLikelihood());\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\n## Example of issue\r\nThe following code does exactly the same thing as the previous example but instead forms the image resources from a GCS URI:\r\n```\r\n  /**\r\n   * Detects faces in the image specified at the provided cloud storage path.\r\n   * @throws IOException \r\n   */\r\n  static public void detectFacesCloudStorage(String cloudStoragePath, PrintStream out) throws IOException {\r\n    List<AnnotateImageRequest> requests = new ArrayList<>();\r\n\r\n    ImageAnnotatorSettings.Builder imageAnnotatorSettingsBuilder =\r\n        ImageAnnotatorSettings.defaultBuilder();\r\n    imageAnnotatorSettingsBuilder.batchAnnotateImagesSettings().getRetrySettingsBuilder()\r\n        .setTotalTimeout(Duration.standardSeconds(30));\r\n    ImageAnnotatorSettings settings = imageAnnotatorSettingsBuilder.build();\r\n    \r\n    ImageSource imgSource = ImageSource.newBuilder().setGcsImageUri(cloudStoragePath).build();\r\n    Image img = Image.newBuilder().setSource(imgSource).build();\r\n    img.writeTo(out);\r\n    Feature feat = Feature.newBuilder().setType(Type.FACE_DETECTION).build();\r\n    \r\n    AnnotateImageRequest request = AnnotateImageRequest.newBuilder()\r\n        .addFeatures(feat)\r\n        .setImage(img)\r\n        .build();\r\n    requests.add(request);\r\n\r\n    ImageAnnotatorClient client = ImageAnnotatorClient.create(settings);\r\n    BatchAnnotateImagesResponse response = client.batchAnnotateImages(requests);\r\n    List<AnnotateImageResponse> responses = response.getResponsesList();\r\n\r\n    for (AnnotateImageResponse res : responses) {\r\n      if (res.hasError()) out.printf(\"Error: %s\\n\", res.getError().getMessage());\r\n\r\n      for (FaceAnnotation annotation : res.getFaceAnnotationsList()) {\r\n        out.printf(\"anger: %s\\njoy: %s\\nsurprise: %s\\n\",\r\n            annotation.getAngerLikelihood(),\r\n            annotation.getJoyLikelihood(),\r\n            annotation.getSurpriseLikelihood());\r\n      }\r\n    }\r\n  }\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1527",
        "number": 1527,
        "title": "BigQuery 'JobConfiguration.Type' enum should be public",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/JobConfiguration.java#L39\r\n\r\n`JobConfiguration.Type` is package-private. Yet, there is a **public** method in its `Builder` that returns the type of the job configuration, which is kind of useless. Because the enum itself is package private, it's not accessible outside the package/API.\r\n\r\nThus, it makes it hard to:\r\n\r\n1. Check the type returned e.g. is a `QUERY`, `EXTRACT`..\r\n2. Write unit tests\r\n\r\nFor example, clients should be able to do this:\r\n\r\n`assertTrue(jobInfo.getConfiguration().getType() == JobConfiguration.Type.QUERY);`\r\n\r\n..and not have to do this:\r\n\r\n`assertTrue(jobInfo.getConfiguration() instanceof QueryJobConfiguration);`\r\n\r\nIs there a good reason why the enum is package-private, and not public?\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1525",
        "number": 1525,
        "title": "BigQuery: support labels field of Datasets and Table resources",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Docs (talks about datasets, but tables can have labels, too):\r\nhttps://cloud.google.com/bigquery/docs/labeling-datasets\r\n\r\nAPI references:\r\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#labels\r\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/tables#labels\r\n\r\nIf the `patch` request is not yet supported, this will be needed, too.\r\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/patch\r\nhttps://cloud.google.com/bigquery/docs/reference/rest/v2/tables/patch"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1522",
        "number": 1522,
        "title": "Netty incompatibility when using Pub/Sub with Dataproc",
        "labels": [
            "api: pubsub",
            "dependencies",
            "priority: p2",
            "status: blocked",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm trying to send messages from Spark Google Dataproc to Google PubSub. But I'm stuck with the following errors when trying to initialize the PubSub client:\r\n\r\n```\r\n17/01/10 15:12:28 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1, fca-cluster-dev-w-1.c.fcms-sandbox-gce.internal): java.lang.NoSuchMethodError: io.netty.util.AttributeKey.valueOf(Ljava/lang/Class;Ljava/lang/String;)Lio/netty/util/AttributeKey;\r\n    at io.grpc.netty.Utils.<clinit>(Utils.java:85)\r\n    at io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:311)\r\n    at io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:280)\r\n    at io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:230)\r\n    at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:239)\r\n    at com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:119)\r\n    at com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:106)\r\n    at com.google.api.gax.grpc.ProviderManager.getChannel(ProviderManager.java:106)\r\n    at com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:67)\r\n    at com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:78)\r\n    at com.google.cloud.pubsub.spi.v1.PublisherClient.<init>(PublisherClient.java:182)\r\n    at com.google.cloud.pubsub.spi.v1.PublisherClient.create(PublisherClient.java:173)\r\n    at com.google.cloud.pubsub.spi.DefaultPubSubRpc.<init>(DefaultPubSubRpc.java:168)\r\n    at com.google.cloud.pubsub.PubSubOptions$DefaultPubSubRpcFactory.create(PubSubOptions.java:69)\r\n    at com.google.cloud.pubsub.PubSubOptions$DefaultPubSubRpcFactory.create(PubSubOptions.java:63)\r\n    at com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:482)\r\n    at com.google.cloud.pubsub.PubSubImpl.<init>(PubSubImpl.java:115)\r\n    at com.google.cloud.pubsub.PubSubOptions$DefaultPubSubFactory.create(PubSubOptions.java:44)\r\n    at com.google.cloud.pubsub.PubSubOptions$DefaultPubSubFactory.create(PubSubOptions.java:39)\r\n    at com.google.cloud.ServiceOptions.getService(ServiceOptions.java:469)\r\n    at services.PubSubService$.<init>(PubSubService.scala:14)\r\n    at services.PubSubService$.<clinit>(PubSubService.scala)\r\n    at Main$$anonfun$createContext$5$$anonfun$apply$1.apply(Main.scala:93)\r\n    at Main$$anonfun$createContext$5$$anonfun$apply$1.apply(Main.scala:92)\r\n    at scala.collection.Iterator$class.foreach(Iterator.scala:893)\r\n    at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\r\n    at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:894)\r\n    at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$27.apply(RDD.scala:894)\r\n    at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899)\r\n    at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899)\r\n    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)\r\n    at org.apache.spark.scheduler.Task.run(Task.scala:86)\r\n    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n    at java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\nThe client initialization is as follow:\r\n\r\n```\r\n val pubsub: PubSub = PubSubOptions.getDefaultInstance().getService()\r\n```\r\n\r\nI look around and it's an issue between the netty version of Spark Google Dataproc netty-all-4.0.29.Final vs the one on google-cloud-pubsub (com.google.cloud) library in netty-all-4.1.3.Final. Did anyone manage to resolve this ?\r\n\r\nSame issue as #1331 but with Google Dataproc (Spark).\r\n\r\nRegards,"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1521",
        "number": 1521,
        "title": "NoSuchMethodError for com.google.cloud.bigquery.BigQueryOptions.getHttpTransportFactory",
        "labels": [
            "api: bigquery",
            "running on app engine"
        ],
        "state": "closed",
        "body": "   I am trying to upload to bigquery from my java app running on app-engine.\r\n\r\nthe dependecy in my pom:\r\n\r\n    <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-bigquery</artifactId>\r\n        <version>0.8.0-beta</version>\r\n    </dependency>\r\n\r\nHere is my initial code:\r\n\r\n    import com.google.cloud.bigquery.*;\r\n    \r\n    public class MyClass {\r\n    \tpublic static myFuction() throws Exception {\r\n    \t\tBigQuery bigquery = BigQueryOptions.getDefaultInstance().getService();\r\n        }\r\n\r\nwhen I run this locally I succed, but when running on app-engine \r\nI am receiving a `NoSuchMethodError`  error:\r\n\r\n    Exception in thread \"main\" java.lang.NoSuchMethodError: com.google.cloud.bigquery.BigQueryOptions.getHttpTransportFactory()Lcom/google/cloud/HttpServiceOptions$HttpTransportFactory;\r\n    \tat com.google.cloud.bigquery.spi.DefaultBigQueryRpc.<init>(DefaultBigQueryRpc.java:83)\r\n    \tat com.google.cloud.bigquery.BigQueryOptions$DefaultBigQueryRpcFactory.create(BigQueryOptions.java:49)\r\n    \tat com.google.cloud.bigquery.BigQueryOptions$DefaultBigQueryRpcFactory.create(BigQueryOptions.java:43)\r\n    \tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:482)\r\n    \tat com.google.cloud.bigquery.BigQueryImpl.<init>(BigQueryImpl.java:184)\r\n    \tat com.google.cloud.bigquery.BigQueryOptions$DefaultBigqueryFactory.create(BigQueryOptions.java:39)\r\n    \tat com.google.cloud.bigquery.BigQueryOptions$DefaultBigqueryFactory.create(BigQueryOptions.java:33)\r\n    \tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:469)\r\n    \tat com.google.cloud.ServiceOptions.service(ServiceOptions.java:463)\r\n\r\n\r\nI also tried using just \r\n```\r\n\t  <dependency>\r\n                  <groupId>com.google.cloud</groupId>\r\n                  <artifactId>google-cloud</artifactId>\r\n                  <version>0.8.0</version>\r\n        </dependency>  \r\n```\r\n\r\nbut it still didn't work\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1519",
        "number": 1519,
        "title": "[NIO] Files.walkFileTree doesn't visit files",
        "labels": [],
        "state": "closed",
        "body": "There are a couple of problems running this code for deleting a directory recursively: https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L63-L74\r\n\r\n1. The code for `visitFile` is never called.\r\n2. `Files.delete(dir)` fails with \"Can't perform I/O on pseudo-directories (trailing slash)\"\r\n\r\nIt would be good to add tests for Files.walkFileTree (and Files.walk) to the unit tests."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1518",
        "number": 1518,
        "title": "Consider using \"TimeUnit.<unit>.sleep(x)\" for code examples",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "In most code examples given (both in GitHub & official docs) where a `sleep` is needed, then `Thread.sleep(x)` is used. For example:\r\n\r\n- https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-bigquery\r\n- https://cloud.google.com/bigquery/querying-data\r\n\r\nFor better readability/clarity, then it may be prudent to consider using the `TimeUnit` class instead. Yes, it's all the same as it calls `Thread.sleep(x)` under the hood, but consider the following as an example:\r\n\r\n`Thread.sleep(180000)` vs. `TimeUnit.MINUTES.sleep(3)`\r\n\r\nMore info: http://stackoverflow.com/questions/9587673/thread-sleep-vs-timeunit-seconds-sleep"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1514",
        "number": 1514,
        "title": "Why there are two libraries: com.google.api.services.bigquery and com.google.cloud.bigquery?",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "I am running into this problem, and very confused. It seems there are two different libraries I can use. \r\n\r\nOne is com.google.cloud.bigquery where I see it from this source: https://cloud.google.com/bigquery/docs/reference/libraries#client-libraries-usage-java\r\n\r\nThe other one is com.google.api.services.bigquery where I see it from this source: https://github.com/googlearchive/bigquery-samples-java/blob/master/src/main/java/com/google/cloud/bigquery/samples/BigQueryJavaGettingStarted.java\r\n\r\nThe problem I am trying to solve is to set a destination table for the query. Most online QAs point me to use the second source. I followed the first source to set it up, and I am able to connect to the Bigquery now. The only problem is I cannot find a way to set the destination table. \r\n\r\nI am super confused about these two libraries, and hope to have some explanations. Thanks!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1513",
        "number": 1513,
        "title": "Question - How do you rename/move an object in a Storage Bucket?",
        "labels": [
            "api: storage",
            "triaged for GA",
            "type: question"
        ],
        "state": "closed",
        "body": "What the efficient way to do a rename or move?  Storage shows update(), delete()... but I didn't find what I was looking for."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1511",
        "number": 1511,
        "title": "setMaxResults doesn't seem to work for Cloud Storage API",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "I'm using:\r\n\r\n```xml\r\n<dependency>\r\n            <groupId>com.google.cloud</groupId>\r\n            <artifactId>gcloud-java</artifactId>\r\n            <version>0.2.8</version>\r\n</dependency>\r\n```\r\n\r\nwhich transitively depends on `com.google.apis:google-api-services-storage:v1-rev62-1.21.0` and I have the following code:\r\n\r\n```java\r\nStorage storage = ...\r\nstorage.objects().list(bucket).setMaxResults((long) Integer.MAX_VALUE).execute().getItems();\r\n```\r\n\r\nHowever the number of items are still 1000 (which is the default value) regardless of the value I pass to `setMaxResults`:\r\n\r\n```java\r\nSystem.out.println(storage.objects().list(bucket).setMaxResults((long) Integer.MAX_VALUE).execute().size());\r\n```\r\n\r\nThis yields 1000 as result.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1510",
        "number": 1510,
        "title": "PubSub not returning any instance.",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "I'm using Cloud PubSub and trying to get access to the PubSub locally using Service Account JSON credential, but it is not returning anything. Below is the code I'm using to get PubSub instance. Neither it is throwing any exception nor it is returning any PubSub instance. This is an issue which needs to be resolved urgently, anyone can help me.\r\n\r\n```\r\nprivate PubSub getPubSubForLocal() {\r\n\r\n        PubSub pubSub = null;\r\n        InputStream inputStream = getClass().getResourceAsStream(\"/cloud/vostics-cloud-e56ac878e27e.json\");\r\n        try {\r\n            pubSub = PubSubOptions.newBuilder()\r\n                    .setCredentials(ServiceAccountCredentials.fromStream(inputStream))\r\n                    .build()\r\n                    .getService();\r\n\r\n        } catch (IOException e) {\r\n            return null;\r\n        } catch (Exception e) {\r\n            System.out.println(e.getMessage());\r\n        }\r\n\r\n        return pubSub;\r\n    }\r\n\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1503",
        "number": 1503,
        "title": "Update the team page on the website",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "http://googlecloudplatform.github.io/google-cloud-java/0.8.0/team-list.html\r\n\r\nIs out dated.  We should probably just link to repo team."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1502",
        "number": 1502,
        "title": "Issues getting JSON credentials to work in JAR file",
        "labels": [
            "api: storage",
            "auth",
            "dependencies"
        ],
        "state": "closed",
        "body": "I am trying to download some files from Google Cloud Storage to HDFS in a Spark (2.0.2) driver and then process the files in Spark. Everything works fine executed locally but not if I compile it into fat jar and deploy on Spark in YARN client mode (driver works locally); in both cases pulling is from the same cloud storage bucket using the same JSON credentials file. When I use the credentials from InputStream:\r\n```java\r\nval inputStream = this.getClass.getResourceAsStream(\"/GCCredentials.json\")\r\nval credentials = GoogleCredentials.fromStream(inputStream)\r\n      .createScoped(Seq(StorageScopes.DEVSTORAGE_READ_ONLY).asJava)\r\nval storage = StorageOptions.newBuilder().setCredentials(credentials).build().getService\r\n```\r\nI gent the below error:\r\n```java\r\nException in thread \"main\" java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment.  Please set a project ID using the builder.\r\n        at com.google.common.base.Preconditions.checkArgument(Preconditions.java:92)\r\n        at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:283)\r\n        at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:179)\r\n        at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69)\r\n        at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:27)\r\n        at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:64)\r\n```\r\nI also tried with GOOGLE_APPLICATION_CREDENTIALS set and\r\n```java\r\nval credentials = GoogleCredentials.getApplicationDefault\r\n      .createScoped(Seq(StorageScopes.DEVSTORAGE_READ_ONLY).asJava)\r\nval storage = StorageOptions.newBuilder().setCredentials(credentials).build().getService\r\n```\r\nIn this case I get different error:\r\n```java\r\nException in thread \"main\" java.lang.NoSuchMethodError: org.json.JSONTokener.<init>(Ljava/io/InputStream;)V\r\n        at com.google.cloud.ServiceOptions.serviceAccountProjectId(ServiceOptions.java:452)\r\n        at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:346)\r\n        at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:281)\r\n        at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:179)\r\n        at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69)\r\n        at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:27)\r\n        at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:64)\r\n```\r\nJust to clarify, the credentials JSON file and org.json package are both in the JAR. Also, org.json has this method and seems to be in the right version inside JAR. \r\n\r\nThe build is done via SBT. I use sbt-assenbly plugin to build fat jar. GC Java library is in version 0.8.0:\r\n```java\r\n    \"com.google.cloud\" % \"google-cloud\" % \"0.8.0\",\r\n    // tried with and without it but nothing changed\r\n    \"com.google.cloud\" % \"google-cloud-nio\" % \"0.8.0\",\r\n```\r\nAlso source and target is set to Java 8:\r\n```java\r\njavacOptions ++= Seq(\"-source\", \"1.8\", \"-target\", \"1.8\", \"-Xlint\")\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1500",
        "number": 1500,
        "title": "Cloud Java APIs should work with a local Cloud SDK with GAE Standard.",
        "labels": [
            "api: storage",
            "running on app engine"
        ],
        "state": "closed",
        "body": "With the following code in my Java Servlet:\r\n\r\n       Storage storage = StorageOptions.getDefaultInstance().getService();\r\n       \r\n       \r\n        String bucketName = \"rdayalcloudtest\"; // Change this to something unique\r\n        Bucket bucket = storage.create(BucketInfo.of(bucketName));\r\n\r\n        // Upload a blob to the newly created bucket\r\n        BlobId blobId = BlobId.of(bucketName, \"my_blob_name\");\r\n        Blob blob = bucket.create(\r\n            \"my_blob_name \" + request.hashCode(), \"a simple blob\".getBytes(UTF_8), \"text/plain\");\r\n\r\nI receive the following exception when attempting to test the code locally, using DevAppServer2:\r\n\r\nProblem accessing /hello. Reason:\r\n\r\n    access denied (\"java.io.FilePermission\" \"/Users/ludo/.config/gcloud/active_config\" \"read\")\r\nCaused by:\r\n\r\njava.security.AccessControlException: access denied (\"java.io.FilePermission\" \"/Users/ludo/.config/gcloud/active_config\" \"read\")\r\n        at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)\r\n        at java.security.AccessController.checkPermission(AccessController.java:884)\r\n        at java.lang.SecurityManager.checkPermission(SecurityManager.java:549)\r\n        at com.google.appengine.tools.development.devappserver2.DevAppServer2Factory$CustomSecurityManager.checkPermission(DevAppServer2Factory.java:232)\r\n        at java.lang.SecurityManager.checkRead(SecurityManager.java:888)\r\n        at java.io.FileInputStream.<init>(FileInputStream.java:127)\r\n        at com.google.common.io.Files$FileByteSource.openStream(Files.java:125)\r\n        at com.google.common.io.Files$FileByteSource.openStream(Files.java:115)\r\n        at com.google.common.io.ByteSource$AsCharSource.openStream(ByteSource.java:420)\r\n        at com.google.common.io.CharSource.openBufferedStream(CharSource.java:91)\r\n        at com.google.common.io.CharSource.readFirstLine(CharSource.java:168)\r\n        at com.google.common.io.Files.readFirstLine(Files.java:513)\r\n        at com.google.cloud.ServiceOptions.activeGoogleCloudConfig(ServiceOptions.java:354)\r\n        at com.google.cloud.ServiceOptions.googleCloudProjectId(ServiceOptions.java:372)\r\n        at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:348)\r\n        at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:281)\r\n        at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:179)\r\n        at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69)\r\n        at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:27)\r\n        at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:64)\r\n        at com.google.cloud.storage.StorageOptions.getDefaultInstance(StorageOptions.java:99)\r\n        at com.example.HelloAppEngine.doGet(HelloAppEngine.java:40)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1499",
        "number": 1499,
        "title": "MaxMessageSize too low for Cloud Pub/Sub",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Cloud Pub/Sub allows responses of up to 20 MB, so the channel default of 4 MB causes deframing errors for users, as can be seen here https://code.google.com/p/cloud-pubsub/issues/detail?id=50 . MaxMessageSize should either be increased to at least 20 MB, or else users should be given the ability to change it themselves."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1498",
        "number": 1498,
        "title": "Failed to import com.google.cloud.bigquery after authentication",
        "labels": [],
        "state": "closed",
        "body": "Hi, I have configured the maven dependency, and been authenticated with the Cloud SDK, but when I am writing the quickstart code in Intellij, it shows me that the bigquery symbol cannot be resolved for some reason in the importing line as below. \r\n\r\nDid I miss something, or did anything improperly? Could anyone help me out? Thanks a lot!\r\n\r\n![screen shot 2017-01-02 at 6 19 57 am](https://cloud.githubusercontent.com/assets/22078411/21583249/75761506-d0b3-11e6-8f4f-b6b857fc961e.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1493",
        "number": 1493,
        "title": "Tracking issue for PubSub high-perf client integration",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "This issue tracks items we need to do to go from \"the code works\" to \"we're happy with it\"\r\n\r\n- [ ] Document explaining migration to HP client\r\n- [ ] Figure out the proper configuration for Publisher and Subscriber\r\n  - Can executors be shared with the rest of the program?\r\n  - Does each connection have its own channel?\r\n  - See https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1487 for context\r\n- Sample code\r\n  - [ ] Publisher\r\n  - [ ] Subscriber\r\n- Code snippets\r\n  - [ ] Publisher\r\n  - [ ] Subscriber"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1492",
        "number": 1492,
        "title": "don't use `UrlFetchTransport` in App Engine Flex environment",
        "labels": [
            "api: core",
            "api: datastore",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "The decision of whether to use `UrlFetchTransport` instead of `NetHttpTransport` is currently based on the presence of the `com.google.appengine.application.id` system property. This can result in `UrlFetchTranport` being used in the App Engine Flex environment (at least in compat mode).\r\n\r\nOne possible approach is:\r\n\r\n```\r\nif (System.getProperty(\"com.google.appengine.application.id\") != null\r\n    // Rule out App Engine Flex compat mode.\r\n    && System.getenv(\"GAE_VM\") == null\r\n    // Rule out App Engine Flex.\r\n    && System.getenv(\"GCLOUD_PROJECT\" ) == null) {\r\n  // use UrlFetchTransport\r\n}\r\n```\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/e5f90467fe7490759482e6a8bc62b1246318a7f0/google-cloud-core/src/main/java/com/google/cloud/HttpServiceOptions.java#L61\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/0d9d1b3ce548aa5335e23b8c2ec0464df8002d9f/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L318"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1491",
        "number": 1491,
        "title": "Typo in cloud storage readme",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "`BlobInfo blobInfo = BlobInfo.newBuiler(blobId).setContentType(\"text/plain\").build();` has a typo.  The method should be `newBuilder` instead of `newBuiler`."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1490",
        "number": 1490,
        "title": "Error when creating ErrorStatsServiceClient: Couldn't invoke ThreadManager.currentRequestThreadFactory",
        "labels": [
            "api: clouderrorreporting",
            "running on app engine",
            "type: bug"
        ],
        "state": "closed",
        "body": "I successfully ran the App Engine Java Hello World.\r\nNow I import `com.google.devtools.clouderrorreporting.v1beta1.*` and `com.google.cloud.errorreporting.spi.v1beta1.*` and want to retrieve ErrorStats.\r\n\r\nAfter invoking `ErrorStatsServiceClient.create();`, I get the following error when running `mvn appengine:devserver`:\r\n\r\n`Couldn't invoke ThreadManager.currentRequestThreadFactory`\r\n\r\nFind my code:\r\n```java\r\n\r\npackage com.example.appengine.helloworld;\r\n\r\nimport java.io.IOException;\r\nimport java.io.PrintWriter;\r\n\r\nimport javax.servlet.http.HttpServlet;\r\nimport javax.servlet.http.HttpServletRequest;\r\nimport javax.servlet.http.HttpServletResponse;\r\n\r\nimport com.google.devtools.clouderrorreporting.v1beta1.*;\r\nimport com.google.cloud.errorreporting.spi.v1beta1.*;\r\n\r\n@SuppressWarnings(\"serial\")\r\npublic class HelloServlet extends HttpServlet {\r\n  @Override\r\n  public void doGet(HttpServletRequest req, HttpServletResponse resp) throws IOException {\r\n    ErrorStatsServiceClient errorStatsServiceClient = ErrorStatsServiceClient.create();\r\n    PrintWriter out = resp.getWriter();\r\n    out.println(\"Hello, world\");\r\n  }\r\n}\r\n```\r\n\r\nAnd the complete stack trace:\r\n\r\n```\r\nProblem accessing /. Reason:\r\n\r\n    Couldn't invoke ThreadManager.currentRequestThreadFactory\r\nCaused by:\r\n\r\njava.lang.RuntimeException: Couldn't invoke ThreadManager.currentRequestThreadFactory\r\n\tat com.google.common.util.concurrent.MoreExecutors.platformThreadFactory(MoreExecutors.java:787)\r\n\tat com.google.common.util.concurrent.MoreExecutors.newThread(MoreExecutors.java:828)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.addDelayedShutdownHook(MoreExecutors.java:204)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.getExitingScheduledExecutorService(MoreExecutors.java:196)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.getExitingScheduledExecutorService(MoreExecutors.java:228)\r\n\tat com.google.common.util.concurrent.MoreExecutors.getExitingScheduledExecutorService(MoreExecutors.java:176)\r\n\tat com.google.api.gax.grpc.InstantiatingExecutorProvider.getExecutor(InstantiatingExecutorProvider.java:50)\r\n\tat com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:62)\r\n\tat com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:78)\r\n\tat com.google.cloud.errorreporting.spi.v1beta1.ErrorStatsServiceClient.<init>(ErrorStatsServiceClient.java:146)\r\n\tat com.google.cloud.errorreporting.spi.v1beta1.ErrorStatsServiceClient.create(ErrorStatsServiceClient.java:136)\r\n\tat com.google.cloud.errorreporting.spi.v1beta1.ErrorStatsServiceClient.create(ErrorStatsServiceClient.java:127)\r\n\tat com.example.appengine.helloworld.HelloServlet.doGet(HelloServlet.java:36)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:617)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\r\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)\r\n\tat com.google.appengine.api.socket.dev.DevSocketFilter.doFilter(DevSocketFilter.java:74)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.ResponseRewriterFilter.doFilter(ResponseRewriterFilter.java:128)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.HeaderVerificationFilter.doFilter(HeaderVerificationFilter.java:34)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:63)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.StaticFileFilter.doFilter(StaticFileFilter.java:122)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectRequest(DevAppServerModulesFilter.java:366)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectModuleRequest(DevAppServerModulesFilter.java:349)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doFilter(DevAppServerModulesFilter.java:116)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)\r\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\r\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\r\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)\r\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)\r\n\tat com.google.appengine.tools.development.DevAppEngineWebAppContext.handle(DevAppEngineWebAppContext.java:95)\r\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\r\n\tat com.google.appengine.tools.development.JettyContainerService$ApiProxyHandler.handle(JettyContainerService.java:508)\r\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\r\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\r\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\r\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)\r\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)\r\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\r\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\r\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\r\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\r\nCaused by: java.lang.ClassNotFoundException: com.google.appengine.api.ThreadManager\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:366)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:355)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:354)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:425)\r\n\tat com.google.appengine.tools.development.IsolatedAppClassLoader.loadClass(IsolatedAppClassLoader.java:195)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:358)\r\n\tat java.lang.Class.forName0(Native Method)\r\n\tat java.lang.Class.forName(Class.java:195)\r\n\tat com.google.common.util.concurrent.MoreExecutors.platformThreadFactory(MoreExecutors.java:781)\r\n\t... 49 more\r\nCaused by:\r\n\r\njava.lang.ClassNotFoundException: com.google.appengine.api.ThreadManager\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:366)\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:355)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:354)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:425)\r\n\tat com.google.appengine.tools.development.IsolatedAppClassLoader.loadClass(IsolatedAppClassLoader.java:195)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:358)\r\n\tat java.lang.Class.forName0(Native Method)\r\n\tat java.lang.Class.forName(Class.java:195)\r\n\tat com.google.common.util.concurrent.MoreExecutors.platformThreadFactory(MoreExecutors.java:781)\r\n\tat com.google.common.util.concurrent.MoreExecutors.newThread(MoreExecutors.java:828)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.addDelayedShutdownHook(MoreExecutors.java:204)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.getExitingScheduledExecutorService(MoreExecutors.java:196)\r\n\tat com.google.common.util.concurrent.MoreExecutors$Application.getExitingScheduledExecutorService(MoreExecutors.java:228)\r\n\tat com.google.common.util.concurrent.MoreExecutors.getExitingScheduledExecutorService(MoreExecutors.java:176)\r\n\tat com.google.api.gax.grpc.InstantiatingExecutorProvider.getExecutor(InstantiatingExecutorProvider.java:50)\r\n\tat com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:62)\r\n\tat com.google.api.gax.grpc.ClientSettings.getChannelAndExecutor(ClientSettings.java:78)\r\n\tat com.google.cloud.errorreporting.spi.v1beta1.ErrorStatsServiceClient.<init>(ErrorStatsServiceClient.java:146)\r\n\tat com.google.cloud.errorreporting.spi.v1beta1.ErrorStatsServiceClient.create(ErrorStatsServiceClient.java:136)\r\n\tat com.google.cloud.errorreporting.spi.v1beta1.ErrorStatsServiceClient.create(ErrorStatsServiceClient.java:127)\r\n\tat com.example.appengine.helloworld.HelloServlet.doGet(HelloServlet.java:36)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:617)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\r\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)\r\n\tat com.google.appengine.api.socket.dev.DevSocketFilter.doFilter(DevSocketFilter.java:74)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.ResponseRewriterFilter.doFilter(ResponseRewriterFilter.java:128)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.HeaderVerificationFilter.doFilter(HeaderVerificationFilter.java:34)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.api.blobstore.dev.ServeBlobFilter.doFilter(ServeBlobFilter.java:63)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:48)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.StaticFileFilter.doFilter(StaticFileFilter.java:122)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectRequest(DevAppServerModulesFilter.java:366)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doDirectModuleRequest(DevAppServerModulesFilter.java:349)\r\n\tat com.google.appengine.tools.development.DevAppServerModulesFilter.doFilter(DevAppServerModulesFilter.java:116)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)\r\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\r\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\r\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)\r\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)\r\n\tat com.google.appengine.tools.development.DevAppEngineWebAppContext.handle(DevAppEngineWebAppContext.java:95)\r\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\r\n\tat com.google.appengine.tools.development.JettyContainerService$ApiProxyHandler.handle(JettyContainerService.java:508)\r\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\r\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\r\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\r\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)\r\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:547)\r\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\r\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\r\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)\r\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1486",
        "number": 1486,
        "title": "BigQuery: Add support for struct query parameters",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`QueryParameterValue` does not currently support STRUCT parameters.\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/0f6a47e19cc51a8baa9e13d9f1bb8d23c105e00a/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/QueryParameterValue.java#L58\r\n\r\nSee the API docs: https://cloud.google.com/bigquery/querying-data#using_structs_in_parameterized_queries for how these work in the API and an example query."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1485",
        "number": 1485,
        "title": "Binding a FullEntity to a GqlQuery fails",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "The GqlQuery.Builder allows positional and named bindings for FullEntity values. However, when I try to use those methods, the query execution fails with the below exception. Is this supposed to work? Same error occurs when using StructuredQuery.PropertyFilter. Am I misunderstanding the purpose of these methods? \r\n\r\n```\r\nException in thread \"main\" com.google.cloud.datastore.DatastoreException: An entity value is not allowed\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:110)\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:96)\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.runQuery(DefaultDatastoreRpc.java:164)\r\n\tat com.google.cloud.datastore.DatastoreImpl$1.call(DatastoreImpl.java:93)\r\n\tat com.google.cloud.datastore.DatastoreImpl$1.call(DatastoreImpl.java:89)\r\n\tat com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\r\n\tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\r\n\tat com.google.cloud.datastore.DatastoreImpl.runQuery(DatastoreImpl.java:88)\r\n\tat com.google.cloud.datastore.QueryResultsImpl.sendRequest(QueryResultsImpl.java:73)\r\n\tat com.google.cloud.datastore.QueryResultsImpl.<init>(QueryResultsImpl.java:57)\r\n\tat com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:82)\r\n\tat com.google.cloud.datastore.DatastoreImpl.run(DatastoreImpl.java:73)\r\nCaused by: com.google.datastore.v1.client.DatastoreException: An entity value is not allowed, code=INVALID_ARGUMENT\r\n\tat com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:126)\r\n\tat com.google.datastore.v1.client.RemoteRpc.makeException(RemoteRpc.java:169)\r\n\tat com.google.datastore.v1.client.RemoteRpc.call(RemoteRpc.java:89)\r\n\tat com.google.datastore.v1.client.Datastore.runQuery(Datastore.java:108)\r\n\tat com.google.cloud.datastore.spi.DefaultDatastoreRpc.runQuery(DefaultDatastoreRpc.java:162)\r\n```\r\n\r\n### Sample Code \r\n\r\n```\r\nDatastore datastore = DatastoreOptions.getDefaultInstance().getService();\r\nFullEntity<IncompleteKey> cellNumber = FullEntity.newBuilder().set(\"countryCode\", \"1\").set(\"areaCode\", \"111\").set(\"subscriberNumber\", \"2223333\").build();\r\nGqlQuery query = Query.newGqlQueryBuilder(Query.ResultType.ENTITY, \"SELECT * FROM Contact WHERE cellNumber=@1\").addBinding(cellNumber).build();\r\nSystem.out.println(query);\r\nQueryResults<Entity> results = datastore.run(query);\r\nwhile (results.hasNext()) {\r\n\tSystem.out.println(results.next());\r\n}\r\n\r\n```\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1484",
        "number": 1484,
        "title": "firebase storage upload from google cloud storage java api",
        "labels": [],
        "state": "closed",
        "body": "Hi;\r\n\r\nI have a firebase account and I want to upload some photos programmatically to firebase storage. To do this, I am using the google cloud java storage API. I configure the permission and others. I can successfully create buckets, blobs. However, when I tried to upload a picture, either its size is 0 or it cannot downloadable (URL is not generated). The code that  I use is below;\r\n\r\n\r\n\r\n```\r\n\t\tStorage storage = StorageOptions.newBuilder().setProjectId(\"firebaseId\")\r\n\t\t\t\t\t.setCredentials(ServiceAccountCredentials.fromStream(new FileInputStream(\"jsonFileFor Authentication\")))\r\n\t\t\t\t\t.build()\r\n\t\t\t\t\t.getService();\r\n\t\t\tString blobName = \"a.jpg\";\r\n\t\t\tBlobId blobId = BlobId.of(bucket.getName(), blobName);\r\n\t\t\tInputStream inputStream = new FileInputStream(new File(\"a.jpg\"));\r\n\t\t\t//BlobInfo blobInfo = BlobInfo.builder(blobId).contentType(\"image/jpeg\").build();\r\n\t\t\tBlobInfo blobInfo = BlobInfo.builder(bucket.getName(), \"a.jpg\").contentType(\"image/jpeg\").build();\r\n```\r\n\r\n\t\t\ttry (WriteChannel writer = storage.writer(blobInfo)) {\r\n\t\t\t\tbyte[] buffer = new byte[1024];\r\n\t\t\t\tint limit;\r\n\t\t\t\ttry {\r\n\t\t\t\t\twhile ((limit = inputStream.read(buffer)) >= 0) {\r\n\t\t\t\t\t\twriter.write(ByteBuffer.wrap(buffer, 0, limit));\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t} catch (Exception ex) {\r\n\t\t\t\t\t// handle exception\r\n\t\t\t\t}finally {\r\n\t\t\t\t\twriter.close();\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\r\n\r\nAny advice is appreciated. Thanks for the help."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1478",
        "number": 1478,
        "title": "GAPIC-only client libs missing from ReadMe list",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "SCENARIO\r\nNavigate to the [ReadMe](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/README.md) for google-cloud-java.\r\n\r\nEXPECTED\r\nWe should see a list of all the Beta and Alpha client libraries.\r\n\r\nACTUAL\r\nWe are not seeing the GAPIC-only client libs in that list (e.g. Vision, Speech, Language, Monitoring). We should add them to the Alpha list (for now):\r\n\r\n![image](https://cloud.githubusercontent.com/assets/6609430/21211173/28eaf962-c236-11e6-9cbc-6ccf06e875fb.png)\r\n\r\nNOTE\r\nWe need to chat about how to show an example too for the GAPIC libs. And perhaps also update the individual readmes.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1476",
        "number": 1476,
        "title": "Branding updates required for Translate API veneer libraries",
        "labels": [
            "api: translation"
        ],
        "state": "closed",
        "body": "On November 15, 2016, Google launch a rebranding of Google Translate API to Google Cloud Translation API. This does not impact the method names but the URLbase as well as readmes, samples and comments.\r\nURLbase has been already updated to translation.googleapis.com\r\n\r\nWe need to have now for Client library, the readme, client library docs, samples and code comments updated to use \"Google Cloud Translation API\" instead of Google Translate API. The short version of the new name is \"Cloud Translation API\" or \"Translation API:\"\r\n\r\nNote: the product Google Translate still exists. It is the API Google Translate API that has been rebranded."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1472",
        "number": 1472,
        "title": "FR: Datastore should use gRPC and be Async",
        "labels": [],
        "state": "closed",
        "body": "Perhaps we can incorporate parts of [Spotify's library](https://github.com/spotify/async-datastore-client)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1471",
        "number": 1471,
        "title": "FR: version numbers",
        "labels": [],
        "state": "closed",
        "body": "Currently our versions are a bit weird.\r\n\r\n`0.8.0` designates an alpha version\r\n`0.8.0-beta` designates a beta, and presumably\r\n`1.0.0` will be our first GA\r\n\r\nThat's well and good for now though a bit confusing.  I'd like to suggest that code that from now on, code that is not beta, be designated `-alpha` and not `0.8.0`.\r\n\r\nThe real problem is when we go GA however.  We will have a `-SNAPSHOT` which is top of tree Master; we will likely have a Pre-Release (or early release), a Current, and a last release.\r\n\r\nUnfortunately, maven doesn't really understand `-alpha` or `-beta` designations in a clear way.  It considers them to be a \"[qualifier](http://books.sonatype.com/mvnref-book/reference/pom-relationships-sect-pom-syntax.html)\" and sorts them alphabetically.  So while it might allow updating from -alpha to -beta, it is unlikely to update to a GA version. \r\n\r\nFor those of us who use automation (like the [versions plugin](http://www.mojohaus.org/versions-maven-plugin/)) this is a bit of a problem.\r\n\r\nThe auth library chose to go with all release update the major version (first # before the dot).  \r\n\r\nI wish I had a clear suggestion to go with your desire to be clear that this is a `beta` release.  I don't.  But I wish you had gone with a the java standard rather that following the path of some of our other teams and making something up that isn't idiomatic.\r\n\r\n@omaray @garrettjonesgoogle @tswast "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1466",
        "number": 1466,
        "title": "Missing READMEs",
        "labels": [
            "api: core",
            "api: language",
            "api: speech",
            "api: vision"
        ],
        "state": "closed",
        "body": "Some APIs don't have READMEs:\r\n- [x] Language\r\n- [x] Speech\r\n- [x] Vision"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1462",
        "number": 1462,
        "title": "Can't instantiate PubSub because of this error ClassNotFoundException: io.netty.handler.codec.Headers",
        "labels": [
            "api: logging",
            "api: pubsub",
            "priority: p2",
            "running on app engine",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "I've added following dependency\r\n\r\n\t\t<dependency>\r\n    \t\t<groupId>com.google.cloud</groupId>\r\n    \t\t<artifactId>google-cloud-pubsub</artifactId>\r\n    \t\t<version>0.6.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n  \t\t\t<groupId>com.google.auth</groupId>\r\n  \t\t\t<artifactId>google-auth-library-oauth2-http</artifactId>\r\n  \t\t\t<version>0.6.0</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n    \t\t<groupId>com.google.appengine</groupId>\r\n    \t\t<artifactId>appengine-api-1.0-sdk</artifactId>\r\n    \t\t<version>1.9.48</version>\r\n\t\t</dependency>\r\n\t\t<dependency>\r\n\t\t\t<groupId>com.google.cloud</groupId>\r\n\t\t\t<artifactId>google-cloud-nio</artifactId>\r\n\t\t\t<version>0.6.0</version>\r\n\t    </dependency>\r\n\r\nBelow is the code snippet\r\n\r\n    PubSub buildPubSub(String appName){\r\n        PubSubOptions.Builder optionsBuilder = PubSubOptions.newBuilder();\r\n        return optionsBuilder.setProjectId(appName).build().getService();\r\n    }\r\n\r\n\r\nI keep on getting below error\r\n\r\nCaused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.google.cloud.pubsub.PubSub]: Factory method 'pubSub' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/handler/codec/Headers\r\n\tat org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189) ~[spring-beans-4.2.4.RELEASE.jar:4.2.4.RELEASE]\r\n\tat org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588) ~[spring-beans-4.2.4.RELEASE.jar:4.2.4.RELEASE]\r\n\t... 104 common frames omitted\r\nCaused by: java.lang.NoClassDefFoundError: io/netty/handler/codec/Headers\r\n\tat java.lang.ClassLoader.defineClass1(Native Method) ~[na:1.8.0_45]\r\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:760) ~[na:1.8.0_45]\r\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) ~[na:1.8.0_45]\r\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:467) ~[na:1.8.0_45]\r\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:73) ~[na:1.8.0_45]\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:368) ~[na:1.8.0_45]\r\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:362) ~[na:1.8.0_45]\r\n\tat java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_45]\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:361) ~[na:1.8.0_45]\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_45]\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_45]\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_45]\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:311) ~[grpc-netty-1.0.1.jar:1.0.1]\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:280) ~[grpc-netty-1.0.1.jar:1.0.1]\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:230) ~[grpc-netty-1.0.1.jar:1.0.1]\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:239) ~[grpc-core-1.0.1.jar:1.0.1]\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.createChannel(InstantiatingChannelProvider.java:120) ~[gax-0.0.22.jar:na]\r\n\tat com.google.api.gax.grpc.InstantiatingChannelProvider.getChannel(InstantiatingChannelProvider.java:107) ~[gax-0.0.22.jar:na]\r\n\tat com.google.api.gax.grpc.ProviderManager.getChannel(ProviderManager.java:107) ~[gax-0.0.22.jar:na]\r\n\tat com.google.api.gax.grpc.ChannelAndExecutor.create(ChannelAndExecutor.java:68) ~[gax-0.0.22.jar:na]\r\n\tat com.google.api.gax.grpc.ServiceApiSettings.getChannelAndExecutor(ServiceApiSettings.java:82) ~[gax-0.0.22.jar:na]\r\n\tat com.google.cloud.pubsub.spi.v1.PublisherApi.<init>(PublisherApi.java:203) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.spi.v1.PublisherApi.create(PublisherApi.java:194) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.spi.DefaultPubSubRpc.<init>(DefaultPubSubRpc.java:168) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.PubSubOptions$DefaultPubSubRpcFactory.create(PubSubOptions.java:69) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.PubSubOptions$DefaultPubSubRpcFactory.create(PubSubOptions.java:63) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:478) ~[google-cloud-core-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.PubSubImpl.<init>(PubSubImpl.java:115) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.PubSubOptions$DefaultPubSubFactory.create(PubSubOptions.java:44) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.pubsub.PubSubOptions$DefaultPubSubFactory.create(PubSubOptions.java:39) ~[google-cloud-pubsub-0.6.0.jar:0.6.0]\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:465) ~[google-cloud-core-0.6.0.jar:0.6.0]\r\n\tat com.homedepot.checkout.pubsub.PubSubAdapter.buildPubSub(PubSubAdapter.java:83) ~[classes/:na]\r\n\tat com.homedepot.checkout.pubsub.PubSubConfiguration.pubSub(PubSubConfiguration.java:69) ~[classes/:na]\r\n\tat com.homedepot.checkout.pubsub.PubSubConfiguration$$EnhancerBySpringCGLIB$$2a49f60b.CGLIB$pubSub$1(<generated>) ~[classes/:na]\r\n\tat com.homedepot.checkout.pubsub.PubSubConfiguration$$EnhancerBySpringCGLIB$$2a49f60b$$FastClassBySpringCGLIB$$b610cce5.invoke(<generated>) ~[classes/:na]\r\n\tat org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) ~[spring-core-4.2.4.RELEASE.jar:4.2.4.RELEASE]\r\n\tat org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:355) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]\r\n\tat com.homedepot.checkout.pubsub.PubSubConfiguration$$EnhancerBySpringCGLIB$$2a49f60b.pubSub(<generated>) ~[classes/:na]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_45]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_45]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_45]\r\n\tat java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_45]\r\n\tat org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162) ~[spring-beans-4.2.4.RELEASE.jar:4.2.4.RELEASE]\r\n\t... 105 common frames omitted\r\nCaused by: java.lang.ClassNotFoundException: io.netty.handler.codec.Headers\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_45]\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_45]\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_45]\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_45]\r\n\t... 148 common frames omitted\r\n\r\nAny help would be appreciated.\r\n\r\nThanks\r\nMV"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1458",
        "number": 1458,
        "title": "How launch many instances at once? ",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The snippet at [this link](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-examples/src/main/java/com/google/cloud/examples/compute/snippets/CreateInstance.java) shows how launch a compute instance, however I was unable to find in the API a way to specify the number of instances to run. \r\n\r\nIs that possible or it is needed to invoke the `create` operation as many times as the number of instances to launch ?\r\n\r\n  "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1450",
        "number": 1450,
        "title": "[NIO] Make CloudStorageFileSystem#newFileSystem more lenient in the URIs it accepts",
        "labels": [],
        "state": "closed",
        "body": "Currently the URIs must be of the form `gs://bucket`, and URIs with port, user info, path, query or fragment parts will fail.\r\n\r\nThis seems to be unnecessarily restrictive, and causes legitimate uses to fail - e.g. if we are [trying to find a FileSystem for a given URI](https://github.com/broadinstitute/gatk/blob/5e17764f74fdf110d4ea09cc0b5508fbad9a1305/src/main/java/org/broadinstitute/hellbender/utils/io/IOUtils.java) then we shouldn't have to know that GS is more restrictive than other providers, and remove everything from the URI except the scheme and host.\r\n\r\nI suggest that the implementation accept the extra information in URIs and just ignore it."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1449",
        "number": 1449,
        "title": "Large memory usage by gcloud-logging API.",
        "labels": [
            "api: logging",
            "performance"
        ],
        "state": "closed",
        "body": "The logging API has a large memory foot print, with approximately 4KB of memory consumed for each log generated.\r\n\r\nThis was measured with the following program:\r\n\r\n```java\r\npackage com.google.cloud.runtimes.jetty9;\r\n\r\nimport java.util.concurrent.TimeUnit;\r\nimport java.util.logging.Logger;\r\n\r\npublic class StackDriverLogging {\r\n\r\n  static void init() throws Exception {\r\n    Logger log = Logger.getLogger(StackDriverLogging.class.getName());\r\n    log.info(\"test info\");\r\n    log.fine(\"test fine\");\r\n\r\n    long last = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();\r\n\r\n    // Run 50 times to ensure everything is hot and any queues are max allocated\r\n    for (int r=50;r-->0;) {\r\n      long total = Runtime.getRuntime().totalMemory();\r\n      long free = Runtime.getRuntime().freeMemory();\r\n      long used = total - free;\r\n      long delta = used - last;\r\n      last = used;\r\n      System.err.printf(\"total(%d)-free(%d)=used(%d) delta=%d%n\", total, free, used, delta);\r\n\r\n      for (int i = 1000; i-- > 0;)\r\n        log.info(\"test info\");\r\n      \r\n      if (r==10) {\r\n        System.err.println(\"DRAINING...\");\r\n        // Wait a minute so all queued logs can drain out\r\n        TimeUnit.MINUTES.sleep(1);\r\n        System.gc();\r\n        System.err.println(\"LAST 10...\");\r\n      }\r\n      \r\n      Thread.sleep(10);\r\n    }\r\n\r\n    System.err.println(\"DUMP!\");\r\n    Thread.sleep(1000000);\r\n    \r\n  }\r\n\r\n  public static void main(String... args) throws Exception {\r\n    init();\r\n  }\r\n}\r\n```\r\n\r\nEclipse MAT was used to analyse a head dump taken immediately after 10K log entries were generated, then again once the program had returned to idle and network monitor indicated that all data had been flushed.\r\n\r\nAfter 10L log messages, the heap was 51MB, which reduced to 13.4MB once the logs had been flushed (but no forced GC, so the difference may be larger).  Thus at least 38MB appears to be consumed by logging 10K messages, which is 3.9KB per message.   The attached reports( [10K Top Consumers.pdf](https://github.com/GoogleCloudPlatform/google-cloud-java/files/632824/10K.Top.Consumers.pdf) & [Idle Top Consumers.pdf](https://github.com/GoogleCloudPlatform/google-cloud-java/files/632825/Idle.Top.Consumers.pdf) ) indicate that 22.9 MB is used by `io.grpc.netty.NettyClientTransport$2` and 12.1MB alone is consumed by `io.netty.handler.codec.http2.StreamBufferingEncoder`.\r\n\r\nIdeally, the memory usage per log line could be greatly reduced.  Eitherway, it would also be highly desirable to be able to put some limits on the memory consumed by the logging subsystem so that excessively verbose logs are either discarded, summarized, blocked or excepted.\r\n\r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1448",
        "number": 1448,
        "title": "Update ReadMe to reflect quality levels of client libraries",
        "labels": [],
        "state": "closed",
        "body": "We will soon have client libraries at different quality levels. Let's make sure we reflect this information in our top-level ReadMe file the moment we cut the new release.\r\n\r\nThe update for [PHP's ReadMe](https://github.com/omaray/google-cloud-php/blob/readme-update-beta/README.md) has already be done (as a [Pull Request](https://github.com/GoogleCloudPlatform/google-cloud-php/pull/274) for now) and can be used as the canonical example to follow. The list below highlights the main changes to follow for this repo.\r\n\r\n## General\r\n- [ ] Remove the text \"This client supports the following Google Cloud Platform services:\"\r\n\r\n## Listing Beta client libraries\r\n\r\n- [ ] Create a section to show the Beta client libraries (see image right below for text & layout)\r\n\r\n- [ ] Make the term `Beta` link to the **Versioning** section of the ReadMe (see image right below)\r\n\r\n- [ ] Add the term `(Beta)` next to each API name (see image right below for text and visual):\r\n\r\n![image](https://cloud.githubusercontent.com/assets/6609430/20909391/4b49169c-bb10-11e6-8409-7903c317937f.png)\r\n\r\n## Listing Alpha client libraries\r\n- [ ] Create a section to show the Alpha client libraries (see image right below for text and layout)\r\n\r\n- [ ] Make the term `Alpha` link to the **Versioning** section of the ReadMe (see image right below)\r\n\r\n- [ ] Add the term `(Alpha)` next to each API name (see image right below for text and visual):\r\n\r\n![image](https://cloud.githubusercontent.com/assets/6609430/20909394/550feef8-bb10-11e6-8390-f6756bc2301b.png)\r\n\r\n## Client Library per API section\r\n\r\n- [ ] If there is a section in the ReadMe for each API, add the term (Beta) or (Alpha) appropriately (see image right below for visual):\r\n\r\n![image](https://cloud.githubusercontent.com/assets/6609430/20909380/3fbb7f4a-bb10-11e6-9841-3acba85e1b41.png)\r\n\r\n## Versioning section\r\n\r\n- [ ] If the **Versioning** section doesn't exist, add one.\r\n\r\n- [ ] Add the following content in the **Versioning** section:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/6609430/20909795/9c6eb1a6-bb12-11e6-93c4-4d4780368196.png)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1447",
        "number": 1447,
        "title": "Error reporting library",
        "labels": [
            "api: clouderrorreporting"
        ],
        "state": "closed",
        "body": "Error Reporting client library seems to be missing implementation (auto gen code?). It would be very useful to have that done along with some instrumentation (handling SIGTERM for example).\r\n\r\nI could not find another tracking bug for that."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1445",
        "number": 1445,
        "title": "Fully document supported retry mechanisms",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "There does not seem to be any documentation for what retry mechanisms are implemented by the clients (except for \"Supporting new services\" docs -- which are not relevant to most users).  Would be wonderful if this were highlighted, explicitly.  These cases are important in particular for users to decide whether to implement their own error handling:\r\n1.  Re-tryable errors.\r\n2. Non-retryable errors.\r\n3. Prolonged non-retry-able errors (hours)."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1441",
        "number": 1441,
        "title": "BigQuery: Add support to FormatOptions for AVRO",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "`configuration.load.sourceFormat` accepts  `CSV`, `DATASTORE_BACKUP`, `NEWLINE_DELIMITED_JSON`, and `AVRO`. See the [API reference docs](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs).\r\n\r\n[FormatOptions](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/FormatOptions.java) is missing an option for Avro."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1440",
        "number": 1440,
        "title": "Google Storage parallel upload",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Does the Google Storage Java SDK provides an API for parallel multi-parts upload? Is there any example out there?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1439",
        "number": 1439,
        "title": "Logging should support loggers besides JUL",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "http://blog.takipi.com/is-standard-java-logging-dead-log4j-vs-log4j2-vs-logback-vs-java-util-logging/\r\n\r\nMost GH projects use logback (aka SLF4J), we should work with that easily."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1435",
        "number": 1435,
        "title": "Republish javadocs to show latest (0.7.0)",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "SCENARIO\r\n- Navigate to https://github.com/GoogleCloudPlatform/google-cloud-java\r\n- Click on the doc link at the top: http://googlecloudplatform.github.io/google-cloud-java\r\n\r\nEXPECTED RESULTS\r\n- You should navigate to the 0.7.0 docs at http://googlecloudplatform.github.io/google-cloud-java/0.7.0/index.html\r\n\r\nACTUAL RESULTS\r\n- You navigate to the 0.6.0 docs at: http://googlecloudplatform.github.io/google-cloud-java/0.6.0/index.html\r\n\r\n(And clicking on \"Read The Docs\" button takes you to the javadoc of the 0.6.0 as well and it should be 0.7.0)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1434",
        "number": 1434,
        "title": "default client version is null",
        "labels": [],
        "state": "closed",
        "body": "The default client version is set to null so the agent header looks like this:\r\nx-google-apis-agent: gcloud-java/;gapic/0.1.0;gax/0.1.0;java/1.8.0_102-google-v7"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1433",
        "number": 1433,
        "title": "netty 4.1.3 memory leak affecting pubsub",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "We believe the following issue https://github.com/grpc/grpc-java/issues/2358 is affecting the pubsub as we are seeing OOM exceptions.\r\n\r\nAs gcloud 0.5.0 and 0.7.0 java is hard bundled with GRPC & netty version 4.1.3 it won't work by overriding the netty-all version (reason unknown but it is just quiet...)\r\n\r\nWould it be possible to upgrade this dependency or let us know how this dependency can be manually overridden?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1432",
        "number": 1432,
        "title": "Can the bundling behavior of gRPC be disabled for pubsub publishers?",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "I've encountered a case where an application that publishes pubsub messages (using `google-cloud-pubsub:0.5.1`) has encountered OutOfMemoryErrors which I have traced down to an instance of `com.google.api.gax.bundling.ThresholdBundler` taking up 92% of the heap space. This application purposefully runs with a small heap of ~256mb. \r\n\r\nThis application publishes all of it's messages to a single topic, so it seems as if all of the requests end up in the same ThresholdBundler instance. In the heap dump that I have, the `ThresholdBundler` instance has 63984 elements in the `closedBundles` list.\r\n\r\nIt looks like the gax library allows for the bundling behavior to be disabled via `BundlingSettings$Builder.setIsEnabled(Boolean)`, but the pubsub layer does not expose any of these options and always leaves the bundling behavior as enabled.\r\n\r\nWould it be possible to add flags to PubsubOptions (or wherever is appropriate) to allow for this request batching to be disabled if desired?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1431",
        "number": 1431,
        "title": "BaseEntity.toPb method is not public",
        "labels": [
            "api: datastore",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "There are cases where users want to convert com.google.cloud.datastore.Entity objects to native protobuf Entity objects (com.google.datastore.v1.Entity). For ex: while using Cloud Dataflow DatastoreIO, which only works with protobuf Entities. It would be nice to expose the toPb method by making it public. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1430",
        "number": 1430,
        "title": "DEADLINE_EXCEEDED when using Cloud Pub/Sub library from Compute Engine",
        "labels": [
            "api: core",
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "When using the Cloud Pub/Sub library in a Java application that has been deployed in a Google Compute Engine instance, a DEADLINE_EXCEEDED exception occurs. The application resides in a Docker container within a Container Engine-managed Compute Engine instance. The Pub/Sub topic and the Compute Engine instance are in the same project.\r\n\r\nThe Compute Engine service account has project editor permissions.\r\n\r\nNo problems with the old google-api-services-pubsub library.\r\n\r\nThe code to create the instance looks like this:\r\n```java\r\nInputStream credentialsStream = IOUtils.toInputStream(SERVICE_ACCOUNT_JSON, StandardCharsets.UTF_8);\r\nCredentials credentials = ServiceAccountCredentials.fromStream(credentialsStream);\r\nPubSubOptions options = PubSubOptions.newBuilder().setCredentials(credentials).build();\r\nPubSub pubsub = options.getService();\r\n```\r\nThen doing something like this (or alternatively, create a topic):\r\n```java\r\nfor (Subscription subscription : pubsub.listSubscriptions().getValues()) {\r\n...\r\n}\r\n```\r\nresults in the following:\r\n> com.google.cloud.pubsub.PubSubException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED\r\n\r\nVersions:\r\n```\r\ngoogle-cloud-pubsub - v0.6.0\r\ngoogle-auth-library-oauth2-http - v0.6.0\r\ngoogle-auth-library-credentials - v0.6.0\r\ngoogle-* - v1.22.0\r\n```\r\n\r\nI also found this issue at [Stackoverflow](http://stackoverflow.com/questions/40554096/deadline-exceeded-when-publishing-to-a-cloud-pub-sub-topic-from-compute-engine)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1429",
        "number": 1429,
        "title": "Integration tests flaky in AppVeyor",
        "labels": [
            "api: bigquery",
            "api: logging",
            "api: pubsub",
            "api: translation"
        ],
        "state": "closed",
        "body": "#1421 AppVeyor failed on DNS for this, succeeded for Travis, I'm going to approve this.\r\n\r\n```\r\nTests run: 35, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 3.391 sec <<< FAILURE! - in com.google.cloud.dns.testing.LocalDnsHelperTest\r\ntestListRecordSets(com.google.cloud.dns.testing.LocalDnsHelperTest)  Time elapsed: 0.032 sec  <<< FAILURE!\r\njava.lang.AssertionError\r\n\tat com.google.cloud.dns.testing.LocalDnsHelperTest.testListRecordSets(LocalDnsHelperTest.java:822)\r\n\r\n    assertNull(record.getType());\r\n    assertNotNull(record.getTtl());\r\n    assertNull(listResult.pageToken());\r\n```\r\n\r\n`getTtl()` appears to be Null."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1428",
        "number": 1428,
        "title": "[Datastore question] How to build AllocateIdRequest?",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "Greetings,\r\n\r\nAs I understand, a Java `AllocateIdsRequest` instance can be built using `Key`s or `PathElement`s, but according to the API it expects the key to contain incomplete paths. I saw no public way to build a `Key` without an id or name, and I no public way to get the path of an `IncompleteKey`. Can you please provide and example of building an `AllocateIdsRequest` from a string representing the kind? Also, wouldn't it make sense to be able to build `AllocateIdsRequest` from `IncompleteKey`s?\r\n\r\nThanks."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1427",
        "number": 1427,
        "title": "LocalDatastoreHelper throws an exception in empty test method",
        "labels": [
            "api: datastore",
            "type: bug"
        ],
        "state": "closed",
        "body": "Consider this code:\r\n\r\n```java\r\npublic class AnyTest {\r\n    private final LocalDatastoreHelper helper = LocalDatastoreHelper.create();\r\n\r\n    @Before\r\n    public void setUp() throws IOException, InterruptedException {\r\n        helper.start();\r\n    }\r\n\r\n    @After\r\n    public void tearDown() throws IOException, InterruptedException {\r\n        helper.stop();\r\n    }\r\n\r\n    @Test\r\n    public void testOk(){\r\n        Datastore datastore = helper.getOptions().getService();\r\n\r\n        Key key = datastore.newKeyFactory().setKind(\"AnyKind\").newKey(1234);\r\n        Entity entity = Entity.newBuilder(key).build();\r\n\r\n        datastore.put(entity);\r\n    }\r\n\r\n    @Test\r\n    public void testWeird(){\r\n        \r\n    }\r\n}\r\n```\r\n\r\nWhen I execute these tests, `testOk()` pass but the empty `testWeird()` does not pass. It gives me the following exception:\r\n\r\n```\r\njava.net.ConnectException: Connection refused: connect\r\n\r\n\tat java.net.DualStackPlainSocketImpl.connect0(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)\r\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\r\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\r\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\r\n\tat java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\r\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\r\n\tat java.net.Socket.connect(Socket.java:589)\r\n\tat java.net.Socket.connect(Socket.java:538)\r\n\tat sun.net.NetworkClient.doConnect(NetworkClient.java:180)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:432)\r\n\tat sun.net.www.http.HttpClient.openServer(HttpClient.java:527)\r\n\tat sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:781)\r\n\tat sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474)\r\n\tat com.google.cloud.testing.BaseEmulatorHelper.sendPostRequest(BaseEmulatorHelper.java:163)\r\n\tat com.google.cloud.datastore.testing.LocalDatastoreHelper.stop(LocalDatastoreHelper.java:229)\r\n\tat com.usefulmilk.endpoints.example.AnyTest.tearDown(AnyTest.java:46)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\r\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\r\n\tat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:237)\r\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\r\n```\r\n\r\nAnother thing to consider is when we remove `datastore.put(entity);` from `testOk()` method, the exception is being thrown too."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1420",
        "number": 1420,
        "title": "Support for GCS Cloud Pub/Sub Notifications",
        "labels": [
            "api: storage",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "GCS has a new feature (currently in private alpha) wherein buckets can be configured to send object change notifications to Cloud Pub/Sub topics, rather than as push notifications to HTTPS endpoints.\r\n\r\nIn gcloud-java, I imagine such a feature might look something like this:\r\n\r\n    Storage storage = StorageOptions.getDefaultInstance().getService();\r\n    PubSub pubsub = PubSubOptions.getDefaultInstance().getService()\r\n\r\n    Bucket bucket = storage.get(BUCKET_NAME);\r\n    Topic topic = pubsub.getTopic(TOPIC_NAME);\r\n    NotificationConfig notificationConfig = bucket.sendNotificationsTo(topic);"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1418",
        "number": 1418,
        "title": "pubsub 6.0 fails to fall back to HTTP on AppEngine",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "http://stackoverflow.com/questions/40741577/pubsub-java-api-on-appengine-uses-restricted-selectorprovider"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1412",
        "number": 1412,
        "title": "Expose ListenableFuture instead of Future for asynchronous operations",
        "labels": [],
        "state": "closed",
        "body": "We currently expose `Future` for asynchronous calls in `PubSub` and `Logging`, which creates a problem for thread consumption because every `get()` call needs a thread while the asynchronous work is outstanding, whereas callbacks (supported by `ListenableFuture`) don't consume a thread. A potential issue with converting to `ListenableFuture` is that it makes a Guava class part of our interface. @mziccard , is that why `Future` was used?\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1411",
        "number": 1411,
        "title": "BigQuery: Add support for query parameters",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query#request-body\r\n\r\nA query can put placeholders in the query text, which can then be filled in with `queryParameters`. Depending on what `parameterMode` is set to, the parameter can be positional `?` or names `@somename`.\r\n\r\nI'd expect these to be available on the [QueryRequest](http://googlecloudplatform.github.io/google-cloud-java/0.6.0/apidocs/com/google/cloud/bigquery/QueryRequest.html).\r\n\r\nSee also: https://github.com/GoogleCloudPlatform/google-cloud-python/issues/2551"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1409",
        "number": 1409,
        "title": "BigQuery does not have listProjects method",
        "labels": [
            "api: bigquery",
            "priority: p1",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See: https://cloud.google.com/bigquery/docs/managing_jobs_datasets_projects#projects\r\nand https://cloud-dot-devsite.googleplex.com/bigquery/docs/reference/rest/v2/projects/list\r\n\r\nThe BigQuery API provides a way to access the list of projects available. (This is because BigQuery was one of the first Google Cloud APIs and customers may wish to access BigQuery projects without using resource manager.)\r\n\r\nSee also: https://github.com/GoogleCloudPlatform/google-cloud-python/issues/2143"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1408",
        "number": 1408,
        "title": "Update the NL Library to v1 API",
        "labels": [
            "api: language"
        ],
        "state": "closed",
        "body": "The library needs to be updated to the new version of API aka v1."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1405",
        "number": 1405,
        "title": "Exception: API Key and the authentication credential are from different projects",
        "labels": [
            "api: translation",
            "auth",
            "type: bug"
        ],
        "state": "closed",
        "body": "If you have multiple sets of valid credentials configured in your Java environment, the Cloud library will not resolve between the two.\r\n\r\n## Repro steps\r\n\r\n1. Configure client library for API key: `export GOOGLE_API_KEY=SOME_VALID_DEVELOPER_KEY`\r\n2. Configure client library for valid credentials from separate project: `export GOOGLE_APPLICATION_CREDENTIALS=./creds.json`\r\n3. Run java sample, e.g. from github.com/GoogleCloudPlatform/java-docs-samples/translate...\r\n\r\n```\r\nmvn clean compile assembly:single\r\nJAR_FILE=target/translate-1.0-jar-with-dependencies.jar\r\nINPUT=\"A quick brown fox jumped over a lazy dog.\"\r\nSOURCE_LANG=\"en\"\r\nTARGET_LANG=\"fr\"\r\njava -jar $JAR_FILE translate \"$INPUT\" $SOURCE_LANG $TARGET_LANG\r\n```\r\n\r\n## Expected outcome\r\n\r\nClient library warns developer but uses an access token from the service account.\r\n\r\n## Actual outcome\r\nClient library fails, throwing exception and crashing app.\r\n\r\n    Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request\r\n    {\r\n      \"code\" : 400,\r\n      \"errors\" : [ {\r\n        \"domain\" : \"global\",\r\n        \"message\" : \"The API Key and the authentication credential are from different projects.\",\r\n        \"reason\" : \"badRequest\"\r\n      } ],\r\n      \"message\" : \"The API Key and the authentication credential are from different projects.\",\r\n      \"status\" : \"INVALID_ARGUMENT\"\r\n    }"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1397",
        "number": 1397,
        "title": "NoSuchmethodError on pubsub.PubSubOptions.newBuilder()",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "My code compiles with this clause in pom.xml\r\n    <dependency>\r\n        <groupId>com.google.cloud</groupId>\r\n        <artifactId>google-cloud-pubsub</artifactId>\r\n        <version>0.5.0</version>\r\n    </dependency>\r\n\r\nBut crashes immediately at run time when I attempt to create a new option builder:\r\n   public static void main( String[] args ) throws ParseException, java.io.IOException\r\n    {\r\n        CommandLine cmd = parseCommandLineArgs( args );\r\n        PubSubOptions options = PubSubOptions.newBuilder().build();\r\n     ...\r\n     }\r\n\r\nWith \r\nException in thread \"main\" java.lang.NoSuchMethodError: com.google.cloud.pubsub.PubSubOptions.newBuilder()Lcom/google/cloud/pubsub/PubSubOptions$Builder;\r\n\r\n1. What am I doing wrong?\r\n2. I modeled this line on the datastore example on the read-the-code front page.  If this is different, that's something to be fixed either in the API or the docs :) \r\n3. It is super hard to figure out how to actually create a properly authenticated client from the Javadoc. There are not examples and most of the key methods are right in the middle of being deprecated.  I'd love clean documentation on the client creation classes."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1392",
        "number": 1392,
        "title": "BigQuery: support `/upload` method for loading data from local files.",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "See documentation: https://cloud.google.com/bigquery/loading-data-post-request\r\n\r\nPython, PHP, Ruby, and Node.js provide an upload-from-file method on the Table object.\r\n\r\nThis is blocking documentation samples."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1391",
        "number": 1391,
        "title": "BigQueryException when patching a table does not contain propagated error codes",
        "labels": [],
        "state": "closed",
        "body": "It looks like there are other flows that also don\u2019t propagate error codes, but this particular one is what I saw.\r\n\r\nI noticed this when I was updating a table.  Our code has retry logic if the returned BigQueryException has an error code of 403.\r\n\r\nrelevant code lines:\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/spi/DefaultBigQueryRpc.java#L206\r\n\r\nhttps://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/spi/DefaultBigQueryRpc.java#L93\r\n\r\nGoogleJsonResponseException is a subclass of IOException, but the error code there isn't ending up in the wrapping BigQueryException.\r\n\r\nThe part of my stack trace that lead me to this conclusion:\r\n\r\n```\r\nCaused by: com.google.cloud.bigquery.BigQueryException: Exceeded rate limits: Your table exceeded quota for table.insert or table.update per table. For more information, see https://cloud.google.com/bigquery/troubleshooting-errors\r\n\r\nat com.google.cloud.bigquery.spi.DefaultBigQueryRpc.translate(DefaultBigQueryRpc.java:93)\r\nat com.google.cloud.bigquery.spi.DefaultBigQueryRpc.patch(DefaultBigQueryRpc.java:218)\r\nat com.google.cloud.bigquery.BigQueryImpl$10.call(BigQueryImpl.java:329)\r\nat com.google.cloud.bigquery.BigQueryImpl$10.call(BigQueryImpl.java:326)\r\nat com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\r\nat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\r\nat com.google.cloud.bigquery.BigQueryImpl.update(BigQueryImpl.java:325)\r\nat com.wepay.kafka.connect.bigquery.SchemaManager.updateSchema(SchemaManager.java:57)\r\nat com.wepay.kafka.connect.bigquery.write.row.AdaptiveBigQueryWriter.performWriteRequest(AdaptiveBigQueryWriter.java:86)\r\nat com.wepay.kafka.connect.bigquery.write.row.BigQueryWriter.writeRows(BigQueryWriter.java:158) <\u2014 catching the 403 was expected to happen around here.\r\nat com.wepay.kafka.connect.bigquery.write.batch.DynamicBatchWriter.seekingWriteAll(DynamicBatchWriter.java:131)\r\n... 7 more\r\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden\r\n{\r\n  \"code\" : 403,\r\n  \"errors\" : [ {\r\n    \"domain\" : \"global\",\r\n    \"location\" : \"table.write\",\r\n    \"locationType\" : \"other\",\r\n    \"message\" : \"Exceeded rate limits: Your table exceeded quota for table.insert or table.update per table. For more information, see https://cloud.google.com/bigquery/troubleshooting-errors\",\r\n    \"reason\" : \"rateLimitExceeded\"\r\n  } ],\r\n  \"message\" : \"Exceeded rate limits: Your table exceeded quota for table.insert or table.update per table. For more information, see https://cloud.google.com/bigquery/troubleshooting-errors\"\r\n}\r\nat com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\r\nat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\nat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\nat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1065)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\nat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\nat com.google.cloud.bigquery.spi.DefaultBigQueryRpc.patch(DefaultBigQueryRpc.java:213)\r\n... 16 more\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1389",
        "number": 1389,
        "title": "Integer Overflow In BaseWriteChannel",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Hi there. I'm testing out com.google.cloud.storage.Storage.writer() for writing to GCS. It works very well for files smaller than 2GB, but right around the 2GB mark WriteChannel throws an exception indicating that there's something wrong with the Content-Range header.\r\n\r\n`com.google.api.client.http.HttpResponseException: 400|Failed to parse Content-Range header.`\r\n\r\nI noticed that the Content-Range header is set in com.google.cloud.storage.spi.DefaultStorageRpc.write() and is calculated using com.google.cloud.BaseWriteChannel.position, which is an int. The problem is that at the 2GB mark the position variable overflows and becomes negative, causing panic and mayhem.\r\n\r\nHere are some screenshots to paint a fuller picture:\r\n\r\n![trace1](https://cloud.githubusercontent.com/assets/8976403/20188491/7cee211e-a73e-11e6-9197-945755142b08.jpg)\r\n\r\n![trace2](https://cloud.githubusercontent.com/assets/8976403/20188495/81a45be2-a73e-11e6-91d9-3c5eb1c6a578.png)\r\n\r\nAny chance we can get a patch for this? Should I submit a pull request?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1388",
        "number": 1388,
        "title": "Add support for DATE, TIME, and DATETIME schema types",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "BigQuery allows creation of tables with fields of type DATE, TIME, and DATETIME. However the Java client does not recognize these types. So for example, executing a load job to import JSON into a table an existing table with one of these field types in the schema will fail.\r\n\r\nSchema:\r\n```\r\n    ItemDate:DATE,Description:STRING\r\n```\r\n\r\nJSON:\r\n```\r\n{\"ItemDate\": \"2016-11-01\", \"Description\": \"Item 1\"}\r\n{\"ItemDate\": \"2016-11-02\", \"Description\": \"Item 2\"}\r\n{\"ItemDate\": \"2016-11-03\", \"Description\": \"Item 3\"}\r\n{\"ItemDate\": \"2016-11-04\", \"Description\": \"Item 4\"}\r\n```\r\n\r\nCreate job: (Example from Scala repl but using the Java client)\r\n```\r\nval tableId = TableId.of(\"instant-bonbon-111304\", \"TestData\", \"Date_Test\")\r\nval uris = new java.util.ArrayList[String]()\r\nuris.add(\"gs://ih_test_v1/date_test/date_test.json\")\r\n\r\nval jobConf = LoadJobConfiguration.newBuilder(tableId, uris).\r\n  setWriteDisposition(JobInfo.WriteDisposition.WRITE_APPEND).\r\n  setFormatOptions(FormatOptions.json).\r\n  build\r\n\r\nval jobInfo = JobInfo.of(jobConf)\r\n\r\nvar job : Job = null\r\n\r\ntry {\r\n  job = bigquery.create(jobInfo)\r\n} catch {\r\n  case e: BigQueryException => println(e)\r\n}\r\n```\r\n\r\nError:\r\n```\r\njava.lang.IllegalArgumentException: No enum constant com.google.cloud.bigquery.Field.Type.Value.DATE\r\n        at java.lang.Enum.valueOf(Enum.java:238)\r\n        at com.google.cloud.bigquery.Field$Type$Value.valueOf(Field.java:75)\r\n        at com.google.cloud.bigquery.Field.fromPb(Field.java:477)\r\n        at com.google.cloud.bigquery.Field$1.apply(Field.java:46)\r\n        at com.google.cloud.bigquery.Field$1.apply(Field.java:43)\r\n        at com.google.common.collect.Lists$TransformingRandomAccessList.get(Lists.java:451)\r\n        at java.util.AbstractList$Itr.next(AbstractList.java:358)\r\n        at java.util.AbstractCollection.toArray(AbstractCollection.java:141)\r\n        at java.util.ArrayList.<init>(ArrayList.java:177)\r\n        at com.google.common.collect.Lists.newArrayList(Lists.java:119)\r\n        at com.google.cloud.bigquery.Schema$Builder.setFields(Schema.java:86)\r\n        at com.google.cloud.bigquery.Schema.of(Schema.java:189)\r\n        at com.google.cloud.bigquery.Schema.fromPb(Schema.java:200)\r\n        at com.google.cloud.bigquery.LoadJobConfiguration$Builder.<init>(LoadJobConfiguration.java:117)\r\n        at com.google.cloud.bigquery.LoadJobConfiguration$Builder.<init>(LoadJobConfiguration.java:48)\r\n        at com.google.cloud.bigquery.LoadJobConfiguration.fromPb(LoadJobConfiguration.java:553)\r\n        at com.google.cloud.bigquery.JobConfiguration.fromPb(JobConfiguration.java:145)\r\n        at com.google.cloud.bigquery.JobInfo$BuilderImpl.<init>(JobInfo.java:182)\r\n        at com.google.cloud.bigquery.Job.fromPb(Job.java:324)\r\n        at com.google.cloud.bigquery.BigQueryImpl.create(BigQueryImpl.java:229)\r\n        ...\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1386",
        "number": 1386,
        "title": "LoggingHandler is re-entrant when logging FINE",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "When using the LoggingHandler with logging turned up to FINE, it becomes re-entrant causing either an error or a stack overflow.\r\n\r\nThis appears due to the fact that classes used to implement LoggingHandler are themselves instrumented with Java Util Logging!   Examples I have found are `io.netty` (first stack trace below)\r\nand `HttpURLConnection` (second stack trace using a cut/paste of LoggingHandler to com.google.cloud.runtimes.jetty9.LoggingHandler as I'm working on Issue #1329\r\n\r\n```\r\nNov 10, 2016 5:57:44 PM com.google.cloud.runtimes.jetty9.StackDriverLogging init\r\nINFO: test info\r\nNov 10, 2016 5:57:45 PM io.netty.util.internal.logging.InternalLoggerFactory newDefaultFactory\r\nFINE: Using java.util.logging as the default logging framework\r\nException in thread \"main\" java.lang.ExceptionInInitializerError\r\n\tat io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:36)\r\n\tat io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)\r\n\tat io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)\r\n\tat io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:58)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:77)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:72)\r\n\tat io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:59)\r\n\tat io.grpc.netty.Utils$DefaultEventLoopGroupResource.create(Utils.java:187)\r\n\tat io.grpc.netty.Utils$DefaultEventLoopGroupResource.create(Utils.java:171)\r\n\tat io.grpc.internal.SharedResourceHolder.getInternal(SharedResourceHolder.java:124)\r\n\tat io.grpc.internal.SharedResourceHolder.get(SharedResourceHolder.java:94)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:311)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:280)\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:230)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:239)\r\n\tat com.google.api.gax.grpc.ServiceApiSettings$Builder$3.getOrBuildChannel(ServiceApiSettings.java:349)\r\n\tat com.google.cloud.logging.spi.v2.ConfigServiceV2Api.<init>(ConfigServiceV2Api.java:155)\r\n\tat com.google.cloud.logging.spi.v2.ConfigServiceV2Api.create(ConfigServiceV2Api.java:145)\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc.<init>(DefaultLoggingRpc.java:140)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:68)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:62)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:491)\r\n\tat com.google.cloud.logging.LoggingImpl.<init>(LoggingImpl.java:96)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:43)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:38)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:478)\r\n\tat com.google.cloud.logging.LoggingHandler.getLogging(LoggingHandler.java:276)\r\n\tat com.google.cloud.logging.LoggingHandler.write(LoggingHandler.java:351)\r\n\tat com.google.cloud.logging.LoggingHandler.flush(LoggingHandler.java:357)\r\n\tat com.google.cloud.logging.LoggingHandler.publish(LoggingHandler.java:292)\r\n\tat java.util.logging.Logger.log(Logger.java:738)\r\n\tat io.netty.util.internal.logging.JdkLogger.log(JdkLogger.java:606)\r\n\tat io.netty.util.internal.logging.JdkLogger.debug(JdkLogger.java:186)\r\n\tat io.netty.util.internal.logging.InternalLoggerFactory.newDefaultFactory(InternalLoggerFactory.java:62)\r\n\tat io.netty.util.internal.logging.InternalLoggerFactory.<clinit>(InternalLoggerFactory.java:37)\r\n\tat io.netty.channel.MultithreadEventLoopGroup.<clinit>(MultithreadEventLoopGroup.java:34)\r\n\tat io.grpc.netty.Utils$DefaultEventLoopGroupResource.create(Utils.java:187)\r\n\tat io.grpc.netty.Utils$DefaultEventLoopGroupResource.create(Utils.java:171)\r\n\tat io.grpc.internal.SharedResourceHolder.getInternal(SharedResourceHolder.java:124)\r\n\tat io.grpc.internal.SharedResourceHolder.get(SharedResourceHolder.java:94)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:311)\r\n\tat io.grpc.netty.NettyChannelBuilder$NettyTransportFactory.<init>(NettyChannelBuilder.java:280)\r\n\tat io.grpc.netty.NettyChannelBuilder.buildTransportFactory(NettyChannelBuilder.java:230)\r\n\tat io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:239)\r\n\tat com.google.api.gax.grpc.ServiceApiSettings$Builder$3.getOrBuildChannel(ServiceApiSettings.java:349)\r\n\tat com.google.cloud.logging.spi.v2.ConfigServiceV2Api.<init>(ConfigServiceV2Api.java:155)\r\n\tat com.google.cloud.logging.spi.v2.ConfigServiceV2Api.create(ConfigServiceV2Api.java:145)\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc.<init>(DefaultLoggingRpc.java:140)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:68)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingRpcFactory.create(LoggingOptions.java:62)\r\n\tat com.google.cloud.ServiceOptions.getRpc(ServiceOptions.java:491)\r\n\tat com.google.cloud.logging.LoggingImpl.<init>(LoggingImpl.java:96)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:43)\r\n\tat com.google.cloud.logging.LoggingOptions$DefaultLoggingFactory.create(LoggingOptions.java:38)\r\n\tat com.google.cloud.ServiceOptions.getService(ServiceOptions.java:478)\r\n\tat com.google.cloud.logging.LoggingHandler.getLogging(LoggingHandler.java:276)\r\n\tat com.google.cloud.logging.LoggingHandler.write(LoggingHandler.java:351)\r\n\tat com.google.cloud.logging.LoggingHandler.flush(LoggingHandler.java:357)\r\n\tat com.google.cloud.logging.LoggingHandler.publish(LoggingHandler.java:292)\r\n\tat java.util.logging.Logger.log(Logger.java:738)\r\n\tat java.util.logging.Logger.doLog(Logger.java:765)\r\n\tat java.util.logging.Logger.log(Logger.java:788)\r\n\tat java.util.logging.Logger.info(Logger.java:1489)\r\n\tat com.google.cloud.runtimes.jetty9.StackDriverLogging.init(StackDriverLogging.java:37)\r\n\tat com.google.cloud.runtimes.jetty9.StackDriverLogging.main(StackDriverLogging.java:47)\r\nCaused by: java.lang.NullPointerException\r\n\tat io.netty.util.internal.logging.InternalLoggerFactory.getInstance(InternalLoggerFactory.java:97)\r\n\tat io.netty.util.internal.logging.InternalLoggerFactory.getInstance(InternalLoggerFactory.java:90)\r\n\tat io.netty.util.concurrent.DefaultPromise.<clinit>(DefaultPromise.java:35)\r\n\t... 65 more\r\n```\r\n\r\n```\r\nException in thread \"main\" java.lang.StackOverflowError\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat sun.security.jca.ProviderConfig.doLoadProvider(ProviderConfig.java:206)\r\n\tat sun.security.jca.ProviderConfig.getProvider(ProviderConfig.java:187)\r\n\tat sun.security.jca.ProviderList.getProvider(ProviderList.java:233)\r\n\tat sun.security.jca.ProviderList$ServiceList.tryGet(ProviderList.java:434)\r\n\tat sun.security.jca.ProviderList$ServiceList.access$200(ProviderList.java:376)\r\n\tat sun.security.jca.ProviderList$ServiceList$1.hasNext(ProviderList.java:486)\r\n\tat java.security.Signature$Delegate.chooseProvider(Signature.java:1094)\r\n\tat java.security.Signature$Delegate.engineInitSign(Signature.java:1176)\r\n\tat java.security.Signature.initSign(Signature.java:527)\r\n\tat com.google.api.client.util.SecurityUtils.sign(SecurityUtils.java:145)\r\n\tat com.google.api.client.json.webtoken.JsonWebSignature.signUsingRsaSha256(JsonWebSignature.java:637)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:208)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:97)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:74)\r\n\tat io.grpc.auth.ClientAuthInterceptor.getRequestMetadata(ClientAuthInterceptor.java:150)\r\n\tat io.grpc.auth.ClientAuthInterceptor.access$100(ClientAuthInterceptor.java:64)\r\n\tat io.grpc.auth.ClientAuthInterceptor$1.checkedStart(ClientAuthInterceptor.java:96)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:195)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:64)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:273)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:252)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:189)\r\n\tat com.google.api.gax.grpc.DirectCallable.futureCall(DirectCallable.java:58)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:66)\r\n\tat com.google.api.gax.grpc.RetryingCallable$RetryingResultFuture.issueCall(RetryingCallable.java:222)\r\n\tat com.google.api.gax.grpc.RetryingCallable.futureCall(RetryingCallable.java:90)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:242)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:253)\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc.write(DefaultLoggingRpc.java:199)\r\n\tat com.google.cloud.logging.LoggingImpl.writeAsync(LoggingImpl.java:503)\r\n\tat com.google.cloud.runtimes.jetty9.AsyncLoggingHandler.write(AsyncLoggingHandler.java:101)\r\n\tat com.google.cloud.runtimes.jetty9.LoggingHandler.flush(LoggingHandler.java:365)\r\n\tat com.google.cloud.runtimes.jetty9.LoggingHandler.publish(LoggingHandler.java:298)\r\n\tat java.util.logging.Logger.log(Logger.java:738)\r\n\tat java.util.logging.Logger.doLog(Logger.java:765)\r\n\tat java.util.logging.Logger.log(Logger.java:788)\r\n\tat java.util.logging.LoggingProxyImpl.log(LoggingProxyImpl.java:61)\r\n\tat sun.util.logging.LoggingSupport.log(LoggingSupport.java:120)\r\n\tat sun.util.logging.PlatformLogger$JavaLoggerProxy.doLog(PlatformLogger.java:610)\r\n\tat sun.util.logging.PlatformLogger.fine(PlatformLogger.java:364)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:658)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1293)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1258)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:225)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:97)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:74)\r\n\tat io.grpc.auth.ClientAuthInterceptor.getRequestMetadata(ClientAuthInterceptor.java:150)\r\n\tat io.grpc.auth.ClientAuthInterceptor.access$100(ClientAuthInterceptor.java:64)\r\n\tat io.grpc.auth.ClientAuthInterceptor$1.checkedStart(ClientAuthInterceptor.java:96)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:195)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:64)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:273)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:252)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:189)\r\n\tat com.google.api.gax.grpc.DirectCallable.futureCall(DirectCallable.java:58)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:66)\r\n\r\n...\r\n\r\n\tat com.google.api.gax.grpc.RetryingCallable$RetryingResultFuture.issueCall(RetryingCallable.java:222)\r\n\tat com.google.api.gax.grpc.RetryingCallable.futureCall(RetryingCallable.java:90)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:242)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:253)\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc.write(DefaultLoggingRpc.java:199)\r\n\tat com.google.cloud.logging.LoggingImpl.writeAsync(LoggingImpl.java:503)\r\n\tat com.google.cloud.runtimes.jetty9.AsyncLoggingHandler.write(AsyncLoggingHandler.java:101)\r\n\tat com.google.cloud.runtimes.jetty9.LoggingHandler.flush(LoggingHandler.java:365)\r\n\tat com.google.cloud.runtimes.jetty9.LoggingHandler.publish(LoggingHandler.java:298)\r\n\tat java.util.logging.Logger.log(Logger.java:738)\r\n\tat java.util.logging.Logger.doLog(Logger.java:765)\r\n\tat java.util.logging.Logger.log(Logger.java:788)\r\n\tat java.util.logging.LoggingProxyImpl.log(LoggingProxyImpl.java:61)\r\n\tat sun.util.logging.LoggingSupport.log(LoggingSupport.java:120)\r\n\tat sun.util.logging.PlatformLogger$JavaLoggerProxy.doLog(PlatformLogger.java:610)\r\n\tat sun.util.logging.PlatformLogger.fine(PlatformLogger.java:364)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:658)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1293)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1258)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:225)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:97)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:74)\r\n\tat io.grpc.auth.ClientAuthInterceptor.getRequestMetadata(ClientAuthInterceptor.java:150)\r\n\tat io.grpc.auth.ClientAuthInterceptor.access$100(ClientAuthInterceptor.java:64)\r\n\tat io.grpc.auth.ClientAuthInterceptor$1.checkedStart(ClientAuthInterceptor.java:96)\r\n\tat io.grpc.ClientInterceptors$CheckedForwardingClientCall.start(ClientInterceptors.java:195)\r\n\tat io.grpc.ForwardingClientCall.start(ForwardingClientCall.java:47)\r\n\tat com.google.api.gax.grpc.HeaderInterceptor$1.start(HeaderInterceptor.java:64)\r\n\tat io.grpc.stub.ClientCalls.startCall(ClientCalls.java:273)\r\n\tat io.grpc.stub.ClientCalls.asyncUnaryRequestCall(ClientCalls.java:252)\r\n\tat io.grpc.stub.ClientCalls.futureUnaryCall(ClientCalls.java:189)\r\n\tat com.google.api.gax.grpc.DirectCallable.futureCall(DirectCallable.java:58)\r\n\tat com.google.api.gax.grpc.ExceptionTransformingCallable.futureCall(ExceptionTransformingCallable.java:66)\r\n\tat com.google.api.gax.grpc.RetryingCallable$RetryingResultFuture.issueCall(RetryingCallable.java:222)\r\n\tat com.google.api.gax.grpc.RetryingCallable.futureCall(RetryingCallable.java:90)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:242)\r\n\tat com.google.api.gax.grpc.UnaryCallable.futureCall(UnaryCallable.java:253)\r\n\tat com.google.cloud.logging.spi.DefaultLoggingRpc.write(DefaultLoggingRpc.java:199)\r\n\tat com.google.cloud.logging.LoggingImpl.writeAsync(LoggingImpl.java:503)\r\n\tat com.google.cloud.runtimes.jetty9.AsyncLoggingHandler.write(AsyncLoggingHandler.java:101)\r\n\tat com.google.cloud.runtimes.jetty9.LoggingHandler.flush(LoggingHandler.java:365)\r\n\tat com.google.cloud.runtimes.jetty9.LoggingHandler.publish(LoggingHandler.java:298)\r\n\tat java.util.logging.Logger.log(Logger.java:738)\r\n\tat java.util.logging.Logger.doLog(Logger.java:765)\r\n\tat java.util.logging.Logger.log(Logger.java:788)\r\n\tat java.util.logging.LoggingProxyImpl.log(LoggingProxyImpl.java:61)\r\n\tat sun.util.logging.LoggingSupport.log(LoggingSupport.java:120)\r\n\tat sun.util.logging.PlatformLogger$JavaLoggerProxy.doLog(PlatformLogger.java:610)\r\n\tat sun.util.logging.PlatformLogger.fine(PlatformLogger.java:364)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:658)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1293)\r\n\tat sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1258)\r\n\tat sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250)\r\n\tat com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\r\n\tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\r\n\tat com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:225)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:97)\r\n\tat com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:74)\r\n\tat io.grpc.auth.ClientAuthInterceptor.getRequestMetadata(ClientAuthInterceptor.java:150)\r\n```\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1383",
        "number": 1383,
        "title": "Query (and possibly other classes) in Datastore library using @Deprecated with no documentation of what to use instead",
        "labels": [],
        "state": "closed",
        "body": "com.google.cloud.datastore.Query:171 is an instance of this, although there are others in that class.\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1381",
        "number": 1381,
        "title": "pubsub emulator authinterceptor question",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "status: blocked",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "I get the following when subscribing to a topics subscription locally:\r\n```\r\n...\r\n[pubsub] Nov 09, 2016 1:46:17 PM com.google.cloud.iam.testing.v1.shared.authorization.AuthInterceptor interceptCall\r\n[pubsub] INFO: Authentication interceptor: Header value is null\r\n[pubsub] Nov 09, 2016 1:46:17 PM com.google.cloud.iam.testing.v1.shared.authorization.AuthInterceptor interceptCall\r\n[pubsub] INFO: Authentication interceptor: invalid or missing token\r\n[pubsub] Nov 09, 2016 1:46:17 PM com.google.cloud.iam.testing.v1.shared.authorization.AuthInterceptor interceptCall\r\n[pubsub] INFO: Authentication interceptor: Header value is null\r\n...\r\n```\r\nGiven the below information, what could be wrong?\r\n\r\nMy java code works with the actual cloud service but when using the following code:\r\n\r\n```java\r\nPubSubOptions.Builder optionsBuilder = PubSubOptions.newBuilder().setProjectId(\"project\");\r\noptionsBuilder.setAuthCredentials(AuthCredentials.noAuth());\r\noptionsBuilder.setHost(\"localhost:8989\");\r\nPubSub pubsub = optionsBuilder.build().getService();\r\n\r\n//then using pubsub.pullAsync(...) for the actual pulling of messages\r\n```\r\n\r\ngcloud pubsub emulator started like this:\r\n`gcloud beta emulators pubsub start --host-port=0.0.0.0:8989`\r\n\r\nVersions:\r\ngcloud-java-pubsub -> 0.5.1\r\n\r\n$ gcloud --version\r\nGoogle Cloud SDK 133.0.0\r\nalpha 2016.01.12\r\nbeta 2016.01.12\r\nbq 2.0.24\r\nbq-nix 2.0.24\r\ncore 2016.11.01\r\ncore-nix 2016.11.01\r\ngcloud\r\ngsutil 4.22\r\ngsutil-nix 4.22\r\npubsub-emulator 2016.08.19"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1376",
        "number": 1376,
        "title": "pubsub permission question regarding getTopic and getSubscription",
        "labels": [],
        "state": "closed",
        "body": "We would like to have a service account with access only to subscribe to a topic and not t to publish or create anything else than create its subscription on one topic if the subscription doesn't exists.\r\n\r\nGiven the code below what is needed to get it to work without granting access to the actual project?\r\n\r\n```Java\r\n  private static void ensureTopicAndSubscriptionExist(\r\n      PubSub pubsub, String topic, String subscription) {\r\n   \r\n    if (pubsub.getTopic(topic) == null) {\r\n      throw new IllegalStateException(\"Topic does not exist: \" + topic);\r\n    }\r\n   \r\n    if (pubsub.getSubscription(subscription) == null) {\r\n      LOG.info(\"creating PubSub subscription={} for topic={}\", subscription, topic);\r\n      pubsub.create(SubscriptionInfo.of(topic, subscription));\r\n      LOG.info(\"created PubSub subscription={} for topic={}\", subscription, topic);\r\n    }\r\n  }\r\n```\r\n\r\nWe only get this to work if the service account user has edit rights on the project"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1373",
        "number": 1373,
        "title": "Error when updating ACL on an object",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "The following code (suggested in documentation) results in an error:\r\n\r\n```\r\nIterator<Blob> it = storage.list(COVER).iterateAll();\r\nwhile (it.hasNext()) {\r\n\r\n    Blob blob = it.next();\r\n    storage.updateAcl(blob.blobId(), Acl.of(User.ofAllUsers(), Role.READER));\r\n    // blob.updateAcl(Acl.of(User.ofAllUsers(), Role.READER));  - results in the same error\r\n}\r\n```\r\n\r\nThe error message (not very useful):\r\n\r\n> Exception in thread \"main\" com.google.cloud.storage.StorageException: Not Found\r\n> \tat com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:198)\r\n> \tat com.google.cloud.storage.spi.DefaultStorageRpc.patchAcl(DefaultStorageRpc.java:818)\r\n> \tat com.google.cloud.storage.StorageImpl$33.call(StorageImpl.java:827)\r\n> \tat com.google.cloud.storage.StorageImpl$33.call(StorageImpl.java:824)\r\n> \tat com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\r\n> \tat com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\r\n> \tat com.google.cloud.storage.StorageImpl.updateAcl(StorageImpl.java:824)\r\n> \tat com.rebelation.ingest.server.VerifyCoverFiles.main(VerifyCoverFiles.java:52)\r\n> Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found\r\n> {\r\n>   \"code\" : 404,\r\n>   \"errors\" : [ {\r\n>     \"domain\" : \"global\",\r\n>     \"message\" : \"Not Found\",\r\n>     \"reason\" : \"notFound\"\r\n>   } ],\r\n>   \"message\" : \"Not Found\"\r\n> }\r\n> \tat com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)\r\n> \tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\r\n> \tat com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\r\n> \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\r\n> \tat com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056)\r\n> \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\r\n> \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\r\n> \tat com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\r\n> \tat com.google.cloud.storage.spi.DefaultStorageRpc.patchAcl(DefaultStorageRpc.java:813)\r\n> \t... 6 more"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1370",
        "number": 1370,
        "title": "bigquery: support loading a POJO or Map like GSON does",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The code for processing the results of a query is a bit convoluted.\r\n\r\nExample from https://github.com/GoogleCloudPlatform/java-docs-samples/blob/2e3f285b7dccfd978b14033f9869e728e8c13e56/bigquery/cloud-client/src/main/java/com/example/bigquery/SimpleApp.java#L53\r\n\r\n```\r\n    QueryResult result = response.result();\r\n\r\n    while (result != null) {\r\n      Iterator<List<FieldValue>> iter = result.iterateAll();\r\n\r\n      while (iter.hasNext()) {\r\n        List<FieldValue> row = iter.next();\r\n        List<FieldValue> titles = row.get(0).repeatedValue();\r\n        System.out.println(\"titles:\");\r\n\r\n        for (FieldValue titleValue : titles) {\r\n          List<FieldValue> titleRecord = titleValue.recordValue();\r\n          String title = titleRecord.get(0).stringValue();\r\n          long uniqueWords = titleRecord.get(1).longValue();\r\n          System.out.printf(\"\\t%s: %d\\n\", title, uniqueWords);\r\n        }\r\n\r\n        long uniqueWords = row.get(1).longValue();\r\n        System.out.printf(\"total unique words: %d\\n\", uniqueWords);\r\n      }\r\n\r\n      result = result.nextPage();\r\n```\r\n\r\nFor a fixed query, I'd love to be able to fill in the object the way that I can in GSON. Then I'd be able to do something like:\r\n\r\n```\r\n    QueryResult result = response.result();\r\n\r\n    while (result != null) {\r\n      Iterator<List<FieldValue>> iter = result.iterateAll();\r\n\r\n      while (iter.hasNext()) {\r\n        List<FieldValue> row = iter.next();\r\n        // I can't do this yet, but I'd love to be able to load an object\r\n        // like I can with GSON.\r\n        // I'm thinking maybe it only makes sense per-row rather than for\r\n        // a whole query, due to paging.\r\n        WordCounts counts = row.as(WordCounts.class);\r\n        System.out.println(\"titles:\");\r\n\r\n        for (Title title : counts.getTitles()) {\r\n          System.out.printf(\"\\t%s: %d\\n\", title.getTitle(), title.getUniqueWords());\r\n        }\r\n\r\n        System.out.printf(\"total unique words: %d\\n\", counts.getTotalWords());\r\n      }\r\n\r\n      result = result.nextPage();\r\n```\r\n\r\nFor context, here is a similar issue in the Go libraries: https://github.com/GoogleCloudPlatform/google-cloud-go/issues/399"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1369",
        "number": 1369,
        "title": "Please update README with Alpha->Beta->GA timelines for each library",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It helpful for customers to easily 'see' when a particular GCP client library will be at GA.\r\n\r\n(i'll file one for gcloud-puthon to get the library status add to that README too)"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1368",
        "number": 1368,
        "title": "Support PubSub on AppEngine Standard",
        "labels": [],
        "state": "closed",
        "body": "Pubsub doens't work on GAE standard.  Please add support for GAEStandard.\r\npubsub-java throws the following error on initialization \r\nwith \r\n```\r\n      PubSub pubsub = PubSubOptions.getDefaultInstance().getService();\r\n```\r\n```\r\n  error:\r\n   java.lang.NoClassDefFoundError: java.nio.channels.spi.SelectorProvider is a restricted class.\r\n Please see the Google App Engine developer's guide for more details. at \r\n```\r\n\r\n(i suspect its not supported if the library now is gRPC only)\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1367",
        "number": 1367,
        "title": "Pubsub java client has pub/ack latency greater than a second",
        "labels": [],
        "state": "closed",
        "body": "In comparative tests, the gcloud java client's publish latency is over 10x worse than a grpc client in java and the gcloud Python client. Even in relatively low-throughput tests, the client consistently takes 1-2 seconds for a publish call, when other tests are getting results on the order of tens of milliseconds. at the same message size/QPS. "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1366",
        "number": 1366,
        "title": "Support generic Batch HTTP requests",
        "labels": [
            "api: bigquery",
            "api: core",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We got feedback on this page that we don't have any code samples. https://cloud.google.com/bigquery/batch\r\n\r\nThe API clients support batch requests, https://developers.google.com/api-client-library/java/google-api-java-client/batch but I don't think the Cloud libraries do.\r\n\r\nI'm marking as BigQuery, since that's where we got the feedback, but I'm sure it applies to the other products, as well."
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1364",
        "number": 1364,
        "title": "Datastore - Support for OR predicate in GQL/Query Filters ",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Is there a reason why a datastore query (GQL or otherwise) does not allow OR predicate? I noticed that the AppEngine Datastore supports this - \r\n\r\n(https://cloud.google.com/appengine/docs/java/javadoc/com/google/appengine/api/datastore/Query.CompositeFilter). \r\n\r\nI was under the impression that Cloud Datastore is similar (or same) as AppEngine Datastore. \r\n\r\nIn any case, is this some thing that can be supported? \r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1363",
        "number": 1363,
        "title": "Upgrade to protobuf 3.1.0?",
        "labels": [],
        "state": "closed",
        "body": "Protobuf has been 3.1.0 since September and other projects have adopted it, and it appears google-cloud-java (specifically datastore) is using 3.0.0 which is causing us conflicts. \r\n\r\nAny plans to move to 3.1.0?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1361",
        "number": 1361,
        "title": "Dependency conflict when adding google-cloud-translate to Android app.",
        "labels": [],
        "state": "closed",
        "body": "This is essentially a dupe of [issue #1319](https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1319) but with Google Translate.\r\n\r\nI added the Google Translate Java client library to my Android app per [these instructions](https://cloud.google.com/translate/docs/reference/libraries#java-install), which consists of adding this line to my build.gradle file of my **library project** (which is a dependency of my app project):\r\n\r\n`compile group: 'com.google.cloud', name: 'google-cloud-translate', version: '0.4.0'`\r\n\r\nHowever when I build, I get this error:\r\n```\r\nError:Execution failed for task ':typeSmart:transformResourcesWithMergeJavaResForDebug'.\r\n> com.android.build.api.transform.TransformException: com.android.builder.packaging.DuplicateFileException: Duplicate files copied in APK META-INF/LICENSE\r\n\tFile1: C:\\Users\\Barry\\.gradle\\caches\\modules-2\\files-2.1\\com.google.auto.value\\auto-value\\1.1\\f6951c141ea3e89c0f8b01da16834880a1ebf162\\auto-value-1.1.jar\r\n\tFile2: C:\\Users\\Barry\\.gradle\\caches\\modules-2\\files-2.1\\org.codehaus.jackson\\jackson-core-asl\\1.9.11\\e32303ef8bd18a5c9272780d49b81c95e05ddf43\\jackson-core-asl-1.9.11.jar\r\n\tFile3: C:\\Users\\Barry\\.gradle\\caches\\modules-2\\files-2.1\\com.google.inject\\guice\\4.0\\f990a43d3725781b6db7cd0acf0a8b62dfd1649\\guice-4.0.jar\r\n```\r\n\r\nI tried all the suggestions in the other issue but I'm happy to go over them again.\r\n\r\nI'm using the latest version of Android Studio (2.2.2) with the Gradle wrapper.\r\n\r\nAny help is much appreciated. Thanks in advance!"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1360",
        "number": 1360,
        "title": "Error:Execution failed for task ':app:transformClassesWithDexForDebug'. > duplicate entry: com/google/protobuf/AbstractMessageLite$Builder$LimitedInputStream.class",
        "labels": [
            "android",
            "api: translation"
        ],
        "state": "closed",
        "body": "Hi, i am getting this error when i run my app with 'com.google.cloud:google-cloud-translate:0.5.0' dependency.\r\n\r\nNote: when i build my app, it gives 8  warnings with zero errors but when i run i am getting this error: **\"Error:Execution failed for task ':app:transformClassesWithJarMergingForDebug'.\r\n> com.android.build.api.transform.TransformException: java.util.zip.ZipException: duplicate entry: com/google/protobuf/AbstractMessageLite$Builder$LimitedInputStream.class**\r\n\r\nhow can i resolve it??/ "
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1359",
        "number": 1359,
        "title": "PubSub modifyAckDeadline question",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Given a MessageConsumer constructed like this:\r\n```Java\r\n MessageConsumer consumer = pubsub.pullAsync(\r\n        subscription,\r\n        messageProcessor,\r\n        PubSub.PullOption.maxQueuedCallbacks(maxQueuedCallbacks),\r\n        PubSub.PullOption.executorFactory(executorFactory)\r\n    );\r\n```\r\nHow can I modify the acknowledge deadline for a the message?\r\nTo use the `pubsub.modifyAckDeadline();` I need to know the ackId or ackId's but I can't get that from the process(Message) call.\r\n \r\n```Java\r\npublic class BuildEventHandler implements PubSub.MessageProcessor {\r\n  public void process(Message message) throws Exception {\r\n  }\r\n}\r\n```"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1357",
        "number": 1357,
        "title": "Make Key.toUrlSafe() consistent with the URL-safe key displayed in Google Cloud Datastore Console",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "The `Key.toUrlSafe()` returns a URL encoded (similar to `URLEncoder.encode`) version of the key like the one below: \r\n\r\n`partition_id+%7B%0A++project_id%3A+%22my-project%22%0A++namespace_id%3A+%22MyNamespace%22%0A%7D%0Apath+%7B%0A++kind%3A+%22MyEntity%22%0A++name%3A+%22MyKey%22%0A%7D%0A`\r\n\r\nThe Google Cloud Datastore Console displays a Base64 encoded version of the key, which looks something like - \r\n\r\n`agVoZWxsb3IPCxIHQWNjb3VudBiZiwIM`\r\n\r\nThe Console allows filtering on key by URL-safe key, which works fine if I use the URL-safe value displayed by the GCD Console, but does not work when using the value returned from `Key.toUrlSafe()`. \r\n\r\nThe Console Documentation states that - \r\n\r\n> **URL-safe key**\r\n> \r\n> This is a base64-encoded, serialized version of your entity key. **The encoding method is available in any Cloud Datastore client library**\r\n> \r\n> Example: agVoZWxsb3IPCxIHQWNjb3VudBiZiwIM\r\n\r\nSo, the client libraries are expected to match with the Base64 version? Nonetheless, it would be nice to have the client libraries and Console in sync to help with crosschecking/debugging purposes. \r\n\r\n\r\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1356",
        "number": 1356,
        "title": "Datastore: Divergence in failure treatments in add/put with multiples entities",
        "labels": [],
        "state": "closed",
        "body": "I'm using the following code block to generate a big random blob of characters\r\n\r\n```\r\nRandom r = new Random();\r\n\r\nint msgSize = 5200;  // in KB\r\nmsgSize = msgSize/2; // Java chars are 2 bytes\r\nmsgSize = msgSize * 1024;\r\nStringBuilder sb = new StringBuilder(msgSize);\r\nfor (int i=0; i<msgSize; i++) {\r\n    sb.append((char)(r.nextInt(26) + 'a'));\r\n}\r\n```\r\n\r\nI find that if I put a blob in an entity and store it...\r\n\r\n`entityBuilder.set(\"myTextBlob\", BlobValue.builder(Blob.copyFrom(sb.toString())).excludeFromIndexes(true).build());\r\n`\r\n\r\nAnd then build my entity and save it that it works... and all *other* properties make it into the datastore... but the blob property is silently dropped.  Is there a correct way to validate an entity before inserting it?  Datastore items are max 1MB in size right?"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1354",
        "number": 1354,
        "title": "GqlQuery#allowLiteral() - should it be renamed to isAllowLiteral()?",
        "labels": [],
        "state": "closed",
        "body": "`GqlQuery#allowLiteral()` - should it be renamed to `isAllowLiteral()`, for consistency?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1353",
        "number": 1353,
        "title": "DatastoreOptions.Builder#namespace(String) should be setNamespace ",
        "labels": [],
        "state": "closed",
        "body": "Just like how there is `setProjectId(String)`, `setAuthCredentials(AuthCredentials)`, need `setNamespace(String)` for consistency. Deprecate the `namespace(String)` method. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1352",
        "number": 1352,
        "title": "ValueBuilder - excludeFromIndexes - Method name consistency ",
        "labels": [],
        "state": "closed",
        "body": "The accessor methods for excludeFromIndexes in ValueBuilder are not consistent. Something to look into. \n\n`setExcludeFromIndexes(boolean)` is good. \n`excludeFromIndexes(boolean)` is Deprecated per the new conventions, so that is also good. \n\nThe Getter method is the one that is **not** consistent. Perhaps we need to add `isExcludeFromIndexes()` and deprecate `excludeFromIndexes()`? \n\n```\npublic interface ValueBuilder<V, P extends Value<V>, B extends ValueBuilder<V, P, B>> {\n\n  @Deprecated\n  boolean getExcludeFromIndexes();\n\n  boolean excludeFromIndexes();\n\n  @Deprecated\n  B excludeFromIndexes(boolean excludeFromIndexes);\n\n  B setExcludeFromIndexes(boolean excludeFromIndexes);\n//...\n}\n\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1351",
        "number": 1351,
        "title": "Transaction.Response - Both generatedKeys() and getGeneratedKeys() are marked as deprecated",
        "labels": [],
        "state": "closed",
        "body": "In the Datastore API 0.5.0, in Transaction.Response interface - Both generatedKeys() and getGeneratedKeys() are marked as deprecated. What is the alternative? I wonder if the new method getGeneratedKeys was unintentionally marked as deprecated? \n\n```\npublic interface Transaction extends DatastoreBatchWriter, DatastoreReaderWriter {\n\n  interface Response {\n    /**\n     * Returns a list of keys generated by a transaction.\n     */\n    @Deprecated\n    List<Key> generatedKeys();\n\n    /**\n     * Returns a list of keys generated by a transaction.\n     */\n    @Deprecated\n    List<Key> getGeneratedKeys();\n  }\n//...\n}\n\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1346",
        "number": 1346,
        "title": "Regression in storage url signing",
        "labels": [],
        "state": "closed",
        "body": "@ostronom @mziccard It seems #1277 has caused a regression in my code.  I use `/` characters in the blob names, and they are now being unexpectedly encoded as `%2F` in the signed path.\n\nIt seems that [object naming requirements](https://cloud.google.com/storage/docs/naming#objectnames) are not equivalent to URL encoding.\n\nWhen I round-trip a signed url, `Storage#get` now fails to find the successfully uploaded file (confirmed via `gsutil` and Cloud Console). \n\nMy understanding is that `/`s are valid characters for blob names. From the same page quoted above:\n\n> The canonical resource is everything that follows the host name. For example, if the Cloud Storage URL is https://storage.googleapis.com/example-bucket/cat-pics/tabby.jpeg, then the canonical resource is /example-bucket/cat-pics/tabby.jpeg.\n\nIt seems like this library needs to use a different escape function for object names. (Also, I noticed that the new test `testSignUrlForBlobWithSpecialChars`, does not cover slashes.)\n\nDoes this make sense? What is the intended behavior for blob names containing slashes?\n\n---\n\nrepro test:\n\n``` java\n    BlobInfo blobInfo1 = BlobInfo.builder(bucketName, \"foo/bar/baz #%20other cool stuff.txt\").build();\n    storage.create(blobInfo1, \"content\".getBytes());\n    URL url = storage.signUrl(\n        blobInfo1,\n        1,\n        TimeUnit.HOURS,\n        httpMethod(HttpMethod.PUT),\n        httpMethod(HttpMethod.GET)\n    );\n    final String[] split = url.getPath().split(\"/\");\n    Blob notFound = storage.get(split[1], split[2]); // unexpectedly null!\n    Blob found = storage.get(split[1], URLDecoder.decode(split[2])); // found, surprisingly\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1345",
        "number": 1345,
        "title": "Plans to harmonize authentication?",
        "labels": [],
        "state": "closed",
        "body": "@Horneth reports:\n\n> The class used for authentication in the google.cloud library (`com.google.cloud.AuthCredentials`) is different from the one in google.api.client (`com.google.api.client.auth.oauth2.Credential`). We need to maintain 2 different sets of authentication classes for the same authentication mode. I was wondering if there are any plans to harmonize those in the future.\n\nDo we have some guidance we can share, or plans to harmonize across these projects?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1344",
        "number": 1344,
        "title": "Unable to use pubsub and monitoring libraries in same Clojure project",
        "labels": [],
        "state": "closed",
        "body": "I would like to be able to use both \ncom.google.cloud/google-cloud \"0.4.0\"\nand \ncom.google.apis/google-api-services-monitoring \"v3-rev11-1.22.0\" in the same Clojure (Java) project. \n\nSpecifically, I am using PubSub to publish/subscribe messages while I am using the API to monitor the number of messages on the queue. In separate projects, both work fine. \nHowever, when used in the same project, I get the following error: \"NoSuchMethodError com.google.common.util.concurrent.MoreExecutors.directExecutor()Ljava/util/concurrent/Executor;  io.grpc.internal.ClientCallImpl.<init> (ClientCallImpl.java:103)\"\n\nThis seems to be due to (perhaps) conflicting dependencies in the two libraries. Is there an easy way to solve this?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1343",
        "number": 1343,
        "title": "NIO: Using custom options reduces cross-bucket performance",
        "labels": [
            "api: storage",
            "performance",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`google-cloud-nio` normally uses the default credentials, but there's an \"escape hatch\" to provide your own:\n\n[`CloudStorageFileSystem.forBucket(String bucket, CloudStorageConfiguration config)`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageFileSystem.java#L90). \n\nAn unexpected side effect of the way the code is written is that when using custom credentials, bucket-to-bucket copies are slower.\n\nThe reason is that this creates a new `CloudStorageFileSystemProvider`. When asking for a copy across providers, NIO will read from one and write to the other (thus routing all the data via the client's computer). Instead, when it's the same provider, NIO can use the far more efficient copy method (data then don't have to leave the datacenter).\n\nA natural fix would be for our code to check whether the passed `config` was seen before and, if so, reuse the same `CloudStorageFileSystemProvider`. This could be done directly by our users as a workaround, but it makes sense for us to do it transparently.\n\ncc:@mziccard, @jart\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1339",
        "number": 1339,
        "title": "JavaDoc not clear as it could be, e.g. Datastore.add vs. Datastore.put",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "What's the difference between Datastore.add and Datastore.put?\n\nAm I right in assuming that \"add\" will **not** clobber existing entities?  \n\nMaybe a quick update to the javadoc to clarify--would be much appreciated!!!\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1338",
        "number": 1338,
        "title": "Changing over pub sub from google client libraries to Google cloud java has increased tail latencies",
        "labels": [
            "api: pubsub",
            "performance"
        ],
        "state": "closed",
        "body": "Hi team, I wasn't sure where to file this issue\n\nHere is the chart from our production where we measure roundtrip latencies on messages sent through pub-sub as measured by the same server. \n\nAs you can see before the big spike we were on the old Google client libraries the performance was stellar. with p99 close to p50 at around 120ms\nThe big spike you see is moving over to the Google cloud java version of the pubsub library.\nThe lower period after that is us moving to directly using the grpc stubs.\n\nThe take-away is that GRPC based pub-sub (with return immediately = false) is much worse than what we used to have when we were on the google client library version of pubsub.\n\nEven today in production I can consistenly see roundtrip latencies varying from  120-180s range that spikes to 4-6s every now and then. This was solidly steady in the 120ms range previously.\n\n<img width=\"1230\" alt=\"screen shot 2016-10-26 at 1 12 47 pm\" src=\"https://cloud.githubusercontent.com/assets/11711723/19738670/f2f787fa-9b7d-11e6-8a64-b1df592d5f45.png\">\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1336",
        "number": 1336,
        "title": "Can't set CORS to `<Origin>*</Origin>` when initiating resumable uploads?",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "https://cloud.google.com/storage/docs/cross-origin#How_CORS_Works:\n\n> When using the resumable upload protocol, the Origin from the first (start upload) request is always used to decide the Access-Control-Allow-Origin header in the response, even if you use a different Origin for subsequent requests. Therefore, you should either use the same Origin for the first and subsequent requests, or if the first request has a different Origin than subsequent requests, use the XML API with the CORS configuration set to <Origin>*</Origin>.\n\nI'm initiating resumable uploads from my server, sending the generated upload URL to my clients (web/mobile apps), and then having them actually POST files to Google Cloud Storage. It seems I need CORS configured to `<Origin>*</Origin>` to support this, but I don't see a way to do so in the SDK. Is there a solution I'm missing?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1334",
        "number": 1334,
        "title": "Index.yaml location",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "I'm running my application as a Jetty jar: `java -jar app.jar` will start a webserver on `$PORT`, which serves both static files and services API calls.\n\nI'm having an issue with datastore indices not being honoured. I've followed the instructions both on [`google-cloud-java`](https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-datastore#running-a-query) and its linked [datastore-index-specific page](https://cloud.google.com/datastore/docs/tools/indexconfig), which appears to state that the index configuration `index.yaml` should be in `WEB-INF/index.yaml` in my jar:\n\n> The index.yaml is located in the <project-directory>/WEB-INF/ folder.\n\nHowever, even with this `index.yaml` file configured, my datastore requests are still failing:\n\n```\nCaused by: com.google.datastore.v1.client.DatastoreException: no matching index found. recommended index is:\n- kind: TextMessage\n  properties:\n  - name: sender\n  - name: date\n```\n\nIs my `index.yaml` in the correct spot? Can I provide the `index.yaml` resource path to the Client Datastore API? Is the `index.yaml` supposed to be visible on my app via an `http` request?\n\nFor reference, my `index.yaml` is:\n\n```\nindexes:\n- kind: TextMessage\n  properties:\n  - name: sender\n  - name: date\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1332",
        "number": 1332,
        "title": "remove unneeded dependencies from nio",
        "labels": [],
        "state": "closed",
        "body": "mziccard noticed the following with google-cloud-nio:\n1.  org.mockito:mockito-core dependency should have test scope\n2.  google-cloud-nio now depends on the whole google-cloud, we should depend just on google-cloud-storage\n3.  To make 2. effective we need to also remove google-cloud dependency from google-cloud-contrib main pom.xml, we can let each child module pull its own dependencies.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1331",
        "number": 1331,
        "title": "Using Pub/Sub JAVA client in play framework 2.5 - netty conflicts",
        "labels": [
            "api: logging",
            "api: pubsub",
            "dependencies",
            "priority: p2",
            "status: blocked",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "Issue summary: Client's services are built on top of the play framework 2.5. Some of their services need to publish messages to pub/sub, but the Google Pub/Sub java api depends on netty 4.1.x, which conflicts with netty 4.0.x used by play framework 2.5.\nIs there a solution to get around this?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1329",
        "number": 1329,
        "title": "Allow customization for context of LogEntry instances created by LoggingHandler ",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "The https://github.com/GoogleCloudPlatform/jetty-runtime needs to be able to generate stackdriver log messages with the label `traceid` set the the value obtained from the `x-cloud-trace-context` HTTP header.\n\nHowever, the [LoggingHandler#getLogEntry](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/v0.4.0/google-cloud-logging/src/main/java/com/google/cloud/logging/LoggingHandler.java#L296) method does not allow for easy extension to support traceid as the method is private rather than protected, thus to change behaviour more methods on the class need to be replaced to customize the LogEntry.\n\nIf this method could be made protected, then it would be easy to extend the handler to use a threadlocal label map to set additional labels (eg traceid).\n\nBetter yet, such a threadlocal context could be implemented as a standard feature of the LogHandler?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1328",
        "number": 1328,
        "title": "Client Datastore API with App Engine Devserver",
        "labels": [],
        "state": "closed",
        "body": "I've investigated into #216, but I can't quite get my Client Datastore connection to work with the App Engine Devserver.\n\nI've tried:\n\n```\n# No environment variables, DatastoreOptions.defaultInstance().service()\ncom.google.datastore.v1.client.DatastoreException: Request had invalid authentication credentials.\n\n# DATASTORE_EMULATOR_HOST=localhost:8080\n# DatastoreOptions.defaultInstance().service()\nWARNING: No file found for: /v1/projects/navistream2dev:runQuery\nSEVERE: com.google.cloud.datastore.DatastoreException: Non-protobuf error: <html><head><title>Error 404</title></head>\n<body><h2>Error 404</h2></body>\n</html>. HTTP status code was 404.\n\n# export DATASTORE_PROJECT_ID=navistream2dev   \n# export DATASTORE_EMULATOR_HOST=localhost:8080\n# DatastoreOptions.defaultInstance().service()\nWARNING: No file found for: /v1/projects/navistream2dev:runQuery\nSEVERE: com.google.cloud.datastore.DatastoreException: Non-protobuf error: <html><head><title>Error 404</title></head>\n<body><h2>Error 404</h2></body>\n</html>. HTTP status code was 404.\n\n# export DATASTORE_PROJECT_ID=navistream2dev\n# DatastoreOptions.defaultInstance().service()\nWARNING: failed _ah_AbandonedTransactionDetector: java.lang.RuntimeException: Could not get Cloud Datastore options from environment.\nOct 20, 2016 4:45:00 PM com.google.apphosting.utils.jetty.JettyLogger warn\nWARNING: Failed startup of context com.google.appengine.tools.development.DevAppEngineWebAppContext@21ffbe3b{/,/home/mitch/dev/navistream/server/navistream/build/exploded-app}\njava.lang.RuntimeException: Could not get Cloud Datastore options from environment.\nCaused by: java.io.IOException: Application Default Credentials failed to create the Google App Engine service account credentials class com.google.appengine.repackaged.com.google.api.client.googleapis.extensions.appengine.auth.oauth2.AppIdentityCredential$AppEngineCredentialWrapper. Check that the component 'google-api-client-appengine' is deployed.\nCaused by: java.lang.ClassNotFoundException: com.google.appengine.repackaged.com.google.api.client.googleapis.extensions.appengine.auth.oauth2.AppIdentityCredential$AppEngineCredentialWrapper\n\n// Interestingly, this is trying to get `AppIdentityCredential` from \"com.google.appengine.repackaged.com.google.api...\", rather than from \"com.google.api...\"\n```\n\nAm I missing an environment variable for configuration to make this work nicely?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1325",
        "number": 1325,
        "title": "Client Datastore API: writing \"Text\" values",
        "labels": [],
        "state": "closed",
        "body": "Hello again!\n\nAccording to the [App Engine Entity Property Reference](https://cloud.google.com/appengine/docs/java/datastore/entity-property-reference), there's a \"Text\" data type which allows Strings up to 1MB.\n\nHowever, with the Client Datastore, the only text-related `Value` type is `StringValue`. How can I store a `Text` value? I was considering `Blob`, but that's actually its own, separate type in Datastore (according to the Entity Property Reference)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1324",
        "number": 1324,
        "title": "README.md, TESTING.md, etc - should use merged code instead of untested code.",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently, we merge snippets (which are tested) into files that we generate our JavaDocs against.  It would be great if we also did this for our all our `README`'s as they aren't tested currently.\n\nIt should be possible to use hidden tags like:\n\n`<!-- [INCLUDE blah] -->`\n\nIn any `*.md` file\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1320",
        "number": 1320,
        "title": "Is this library thread safe?",
        "labels": [],
        "state": "closed",
        "body": "Hi, all.\n\nHow do we talk about the thread safety of the client library for Pub/Sub specifically?  Are the HTTP2 connections shared in gRPC cases? What about HTTP1 connections in the fallback case? Are there any other cases where thread safety might be an issue?\n\nKIr\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1319",
        "number": 1319,
        "title": "internal dependency conflict appears when compiling google-cloud-pubsub",
        "labels": [],
        "state": "closed",
        "body": "Reposting this submission to cloud-pubsub-discuss@googlegroups.com as a bug: \n\nThe cloud pubsub library is not working with Android Studio 2.2.1 (Build #AI-145.3330264, built on October 6, 2016, JRE: 1.8.0_76-release-b03 amd64, JVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o) under Debian (3.2.0-4-amd64 #1 SMP Debian 3.2.81-2 x86_64 GNU/Linux). \n\nI added [compile group: 'com.google.cloud', name: 'google-cloud-pubsub', version: '0.4.0'] to gradle file, but it states the following: \"Execution failed for task ':app:prepareDebugAndroidTestDependencies'.>Dependency Error. See console for details.\" \n\nI checked the console and the output shows the following: \"Conflict with dependency 'com.google.code.findbugs:jsr305'. Resolved versions for app (3.0.0) and test app (2.0.1) differ. See http://g.co/androidstudio/app-test-app-conflict for details.\".\n\nI tried to solve it by adding the following line to the android{} section of gradle file: \"configurations.all { resolutionStrategy.force 'com.google.code.findbugs:jsr305:3.0.0' }\", but it resulted in the following output in console(see below):\n\"Error:FAILURE: Build failed with an exception.\n- What went wrong:\n  Execution failed for task ':app:transformResourcesWithMergeJavaResForDebug'.\n  \n  > com.android.build.api.transform.TransformException: com.android.builder.packaging.DuplicateFileException: Duplicate files copied in APK META-INF/LICENSE\n  >   File1: /home/debi/.gradle/caches/modules-2/files-2.1/com.google.auto.value/auto-value/1.1/f6951c141ea3e89c0f8b01da16834880a1ebf162/auto-value-1.1.jar\n  >   File2: /home/debi/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-core-asl/1.9.11/e32303ef8bd18a5c9272780d49b81c95e05ddf43/jackson-core-asl-1.9.11.jar\n  >   File3: /home/debi/.gradle/caches/modules-2/files-2.1/com.google.inject/guice/4.0/f990a43d3725781b6db7cd0acf0a8b62dfd1649/guice-4.0.jar\n- Try:\n  Run with --stacktrace option to get the stack trace. Run with --debug option to get more log output. \"\n\nWhat should I do?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1318",
        "number": 1318,
        "title": "[PubSub] Exception thrown at run-time, related to Pubsub builder",
        "labels": [],
        "state": "closed",
        "body": "Hello, I'm currently trying to use the **pubsub** library in a **clojure** project, but keep running into a problem.\n\nAt run-time, my project throws this exception when I try and instantiate my PubSub object: \n\n```\nAbstractMethodError io.netty.util.concurrent.MultithreadEventExecutorGroup.newChild(Ljava/util/concurrent/Executor;\n[Ljava/lang/Object;)Lio/netty/util/concurrent/EventExecutor;  \nio.netty.util.concurrent.MultithreadEventExecutorGroup.<init> (MultithreadEventExecutorGroup.java:84)\n```\n\nThis is how I've tried setting up the object: \n`pubsubClient (-> (PubSubOptions/defaultInstance) (.service))`\n\nI've also tried this method: \n`pubsubClient (-> (PubSubOptions/builder) (.build) (.service))`\n\nUsing logs, I've been able to pinpoint the exception to this line, but I can't figure out why it's happening. This library works just fine in Scala, any one know what I'm missing here?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1314",
        "number": 1314,
        "title": "Client Datastore API: default consistency of 1.0 when testing",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "I just spent a few hours debugging flaky tests, and I _finally_ realized that it was due to the \"consistency\" settings that I was using.\n\nWhen `LocalDatastoreHelper.create()` is called, perhaps a default consistency of `1.0` should be used? Otherwise, integration tests to verify proper API usage will \"randomly\" fail, even if the tests are fairly small.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1309",
        "number": 1309,
        "title": "io.grpc.StatusRuntimeException: UNAVAILABLE: The service was unable to fulfill your request. Please try again. [code=8a75]",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "We started seeing this issue today. Is there a service outage happening?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1307",
        "number": 1307,
        "title": "Datastore Viewer",
        "labels": [],
        "state": "closed",
        "body": "I'm currently migrating from the Google App Engine development environment to a more discrete environment, using the Client Datastore API to manage data. When developing with App Engine, I would be able to start a \"Devserver\", which would run my app's `war` file and provide helpful tooling, like the Datastore Viewer:\n\n![2016-10-03-162356_1716x282_scrot](https://cloud.githubusercontent.com/assets/7784737/19057620/0fd1d0a6-8986-11e6-8a4e-82326741001e.png)\n\nDoes Google Cloud's Datastore Emulator provide a Datastore Viewer? If not, then this is a feature request :smile:\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1305",
        "number": 1305,
        "title": "Add support for RuntimeConfig API",
        "labels": [
            "api: runtimeconfig",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "There is a RuntimeConfig API, which is useful for storing configuration values.\n\nSee:\nhttps://cloud.google.com/deployment-manager/runtime-configurator/reference/rest/\n\nI started adding support in Python. https://github.com/GoogleCloudPlatform/google-cloud-python/pull/2485 I'd love to have this for Java, too.\n\nThe most important methods for my use cases (and most Cloud samples/applications in general, I believe) are listing variables and getting variable values. I wouldn't expect the watcher API to be supported yet, or even create/update methods, since in general the workflow will be to set variables from the command-line and read the latest value on app start-up.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1300",
        "number": 1300,
        "title": "It is too slow testing Datastore locally when use LocalDatastoreHelper",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "It is too slow testing Datastore locally when we use `com.google.cloud.datastore.testing.LocalDatastoreHelper` in `google-cloud-0.4.0` with `cloud-datastore-emulator 1.2.1`.\n\nI figure out  `LocalDatastoreHelper` define `private static final String GCD_VERSION = \"1.2.0\";` and lastest gcloud datastore version is `cloud-datastore-emulator 1.2.1` (`gcloud-tools` current version is `128.0.0`).  So, when we test by using LocalDatastoreHelper, it cannot find the `cloud-datastore-emulator 1.2.0` version in gcloud path, and as result, it ends up making download of `cloud-datastore-emulator 1.2.1` for each test case.\n\nTo solve this problem, I had to downgrade the `gcloud-tools` to `125.0.0`. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1299",
        "number": 1299,
        "title": "setReturnImmediately is not configurable in this version of pubsub api",
        "labels": [],
        "state": "closed",
        "body": "setReturnImmediately(true). This causes latency issues for us. We would like to go back to the long poll. Please expose a way for that\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1292",
        "number": 1292,
        "title": "Datastore Testing: Wiping data between tests?",
        "labels": [],
        "state": "closed",
        "body": "I'm migrating from the App Engine Datastore API to the Cloud Datastore API (so that I can connect to Datastore from a VPS). A happy thing about the previous API is that it didn't spin up a separate emulator process (5+ seconds) when `helper.setUp()` is called. With the Cloud Datastore API, it's a different model, so it's a little slower.\n\nI don't want to have to entirely restart my Datastore emulator between tests, but I want a clean slate. Can I either:\n- Still have an in-process datastore implementation to test against, which is fast?\n- Clear the remote emulator datastore, so it doesn't need to be fully restarted?\n\nI've looked through `LocalDatastoreHelper`, `DatastoreOptions` and `Datastore` itself, but I can't find any immediately solutions to my problem.\n\nNote: I can't just `@After` and delete a set of keys, since some tests involve letting Datastore choose the `id` of an inserted entity\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1291",
        "number": 1291,
        "title": "Datastore upgrade before Sep 30th",
        "labels": [],
        "state": "closed",
        "body": "We are using dataflow api with protobuf and google api's like datastore, ads, bigquery and lot more other apis. Now we got an email to update the datastore-api to v1 (currrently using protobuf 2.6.1 and other v1beta2: datastore).\n\nI see lot of different versions of datastore and I'm not sure what exact version to use ?\n\nI just picked one and updated all the places which gave me compilation errors and when I try to run it in GCE I  hit #1239 .\n\nIs there a migration guide for datastore  ? I'm curious even if I migrate datastore would all these work with a new protobuf version suggested in #1239 . If we have other apis working together in dataflow pipeline what is the best way to do this migration ?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1289",
        "number": 1289,
        "title": "Retry ExceptionHandler could be set through ServiceOptions",
        "labels": [],
        "state": "closed",
        "body": "The [StorageImpl](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-storage/src/main/java/com/google/cloud/storage/StorageImpl.java#L107) class and others use the [EXCEPTION_HANDLER defined in the BaseService class](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/BaseService.java#L47) when invoking [runWithRetries](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/RetryHelper.java#L238). \n\nThe RetryParams and Clock can be set in the [ServiceOptions](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java) and will be used when invoking `runWithRetries`, however the exception handler seems hardcoded.\n\nIs that a definitive decision or would it be possible to have the exception handler also be passed through the options ?\n# Why\n\nIn order to be particularly resilient to transient errors it would be beneficial to be able to retry on a larger set of exceptions.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1285",
        "number": 1285,
        "title": "Google cloud storage class and location",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Is there any example showing how to set the storage class and location of a bucket with the Google storage API ?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1284",
        "number": 1284,
        "title": "Error with gcloud-java-datastore",
        "labels": [],
        "state": "closed",
        "body": "Hey all,\n\nI am facing some issues with the google datastore sdk. It looks like some incompatibilities with packaged proto classes. The error I am seeing is: \n\n`java.lang.VerifyError: Bad return type\nException Details:\n  Location:\n    com/google/cloud/datastore/PathElement.toPb()Lcom/google/protobuf/GeneratedMessage; @4: areturn\n  Reason:\n    Type 'com/google/datastore/v1/Key$PathElement' (current frame, stack[0]) is not assignable to 'com/google/protobuf/GeneratedMessage' (from method signature)\n  Current Frame:\n    bci: @4\n    flags: { }\n    locals: { 'com/google/cloud/datastore/PathElement' }\n    stack: { 'com/google/datastore/v1/Key$PathElement' }`\n\nHas anyone seen that issue?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1281",
        "number": 1281,
        "title": "Stack Overflow link update on client library ref landing page",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "On the [current landing page for google-cloud-java](http://googlecloudplatform.github.io/google-cloud-java) there is a Stack Overflow icon:\n\n![image](https://cloud.githubusercontent.com/assets/6609430/18824123/8f7ada86-8374-11e6-9807-687667b0d488.png)\n\n[Current Result]\nThat icon currently points to http://stackoverflow.com/questions/tagged/gcloud-java\n\n[Expected Result]\nThe icon should now point to: http://stackoverflow.com/questions/tagged/google-cloud-platform+java\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1278",
        "number": 1278,
        "title": "Datastore: duplicate classes in dependencies",
        "labels": [],
        "state": "closed",
        "body": "Using the com.google.cloud:google-cloud-datastore jar version 0.3.0 as a dependency in my project resulted in a lot of transitive dependency jars. I ran the [duplicate-finder plugin](https://github.com/basepom/duplicate-finder-maven-plugin/wiki) and it came up with duplicate classes in multiple of the datastore dependenies. Might be something you can do to exclude some of the dependencies?\n[duplicate-finder.txt](https://github.com/GoogleCloudPlatform/google-cloud-java/files/489209/duplicate-finder.txt)\n\n?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1276",
        "number": 1276,
        "title": "Support Cloud Storage library on local App Engine development server",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "This is somewhat related to #684 but not exactly. I would like to use this library with the existing App Engine development server, not a separate server, because I would need Blobstore and Images APIs to have access to the blobs uploaded through GCS API and use GCS API to read blobs uploaded through Blobstore. Currently the GCS App Engine library contains only a subset of the functionality (I guess it was meant to cover only the functionality that's not in Blobstore API). I would like to gradually replace usage of Blobstore API and GCS GAE with this library.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1271",
        "number": 1271,
        "title": "Dependency Count",
        "labels": [],
        "state": "closed",
        "body": "I am considering this project as a default way to use google cloud with java. (Please correct me if I am wrong.)\n\nI wanted to give a try Stackdriver Logging and for this purpose I added dependency `google-cloud-logging:0.3.0` but I am a little bid shocked because it is transitively pulling more than 50 dependency. I believe that a foundation project like this should include as less as possible. \n\nHere are the dependencies:\n\n```\n[INFO] \\- com.google.cloud:google-cloud-logging:jar:0.3.0:compile\n[INFO]    +- io.netty:netty-tcnative-boringssl-static:jar:1.1.33.Fork17:compile\n[INFO]    +- com.google.cloud:google-cloud-core:jar:0.3.0:compile\n[INFO]    |  +- com.google.auth:google-auth-library-credentials:jar:0.3.1:compile\n[INFO]    |  +- com.google.auth:google-auth-library-oauth2-http:jar:0.3.1:compile\n[INFO]    |  |  \\- com.google.http-client:google-http-client-jackson2:jar:1.19.0:compile\n[INFO]    |  |     \\- com.fasterxml.jackson.core:jackson-core:jar:2.8.1:compile\n[INFO]    |  +- com.google.http-client:google-http-client:jar:1.21.0:compile\n[INFO]    |  |  +- com.google.code.findbugs:jsr305:jar:1.3.9:compile\n[INFO]    |  |  \\- org.apache.httpcomponents:httpclient:jar:4.5.2:compile\n[INFO]    |  |     +- org.apache.httpcomponents:httpcore:jar:4.4.5:compile\n[INFO]    |  |     \\- commons-codec:commons-codec:jar:1.10:compile\n[INFO]    |  +- com.google.oauth-client:google-oauth-client:jar:1.21.0:compile\n[INFO]    |  +- com.google.guava:guava:jar:19.0:compile\n[INFO]    |  +- com.google.api-client:google-api-client-appengine:jar:1.21.0:compile\n[INFO]    |  |  +- com.google.oauth-client:google-oauth-client-appengine:jar:1.21.0:compile\n[INFO]    |  |  |  +- com.google.oauth-client:google-oauth-client-servlet:jar:1.21.0:compile\n[INFO]    |  |  |  |  \\- com.google.http-client:google-http-client-jdo:jar:1.21.0:compile\n[INFO]    |  |  |  \\- javax.servlet:servlet-api:jar:2.5:compile\n[INFO]    |  |  +- com.google.api-client:google-api-client:jar:1.21.0:compile\n[INFO]    |  |  +- com.google.api-client:google-api-client-servlet:jar:1.21.0:compile\n[INFO]    |  |  |  \\- javax.jdo:jdo2-api:jar:2.3-eb:compile\n[INFO]    |  |  |     \\- javax.transaction:transaction-api:jar:1.1:compile\n[INFO]    |  |  \\- com.google.http-client:google-http-client-appengine:jar:1.21.0:compile\n[INFO]    |  +- com.google.http-client:google-http-client-jackson:jar:1.21.0:compile\n[INFO]    |  |  \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.11:compile\n[INFO]    |  +- joda-time:joda-time:jar:2.9.4:compile\n[INFO]    |  +- org.json:json:jar:20140107:compile\n[INFO]    |  +- com.google.protobuf:protobuf-java:jar:3.0.0-beta-3:compile\n[INFO]    |  +- com.google.api:gax:jar:0.0.16:compile\n[INFO]    |  |  \\- com.google.inject:guice:jar:4.0:compile\n[INFO]    |  |     +- javax.inject:javax.inject:jar:1:compile\n[INFO]    |  |     \\- aopalliance:aopalliance:jar:1.0:compile\n[INFO]    |  \\- com.google.api.grpc:grpc-google-common-protos:jar:0.0.7:compile\n[INFO]    +- com.google.api.grpc:grpc-google-logging-v2:jar:0.0.7:compile\n[INFO]    +- io.grpc:grpc-all:jar:0.15.0:compile\n[INFO]    |  +- io.grpc:grpc-auth:jar:0.15.0:compile\n[INFO]    |  +- io.grpc:grpc-netty:jar:0.15.0:compile\n[INFO]    |  |  \\- io.netty:netty-codec-http2:jar:4.1.1.Final:compile (version selected from constraint [4.1.1.Final,4.1.1.Final])\n[INFO]    |  |     +- io.netty:netty-codec-http:jar:4.1.1.Final:compile\n[INFO]    |  |     |  \\- io.netty:netty-codec:jar:4.1.1.Final:compile\n[INFO]    |  |     \\- io.netty:netty-handler:jar:4.1.1.Final:compile\n[INFO]    |  |        +- io.netty:netty-buffer:jar:4.1.1.Final:compile\n[INFO]    |  |        |  \\- io.netty:netty-common:jar:4.1.1.Final:compile\n[INFO]    |  |        \\- io.netty:netty-transport:jar:4.1.1.Final:compile\n[INFO]    |  |           \\- io.netty:netty-resolver:jar:4.1.1.Final:compile\n[INFO]    |  +- io.grpc:grpc-okhttp:jar:0.15.0:compile\n[INFO]    |  |  +- com.squareup.okio:okio:jar:1.6.0:compile\n[INFO]    |  |  \\- com.squareup.okhttp:okhttp:jar:2.5.0:compile\n[INFO]    |  +- io.grpc:grpc-protobuf-nano:jar:0.15.0:compile\n[INFO]    |  |  \\- com.google.protobuf.nano:protobuf-javanano:jar:3.0.0-alpha-5:compile\n[INFO]    |  +- io.grpc:grpc-stub:jar:0.15.0:compile\n[INFO]    |  +- io.grpc:grpc-protobuf:jar:0.15.0:compile\n[INFO]    |  |  \\- com.google.protobuf:protobuf-java-util:jar:3.0.0-beta-3:compile\n[INFO]    |  |     \\- com.google.code.gson:gson:jar:2.7:compile\n[INFO]    |  +- io.grpc:grpc-protobuf-lite:jar:0.15.0:compile\n[INFO]    |  \\- io.grpc:grpc-core:jar:0.15.0:compile (version selected from constraint [0.15.0,0.15.0])\n[INFO]    \\- com.google.auto.value:auto-value:jar:1.1:compile\n```\n\nIf I counted right, there is 56 dependency for just transporting logging statements. \n\nWould you consider decreasing dependencies? \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1267",
        "number": 1267,
        "title": "google-cloud makes endpoints-framework wont work",
        "labels": [],
        "state": "closed",
        "body": "When we put the google-cloud dependency in last endpoints framework sample, you can deploy everythink normally, but when try to request endpoins, it return an error.\n\n**To reproduce this error:** \n\n**1. Clone this sample from github:**\n[https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/appengine/endpoints-frameworks-v2/backend](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/appengine/endpoints-frameworks-v2/backend)\n\n**2. Add Google Cloud Dependency:**\n\n```\n    <dependency>\n        <groupId>com.google.cloud</groupId>\n        <artifactId>google-cloud</artifactId>\n        <version>0.3.0</version>\n    </dependency>\n```\n\n**3. Deploy in google cloud**\n\n**4. Test request**\n\n`curl  -H \"Content-Type: application/json\"  -X POST  -d \"{\\\"message\\\":\\\"echo\\\"}\" https://{service-subdomain}.appspot.com/_ah/api/echo/v1/echo`\n\n**5. Wait reponse from echo request, and you got it:**\n\n```\n    <HTML>\n    <HEAD>\n    <TITLE>Internal Server Error</TITLE>\n    </HEAD>\n    <BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\">\n    <H1>Internal Server Error</H1>\n    <H2>Error 500</H2>\n    </BODY>\n    </HTML>\n```\n\n**Console report error:**\n\n> java.lang.NoClassDefFoundError: com/google/protobuf/AbstractMessage$BuilderParent\n> at com.google.api.servicecontrol.v1.ReportRequest.toBuilder (ReportRequest.java:369)\n> at com.google.api.servicecontrol.v1.ReportRequest.newBuilder (ReportRequest.java:363)\n> at com.google.api.control.aggregator.ReportRequestAggregator.generatedFlushRequests (ReportRequestAggregator.java:212)\n> at com.google.api.control.aggregator.ReportRequestAggregator.flush (ReportRequestAggregator.java:166)\n> at com.google.api.control.Client.flushAndScheduleReports (Client.java:335)\n> at com.google.api.control.Client.initializeFlushing (Client.java:270)\n> at com.google.api.control.Client.start (Client.java:127)\n> at com.google.api.control.ControlFilter.init (ControlFilter.java:118)\n> at org.mortbay.jetty.servlet.FilterHolder.doStart (FilterHolder.java:97)\n> at org.mortbay.component.AbstractLifeCycle.start (AbstractLifeCycle.java:50)\n> at org.mortbay.jetty.servlet.ServletHandler.initialize (ServletHandler.java:662)\n> at org.mortbay.jetty.servlet.Context.startContext (Context.java:140)\n> at org.mortbay.jetty.webapp.WebAppContext.startContext (WebAppContext.java:1250)\n> at org.mortbay.jetty.handler.ContextHandler.doStart (ContextHandler.java:517)\n> at org.mortbay.jetty.webapp.WebAppContext.doStart (WebAppContext.java:467)\n> at org.mortbay.component.AbstractLifeCycle.start (AbstractLifeCycle.java:50)\n> at com.google.apphosting.runtime.jetty.AppVersionHandlerMap.createHandler (AppVersionHandlerMap.java:206)\n> at com.google.apphosting.runtime.jetty.AppVersionHandlerMap.getHandler (AppVersionHandlerMap.java:179)\n> at com.google.apphosting.runtime.jetty.JettyServletEngineAdapter.serviceRequest (JettyServletEngineAdapter.java:136)\n> at com.google.apphosting.runtime.JavaRuntime$RequestRunnable.run (JavaRuntime.java:504)\n> at com.google.tracing.TraceContext$TraceContextRunnable.runInContext (TraceContext.java:446)\n> at com.google.tracing.TraceContext$TraceContextRunnable$1.run (TraceContext.java:453)\n> at com.google.tracing.CurrentContext.runInContext (CurrentContext.java:276)\n> at com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContextNoUnref (TraceContext.java:312)\n> at com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContext (TraceContext.java:304)\n> at com.google.tracing.TraceContext$TraceContextRunnable.run (TraceContext.java:450)\n> at com.google.apphosting.runtime.ThreadGroupPool$PoolEntry.run (ThreadGroupPool.java:235)\n> at java.lang.Thread.run (Thread.java:745)\n> \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1266",
        "number": 1266,
        "title": "DatasetInfo could use a static of() method",
        "labels": [],
        "state": "closed",
        "body": "### What:\n\nAdd a static `of()` method to `DatasetInfo`, like `JobInfo` and `TableId` have.\n### Why:\n\nIt looks nicer than explicitly constructing a builder and then calling `build()` on it. See sample I wrote for `create(DatasetInfo)` and how it could be simplified a bit.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1265",
        "number": 1265,
        "title": "Not obvious what *Options do in create() methods",
        "labels": [
            "api: core",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "### What:\n\nAdd documentation to [create() methods](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-bigquery/src/main/java/com/google/cloud/bigquery/BigQuery.java#L444), explaining that the `*Option`s filter the fields in the results. They do not affect the creation itself.\n### Why:\n\nIt took me more than an hour to figure this out.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1258",
        "number": 1258,
        "title": "BigQuery - No way to create a Job from just a Job ID without doing an RPC to create one.",
        "labels": [
            "api: bigquery",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I wanted to create a Job object for a JobId of a job that doesn't exist. This was to check the Job.exists() method. It also would be useful for an architecture where one process creates a job and then sends the job ID string to another process to check for the status.\n\nIt appears that there is no way to create a Job except for BigQuery.create http://googlecloudplatform.github.io/google-cloud-java/0.3.0/apidocs/index.html\n\nAll the builder constructors and actual constructors are package-private.\nhttp://googlecloudplatform.github.io/google-cloud-java/0.3.0/apidocs/com/google/cloud/bigquery/Job.html\n\nI tried using some of the `of()` methods inherited from JobInfo but the compiler complained that they returned a JobInfo, not a Job.\n\nCC @lesv \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1257",
        "number": 1257,
        "title": "Bug: BigQuery: Need a way to set JobId...",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "There doesn't appear to be a way to set the JobId, making cancel(String JobiD) challenging.\n\nLooking at [Python](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/bigquery/cloud-client/async_query.py#L34-L37) L35, The query Job takes a JobId.  There doesn't appear to be a similar method for Java. ;(\n\n```\n    client = bigquery.Client()\n    query_job = client.run_async_query(str(uuid.uuid4()), query)\n    query_job.use_legacy_sql = False\n    query_job.begin()\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1254",
        "number": 1254,
        "title": "BUG: Bigquery.create(JobInfo ...) param should be jobInfo, not job",
        "labels": [],
        "state": "closed",
        "body": "Especially since the result is a Job\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1253",
        "number": 1253,
        "title": "Insufficient authentication scopes for Logging",
        "labels": [],
        "state": "closed",
        "body": "I am using the following code from the example:\n\n```\nLoggingOptions logginsOptions = LoggingOptions.defaultInstance();\nLogging logging = logginsOptions.service();\n```\n\nWhen I run the app on Compute Engine, I get the following error:\n\n`com.google.cloud.logging.LoggingException: io.grpc.StatusRuntimeException: PERMISSION_DENIED: Request had insufficient authentication scopes.`\n\nI use similar code to initialize Datastore and Storage, and that codes works fine. There is no mention of scopes in the examples, and I could not find a clear explanation in the documentation what scopes need to be provided, if any.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1246",
        "number": 1246,
        "title": "com.google.cloud.datastore.DatastoreException: The value of property is longer than 1500 bytes",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Hello, \n\nI'm using the new google-cloud-datastore 0.3.0\n\nI'm trying to write a json object into the datastore, this object can be larger than 1500 bytes.\n\nThis is my code:\n\n`Entity entity = Entity.builder(syncKey)\n                    .set(\"id\", objId)\n                    .set(\"json_obj\", Blob.copyFrom(objJson.toString().getBytes()))\n                    .set(\"status\", \"on_progress\")\n                    .set(\"type\", syncLocation)\n                    .set(\"started_at\", DateTime.now())\n                    .build();\n                datastore.put(entity);`\n\nAnd I'm getting this exception: \n`\"Code: 3 Message: The value of property \"json_obj\" is longer than 1500 bytes. - com.google.cloud.datastore.DatastoreException: The value of property \"json_obj\" is longer than 1500 bytes.`\n\nI thought the blob object didn't have a 1500 bytes restriction. \n\nIs it possible to specify with the API that this property should not be indexed? \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1242",
        "number": 1242,
        "title": "Add retry logic for ABORTED datastore transactions",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We recently removed `ABORTED` from the set of exceptions to be retried on `TRANSACTIONAL` `commit` (see #1230 for background). We could however add a retry-logic to [`runInTransaction`](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-datastore/src/main/java/com/google/cloud/datastore/DatastoreHelper.java#L92).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1239",
        "number": 1239,
        "title": "protobuf 3 compat issues",
        "labels": [],
        "state": "closed",
        "body": "- `datastore-v1-protos` ships `com.google.protobuf.Timestamp` which implements `com.google.protobuf.GeneratedMessage`\n- `protobuf-java` 3.0.2 ships `com.google.protobuf.Timestamp` which implements `com.google.protobuf.GeneratedMessageV3`\n- As a result, with `protobuf-java` picked by the classloader, `google-cloud-datastore` classes (eg `com.google.datastore.v1.Value.toBuilder`) trigger `java.lang.VerifyError` (`Type 'com/google/protobuf/Timestamp' (current frame, stack[1]) is not assignable to 'com/google/protobuf/GeneratedMessage'`)\n- Excluding `datastore-v1-protos` from the classpath and generating the classes from proto ourselves then breaks `google-cloud-datastore`, eg because of its `com/google/cloud/datastore/PathElement.toPb()Lcom/google/protobuf/GeneratedMessage;`.\n\nI don't even know where to report this, maybe the protobuf team, but I figured the Google Cloud Platform team was a safer bet given it impacts their customers.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1238",
        "number": 1238,
        "title": "Document thread-safety",
        "labels": [
            "api: core",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Our service classes as well as functional classes are thread-safe. We should document that.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1237",
        "number": 1237,
        "title": "400 Bad Request on Storage.copy",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "I started seeing this today. Sometimes our integration tests fail with the following error:\n\n``` java\nITStorageTest.testCopyBlob:683 \u00bb Storage 400 Bad Request\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: \n400 Bad Request\nNo file found in request.\n```\n\nThe code that causes the error is the following:\n\n``` java\nString sourceBlobName = \"test-copy-blob-source\";\nBlobId source = BlobId.of(BUCKET, sourceBlobName);\nImmutableMap<String, String> metadata = ImmutableMap.of(\"k\", \"v\");\nBlobInfo blob = BlobInfo.builder(source)\n    .contentType(CONTENT_TYPE)\n    .metadata(metadata)\n    .build();\nBlob remoteBlob = storage.create(blob, BLOB_BYTE_CONTENT);\nassertNotNull(remoteBlob);\nString targetBlobName = \"test-copy-blob-target\";\nStorage.CopyRequest req = Storage.CopyRequest.of(source, BlobId.of(BUCKET, targetBlobName));\nCopyWriter copyWriter = storage.copy(req); // Exception thrown here\n```\n\nWhat's weird is that we never experienced this error before today and it does not occur systematically. @Capstan any idea?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1232",
        "number": 1232,
        "title": "Storage - StorageWriter how to fail the entire write of InputStream",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "All documentation points to the following being the best practice for uploading a large file\n\n``` Java\nString bucketName = \"my_unique_bucket\";\n String blobName = \"my_blob_name\";\n BlobId blobId = BlobId.of(bucketName, blobName);\n InputStream inputStream = new FileInputStream(new File(\"largefile.zip\"));\n BlobInfo blobInfo = BlobInfo.builder(blobId).contentType(\"application/octet-stream\").build();\n try (WriteChannel writer = storage.writer(blobInfo)) {\n   try {\n       while ((limit = inputStream.read(buffer)) >= 0) {\n            writer.write(ByteBuffer.wrap(buffer, 0, limit));\n       }\n   } catch (Exception ex) {\n     // handle exception\n   }\n }\n```\n\nThe question is how do we fail an upload if an exception is thrown midway?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1230",
        "number": 1230,
        "title": "We should not retry ABORTED transactions",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "In datastore we have `ABORTED` among retryable exceptions. This causes `commit` requests failed due to contention to be retried. Retrying an `ABORTED` transaction always fails with `INVALID ARGUMENT` error.\n\nI suggest we never retry `ABORTED`. \\cc @aozarov @ajkannan \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1227",
        "number": 1227,
        "title": "Storage - SocketException Socket closed (gcloud java 0.28)",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "We still see StorageException caused by SocketExceptions even if they should have been retried.\n\n```\njava.net.SocketException: Socket is closed\n    at sun.security.ssl.SSLSocketImpl.getInputStream\n    at sun.net.www.http.HttpClient.parseHTTP\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream0\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream\n    at java.net.HttpURLConnection.getResponseCode\n    at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode\n    at com.google.api.client.http.javanet.NetHttpResponse.<init>\n    at com.google.api.client.http.javanet.NetHttpRequest.execute\n    at com.google.api.client.http.HttpRequest.execute\n    at com.google.cloud.storage.spi.DefaultStorageRpc.open\n    at com.google.cloud.storage.BlobWriteChannel.<init>\n    at com.google.cloud.storage.StorageImpl.writer\n    at com.google.cloud.storage.StorageImpl.writer\n    at com.google.cloud.storage.StorageImpl.writer\n    at com.spotify.buildartifactarchiver.storage.GcsUploaderClient.storeInputStream\n    at com.spotify.buildartifactarchiver.storage.ArtifactUploader.uploadZipArchive\n    at com.spotify.buildartifactarchiver.storage.ArtifactUploader.upload\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveArtifactsForBuild\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveBuild\n    at com.spotify.buildartifactarchiver.web.ArtifactArchiverPubSubResource.messageHandler\n    at com.spotify.google.cloud.pubsub.client.Puller.lambda$pullBatch$11\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.lambda$wrap$9\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.Pubsub.lambda$requestJavaNet$8\n    at java.util.concurrent.ThreadPoolExecutor.runWorker\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\n    at java.lang.Thread.run\ncom.google.cloud.storage.StorageException: Socket is closed\n    at com.google.cloud.storage.spi.DefaultStorageRpc.translate\n    at com.google.cloud.storage.spi.DefaultStorageRpc.open\n    at com.google.cloud.storage.BlobWriteChannel.<init>\n    at com.google.cloud.storage.StorageImpl.writer\n    at com.google.cloud.storage.StorageImpl.writer\n    at com.google.cloud.storage.StorageImpl.writer\n    at com.spotify.buildartifactarchiver.storage.GcsUploaderClient.storeInputStream\n    at com.spotify.buildartifactarchiver.storage.ArtifactUploader.uploadZipArchive\n    at com.spotify.buildartifactarchiver.storage.ArtifactUploader.upload\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveArtifactsForBuild\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveBuild\n    at com.spotify.buildartifactarchiver.web.ArtifactArchiverPubSubResource.messageHandler\n    at com.spotify.google.cloud.pubsub.client.Puller.lambda$pullBatch$11\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.lambda$wrap$9\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.Pubsub.lambda$requestJavaNet$8\n    at java.util.concurrent.ThreadPoolExecutor.runWorker\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\n    at java.lang.Thread.run\n```\n\nWe are uploading files using the following code if there is something that we might be doing wrong...\n\n``` Java\n  public void storeInputStream(InputStream input, String fileName, String contentType)\n      throws IOException {\n\n    Storage storage = getStorage();\n\n    BlobId blobId = BlobId.of(this.bucketName, fileName);\n    LOG.debug(\"blobId: {}\", blobId);\n    BlobInfo blobInfo = BlobInfo.builder(blobId).contentType(contentType).build();\n    LOG.debug(\"blobInfo: {}\", blobInfo);\n    LOG.info(\"Starting upload to GCS for file: {} with content type:{}\", fileName, contentType);\n    //perform stream uploads of the InputStream\n    try (WriteChannel writer = storage.writer(blobInfo)) {\n      byte[] buffer = new byte[1024];\n      int limit;\n      while ((limit = input.read(buffer)) >= 0) {\n        writer.write(ByteBuffer.wrap(buffer, 0, limit));\n      }\n    }\n  }\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1223",
        "number": 1223,
        "title": "Pubsub: Provide callback capabilities to publishAsync",
        "labels": [
            "api: pubsub",
            "performance"
        ],
        "state": "closed",
        "body": "It would be nice if publishAsync could offer something like Guava's ListenableFuture, so we could add non blocking callbacks to the results of the operation.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1213",
        "number": 1213,
        "title": "Need to ensure we use lower-case gRPC header keys",
        "labels": [],
        "state": "closed",
        "body": "**This might be a no-op, but please double check. Filing this issue just in case.**\n\nWe need to ensure that all headers used for gRPC are written in lower-case. Please review this [Pull Request](https://github.com/GoogleCloudPlatform/gcloud-python/pull/2212) for reference of what needs to be updated.\n\nAgain, perhaps this doesn't apply to your language. Feel free to comment and close the issue (after you double checking).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1210",
        "number": 1210,
        "title": "authCredentials set on DatastoreOptions.builder() is not used so can't access Datastore over http proxy",
        "labels": [],
        "state": "closed",
        "body": "Can't use Datastore over an http proxy.  I first reported this under [issue 1138](https://github.com/GoogleCloudPlatform/gcloud-java/issues/1138)\nThis issue was resolved, however I still can't use Datastore over http proxy due to auth calls not using proxy.  I attempted to configure the AuthCredentials to use my http proxy with the following code:\n\n```\n        return DatastoreOptions.builder()\n                            .authCredentials(\n                                    new MyApplicationDefaultAuthCredentials(\n                                            GoogleCredentials.getApplicationDefault(GcpClientUtil.getHttpTransport())))\n                            .httpTransportFactory(new CustomHttpTransportFactoryWithProxy())\n                            .build()\n                            .service());\n```\n\nWhere MyApplicationDefaultAuthCredentials\n\n```\n  /**\n   * This was copied and modified so that we could provide an instance of GoogleCredentials\n   * \n   * Represents Application Default Credentials, which are credentials that are inferred from the\n   * runtime environment.\n   *\n   * @see <a\n   *     href=\"https://developers.google.com/identity/protocols/application-default-credentials\">\n   *     Google Application Default Credentials</a>\n   */\n  static class MyApplicationDefaultAuthCredentials extends AuthCredentials {\n\n    private GoogleCredentials googleCredentials;\n\n    private static final ApplicationDefaultAuthCredentialsState STATE =\n        new ApplicationDefaultAuthCredentialsState();\n\n    private static class ApplicationDefaultAuthCredentialsState\n        implements RestorableState<AuthCredentials>, Serializable {\n\n      private static final long serialVersionUID = -8839085552021212257L;\n\n      @Override\n      public AuthCredentials restore() {\n        try {\n          return new MyApplicationDefaultAuthCredentials(\n                  GoogleCredentials.getApplicationDefault(GcpClientUtil.getHttpTransport()));\n        } catch (IOException e) {\n          throw new IllegalStateException(\n              \"Could not restore \" + ApplicationDefaultAuthCredentials.class.getSimpleName(), e);\n        }\n      }\n\n      @Override\n      public int hashCode() {\n        return getClass().getName().hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj instanceof ApplicationDefaultAuthCredentialsState;\n      }\n    }\n\n    public MyApplicationDefaultAuthCredentials(GoogleCredentials credentials) {\n      googleCredentials = credentials;\n    }\n\n    @Override\n    public GoogleCredentials credentials() {\n      return googleCredentials;\n    }\n\n    @Override\n    public RestorableState<AuthCredentials> capture() {\n      return STATE;\n    }\n  }\n```\n\nWhere getHttpTransport is something like follows:\n\n```\npublic static HttpTransport getHttpTransport() {\n    URI uri = getGcpHttpProxyURI();\n    if ( uri !=null ) {\n        return new NetHttpTransport.Builder().setProxy(new Proxy(Proxy.Type.HTTP,\n                new InetSocketAddress(parseHostFromUri(uri),parsePortFromUri(uri)))).build();\n    } else {\n        return Utils.getDefaultTransport();\n    }\n}\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1209",
        "number": 1209,
        "title": "Add support for DropWizard Metrics",
        "labels": [
            "api: bigquery",
            "api: datastore",
            "api: pubsub",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "[Cloud Bigtable](https://github.com/GoogleCloudPlatform/cloud-bigtable-client/) has recently (0.9.2) adopted [DropWizard Metrics](http://metrics.dropwizard.io/3.1.0/) to help users trying to understand / debug Bigdata issues.  They include a connection to a [Graphite](https://graphiteapp.org/) server as well.\n\nThis would probably help users of PubSub, BigQuery, and other large data API's. (Datastore / Task Queues?)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1207",
        "number": 1207,
        "title": "Google Cloud Dataflow/Apache Beam and gcloud-java-core",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "We have two external pull requests which add logic to support the active gcloud profile, and also to get the project from the service account which are already supported by gcloud-java-core.\n\nDataflow/Apache Beam would like to depend on gcloud-java-core for the project detection logic found here: https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/cloud/ServiceOptions.java?l=66\n\nAnd also the auth credentials detection here: https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/cloud/ServiceOptions.java?l=237\n\nCurrently these are hidden away, is there a way for you to expose these concepts without needing to create a ServiceOptions subclass?\n\nIf not, how do you advise Dataflow/Apache Beam to integrate with gcloud-java-core?\n\nNote, that Apache Beam would be interested in the python versions of that code, and in general this would be useful in the other language implementations as well.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1199",
        "number": 1199,
        "title": "FR: Storage - Please support managing permissions w/ IAM",
        "labels": [
            "api: storage",
            "iam",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I don't seem to see support in the 0.2.7 JavaDoc\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1198",
        "number": 1198,
        "title": "FR: PubSub needs to support IAM Policies",
        "labels": [
            "api: pubsub",
            "iam",
            "type: feature request"
        ],
        "state": "closed",
        "body": "In going through the 0.2.7 JavaDocs for pubsub, I don't see any IAM support.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1197",
        "number": 1197,
        "title": "FR: PubSub Examples",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "1. Receiving push messages\n2. IAM Policy Examples & Snippets\n   \n   a. Get a subscription policy\n   b. Get a topic policy\n   c. set a subscription policy\n   d. Test permissions for a subscription\n   e. Test permissions for a topic\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1196",
        "number": 1196,
        "title": "FR: Logging Examples",
        "labels": [
            "api: logging",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Logging needs:\n1. To use new updater to maintain Javadocs in sync w/ the snippets & example code.\n2. Snippets and examples should be runnable (like datastore), and have tags `// [START section]` & `// [END section]`\n3. needs to update_a_log_sink sample\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1190",
        "number": 1190,
        "title": "Update utilities/add_snippets_to_file.py to have some limits...",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We might wish to stop deleting if more than 25 lines pass w/o a closing `</pre>` tag.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1188",
        "number": 1188,
        "title": "Allow CloudStorageFileSystemProvider without credentials",
        "labels": [],
        "state": "closed",
        "body": "When using any NIO Filesystem provider, Java will enumerate them all and try to create them.\n\nOur CloudStorageFileSystemProvider will throw an exception if there is no `GOOGLE_APPLICATION_CREDENTIALS` environment variable (because then it can't find credentials). This seems reasonable at first but here this means that even if someone is not using `gs://` at all, just by having our jar in the classpath they become unable to use _other_ filesystem providers.\n\n[This issue](https://github.com/broadinstitute/gatk/issues/2110) shows a concrete instance, with example.\n\nThis suggests we need to allow CloudStorageFileSystemProvider to be created without credentials. We can fail later, when the user tries to get a `CloudStorageFileSystem` instance.\n\nSounds good?\n\ncc: @jart, @mziccard \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1180",
        "number": 1180,
        "title": "Storage - SocketException Socket closed",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Hi fellow Google cloud java users,\nWe are seeing Socket closed quite often. \nThe StorageOptions.Builder().connectTimeout and StorageOptions.Builder().readTimeout are not set so I guess the default of 20 seconds is used.\nI didn't want to change them as 20 seconds should be plenty. \n\nDoes anyone have an idea about this?\n\n```\njava.net.SocketException: Socket closed\n    at java.net.SocketInputStream.read\n    at java.net.SocketInputStream.read\n    at sun.security.ssl.InputRecord.readFully\n    at sun.security.ssl.InputRecord.read\n    at sun.security.ssl.SSLSocketImpl.readRecord\n    at sun.security.ssl.SSLSocketImpl.readDataRecord\n    at sun.security.ssl.AppInputStream.read\n    at java.io.BufferedInputStream.fill\n    at java.io.BufferedInputStream.read1\n    at java.io.BufferedInputStream.read\n    at sun.net.www.http.HttpClient.parseHTTPHeader\n    at sun.net.www.http.HttpClient.parseHTTP\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream0\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream\n    at java.net.HttpURLConnection.getResponseCode\n    at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode\n    at com.google.api.client.http.javanet.NetHttpResponse.<init>\n    at com.google.api.client.http.javanet.NetHttpRequest.execute\n    at com.google.api.client.http.HttpRequest.execute\n    at com.google.cloud.storage.spi.DefaultStorageRpc.write\n    at com.google.cloud.storage.BlobWriteChannel$1.run\n    at java.util.concurrent.Executors$RunnableAdapter.call\n    at com.google.cloud.RetryHelper.doRetry\n    at com.google.cloud.RetryHelper.runWithRetries\n    at com.google.cloud.RetryHelper.runWithRetries\n    at com.google.cloud.storage.BlobWriteChannel.flushBuffer\n    at com.google.cloud.BaseWriteChannel.close\n    at com.spotify.buildartifactarchiver.storage.GcsUploaderClient.storeInputStream\n    at com.spotify.buildartifactarchiver.storage.ArtifactUploader.uploadData\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveRequest\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveBuild\n    at com.spotify.buildartifactarchiver.web.ArtifactArchiverPubSubResource.messageHandler\n    at com.spotify.google.cloud.pubsub.client.Puller.lambda$pullBatch$11\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.lambda$wrap$9\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.Pubsub.lambda$requestJavaNet$8\n    at java.util.concurrent.ThreadPoolExecutor.runWorker\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\n    at java.lang.Thread.run\ncom.google.cloud.storage.StorageException: Socket closed\n    at com.google.cloud.storage.spi.DefaultStorageRpc.translate\n    at com.google.cloud.storage.spi.DefaultStorageRpc.write\n    at com.google.cloud.storage.BlobWriteChannel$1.run\n    at java.util.concurrent.Executors$RunnableAdapter.call\n    at com.google.cloud.RetryHelper.doRetry\n    at com.google.cloud.RetryHelper.runWithRetries\n    at com.google.cloud.RetryHelper.runWithRetries\n    at com.google.cloud.storage.BlobWriteChannel.flushBuffer\n    at com.google.cloud.BaseWriteChannel.close\n    at com.spotify.buildartifactarchiver.storage.GcsUploaderClient.storeInputStream\n    at com.spotify.buildartifactarchiver.storage.ArtifactUploader.uploadData\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveRequest\n    at com.spotify.buildartifactarchiver.ArtifactArchiver.archiveBuild\n    at com.spotify.buildartifactarchiver.web.ArtifactArchiverPubSubResource.messageHandler\n    at com.spotify.google.cloud.pubsub.client.Puller.lambda$pullBatch$11\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.lambda$wrap$9\n    at java.util.concurrent.CompletableFuture.uniWhenComplete\n    at java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire\n    at java.util.concurrent.CompletableFuture.postComplete\n    at java.util.concurrent.CompletableFuture.complete\n    at com.spotify.google.cloud.pubsub.client.PubsubFuture.succeed\n    at com.spotify.google.cloud.pubsub.client.Pubsub.lambda$requestJavaNet$8\n    at java.util.concurrent.ThreadPoolExecutor.runWorker\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run\n    at java.lang.Thread.run\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1175",
        "number": 1175,
        "title": "Datastore emulator doesn't accept any REST call",
        "labels": [],
        "state": "closed",
        "body": "`gcloud beta emulators datastore start --no-legacy`AND `gcloud beta emulators datastore start` won't accept REST or give any meaningful errors.\n`\nPOST /v1/projects/kaamili-ae:lookup` responds with `Not Found (Unsupported API version \"v1\")`\n\nPOST /v1beta3/projects/kaamili-ae:lookup`responds with just a`Not Found`\n\nI've been try-and-erroring for an entire day , tried the legacy one , it's returns the not found with HTML. Also won't accept text or json headers.\n\nAre the emulators meant only for the client libraries only ?, how do I develop for the REST API ? Is that Possible ? \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1172",
        "number": 1172,
        "title": "Update docs menu ordering to be consistent with other platforms",
        "labels": [],
        "state": "closed",
        "body": "In all platforms other than Java, .NET is at the top. For instance, Python:\n\n![python](https://cloud.githubusercontent.com/assets/17011/17777753/9605eb5e-6559-11e6-8d1f-4694389024d6.png)\n\nJava has it at the bottom:\n\n![java](https://cloud.githubusercontent.com/assets/17011/17777768/9e41c464-6559-11e6-95b4-1b2af27aba3a.png)\n\nIn order for this to feel like a single menu just changing the page, the order shouldn't change.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1165",
        "number": 1165,
        "title": "Update gcloud-java/datastore to use the v1 API",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The v1 API is now available.\n\nThe protos are identical (just a different package name). The only behavioral change is captured in the release notes:\nhttps://cloud.google.com/datastore/release-notes\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1159",
        "number": 1159,
        "title": "Pub/Sub unit tests are slow",
        "labels": [],
        "state": "closed",
        "body": "In particular, AckDeadlineRenewerTest and LocalSystemTest take most of the time because of multiple 10 second waits that they do. The overall tests on my machine take 3:13, with 2:32 of it in Pub/Sub. Could these tests be refactored to use a fake clock?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1157",
        "number": 1157,
        "title": "Setting \"return immediately\" flag",
        "labels": [
            "api: core",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Here's an interesting feedback from a customer: \n\nhttp://stackoverflow.com/questions/38628150/gcloud-java-pubsub-api-how-to-set-return-immediately-flag\n\n@mziccard @garrettjonesgoogle \n\nMarco, what are your thoughts? And can you elaborate in this issue where this shows up in the code? It seems like this might cause some unnecessary polling. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1151",
        "number": 1151,
        "title": "pubsub client is accessing pubsub-experimental",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "This[1] line in the code is bad as the experimental endpoint is not currently available.\n\nhttps://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/PublisherSettings.java#L112\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1150",
        "number": 1150,
        "title": "PubSub SDK calls experimental API, fails",
        "labels": [],
        "state": "closed",
        "body": "I recently started getting this error in production:\n\n`PERMISSION_DENIED: Google Cloud Pub/Sub API (Experimental) has not been used in project <my-project> before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/pubsub-experimental.googleapis.com/overview?project= <my-project> then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.`\n\nVisiting that URL is not helpful. It seems that Google has turned off \"experimental\" endpoints, however, I do not explictly call experimental endpoints in my code.\n\nHowever, this file: https://github.com/GoogleCloudPlatform/gcloud-java/blob/v0.2.6/gcloud-java-pubsub/src/main/java/com/google/cloud/pubsub/spi/v1/SubscriberSettings.java#L106\n\nSets `\"pubsub-experimental.googleapis.com\"` as the default RPC endpoint for PubSub subscription calls. I'm specifically referencing the `0.2.6` release, as this is the most recent version in Maven Central, but this setting is also present in `master` as of now.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1148",
        "number": 1148,
        "title": "request: return ListenableFutures in PubSub async methods rather than bare Futures ",
        "labels": [],
        "state": "closed",
        "body": "The com.google.cloud.pubsub.PubSub interface defines async operations which return java.util.concurrent.Future values. \n\nFor anyone who uses the ListenableFuture concept from Guava (or CompletableFutures in Java 8), these [Futures have to be adapted into ListenableFutures by spawning a thread that blocks on the `Future.get()` return](https://github.com/google/guava/blob/8613c4dbde2aaeb871dce3ea0e52811039ee203d/guava/src/com/google/common/util/concurrent/JdkFutureAdapters.java#L40-L58).\n\nIt would be much more convenient if the Futures returned from PubSub were actually ListenableFuture instances (even if the interface did not define the return value to be ListenableFuture) - then it would not be necessary for users to block one thread per future they wish to adapt into a ListenableFuture.\n\nFor instance, internally `PubSubImpl.pullAsync(final String subscription, int maxMessages)` is implemented by using the listenable-like `com.google.cloud.pubsub.spi.PubSubRpc.PullFuture` and attaching callbacks to it, but the returned Future is an anonymous subclass of Future created by `Futures.lazyTransform(..)`.\n\nIs it a conscious decision to avoid using ListenableFutures in the interfaces defined in `gcloud-java-pubsub` and other clients? \n\nIt seems like the `com.google.cloud.pubsub.spi` layer has access to ListenableFuture instances via the generated grpc client code (like `subscriberApi.acknowledgeCallable().futureCall(request)`) but then these are discarded in the `PubSubImpl` layer.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1145",
        "number": 1145,
        "title": "Is there support for performing random/partial write to a particular offset of a file?",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "I couldn't find documentation that supports this. \n\nBasically, I have a file uploaded to google cloud and would like to write at a particular offset of the file and save it in gcloud. Is that possible? Something like microsoft azure page blob random write.\n\nPlease help thanks!\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1138",
        "number": 1138,
        "title": "The httpTransportFactory is not used",
        "labels": [],
        "state": "closed",
        "body": "If you set the DatastoreOptions' builder's httpTransportFactory it is not used.  The \"create\" method of the factory is never called.  This does not allow me to configure a proxy.  This is a defect, but is there a workaround to configure a proxy?\n\n`   public static Datastore createService() {\n        HttpTransportFactory httpTransportFactory = new HttpTransportWithProxyFactory();\n        return DatastoreOptions.builder()\n                .httpTransportFactory(httpTransportFactory).build().\n            service();\n    }\n\n```\npublic static class HttpTransportWithProxyFactory implements HttpTransportFactory {\n\n    public HttpTransport create() {\n        // PUT BREAKPOINT ON NEXT LINE AND IT IS NEVER CALLED\n        Proxy proxy = new Proxy(Type.HTTP, new InetSocketAddress(\"myproxy.com\", 8080));\n        HttpTransport t = new NetHttpTransport.Builder().setProxy(proxy).build();\n        return t;\n    }\n}`\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1137",
        "number": 1137,
        "title": "BigQuery Cannot specify to use Standard SQL instead of Legacy SQL.",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "http://googlecloudplatform.github.io/gcloud-java/0.2.6/apidocs/com/google/cloud/bigquery/QueryRequest.Builder.html\n\nI want to be able to set useLegacySql to false here: https://cloud.google.com/bigquery/docs/reference/v2/jobs/query#request-body\n\nAlso an issue in Python: https://github.com/GoogleCloudPlatform/gcloud-python/issues/2053\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1136",
        "number": 1136,
        "title": "Support PUBSUB_EMULATOR_HOST as env var",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1135",
        "number": 1135,
        "title": "Datastore Retry Logic",
        "labels": [],
        "state": "closed",
        "body": "Hi there. I'm using gcloud 0.2.6 and was recently looking into exceptions thrown when reading from datastore (stacktrace below). The calls are failing on I/O exceptions which I was expecting to be retried by the gcloud utility:\n\nFrom com.google.cloud.datastore.DatastoreImpl:\n\n``` java\n  com.google.datastore.v1beta3.LookupResponse lookup(\n      final com.google.datastore.v1beta3.LookupRequest requestPb) {\n    try {\n      return RetryHelper.runWithRetries(\n          new Callable<com.google.datastore.v1beta3.LookupResponse>() {\n        @Override public com.google.datastore.v1beta3.LookupResponse call()\n            throws DatastoreException {\n          return datastoreRpc.lookup(requestPb);\n        }\n      }, retryParams, EXCEPTION_HANDLER);\n    } catch (RetryHelperException e) {\n      throw DatastoreException.translateAndThrow(e);\n    }\n  }\n```\n\nThe retries don't happen, though, and I think it is because com.google.datastore.v1beta3.client.DatastoreException isn't properly converted to com.google.cloud.datastore.DatastoreException in DefaultDatastoreRpc.translate:\n\n``` java\nprivate static DatastoreException translate(\n      com.google.datastore.v1beta3.client.DatastoreException exception) {\n    String reason = \"\";\n    if (exception.getCode() != null) {\n      reason = exception.getCode().name();\n    }\n    if (reason.isEmpty()) {\n      if (exception.getCause() instanceof IOException) {\n        return new DatastoreException((IOException) exception.getCause());\n      }\n    }\n    return new DatastoreException(\n        exception.getCode().ordinal(), exception.getMessage(), reason, exception);\n  }\n```\n\nProblem here is that we're grabbing the ordinal() of the exception code when it seems like the intent was to grab it's _value_ via getNumber(). So for the UNAVAILABLE error, we end up with a com.google.cloud.datastore.DatastoreException with code = 15, which isn't retryable according to the RETRYABLE_ERRORS Set.\n\nI think this approach to error handling and retries is a bit convoluted and can be reworked, but an easy fix short of that would be to just change exception.getCode().ordina() to exception.getCode().number() in the method above.\n\nWhat are your thoughts? Should I submit a pull request?\n\nException:\n`Error: com.google.cloud.datastore.DatastoreException: I/O error\n    at com.google.cloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:102)\n    at com.google.cloud.datastore.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:139)\n    at com.google.cloud.datastore.DatastoreImpl$3.call(DatastoreImpl.java:289)\n    at com.google.cloud.datastore.DatastoreImpl$3.call(DatastoreImpl.java:285)\n    at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179)\n    at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244)\n    at com.google.cloud.datastore.DatastoreImpl.lookup(DatastoreImpl.java:284)\n    at com.google.cloud.datastore.DatastoreImpl$ResultsIterator.loadResults(DatastoreImpl.java:260)\n    at com.google.cloud.datastore.DatastoreImpl$ResultsIterator.<init>(DatastoreImpl.java:256)\n    at com.google.cloud.datastore.DatastoreImpl.get(DatastoreImpl.java:246)\n    at com.google.cloud.datastore.DatastoreImpl.get(DatastoreImpl.java:210)\n    at com.google.cloud.datastore.DatastoreHelper.get(DatastoreHelper.java:47)\n    at com.google.cloud.datastore.DatastoreImpl.get(DatastoreImpl.java:195)\n    at com.spins.google.api.cpl.CustomProductLibrary.getProductInfo(CustomProductLibrary.java:142)\n    at com.spins.google.api.cpl.CustomProductLibrary.getProduct(CustomProductLibrary.java:121)\n    at com.spins.google.api.cpl.CustomProductLibrary.getProduct(CustomProductLibrary.java:116)\n    at com.spins.hdp.sld.data.ProductLibrarySchema.toReportingString(ProductLibrarySchema.java:102)\n    at com.spins.hdp.sld.PrepareStoreLevelData$R.reduceByUpc(PrepareStoreLevelData.java:377)\n    at com.spins.hdp.sld.PrepareStoreLevelData$R.reduce(PrepareStoreLevelData.java:340)\n    at com.spins.hdp.sld.PrepareStoreLevelData$R.reduce(PrepareStoreLevelData.java:1)\n    at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)\n    at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)\n    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)\n    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at javax.security.auth.Subject.doAs(Subject.java:422)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: com.google.datastore.v1beta3.client.DatastoreException: I/O error, code=UNAVAILABLE\n    at com.google.datastore.v1beta3.client.RemoteRpc.makeException(RemoteRpc.java:126)\n    at com.google.datastore.v1beta3.client.RemoteRpc.call(RemoteRpc.java:95)\n    at com.google.datastore.v1beta3.client.Datastore.lookup(Datastore.java:92)\n    at com.google.cloud.datastore.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:137)\n    ... 26 more\nCaused by: java.net.SocketTimeoutException: Read timed out\n    at java.net.SocketInputStream.socketRead0(Native Method)\n    at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)\n    at java.net.SocketInputStream.read(SocketInputStream.java:170)\n    at java.net.SocketInputStream.read(SocketInputStream.java:141)\n    at sun.security.ssl.InputRecord.readFully(InputRecord.java:465)\n    at sun.security.ssl.InputRecord.read(InputRecord.java:503)\n    at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973)\n    at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930)\n    at sun.security.ssl.AppInputStream.read(AppInputStream.java:105)\n    at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n    at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\n    at java.io.BufferedInputStream.read(BufferedInputStream.java:345)\n    at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704)\n    at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647)\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536)\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441)\n    at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)\n    at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338)\n    at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37)\n    at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94)\n    at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\n    at com.google.datastore.v1beta3.client.RemoteRpc.call(RemoteRpc.java:87)\n    ... 28 more`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1134",
        "number": 1134,
        "title": "Datastore transactions don't provide read-after-write semantics",
        "labels": [],
        "state": "closed",
        "body": "  Here is a simple repro to demonstrate the issue. Reads in transactions will not reflect writes from the same transaction:\n\n```\n// 1. Setup\nDatastore datastore = ...\nKeyFactory keyFactory = datastore.newKeyFactory().kind(\"test\");\nKey key = keyFactory.newKey(1);\n\n// 1. Set initial value of entity to \"old\"\ndatastore.put(Entity.builder(keyFactory.newKey(1)).set(\"value\", \"old\").build());\n\n// 2. Start transaction and make sure value is \"old\"\nTransaction transaction = datastore.newTransaction();\nEntity entity1 = transaction.get(key);\nif (!entity1.getString(\"value\").equals(\"old\")) {\n  throw new IllegalStateException(\"Unexpected value\");\n}\n\n// 3. Write \"new\" value\ntransaction.put(Entity.builder(entity1).set(\"value\", \"new\").build());\n\n// 4. Read entity again, value is still \"old\"\nEntity entity2 = transaction.get(key);\nif (!entity2.getString(\"value\").equals(\"new\")) {\n  throw new IllegalStateException(\"Unexpected value\"); // throws here\n}\n```\n\nAFAIK Datastore v1beta3 makes this explicit by forcing all writes into the commit, making it impossible to read after a write. This behavior should also be reflected in the Java API, perhaps by throwing if there is a read attempt after a write.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1133",
        "number": 1133,
        "title": "Check if Bucket.exists()?",
        "labels": [],
        "state": "closed",
        "body": "Hi,\n\nI still can't understand how can I use bucket.exists from the documentation. I don't even know how to instantiate a new bucket. This is what I did.\n\nBucket bucket = new Bucket(\"bucketname\");\nreturn bucket.exists();\n\nApparently I can't instantiate a new bucket like this, so how then can I use bucket.exists()?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1132",
        "number": 1132,
        "title": "Shared access authentication for google cloud storage?",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Hi,\n\nIs there a way to do shared access using gcloud? I'm coming from azure and s3 and we used to use access key and secret key to construct a token or sas signature for shared access. I can't seem to find any guides on this topic. I see from most tutorials, I need to reference a json file which stores my private key credentials, is it possible to use access key and secret key concept to connect to google cloud storage?\n\nCan anyone please help?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1131",
        "number": 1131,
        "title": "NPE when calling com.google.cloud.bigquery.BigQuery.getTable(...)",
        "labels": [],
        "state": "closed",
        "body": "Relevant part of the exception:\n\n``` java.lang.NullPointerException\n    at com.google.cloud.bigquery.StandardTableDefinition$StreamingBuffer.fromPb(StandardTableDefinition.java:113)\n    at com.google.cloud.bigquery.StandardTableDefinition$Builder.<init>(StandardTableDefinition.java:147)\n    at com.google.cloud.bigquery.StandardTableDefinition$Builder.<init>(StandardTableDefinition.java:119)\n    at com.google.cloud.bigquery.StandardTableDefinition.fromPb(StandardTableDefinition.java:283)\n    at com.google.cloud.bigquery.TableDefinition.fromPb(TableDefinition.java:172)\n    at com.google.cloud.bigquery.TableInfo$BuilderImpl.<init>(TableInfo.java:157)\n    at com.google.cloud.bigquery.Table.fromPb(Table.java:348)\n    at com.google.cloud.bigquery.BigQueryImpl.getTable(BigQueryImpl.java:353)\n```\n\nWe suspect this is happening because the table we are trying to get seems to have a streaming buffer that is empty. Here is what some of the table info looks like:\n\n```\n...\n \"numBytes\": \"85168232\",\n \"numLongTermBytes\": \"0\",\n \"numRows\": \"144534\",\n \"creationTime\": \"1468884348851\",\n \"lastModifiedTime\": \"1469135551174\",\n \"type\": \"TABLE\",\n \"location\": \"US\",\n \"streamingBuffer\": {\n  \"estimatedRows\": \"0\",\n  \"estimatedBytes\": \"0\"\n }\n```\n\nFrom all the documentation it looks like this maybe isn't supposed to happen at all. But, it seems to be happening here, and resulting in an NPE.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1130",
        "number": 1130,
        "title": "Logging Handler Should Have Fluentd Transport",
        "labels": [
            "api: logging",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This might be a \"nice-to-have\", but a Java logging handler that logs by writing to the fluentd handler could be helpful. Biggest consideration here is whether it would perform better than the current one. fluentd is installed on App Engine flexible and can be included in GKE clusters with click of a button so it's good to integrate with it.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1128",
        "number": 1128,
        "title": "Dns zone names can now be up to 64 characters long",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Our DNS tests:\n- `testCreateZoneWithErrors`\n- `testCreateZoneWithErrorsBatch`\n\nstarted failing out of the blue.\n\nThose tests verify that zone creation fails with names that are longer than 32 characters. They started to fail because Cloud Dns now supports longer names for zones (up to 64 characters). We should go ahead and update our integration tests. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1123",
        "number": 1123,
        "title": "BigQuery listTables(DatasetId) does not use project overrided in DatasetId",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "My Google Application Default Credentials are set to the swast-scratch project, but I wish to list the tables in the `publicdata` project's `samples` dataset. This is a public dataset.\n\n``` shell\n$ bq ls publicdata:samples\n      tableId       Type\n ----------------- -------\n  github_nested     TABLE\n  github_timeline   TABLE\n  gsod              TABLE\n  natality          TABLE\n  shakespeare       TABLE\n  trigrams          TABLE\n  wikipedia         TABLE\n```\n\nExample code that displays this issue:\n\n```\nimport com.google.cloud.bigquery.BigQuery;\nimport com.google.cloud.bigquery.BigQueryOptions;\nimport com.google.cloud.bigquery.DatasetId;\nimport com.google.cloud.bigquery.Table;\nimport java.io.PrintWriter;\nimport java.util.Iterator;\n\npublic class TableLister {\n  public static void listTables(PrintWriter out) {\n    BigQuery bigquery = BigQueryOptions.defaultInstance().service();\n    Iterator<Table> tables = bigquery.listTables(DatasetId.of(\"publicdata\", \"samples\")).iterateAll();\n    while (tables.hasNext()) {\n      out.println(tables.next());\n    }\n  }\n\n  public static void main(String[] args) {\n    listTables(new PrintWriter(System.out));\n  }\n}\n```\n\nIt fails with the error: `\"message\" : \"Not found: Dataset swast-scratch:samples\"`, so it appears that it is not using the project that I set in the DatasetId.\n\nhttp://googlecloudplatform.github.io/gcloud-java/0.2.5/apidocs/com/google/cloud/bigquery/DatasetId.html#of-java.lang.String-java.lang.String-\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1120",
        "number": 1120,
        "title": "Support PUBSUB_EMULATOR_HOST environment variable",
        "labels": [],
        "state": "closed",
        "body": "gcloud-java should support detecting `PUBSUB_EMULATOR_HOST` and connect to the pubsub emulator with empty credentials when it is present.\n\nSee GoogleCloudPlatform/gcloud-common/issues/48\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1112",
        "number": 1112,
        "title": "remove newlines from datastore Key.toString() values",
        "labels": [],
        "state": "closed",
        "body": "Calling `.toString()` on a datastore `Key`, for instance when logging some value or operation in application code, returns a String containing newlines and tabs, which might be too verbose in places where each \"log line\" is expected to be a single line.\n\nFor instance:\n\n```\npartition_id {\n  project_id: \"some-project-id\"\n}\npath {\n  kind: \"taskqueue\"\n  id: -1037827333\n}\n```\n\nSince the toString implemented in BaseKey is converting the instance to protobuf and calling toString on the returned GeneratedMessage, could one of the protobuf methods for formatting without newlines be used instead for condensed output?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1082",
        "number": 1082,
        "title": "Add OAuth Callback URL",
        "labels": [],
        "state": "closed",
        "body": "Hello\nI develop app that creates instances with our web app for our clients. Our web app supports Google Cloud OAuth authentification. So for every instances we create DNS name (instance-1.ourcompany.com, instance-2.ourcompany.com...) So next step is to specify OAuth callback urls (http://instance-1.ourcompany.com/oauth/callback ,  http://instance-2.ourcompany.com/oauth/callback ... )\nHow can I do that via Java API?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1081",
        "number": 1081,
        "title": "Startup Script for Instance",
        "labels": [],
        "state": "closed",
        "body": "Hello,\nI'm trying to create an instance with startup script. I saw [ComputeExample.java](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-examples/src/main/java/com/google/cloud/examples/compute/ComputeExample.java) but it describes process how to specify metadata for created instance.\nHow can I correctly specify startup script when create it?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1073",
        "number": 1073,
        "title": "How to access GCS bucket from another project?",
        "labels": [],
        "state": "closed",
        "body": "So I have files in a bucket `BK1` created in gcloud project `A`, and I have appengine service running in project `B`. How do I configure `BK1` bucket (or object) permissions so B's appengine service can access those files?\n\nMy sample code looks like this\n\n```\n        Storage storage = StorageOptions.defaultInstance().service();\n        String filename = \"foo.json\";\n        Blob blob = storage.get(BlobId.of(\"BK1\", filename));\n        if (blob == null) {\n            return null;\n        }\n        System.out.println(\"blob content: \" + new String(blob.content()));\n```\n\nI'm getting \"login required\" error. \n\nI tried adding app engine default service account to BK1's permission, still not working either.\nAny pointer would be appreciated.\nThx!\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1071",
        "number": 1071,
        "title": "Add compile-time check that source files start with license text",
        "labels": [],
        "state": "closed",
        "body": "As [initially suggested](https://github.com/GoogleCloudPlatform/gcloud-java/pull/1067#discussion_r67925353) by @aozarov, this would make sure that code checked in follows that part of the guidelines. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1064",
        "number": 1064,
        "title": "Stackdriver Abstraction",
        "labels": [
            "api: monitoring",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I'd like to propose a stackdriver abstraction to simplify the process of authoring and publishing metrics. My specific needs are for a monitoring library for a GAE based servlet application but the goal would be to write something that can be helpful for any Java application.\n\nThe library should simplify the definition and polling of metrics, especially Gauge metrics which make most sense when polled on a regular periodic basis in the background. The library should also just simplify the API as right now it takes a  lot of bookkeeping to just publish a single metric datapoint.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1061",
        "number": 1061,
        "title": "Consider adding a fullLogName(String) to LoggingOptions",
        "labels": [
            "api: logging",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We could add a `LoggingOptions.fullLogName(String)` method that given a log name like \"syslog\" returns the fully qualified name \"projects/<projectId>/logs/syslog\".\n\nThis method is of no use in our service calls as our params must be partial names but could be useful to users when building filters like: \"logName=projects/<projectId>/logs/syslog\".\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1052",
        "number": 1052,
        "title": "Add support for the App Engine Admin API",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We have an Admin API (service management) for App Engine here:\nhttps://cloud.google.com/appengine/docs/admin-api/reference/rest/\n\nIt's a pretty basic CRUD / REST style API, but it would be great to have wrappers that make it easier to use.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1049",
        "number": 1049,
        "title": "Storage: Emulate directly listing with delim and prefix",
        "labels": [],
        "state": "closed",
        "body": "Anyone knows if it is possible to use prefix and delimiter options at the same time like the following raw REST URL\n\n```\nhttps://www.googleapis.com/storage/v1/b/clientbuilds/o?delimiter=%2F&prefix=dir1%2Fdir2%2F&key={YOUR_API_KEY}\n```\n\n(above is from https://developers.google.com/apis-explorer/#p/storage/v1/storage.objects.list?)\nResults from this is:\n\n```\n{\n \"kind\": \"storage#objects\",\n \"prefixes\": [\n  \"dir1/dir2/6893940/\",\n  \"dir1/dir2/6893942/\"\n ]\n}\n```\n\nSetting the `prefix` I know how to do with `Storage.BlobListOption.prefix(\"dir1/dir2/\")`but I looked in the code and can't really understand how to set the `delimiter`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1047",
        "number": 1047,
        "title": "Fix logging class names",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "The logging class name contains a \"v2\" suffix which is inconsistent with other APIs (pubsub in particular). We can fix this issue by:\n1. Contact the logging team to fix the name in the proto.\n2. Override the name in the generation phase.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1044",
        "number": 1044,
        "title": "skipLeadingRows is long for external tables but integer for load jobs",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I believe this changed recently.\n\nThe `skipLeadingRows` field takes a long value when creating an external table (see [docs](https://cloud.google.com/bigquery/docs/reference/v2/tables#externalDataConfiguration.googleSheetsOptions.skipLeadingRows)). Instead, `skipLeadingRows` in load jobs takes an integer value (see [docs](https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.load.skipLeadingRows)). Why this difference? Load jobs [can take files up to 5TB](https://cloud.google.com/bigquery/quota-policy#import) so in principle there is the chance that users might want to skip more than Integer.MAX_INT rows.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1042",
        "number": 1042,
        "title": "HttpRequest class in grpc-logging-type is missing serverIp",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "`com.google.logging.type.HttpRequest` class, contained in the package:\n\n``` xml\n<dependency>\n  <groupId>com.google.api.grpc</groupId>\n  <artifactId>grpc-logging-type</artifactId>\n  <version>0.0.1</version>\n</dependency>\n```\n\nis missing the `serverIp` field that is instead documented [here](https://cloud.google.com/logging/docs/api/ref_v2beta1/rest/v2beta1/LogEntry#HttpRequest.FIELDS.remote_ip). The field is also missing in the [http_request.proto](https://github.com/googleapis/googleapis/blob/master/google/logging/type/http_request.proto). Should the protos be updated?\n\n/cc @garrettjonesgoogle @shinfan @filipjs\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1039",
        "number": 1039,
        "title": "Add support for BigQuery BYTES data type",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "BigQuery [BYTES](https://cloud.google.com/bigquery/data-types) data type was recently added (see [release notes](https://cloud.google.com/bigquery/release-notes#march_23_2016)). We should add support for it to both [`Field`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-bigquery/src/main/java/com/google/cloud/bigquery/Field.java) and [`FieldValue`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-bigquery/src/main/java/com/google/cloud/bigquery/FieldValue.java) classes.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1037",
        "number": 1037,
        "title": "Support customer-supplied encryption keys in Storage",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Support for customer-supplied encryption keys was added in storage and we should support it as well.\n\nHow to use such keys is documented [here](https://cloud.google.com/storage/docs/encryption#customer-supplied). Fields added to a blob are documented [here](https://cloud.google.com/storage/docs/json_api/v1/objects#customerEncryption).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1035",
        "number": 1035,
        "title": "Channel should be closed in CountBytes example",
        "labels": [],
        "state": "closed",
        "body": "mziccard says that:\n`Channel must be closed also in the CountBytes example`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1032",
        "number": 1032,
        "title": "Storage BlobInfo createdTime not present in library",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Hello,\n\nI have been using the library and checking the [JSON API exposes](https://cloud.google.com/storage/docs/json_api/v1/objects#resource-representations), as a reference to use Google Cloud Storage, I haven't been able to find these fields:\n- timeCreated\n- any of the encryption attributes\n\nHowever one can find them in the library this library is relying on: https://developers.google.com/resources/api-libraries/documentation/storage/v1/java/latest/com/google/api/services/storage/model/StorageObject.html\n\nWould it be possible to at least expose the timeCreated field?\n\nThank you!\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1029",
        "number": 1029,
        "title": "Provide means to create AuthCredentials given an OAuth2 access token",
        "labels": [
            "auth"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1028",
        "number": 1028,
        "title": "We should add tests for AuthCredentials",
        "labels": [
            "auth"
        ],
        "state": "closed",
        "body": "Not all `AuthCredentials` subclasses are platform-dependent. In our unit tests we should cover those credentials whose creation is platform-independent.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1026",
        "number": 1026,
        "title": "How to create instance from snapshot",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "Hi guys, I did not find discussion forum or group so I'm asking here.\n\nI have an VM instance in google cloud and I need to create many clones of the instance. So I created snapshot of instance's disk in Google Cloud Console. The console allows to create new instance based on snapshot, but I need to do it via GCloud Java API, how can I do that?\n\nThanks\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1025",
        "number": 1025,
        "title": "dns-alpha-batch branch should be deleted",
        "labels": [],
        "state": "closed",
        "body": "Also, looks like it is ahead few commits which should probably be merged to master before branch delete.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1018",
        "number": 1018,
        "title": "Storage insufficient data written",
        "labels": [],
        "state": "closed",
        "body": "Could someone help with pointing me to the right direction wrt to an exception I get (sometimes): com.google.cloud.storage.StorageException: insufficient data written.\n\nThe code that uploads and fails sometimes is:\n\n```\npublic void storeInputStream(InputStream input, String fileName, String contentType)\n      throws IOException {\n\n    Storage storage = getStorage();\n\n    BlobId blobId = BlobId.of(this.bucketName, fileName);\n    LOG.debug(\"blobId: {}\", blobId.toString());\n    BlobInfo blobInfo = BlobInfo.builder(blobId).contentType(contentType).build();\n    LOG.debug(\"blobInfo: {}\", blobInfo);\n    //perform stream uploads of the InputStream\n    try (WriteChannel writer = storage.writer(blobInfo)) {\n      byte[] buffer = new byte[1024];\n      int limit;\n      while ((limit = input.read(buffer)) >= 0) {\n        writer.write(ByteBuffer.wrap(buffer, 0, limit));\n      }\n    }\n  }\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1017",
        "number": 1017,
        "title": "Weird behavior when pulling messages and using modifyAckDeadline",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The scenario is the following: 1 topic and 1 subscription with default ack deadline (10 seconds). I publish 2 messages (`message1` and `message2`) to the topic and then pull messages from the subscription. \n\nAfter the first pull I set the ack deadline of `message1` to a big value (let's say 100 seconds). Then I pull messages from the subscription every 20 seconds. The expected behavior is that pulls return only `message2` until ~100 seconds are passed, and then return both `message1` and `message2`.\n\nWhen I run this scenario against the actual service I get the weird behavior: pull requests made before that ~100 seconds are passed after the deadline modification return no messages (as if both messages where affected by `modifyAckDeadline`).\n\nThe veneer toolkit code that reproduces the error is the following:\n\n``` java\nPublisherApi publisher = PublisherApi.create(publisherSettings);\nSubscriberApi subscriber = SubscriberApi.create(subscriberSettings);\nString topicName = PublisherApi.formatTopicName(\"gcloud-devel\", \"test-topic\");\nString subscriptionName =\n    SubscriberApi.formatSubscriptionName(\"gcloud-devel\", \"test-subscription\");\npublisher.createTopic(topicName);\nsubscriber.createSubscription(Subscription.newBuilder()\n    .setName(subscriptionName)\n    .setTopic(topicName)\n    .setAckDeadlineSeconds(10)\n    .build());\npublisher.publish(topicName, ImmutableList.of(\n    PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(\"message1\")).build(),\n    PubsubMessage.newBuilder().setData(ByteString.copyFromUtf8(\"message2\")).build()));\nPullResponse pullResponse = subscriber.pull(subscriptionName, true, 2);\nList<ReceivedMessage> receivedMessages = pullResponse.getReceivedMessagesList();\nfor (ReceivedMessage message : pullResponse.getReceivedMessagesList()) {\n  System.out.printf(\"[%d][PULLED MESSAGE %s]%n\",\n      System.currentTimeMillis(), message.getMessage().getData().toStringUtf8());\n}\n// Set the deadline of the first message far away\nsubscriber.modifyAckDeadline(subscriptionName,\n    ImmutableList.of(receivedMessages.get(0).getAckId()), 100);\n\n// Second message should be again available for pulling after .sleep()\nThread.sleep(20000);\nfor (int i = 0; i < 10; i++) {\n  pullResponse = subscriber.pull(subscriptionName, true, 2);\n  receivedMessages = pullResponse.getReceivedMessagesList();\n  if (receivedMessages.isEmpty()) {\n    System.out.printf(\"[%d][PULLED NO MESSAGES]%n\", System.currentTimeMillis());\n  } else {\n    for (ReceivedMessage message : pullResponse.getReceivedMessagesList()) {\n      System.out.printf(\"[%d][PULLED MESSAGE %s]%n\",\n          System.currentTimeMillis(), message.getMessage().getData().toStringUtf8());\n    }\n  }\n  Thread.sleep(20000);\n}\npublisher.deleteTopic(topicName);\nsubscriber.deleteSubscription(subscriptionName);\n```\n\nWhen I run it against the actual service I get the following output:\n\n``` java\n[1463750536877][PULLED MESSAGE message1]\n[1463750536877][PULLED MESSAGE message2]\n[1463750561558][PULLED NO MESSAGES] // <-- here and in the following I would expect message2\n[1463750584638][PULLED NO MESSAGES]\n[1463750608178][PULLED NO MESSAGES]\n[1463750631240][PULLED NO MESSAGES]\n[1463750653656][PULLED MESSAGE message1]\n[1463750653657][PULLED MESSAGE message2]\n[1463750676241][PULLED MESSAGE message1]\n[1463750676241][PULLED MESSAGE message2]\n[1463750698302][PULLED MESSAGE message1]\n[1463750698302][PULLED MESSAGE message2]\n[1463750720269][PULLED MESSAGE message1]\n[1463750720270][PULLED MESSAGE message2]\n[1463750742847][PULLED MESSAGE message1]\n[1463750742847][PULLED MESSAGE message2]\n```\n\nInstead when I run it agains the emulator the output is as expected:\n\n``` java\n[1463749875238][PULLED MESSAGE message1]\n[1463749875238][PULLED MESSAGE message2]\n[1463749895270][PULLED MESSAGE message2]\n[1463749915289][PULLED MESSAGE message2]\n[1463749935308][PULLED MESSAGE message2]\n[1463749955329][PULLED MESSAGE message2]\n[1463749975347][PULLED MESSAGE message1]\n[1463749975347][PULLED MESSAGE message2]\n[1463749995363][PULLED MESSAGE message1]\n[1463749995363][PULLED MESSAGE message2]\n[1463750015384][PULLED MESSAGE message2]\n[1463750015384][PULLED MESSAGE message1]\n[1463750035403][PULLED MESSAGE message2]\n[1463750035403][PULLED MESSAGE message1]\n[1463750055421][PULLED MESSAGE message2]\n[1463750055422][PULLED MESSAGE message1]\n```\n\n@eschapira @garrettjonesgoogle Any idea about what's going on?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1014",
        "number": 1014,
        "title": "Update to the next datastore emulator script version",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "This emulator uses the same URL structure as the Cloud Datastore.  Because `gcloud-java` depends on the [google-cloud-datastore](https://github.com/GoogleCloudPlatform/google-cloud-datastore/tree/master/java) client, we need to wait until the client updates to use a variable to decide when to append  \"/datastore\" for localhost URLs. (/cc @pcostell)\n\nThere are a couple related changes that need to be made:\n- Update the version of the google cloud datastore client we depend on.\n- The name of the script & folder will change from `gcd` to `cloud-datastore-emulator`.  We should make the necessary updates to accommodate this change.\n- We should also change the logic that checks for a locally-installed emulator to check for major/minor version updates (but not build).  Right now, we do not check version (besides ensuring that the script is for v1beta3).\n- Ensure the \"gcd-emulator\" version will be reported the same way as before by the gcloud SDK.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1012",
        "number": 1012,
        "title": "Storage example should show how to set ACL",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "ACLs are not even mentioned in the examples. Example needs to show both how to set a specific ACL and how to set a PredefinedAcl.\n\nWhen I use this this code, the console Cloud Storage viewer does not show items as shared publicly:\n\n```\nstorage.create(coverBlob, coverImage,\n    BlobTargetOption.predefinedAcl(PredefinedAcl.PUBLIC_READ));\n```\n\nSo it's not clear what this code is supposed to do.\n\nAm I right to assume that ACL should be set on BlobInfo like this?\n\n```\n    .acl(Arrays.asList(Acl.of(User.ofAllUsers(), Role.READER)))\n```\n\nIf this is correct, is it enough, or should be used together with `BlobTargetOption.predefinedAcl(PredefinedAcl.PUBLIC_READ)`?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1007",
        "number": 1007,
        "title": "Storage.readAllBytes() unauthorized when running on App Engine standard with default credentials",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "Create an application running this code:\n\n```\nStorageOptions.defaultInstance().service().readAllBytes(bucket, objectName)\n```\n\nIt will work on a local environment using application default credentials, but it will throw the following error when deployed on App Engine standard (did not try on flexible):\n\n```\ncom.google.cloud.storage.StorageException: 401\nLogin Required\n    at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:98)\n    at com.google.cloud.storage.spi.DefaultStorageRpc.load(DefaultStorageRpc.java:362)\n    at com.google.cloud.storage.StorageImpl$16.call(StorageImpl.java:443)\n    at com.google.cloud.storage.StorageImpl$16.call(StorageImpl.java:440)\n    at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:181)\n    at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:247)\n    at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:237)\n    at com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:440)\n```\n\nThe workaround is to use Storage.reader() to get a ReadChannel.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1006",
        "number": 1006,
        "title": "StorageImpl.signUrl generates invalid URLs for objects names with leading /",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "The generated URL contains zero-chars.\n\nThe problem is probably here: https://github.com/GoogleCloudPlatform/gcloud-java/compare/master...clementdenis:patch-1\n\nThe method should either reject object names leading slash, or handle them correctly.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1005",
        "number": 1005,
        "title": "Allow users to set the scheduled executor service",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "grpc-based services use a `ScheduledExecutorService`. We should allow users to set an executor other than the default one in the service options.\n\nRelated to this: should we create an abstract option class for grpc-based services (that extends `ServiceOptions`?) That could expose some of the grpc-only configurations like setting the executor or converting the connection timeouts (see [here](https://github.com/GoogleCloudPlatform/gcloud-java/pull/1001#discussion_r63060327)).\n\n/cc @aozarov @ajkannan \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1003",
        "number": 1003,
        "title": "Need an easy way to contruct a Key with parent",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Maybe I missed some docs but I can't figure out how to construct a key with parent. Definitely need an example on how to do this.\nI'm using version 0.2.1.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/998",
        "number": 998,
        "title": "Support standard env vars for emulator testing",
        "labels": [],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/gcloud-python/blob/master/gcloud/environment_vars.py\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/997",
        "number": 997,
        "title": "Pub/Sub PullRequest.maxMessages is mandatory",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The `PullRequest.maxMessages` is a mandatory field, if we don't provide it we get this error:\n\n``` json\n{\n \"error\": {\n  \"code\": 400,\n  \"message\": \"A required argument is missing in the request: (argument=\\\"max_messages\\\").\",\n  \"status\": \"INVALID_ARGUMENT\",\n }\n}\n```\n\nThe PubSub API design we drafted considers `maxMessages` an optional option, we must either fix this (by transforming it into a mandatory parameter) or use a default value if the user does not explicitly provide it. /cc @eschapira @aozarov thoughts?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/995",
        "number": 995,
        "title": "Blob creation fails when deploying in an Android device",
        "labels": [],
        "state": "closed",
        "body": "Hello,\n\nTrying to deploy this [snippet code](https://github.com/GoogleCloudPlatform/gcloud-java#google-cloud-storage) into an Android device, I got the a _NoSuchMethodError_ run-time exception saying that crc32c() static method does not exist in class com.google.common.hash.Hashing.\n\nThe exception is thrown at line where the blob is created:\n`Blob blob = storage.create(blobInfo, \"Hello, Cloud Storage!\".getBytes(UTF_8));\n`\n\nThe whole Android code [here](https://github.com/rafaelsf80/cloud-storage-android).\nAny suggestion would be appreciated.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/994",
        "number": 994,
        "title": "Add to Builder methods to Datastore's classes",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Datastore's `ProjectionEntity`, `IncompleteKey`, `Entity` and `Key` have static builder methods:\n\n``` java\npublic static Builder builder(ProjectionEntity copyFrom)\npublic static Builder builder(IncompleteKey copyFrom)\npublic static Builder builder(Entity copyFrom)\npublic static Builder builder(Key copyFrom)\n```\n\nIn other modules we use a `toBuilder()` instance method to create builders from entity objects. Should we use `toBuilder()` also in Datastore? Or is there a reason to prefer static `builder(ResourceType copyFrom)`? \\cc @ajkannan @aozarov \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/993",
        "number": 993,
        "title": "Iterator.next() is ignored for List<Value<T>>",
        "labels": [],
        "state": "closed",
        "body": "This code produces an endless loop:\n\n```\nList<Value<Long>> releases = entity.getList(\"releases\");\nSystem.out.println(releases.size());    // prints 1 \n\nwhile (releases.iterator().hasNext()) {\n    Value<Long> value = releases.iterator().next();\n    System.out.println(value.get());   // prints correct value over and over\n}\n\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/991",
        "number": 991,
        "title": "What should Subscription.topic return when the topic is deleted",
        "labels": [
            "api: pubsub",
            "type: question"
        ],
        "state": "closed",
        "body": "When a topic is deleted its subscriptions are not. For such subscriptions the `topic` field assumes the special value `\"_deleted-topic_:`. What should `Subscription.topic()` getter return in this case? I see two main options (there surely are more).\n- `Subscription.topic()` returns `null`\n- `Subscription.topic()` returns `TopicId.of(\"_deleted-topic_\")`\n\nRegardless, this should be properly documented.\n/cc @aozarov @eschapira to hear your thoughts\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/990",
        "number": 990,
        "title": "LocalPubSubHelper does not work with gcloud beta emulators",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "`gcloud`'s `--host-port` requires both an host and a port to be provided (in the format `host:port`). [This line](https://github.com/GoogleCloudPlatform/gcloud-java/blob/pubsub-alpha/gcloud-java-pubsub/src/main/java/com/google/cloud/pubsub/testing/LocalPubsubHelper.java#L74) must therefore be changed to:\n\n``` java\ngcloudCommand.add(GCLOUD_CMD_PORT_FLAG + \"localhost:\" + port);\n```\n\nAlso we need to change the `blockUntilOutput` to be more specific that the simple port number.\n`gcloud beta emulators pubsub start` in fact first logs the underlying command:\n\n``` bash\nExecuting: /bin/bash <gcloud-path>/platform/pubsub-emulator/bin/cloud-pubsub-fake --host=localhost --port=<port>\n```\n\nSo waiting just for the port to be logged is not enough. I suggest we wait for the whole string:\n\n``` java\n\"Server started, listening on \" + port\n```\n\n/cc @garrettjonesgoogle @shinfan\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/989",
        "number": 989,
        "title": "PubSub Emulator: Subscription.ackDeadlineSeconds is defaulted to 60",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "According to the [docs](https://github.com/googleapis/googleapis/blob/master/google/pubsub/v1/pubsub.proto#L286), if `ackDeadlineSeconds` is not provided it should be defaulted to 10. In the emulator it is set to 60 instead.\n\nSee also GoogleCloudPlatform/gcloud-common#129\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/988",
        "number": 988,
        "title": "PubSub Emulator: subscriptions to deleted topics preserve old topic",
        "labels": [
            "api: pubsub",
            "priority: p2",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "As documented in [projects.topics/delete](https://cloud.google.com/pubsub/reference/rest/v1/projects.topics/delete) when a topic is deleted existing subscriptions to this topic are not deleted, but their `topic` field is set to `_deleted-topic_`.\n\nWhen testing agains the Pub/Sub emulator subscriptions to a deleted topic have their `topic` field still set to the deleted topic's name.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/987",
        "number": 987,
        "title": "NPE when getting non-existing topic or subscription",
        "labels": [
            "api: pubsub",
            "type: bug"
        ],
        "state": "closed",
        "body": "`DefaultPubSubRpc,get` returns a `Future` such that `Future.get()` returns `null` if the resource was not found. In `PubSubImpl`.\n\nIn [PubSubImpl](https://github.com/GoogleCloudPlatform/gcloud-java/blob/pubsub-alpha/gcloud-java-pubsub/src/main/java/com/google/cloud/pubsub/PubSubImpl.java#L76) transform the result using `(Topic/Subscription).fromPbFunction()` which do not handle the `null` case.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/985",
        "number": 985,
        "title": "Travis Skips Tests??",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/982",
        "number": 982,
        "title": "Cannot download gzipped objects larger than ReadChannel chunk size",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "I uploaded some big files with gsutil using gzip encoding:\n`gsutil cp -Z bigfile gs://<bucket_name>/`\n\nThis code is OK when downloading the file:\n\n```\n    Blob blob = storage.get(bucket, name);\n    try (ReadChannel reader = blob.reader()) {\n        int fileSize = blob.size().intValue();\n        reader.chunkSize(fileSize); //any bigger value is also OK\n        ByteStreams.copy(reader, Channels.newChannel(ByteStreams.nullOutputStream()));\n    }\n```\n\nThis code fails (chunk size is smaller the content size):\n\n```\n    Blob blob = storage.get(bucket, name);\n    try (ReadChannel reader = blob.reader()) {\n        int fileSize = blob.size().intValue();\n        reader.chunkSize(fileSize - 1);\n        ByteStreams.copy(reader, Channels.newChannel(ByteStreams.nullOutputStream()));\n    }\n```\n\nwith this exception\n\n```\ncom.google.cloud.storage.StorageException\n    at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:98)\n    at com.google.cloud.storage.spi.DefaultStorageRpc.read(DefaultStorageRpc.java:474)\n    at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127)\n    at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124)\n    at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:181)\n    at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:247)\n    at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:237)\n    at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124)\n    at com.google.common.io.ByteStreams.copy(ByteStreams.java:148)\n    at ...\nCaused by: java.io.EOFException\n    at java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:264)\n    at java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:255)\n    at java.util.zip.GZIPInputStream.readUInt(GZIPInputStream.java:247)\n    at java.util.zip.GZIPInputStream.readTrailer(GZIPInputStream.java:218)\n    at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:118)\n    at java.io.FilterInputStream.read(FilterInputStream.java:107)\n    at com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51)\n    at com.google.api.client.util.IOUtils.copy(IOUtils.java:94)\n    at com.google.api.client.util.IOUtils.copy(IOUtils.java:63)\n    at com.google.api.client.http.HttpResponse.download(HttpResponse.java:421)\n    at com.google.cloud.storage.spi.DefaultStorageRpc.read(DefaultStorageRpc.java:470)\n    ... 31 more\n```\n\nIt is of course not practical to increase the chunk size indefinitely, as the whole chunk is uncompressed in memory and might create OutOfMemoryErrors.\n\nBTW, the generated Java API client fails with the same error (I suppose it uses the same http stack for downloads).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/979",
        "number": 979,
        "title": "ProjectId override question",
        "labels": [],
        "state": "closed",
        "body": "After following the procedures outlined in the README ([here](https://github.com/GoogleCloudPlatform/gcloud-java#authentication)) for creating a service account for machine integration the projectId is correctly set in the json key file however the usage of it is not.\n\nI have two questions that I hope I can get help with:\n- When changing the project_id in code some project which is wrong it still works. Can someone explain if the gcloud-java or the Google Cloud service stores or parses the service account to extract the correct project_id?\n\n``` javascript\nStorage storage = StorageOptions.builder() \n  .authCredentials(AuthCredentials.createForJson(new FileInputStream(\"/path/to/my/key.json\"))\n  .projectId(\"projectDoesNotExist\") // <---- HERE\n  .build()\n  .service();\n// It is possible to use the Storage.writer and upload correctly to the service accounts project_id!!!\n```\n- Reading [Specifying a Project ID](https://github.com/GoogleCloudPlatform/gcloud-java#specifying-a-project-id) there are various ways to set the project id, however none using the following flow from code. Question is if it would be good if the StorageOptions.builder() could take a file String as argument?\n\n``` javascript\n//Todays API\nStorage storage = StorageOptions.builder() \n  .authCredentials(AuthCredentials.createForJson(new FileInputStream(\"/path/to/my/key.json\"))\n  .build()\n  .service();\n//here the project_id of StorageOptions is never set if no environment variable is set as the json project_id is never parsed\n```\n\n``` javascript\n//Proposed API change which automatically uses AuthCredentials is the json file is supplied\nStorage storage = StorageOptions.builder(\"/path/to/my/key.json\") \n  .build()\n  .service();\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/978",
        "number": 978,
        "title": "PubSub.listSubscriptions(topic) returns only names, not full subscriptions",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "We need to change the signature of:\n- `Page<Subscription> listSubscriptions(String topic, ListOption... options)`\n- `Future<AsyncPage<Subscription>> listSubscriptionsAsync(String topic, ListOption... options);`\n\nto:\n- `Page<String> listSubscriptions(String topic, ListOption... options)`\n- `Future<AsyncPage<String>> listSubscriptionsAsync(String topic, ListOption... options);`\n\nAs listing subscriptions by topic returns only names (see [here](https://cloud.google.com/pubsub/reference/rpc/google.pubsub.v1#google.pubsub.v1.ListTopicSubscriptionsResponse)). /cc @aozarov \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/972",
        "number": 972,
        "title": "Add support for EmbeddedEntity in Datastore",
        "labels": [],
        "state": "closed",
        "body": "Currently there is no support for embedded entities and no mentions of them in the documentation or Datastore example.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/969",
        "number": 969,
        "title": "Datastore: Intermittent Backend Errors since wednesday (22:00 GMT) us-central",
        "labels": [],
        "state": "closed",
        "body": "We suddenly started receiving these errors in the us-central region:\n\nCaused by: com.google.api.services.datastore.client.DatastoreException: Backend Error\n    at com.google.api.services.datastore.client.RemoteRpc.makeException(RemoteRpc.java:115)\n    at com.google.api.services.datastore.client.RemoteRpc.call(RemoteRpc.java:81)\n    at com.google.api.services.datastore.client.BaseDatastoreFactory$RemoteRpc.call(BaseDatastoreFactory.java:41)\n    at com.google.api.services.datastore.client.Datastore.runQuery(Datastore.java:109)\n    at com.google.gcloud.spi.DefaultDatastoreRpc.runQuery(DefaultDatastoreRpc.java:163)\n    ... 58 more\nCaused by: com.google.api.client.http.HttpResponseException: 503 Service Unavailable\nBackend Error\n    at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1061)\n    at com.google.api.services.datastore.client.RemoteRpc.call(RemoteRpc.java:78)\n    ... 61 more\"\n\nSome calls succeed others fail.  I can't see a gcloud API usage pattern that causes it... it just randomly happens!\n\nI asked Google to check the logs and they stated the failures were due to the use of an invalid project-id.\nFor example our project id is \"production-1103\" and they claim to see in the logs \"s~production-1103\"\n\nWe're using gcloud-java 0.1.4 and don't experience these problems in the EU region.  Could some external service change influence the project-id corruption?  Has anyone else seen this sort of thing in the past?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/964",
        "number": 964,
        "title": "Travis timeout when running Compute integration tests",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "By default Travis times out if a command runs with no output for more that 10 minutes. The error is the following:\n\n> No output has been received in the last 10 minutes, this potentially indicates a stalled build or something wrong with the build itself.\n\nBy default `mvn integration-test` produces no output until all ITs are done. In Compute this causes Travis to error as integration tests take more than 10 minutes.\n\nThis could be overcome by setting [travis_wait](https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received`) to be more tolerant.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/963",
        "number": 963,
        "title": "Provide means to wait for an Operation/Job to complete",
        "labels": [
            "api: bigquery",
            "api: compute"
        ],
        "state": "closed",
        "body": "To wait for a `Compute` operation or a `BigQuery` job users can now do:\n\n``` java\nwhile (!operation.isDone()) {\n  Thread.sleap(1000);\n}\n// User operation\n```\n\nWe could provide a better way to wait for completion, as, for instance:\n\n``` java\noperation.whenDone(new OperationCallback() {\n  public void onSuccess(Operation operation) {\n    // operation succeeded\n    // if operation == null => operation no longer exists\n  }\n\n  public void onFailure(List<OperationError> errors) {\n    // handle operation failure\n  }\n});\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/958",
        "number": 958,
        "title": "Consider moving Compute's ServiceAccount to core",
        "labels": [
            "api: compute",
            "api: core",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Compute instances contain a list of service accounts, each of each has an `email` and `scope` fields. We should consider moving this information to `gcloud-java-core` as soon as it might be needed elsewhere.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/950",
        "number": 950,
        "title": "Replace RetryHandler package-scoped StopWatch with Option's Clock",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "We should use the Clock from ServiceOptions and pass it along to the RetryHandler (instead of the StopWatch)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/949",
        "number": 949,
        "title": "DNS batch getZone do not return null for NOT FOUND",
        "labels": [
            "api: dns",
            "type: bug"
        ],
        "state": "closed",
        "body": "Although documented [here](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-dns/src/main/java/com/google/cloud/dns/DnsBatch.java#L116) 404 (NOT FOUND) exceptions are not translated into `null` (should be done [here](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-dns/src/main/java/com/google/cloud/dns/DnsBatch.java#L271)).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/945",
        "number": 945,
        "title": "BigQueryException discards exception context",
        "labels": [],
        "state": "closed",
        "body": "If BigQueryException.translateAndThrow is passed an exception that cannot be handled by BaseServiceException it throws a new exception with the message from the passed exception. However this throws away context.\n\nIt would be better if the fallback chained the inner exception.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/943",
        "number": 943,
        "title": "UnsupportedClassVersionError when testing gcloud-java-logging",
        "labels": [
            "api: logging",
            "type: bug"
        ],
        "state": "closed",
        "body": "If I try to run tests for `gcloud-java-logging` (`mvn test`) I get the following exception:\n\n```\njava.lang.UnsupportedClassVersionError: com/google/logging/v2/LoggingServiceV2Grpc$LoggingServiceV2 : Unsupported major.minor version 52.0\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:800)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:71)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:361)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at com.google.cloud.logging.spi.v2.LoggingServiceV2ApiTest.startStaticServer(LoggingServiceV2ApiTest.java:40)\n        ...\n```\n\nThis is probably caused by the fact that `grpc-logging-v2:0.0.1` is not compatible with Java7. @garrettjonesgoogle @shinfan could you please fix this? Also please check that also other `gcloud-java-logging` dependencies are compatible with Java7 (namely `grpc-logging-type:0.0.1` and `grpc-core-proto:0.0.2`, the latest probably just need to be updated to version `0.0.3`).\n\nThe reason we didn't notice this before is that `gcloud-java-logging` was not added to our parent pom, thus `mvn test` run in the root directory did not trigger tests in `gcloud-java-logging`, this should be fixed as well.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/939",
        "number": 939,
        "title": "Remove gax-related directories from logging-alpha branch",
        "labels": [
            "api: logging",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "In the [logging-alpha branch](https://github.com/GoogleCloudPlatform/gcloud-java/tree/logging-alpha) we still have gax-related directories that are no longer used. Can we remove them? /cc @shinfan @garrettjonesgoogle \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/935",
        "number": 935,
        "title": "Support Container Engine for default credentials",
        "labels": [],
        "state": "closed",
        "body": "Container Engine runs on Compute Engine and I have tried to connect datastore from Container Engine\n`DatastoreOptions.defaultInstance().service()`\nIt throws authentication exception. I think It should support with default credentials, it still runs on Google Cloud Sandbox\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/932",
        "number": 932,
        "title": "Prefixes field is not selected when listing blobs with field selector",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "Thanks to @jean-philippe-martin for spotting this.\n\nThe `prefixes` field is not selected (and thus returned in the JSON) with our field selector option. This causes `list(bucket)` to return ONLY files (and NOT directories) in the current directory when `BlobListOptions.currentDirectory()` is provided along with `BlobListOption.fields()`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/930",
        "number": 930,
        "title": "Investigate connection reset in DNS helper ",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Without catching an IOException in the DNS helper `handleBatch` method, the `testCreateChangeBatch` causes connection reset.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/929",
        "number": 929,
        "title": "DNS batch request URLs contain host",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "The individual requests in the multipartite batch request contain the scheme and host:\n\n`/dns/v1/projects/dummyprojectid/managedZones`\n\nvs\n\n`http://localhost:43754/dns/v1/projects/dummyprojectid/managedZones`\n\nTherefore, in `LocalDNSHelper` in the `pickHandler` method, we sometime relativize the URI directly and sometimes extract path first. We should investigate if this is the correct way or if we should make the queued batch requests consistent in providing URI without the scheme (by not setting host in the `options`).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/924",
        "number": 924,
        "title": "Idempotent methods: hide exceptions on retries if there is evidence the original operation succeeded",
        "labels": [
            "api: core",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This issue follows up on #883. Some idempotent methods can report an exception when retries. This was observed for example within #808 and #816. The intuition is that there are cases when the socket connection reports a timeout while waiting for a server response. A subsequent retry then receives an error because the operation finished in the meantime.\n\nWe introduced a new attribute `rejected` in BaseServiceException which indicates if an error has been certainly refused by the server (for example when quota has been exceeded). We need to adjust error handling in all the modules to properly work with `idempotent` and `rejected` attributes. The discussion regarding create and delete operations in #883 should be kept in mind.\n\nWe established that 500-type errors should not be treated as `rejected` because we cannot guarantee that the server did not process anything. We should assume that we can get a 500 while the request has been processed and committed on the service side.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/922",
        "number": 922,
        "title": "Missing DNS section in TESTING.md",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/920",
        "number": 920,
        "title": "We could use a DNS to provide syntactic sugar to operations that now accept one argument",
        "labels": [
            "api: dns",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "e.g.  in addition to `Zone getZone(String zoneName)` we can provide `Iterable<Zone> getZones(Iterable<String> zoneNames)` and/or the vararg version of it.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/918",
        "number": 918,
        "title": "Ensure consistency in error checking between batch and DNS",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/916",
        "number": 916,
        "title": "Compute instances' networkInterface only accepts one access config",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "`Instance.networkInterfaces[].accessConfigs` is [documented](https://cloud.google.com/compute/docs/reference/latest/instances#networkInterfaces.accessConfigs) as an array of access configurations. However if I try to provide more than one access config I get:\n\n``` json\n{\n  \"code\" : 400,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"Invalid value for field 'resource.networkInterfaces[0]': ''. Multiple access configs are not supported.\",\n    \"reason\" : \"invalid\"\n  } ],\n  \"message\" : \"Invalid value for field 'resource.networkInterfaces[0]': ''. Multiple access configs are not supported.\"\n}\n```\n\nAre multiple access configs going to be supported? Regardless, I believe this should be added to the docs.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/915",
        "number": 915,
        "title": "Compute instances only accept one network interface",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "`Instance.networkInterfaces` is [documented](https://cloud.google.com/compute/docs/reference/latest/instances#networkInterfaces) as an array of network interface configurations. However if I try to provide more than one network interface I get:\n\n``` json\n{\n  \"code\" : 400,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"Invalid value for field 'resource': ''. Expected one network interface.\",\n    \"reason\" : \"invalid\"\n  } ],\n  \"message\" : \"Invalid value for field 'resource': ''. Expected one network interface.\"\n}\n```\n\nAre multiple network interfaces going to be supported? Regardless, I believe this should be added to the docs.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/910",
        "number": 910,
        "title": "Overload options method to take a default namespace in LocalDatastoreHelper",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "We should also document the default namespace in the options class and builder.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/903",
        "number": 903,
        "title": "Broken links to Github repos in Maven-generated website ",
        "labels": [],
        "state": "closed",
        "body": "On one of our website pages ([see here](http://googlecloudplatform.github.io/gcloud-java/0.1.7/gcloud-java/dependencies.html)), the links to our modules under `ArtifactId` in the `compile` section and some of the links to transitive dependencies below are broken because they don't use `/tree/master` in the URLs.  For example, the link to gcloud-java-datastore is `https://github.com/GoogleCloudPlatform/gcloud-java/gcloud-java-datastore` instead of `https://github.com/GoogleCloudPlatform/gcloud-java/tree/master/gcloud-java-datastore`. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/902",
        "number": 902,
        "title": "Update site/apt/index.apt with current set of services",
        "labels": [],
        "state": "closed",
        "body": "This should also be included in the doc for adding a service.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/898",
        "number": 898,
        "title": "Retry the rpc call if the status code is RESOURCE_EXHAUSTED",
        "labels": [],
        "state": "closed",
        "body": "Right now we ignore the status code if the method is non-idempotent. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/897",
        "number": 897,
        "title": "Refactor PageStreaming by introducing PageAccessor",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Refactor page-streaming feature in both GAX and Pubsub by introducing a PageAccessor object, which will allow better control over pages.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/896",
        "number": 896,
        "title": "All param descriptions should start with lower case and does not need a period",
        "labels": [],
        "state": "closed",
        "body": "Related PR: https://github.com/GoogleCloudPlatform/gcloud-java/pull/885\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/890",
        "number": 890,
        "title": "StackOverflowError mocking our functional objects",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "There seem to be a problem with `EasyMock` (as well as `Mockito`) when mocking classes that have a `final` `equals()` method that in its body calls other methods on the current object.\nThis results in a StackOverflowError as the following:\n\n```\njava.lang.StackOverflowError\n    at java.util.ArrayList$Itr.<init>(ArrayList.java:820)\n    at java.util.ArrayList$Itr.<init>(ArrayList.java:820)\n    at java.util.ArrayList.iterator(ArrayList.java:814)\n    at org.easymock.internal.UnorderedBehavior.addActual(UnorderedBehavior.java:50)\n    at org.easymock.internal.MocksBehavior.addActual(MocksBehavior.java:87)\n    at org.easymock.internal.ReplayState.invokeInner(ReplayState.java:58)\n    at org.easymock.internal.ReplayState.invoke(ReplayState.java:46)\n    at org.easymock.internal.MockInvocationHandler.invoke(MockInvocationHandler.java:40)\n    at org.easymock.internal.ObjectMethodsFilter.invoke(ObjectMethodsFilter.java:94)\n    at org.easymock.internal.ClassProxyFactory$MockMethodInterceptor.intercept(ClassProxyFactory.java:97)\n    at com.google.gcloud.storage.Blob$$EnhancerByCGLIB$$aa59c155.toPb(<generated>)\n    at com.google.gcloud.storage.Blob.equals(Blob.java:529)\n    at org.easymock.internal.ExpectedInvocation.matches(ExpectedInvocation.java:85)\n    at org.easymock.internal.UnorderedBehavior.addActual(UnorderedBehavior.java:57)\n    at org.easymock.internal.MocksBehavior.addActual(MocksBehavior.java:87)\n    at org.easymock.internal.ReplayState.invokeInner(ReplayState.java:58)\n    at org.easymock.internal.ReplayState.invoke(ReplayState.java:46)\n    at org.easymock.internal.MockInvocationHandler.invoke(MockInvocationHandler.java:40)\n    at org.easymock.internal.ObjectMethodsFilter.invoke(ObjectMethodsFilter.java:94)\n    at org.easymock.internal.ClassProxyFactory$MockMethodInterceptor.intercept(ClassProxyFactory.java:97)\n    at com.google.gcloud.storage.Blob$$EnhancerByCGLIB$$aa59c155.toPb(<generated>)\n    at com.google.gcloud.storage.Blob.equals(Blob.java:529)\n```\n\nTo overcome this error all `final` `equals` methods should first check for \"pointer\" equality. For instance [`Blob.equals`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/storage/Blob.java#L528) must become:\n\n``` java\n@Override\npublic final boolean equals(Object obj) {\n  return this == obj || (obj instanceof Blob && Objects.equals(toPb(), ((Blob) obj).toPb())\n      && Objects.equals(options, ((Blob) obj).options));\n}\n```\n\nThis should be fixed ASAP. Even tough we don't encourage users to mock our objects and provide test helpers to aid testing we don't want them to stumble upon this error.\n\nThis issue should remain open until fixed in compute as well.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/888",
        "number": 888,
        "title": "Create release profile and move source and javadoc generation/jar to it",
        "labels": [],
        "state": "closed",
        "body": "This follows the discussion in #876\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/887",
        "number": 887,
        "title": "Rename DiskTypeId.diskType() to type()",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/886",
        "number": 886,
        "title": "Make it easier to create ListValue by adding specific type flavours of ListValue.of method",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "e.g. `ListValue.of(String..)`, `ListValue.of(double...)`,...\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/880",
        "number": 880,
        "title": "We should move the unit-tests for the Local/Remote service test helpers to be under \"testing\"",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "They should match the same package name as the class they test.\nIt looks like we already do that for DNS.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/879",
        "number": 879,
        "title": "Create base class for local test helpers",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "There is some functionality, such as finding free ports to bind and listen to, that are useful across local test helpers.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/877",
        "number": 877,
        "title": "Migrate from com.google.gcloud.* to com.google.cloud",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "The current plan is to:\n\n1) rename our Java package structure from `com.google.gcloud.` to `com.google.cloud.`\n\n2) rename maven group-id from `com.google.gcloud` to `com.google.cloud`.\n\nFor now we are going to keep the following:\n\n1) repository (and repository name).\n\n2) maven artifact-id (should match repository name and therefore should be kept for now as gcloud-java).\n\n3) directory structure and maven modules.\n\n/cc @jgeewax \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/874",
        "number": 874,
        "title": "Implement integration tests for DNS batch",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/873",
        "number": 873,
        "title": "Add expiration date to App Engine credentials",
        "labels": [
            "auth"
        ],
        "state": "closed",
        "body": "See [this PR](https://github.com/google/google-auth-library-java/pull/60#issue-146614817) for context.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/872",
        "number": 872,
        "title": "makeClient INFO: Not using any credentials",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Well I was hoping that this would completely go away with 0.1.7... but I see this has been changed from a WARNING to an INFO.  I don't need credentials because of my setup.  Despite that, this is in my logs _for every single call_ to the datastore.  Thousands of times.  Makes my logs much harder to read.  Is there a \"quiet\" option?  If not I'd like to formally request one.  This is spit out on stderr.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/867",
        "number": 867,
        "title": "When running in GCE, it should respect GOOGLE_APPLICATION_CREDENTIALS first",
        "labels": [
            "auth"
        ],
        "state": "closed",
        "body": "When running inside of GCE, it seems to be picking up machine credentials. I have credentials set via the env var `GOOGLE_APPLICATION_CREDENTIALS`\n\n```\nroot@6a740ead3d2c:/# export\ndeclare -x GOOGLE_APPLICATION_CREDENTIALS=\"/var/secrets/wise-coyote-827.json\"\n```\n\n```\nroot@6a740ead3d2c:/# ls -lh $GOOGLE_APPLICATION_CREDENTIALS\n-rw------- 1 1001 1001 2.3K Apr  6 17:47 /var/secrets/wise-coyote-827.json\n```\n\n```\nroot@6a740ead3d2c:/# cat $GOOGLE_APPLICATION_CREDENTIALS\n{\n  \"type\": \"service_account\",\n...\n```\n\nWhen I start my app, it complains:\n\n```\nApr 06, 2016 6:08:29 PM com.google.datastore.v1beta3.client.DatastoreFactory makeClient\nINFO: Not using any credentials\n18:08:29.859 [main] ERROR c.s.apollo.httpservice.HttpService - Uncaught exception on thread Thread[main,5,main], exiting\ncom.spotify.apollo.httpservice.LoadingException: Something went wrong\n    at com.spotify.apollo.httpservice.HttpService.failure(HttpService.java:149) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpService.boot(HttpService.java:142) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpService.boot(HttpService.java:90) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpService.boot(HttpService.java:80) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpService.boot(HttpService.java:71) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.example.apollo.books.BooksService.main(BooksService.java:25) ~[books-service.jar:na]\nCaused by: com.google.gcloud.datastore.DatastoreException: Not authorized.\n    at com.google.gcloud.datastore.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:102) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    at com.google.gcloud.datastore.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:139) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    at com.google.gcloud.datastore.DatastoreOptions.normalize(DatastoreOptions.java:116) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    at com.google.gcloud.datastore.DatastoreOptions.access$300(DatastoreOptions.java:34) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    at com.google.gcloud.datastore.DatastoreOptions$Builder.build(DatastoreOptions.java:81) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    at com.google.gcloud.datastore.DatastoreOptions.defaultInstance(DatastoreOptions.java:167) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    at com.example.apollo.books.BooksService.init(BooksService.java:29) ~[books-service.jar:na]\n    at com.spotify.apollo.environment.ApolloEnvironmentModule$ApolloEnvironmentImpl.initialize(ApolloEnvironmentModule.java:155) ~[apollo-environment-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpServiceModule.lambda$bindAppInit$1(HttpServiceModule.java:52) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpServiceModule.requestHandler(HttpServiceModule.java:58) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    at com.spotify.apollo.httpservice.HttpService.boot(HttpService.java:116) ~[apollo-http-service-1.0.4.jar:1.0.4]\n    ... 4 common frames omitted\nCaused by: com.google.datastore.v1beta3.client.DatastoreException: Not authorized.\n    at com.google.datastore.v1beta3.client.RemoteRpc.makeException(RemoteRpc.java:126) ~[datastore-v1beta3-proto-client-1.0.0-beta.jar:na]\n    at com.google.datastore.v1beta3.client.RemoteRpc.makeException(RemoteRpc.java:169) ~[datastore-v1beta3-proto-client-1.0.0-beta.jar:na]\n    at com.google.datastore.v1beta3.client.RemoteRpc.call(RemoteRpc.java:89) ~[datastore-v1beta3-proto-client-1.0.0-beta.jar:na]\n    at com.google.datastore.v1beta3.client.Datastore.lookup(Datastore.java:92) ~[datastore-v1beta3-proto-client-1.0.0-beta.jar:na]\n    at com.google.gcloud.datastore.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:137) ~[gcloud-java-datastore-0.1.7.jar:0.1.7]\n    ... 13 common frames omitted\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/863",
        "number": 863,
        "title": "Change examples' javadoc to show how to use appassembler",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "Right now our example classes contain the following javadoc (example taken from resourcemanager):\n\n```\nSteps needed for running the example:\n\nlogin using gcloud SDK - gcloud auth login.\ncompile using maven - mvn compile\nrun using maven - mvn exec:java -Dexec.mainClass=\"com.google.gcloud.examples.resourcemanager.ResourceManagerExample\" -Dexec.args=\"[list | [create | delete | get] projectId]\"\n```\n\nOnce `gcloud-java-nio` is merged we will move to `appassembler` hence javadoc should be updated accordingly. /cc @aozarov @jean-philippe-martin \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/861",
        "number": 861,
        "title": "Add example applications on website and readme",
        "labels": [],
        "state": "closed",
        "body": "There are a couple more samples in the java-docs-samples repo that can be added to the readme and website.  Also \"Managed VMs\" should be renamed \"Flexible Environment\" for the SparkJava app.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/859",
        "number": 859,
        "title": "Include LocalStorageService in the testing documentation.",
        "labels": [
            "api: core",
            "api: storage"
        ],
        "state": "closed",
        "body": "Currently LocalStorageService is being implemented in the gcs-nio branch.\nOnce that branch is merged and `LocalStorageService` is ready for use we should make sure\nit has its own `package-info.java` and update the [TESTING](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/TESTING.md) instructions to include it.\n\n/cc @jart @jean-philippe-martin \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/857",
        "number": 857,
        "title": "When using default retry settings we should get that default from the specific service options",
        "labels": [
            "api: core",
            "api: datastore",
            "api: storage"
        ],
        "state": "closed",
        "body": "As service may provide a specific exponential back-off requirements in its SLA.\nE.g. for Datastore see [this](https://cloud.google.com/datastore/sla).\n\nWe should add a protected method in `ServiceOptions` to return the defaultRetryParams which \nwill be used when user didn't explicitly provided one. Default implementation should return `RetryParams.defaultInstance()`.\n\nWe should override this method in services that provide their own specific retry settings such as Datastore and Storage.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/855",
        "number": 855,
        "title": "Use appassembler in the DNS examples",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "For reference see #839 \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/851",
        "number": 851,
        "title": "BigQueryJob returns false if it does not exists",
        "labels": [
            "api: compute",
            "type: bug"
        ],
        "state": "closed",
        "body": "On line 183, the job return `false` if it is `null`. It makes more sense for it to return `true`. A job once created cannot be deleted. If a user somehow obtained a non-null `Job` instance, the only way for this get to receive `null` is that the job was completed and somehow perished.\n\n/cc @aozarov @mziccard \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/846",
        "number": 846,
        "title": "Language switcher uses the wrong logo for Ruby",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "We're using the Rails logo, not the Ruby logo -- can we switch this out ASAP?\n\nHere's the list of logos:\n\nhttps://github.com/GoogleCloudPlatform/gcloud-node/tree/gh-pages/src/images\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/843",
        "number": 843,
        "title": "Credentials fail with \"Cloud Datastore API not enabled\"",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "I use the same credentials to access Cloud Storage API and Cloud Datastore API. Both APIs are enabled for my project. The Cloud Storage works as expected. Datastore fails with:\n\n```\ncom.google.datastore.v1beta3.client.DatastoreException: The Cloud Datastore API is not enabled for the project rebelplayercom, code=FAILED_PRECONDITION\n    at com.google.datastore.v1beta3.client.RemoteRpc.makeException(RemoteRpc.java:126)\n    at com.google.datastore.v1beta3.client.RemoteRpc.makeException(RemoteRpc.java:169)\n    at com.google.datastore.v1beta3.client.RemoteRpc.call(RemoteRpc.java:89)\n    at com.google.datastore.v1beta3.client.Datastore.lookup(Datastore.java:92)\n    at com.google.gcloud.datastore.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:137)\n```\n\nAt least one more user reported the same problem yesterday on StackOverflow. He also claims that the Datastore API is enabled for his project.\n\nNote that the API explorer shows v1beta2 for Cloud Datastore API, not v1beta3. Can it be the cause of this problem?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/841",
        "number": 841,
        "title": "Update order of after_success tasks for deployment",
        "labels": [],
        "state": "closed",
        "body": "We should push website and readme version updates after the artifacts have successfully been pushed.  Integration tests (part of the deployment step) sometimes fail because of flakiness, and it's wasted effort to push a new version of the website send a PR to update the readme versions when Travis will have to be rerun.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/840",
        "number": 840,
        "title": "Write integration tests for Datastore",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Datastore already has a beefed-up local emulator, so these integration tests don't need to be very detailed.  The main point is that they can interact with the actual service (i.e. the request endpoint is correct, errors are being translated properly, etc)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/836",
        "number": 836,
        "title": "ITBigQueryTest flakiness",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "Recently, these two tests have been failing more often than passing:\n\n```\ntestInsertFromFile(com.google.gcloud.bigquery.it.ITBigQueryTest)  Time elapsed: 13.864 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<RECORD> but was:<PRIMITIVE>\n    at com.google.gcloud.bigquery.it.ITBigQueryTest.testInsertFromFile(ITBigQueryTest.java:939)\ntestListAllTableData(com.google.gcloud.bigquery.it.ITBigQueryTest)  Time elapsed: 0.291 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<RECORD> but was:<PRIMITIVE>\n    at com.google.gcloud.bigquery.it.ITBigQueryTest.testListAllTableData(ITBigQueryTest.java:640)\n```\n\nI will comment out these two tests for now, but we should uncomment and diagnose the problem when possible.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/830",
        "number": 830,
        "title": "Fix null pointer test in CloudStorageFileSystemProviderTest",
        "labels": [
            "api: storage",
            "priority: p1",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "A null pointer is triggered from `testNullness` and therefore is disabled.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/829",
        "number": 829,
        "title": "NIO generation support",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It's very important that we have richer testing for the atomicity of certain storage operations, like creating an object only if doesn't exist. We should also implement NIO `OpenOption` and `CopyOption` implementations for generations, which map to the functionality provided by `StorageRpc.Option`. `FakeStorageRpc` should have generational awareness for supporting this. \n\n@jean-philippe-martin \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/828",
        "number": 828,
        "title": "Ability to inline JSON into GOOGLE_APPLICATION_CREDENTIALS",
        "labels": [
            "api: core",
            "auth"
        ],
        "state": "closed",
        "body": "Some CI systems don't really give you the option to have files. Since we're not sure yet if it would be a good idea to allow the user to configure the default instance of `CloudStorageFileSystemProvider` with a `Storage` object that has custom authentication, it would be really nice if the environment variable provided greater flexibility.\n\nI propose that, if the `GOOGLE_APPLICATION_CREDENTIALS` environment has a value that:\n1. Starts with `^\\s*\\{`\n2. Is valid JSON\n\nThen it will be treated as though it's the contents of the key file, rather than a filename.\n\n@aozarov @jean-philippe-martin \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/827",
        "number": 827,
        "title": "Wrong default project ID is chosen when active configuration is not the default or service keys are used",
        "labels": [],
        "state": "closed",
        "body": "# Wrong gcloud command configuration is loaded\n## Problem\n\nMy `~/.config/gcloud/configurations/config_default` contents:\n\n```\n[core]\naccount = ***REDACTED***@gmail.com\nproject = gcpnext2016-swast\n[compute]\nzone = us-central1-a\nregion = us-central1\n```\n\nMy active configuration:\n\n```\n$ gcloud config list\nYour active configuration is: [swast-test-flexible]\n[app]\nsuppress_change_warning = true\n[compute]\nregion = us-central1\nzone = us-central1-b\n[core]\naccount = swast@google.com\ndisable_usage_reporting = False\nproject = swast-test-flexible\n[metrics]\ncommand_name = gcloud.config.list\n```\n\nWhen I run the [Bookshelf](https://cloud.google.com/java/getting-started/tutorial-app) application, which uses Application Default Credentials locally with `mvn -Plocal clean jetty:run-exploded` and I connect to http://localhost:8080, I see data from my `gcpnext2016-swast` project, not the `swast-test-flexible` project like I expect.\n## Steps to reproduce\n1. Run the [Bookshelf](https://cloud.google.com/java/getting-started/tutorial-app) application, which uses Application Default Credentials locally with `mvn -Plocal clean jetty:run-exploded` and I connect to http://localhost:8080\n2. Add a few books.\n3. Run `gcloud init`.\n4. Create a new configuration instead of modifying the default, and select a different project this time.\n5. Run the Bookshelf application again.\n6. Notice that you still see the same data from the project selected in the default configuration, not the new configuration that you just activated.\n## Suspected root cause\n\ngcloud-java uses default configuration rather than the currently selected one to figure out which project to send RPCs to. https://github.com/GoogleCloudPlatform/gcloud-java/blob/d03e5a7d80dc17d9012476557015e4f44be64687/gcloud-java-core/src/main/java/com/google/gcloud/ServiceOptions.java#L394\n# Project ID is not extracted from service keys\n## Problem\n\nWhen I use a service key, with the Bookshelf app command\n\n```\nGOOGLE_APPLICATION_CREDENTIALS=$HOME/src/service-keys/swast-test-flexible.json mvn -Plocal clean jetty:run-exploded\n```\n\nI get an exception when my default gcloud command configuration has a different project ID than the service key.\n\n```\nCaused by: com.google.gcloud.datastore.DatastoreException: Unauthorized.\n```\n## Steps to reproduce\n1. Create a JSON service key for a project (a different project than what the default gcloud command configuration is set to).\n2. Run the Bookshelf application using this service key.\n   `\n   GOOGLE_APPLICATION_CREDENTIALS=path/to/key.json mvn -Plocal clean jetty:run-exploded\n   `\n3. Observe an unexpected `com.google.gcloud.datastore.DatastoreException`.\n## Suspected root cause\n\nThe defaultProjectId is not extracting the project information from the service key, as I would expect it to. Note that a key is of the format:\n\n```\n{\n  \"type\": \"service_account\",\n  \"project_id\": \"swast-test-flexible\",  <-- gcloud-java should be using this, but it's not.\n  \"private_key_id\": \"abcdedfghijklmnop\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nBLAHblahBLAH\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"getting-started-java-laptop@swast-test-flexible.iam.gserviceaccount.com\",\n  \"client_id\": \"1234567890\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/getting-started-java-laptop%40swast-test-flexible.iam.gserviceaccount.com\"\n}\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/824",
        "number": 824,
        "title": "Better naming for resource identities and service ids",
        "labels": [
            "api: compute",
            "type: cleanup",
            "type: question"
        ],
        "state": "closed",
        "body": "Our `XxxInfo` classes have two fields with a similar name\n- `xxxId`: this fields is of type `XxxId` and holds a user-defined identity for the resource\n- `id`: this fields holds a service-generated (opaque) id\n\nWe should provide a better naming to easily distinguish the two fields. Possible solutions are:\n- renaming `id` to `generatedId` (this is the preferred way so far)\n- renaming `id` to `opaqueId`\n\nNote: this issue also applies to other classes (e.g. compute's `DiskImageConfiguration`).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/819",
        "number": 819,
        "title": "Write docs on steps necessary for supporting a new service.",
        "labels": [],
        "state": "closed",
        "body": "This readme should contain items such as (but not limited to):\n- Splitting code into distinct SPI and API layer\n- Writing local test helpers if an emulator doesn't already exist (and discuss standards for a test helper/emulator)\n- Documentation (package info, step-by-step guide, other docs that need to be updated)\n- Adding example code to gcloud-java-examples\n- Making sure any versioned jars/docs/etc are included in the update_pom_version.sh script\n- Add the example to the list of examples in gcloud-java-examples/pom.xml in the assembler plugin\n- Look at the SLA to determine the appropriate default retry settings (see #857)\n- Be aware that library version in READMEs is auto-updated by utilities/update_docs_version.sh when releasing.\n- Mention that code should be added to [gcloud-java-examples/test-apps](https://github.com/GoogleCloudPlatform/gcloud-java-examples/tree/master/test-apps) for each new service. \n\nThis doc can be linked from the CONTRIBUTING docs page.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/818",
        "number": 818,
        "title": "Add LocalDnsHelper to TESTING.md",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/816",
        "number": 816,
        "title": "Create a retry helper that doesn't retry on socket timeouts",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "For non-reentrant operations (e.g. creating resources and applying a change request), we should have a separate retry handler that won't retry on socket timeouts.  This is because a socket timeout error can occur after a request was successfully sent to the service.  This would be helpful in DNS (see issue #808), but may also be helpful in other services.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/815",
        "number": 815,
        "title": "Remove comments for private methods in generated spi code",
        "labels": [
            "api: logging",
            "api: pubsub",
            "triaged for GA"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/814",
        "number": 814,
        "title": "Improve the method names in BackoffParams",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Right now method names only fit for retry settings but not the timeout.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/813",
        "number": 813,
        "title": "NIO: Implement directory listing",
        "labels": [],
        "state": "closed",
        "body": "Implement these methods:\n\n``` java\n  /**\n   * Throws {@link UnsupportedOperationException} because this feature hasn't been implemented yet.\n   */\n  @Override\n  public DirectoryStream<Path> newDirectoryStream(Path dir, Filter<? super Path> filter) {\n    // TODO: Implement me.\n    throw new UnsupportedOperationException();\n  }\n\n  /**\n   * Throws {@link UnsupportedOperationException} because this feature hasn't been implemented yet.\n   */\n  @Override\n  public PathMatcher getPathMatcher(String syntaxAndPattern) {\n    // TODO: Implement me.\n    throw new UnsupportedOperationException();\n  }\n\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/812",
        "number": 812,
        "title": "CreateTopic method in pubsub-v1 should not need bundling",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Users probably do not need bundling for createTopic method since it is rare to create many topics at a time.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/811",
        "number": 811,
        "title": "NIO: Support string file attributes",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Implement these method:\n\n``` java\n  public Map<String, Object> readAttributes(Path path, String attributes, LinkOption... options) {\n    // Java 7 NIO defines at least eleven string attributes we'd want to support\n    // (eg. BasicFileAttributeView and PosixFileAttributeView), so rather than a partial\n    // implementation we rely on the other overload for now.\n    throw new UnsupportedOperationException();\n  }\n\n  /**\n   * Throws {@link UnsupportedOperationException} because Cloud Storage objects are immutable.\n   */\n  @Override\n  public void setAttribute(Path path, String attribute, Object value, LinkOption... options) {\n    throw new CloudStorageObjectImmutableException();\n  }\n```\n\nThis hasn't been a priority so far, because a type-safe version of this API exists that offers the exact same functionality. We consider that API better. Bet we need to support this too.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/810",
        "number": 810,
        "title": "NIO: Further research error code translation",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See `CloudStorageFileSystemProvider#asIOException` method.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/809",
        "number": 809,
        "title": "NIO: Close channels on FS close",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "CloudStorageFileSystem#close() should synchronously close all active channels associated with the file system instance, per NIO documentation.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/808",
        "number": 808,
        "title": "Investigate flaky DNS integration test",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "[This build](https://travis-ci.org/GoogleCloudPlatform/gcloud-java/builds/119298316) saw the integration test pass in two modules and fail in the third with the following issue:\n\n```\nRunning com.google.gcloud.dns.it.ITDnsTest\nTests run: 12, Failures: 1, Errors: 1, Skipped: 0, Time elapsed: 114.627 sec <<< FAILURE! - in com.google.gcloud.dns.it.ITDnsTest\ntestInvalidChangeRequest(com.google.gcloud.dns.it.ITDnsTest)  Time elapsed: 24.69 sec  <<< ERROR!\ncom.google.gcloud.dns.DnsException: The 'entity.change.deletions[0]' resource named 'subdomain.gcldjvit-65ccc5a3-5403-47f3-94ee.com. (A)' does not exist.\n    at com.google.gcloud.dns.it.ITDnsTest.testInvalidChangeRequest(ITDnsTest.java:652)\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: \n404 Not Found\n{\n  \"code\" : 404,\n  \"errors\" : [ {\n    \"domain\" : \"global\",\n    \"message\" : \"The 'entity.change.deletions[0]' resource named 'subdomain.gcldjvit-65ccc5a3-5403-47f3-94ee.com. (A)' does not exist.\",\n    \"reason\" : \"notFound\"\n  } ],\n  \"message\" : \"The 'entity.change.deletions[0]' resource named 'subdomain.gcldjvit-65ccc5a3-5403-47f3-94ee.com. (A)' does not exist.\"\n}\n    at com.google.gcloud.dns.it.ITDnsTest.testInvalidChangeRequest(ITDnsTest.java:652)\ntestListZones(com.google.gcloud.dns.it.ITDnsTest)  Time elapsed: 0.686 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<0> but was:<1>\n    at com.google.gcloud.dns.it.ITDnsTest.testListZones(ITDnsTest.java:379)\nResults :\nFailed tests: \n  ITDnsTest.testListZones:379 expected:<0> but was:<1>\nTests in error: \n  ITDnsTest.testInvalidChangeRequest:652 \u00bb Dns The 'entity.change.deletions[0]' ...\nTests run: 12, Failures: 1, Errors: 1, Skipped: 0\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/804",
        "number": 804,
        "title": "Add javadoc bundling step in RELEASING docs",
        "labels": [],
        "state": "closed",
        "body": "This is pertinent when releasing a new module.  An example PR is #802 for DNS.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/803",
        "number": 803,
        "title": "Add package-info for dns.testing package",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/793",
        "number": 793,
        "title": "Merge dns-alpha to master",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Merge dns-alpha to master after #789 is merged.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/792",
        "number": 792,
        "title": "Make Operation.targetId of ResourceId type",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Compute's operations have a `targetId` field that right now is of type `String`.\nAs soon as we mapped all possible resource URLs to identity classes we should change `targetId` to `ResourceId` type. Operation class should become:\n\n``` java\npublic class Operation<T extends ResourceId> {\n  // ...\n  T targetId();\n  // ...\n}\n```\n\nThis way all methods in `Compute` will return the corresponding operation, eg:\n\n``` java\nOperation<SnapshotId> createSnapshot(SnapshotInfo snapshot, OperationOption... options);\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/791",
        "number": 791,
        "title": "Decide whether to add another NIO example and split into two example jars",
        "labels": [],
        "state": "closed",
        "body": "Discussing #714, we considered adding another example that uses NIO in the \"normal\" way (via Maven), in addition to the unit tests. The downside of doing that is that we'd have to split the examples into two projects, since if we add a gcloud-java-nio dependency to the examples project then the Stat example will become pointless (its purpose is to show how to add GCS support to a project that does _not_ depend on gcloud-java-nio).\n\ncontext: [#714 (comment)](https://github.com/GoogleCloudPlatform/gcloud-java/pull/714#discussion_r57388202)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/790",
        "number": 790,
        "title": "Update example documentation with correct APIs to enable (if necessary)",
        "labels": [],
        "state": "closed",
        "body": "Check whether we need to tell people to enable both\"Google Cloud Storage\" and \"Google Cloud Storage JSON API\". If so, update the docs.\n\nContext: [#714 (comment)](https://github.com/GoogleCloudPlatform/gcloud-java/pull/714#discussion_r57408959).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/788",
        "number": 788,
        "title": "Adjust DNS documentation to treat ChangeRequest at functional object.",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/779",
        "number": 779,
        "title": "Rename class DnsRecord",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "This was pointed out by the DNS team.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/778",
        "number": 778,
        "title": "Consider running all examples from a jar file",
        "labels": [],
        "state": "closed",
        "body": "context: https://github.com/GoogleCloudPlatform/gcloud-java/pull/714#discussion_r55616331\n\nThe Stat example uses a jar (that's its raison d'etre). @aozarov suggests we change the other examples to also use a jar.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/771",
        "number": 771,
        "title": "Move field declarations at the top of the class in gcloud-java-logging",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "Fields should be declared at the top of the class, before any method declarations, constructors, initializers or inner classes.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/769",
        "number": 769,
        "title": "LocalLoggingHelper uses 8080 as default port.",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The test could fail if the port is occupied. LocalLoggingHelper should be able to search for available ports.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/763",
        "number": 763,
        "title": "Remove reflection to get App Engine credentials and project ID",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "In production App Engine (standard runtime), reflection to get project ID and credentials won't work unless the user depends on appengine-api-1.0-sdk, even though the necessary jars are already provided by the runtime.  To get around this, we should declare a \"provided\"-scoped dependency on that library in `gcloud-java-core` and use the `AppIdentityService` directly instead of through reflection to get credentials and the project ID.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/759",
        "number": 759,
        "title": "Both pageToken and startPageToken are used as list options",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "As noticed by @mderka we are using `pageToken` in `resourcemanager` while `startPageToken` in `storage` and `bigquery`. We should probably pick a name and stick to it.\n\nMy feeling is that `pageToken` is already clear enough so we can go with it and remove all `startPageToken`. What do you guys think?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/757",
        "number": 757,
        "title": "Migrate DNS to new common serialization",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/756",
        "number": 756,
        "title": "Fix coding style problems in gcloud-pubsub-java",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Output from the style checker:\n\n```\nStarting audit...\nPublisherApiTest.java:19:8: error: Unused import: com.google.api.gax.grpc.ApiCallSettings. Use /google/src/head/depot/google3/tools/java/remove_unused_imports.py to automatically remove unused imports.\nPublisherApiTest.java:34: warning: Wrong order for org.junit.After import. Use /google/src/head/depot/google3/tools/java/sort_java_imports.py to automatically sort your imports.\nPublisherApiTest.java:112: error: Line is longer than 100 characters (found 109).\nSubscriberApi.java:36:8: error: Unused import: com.google.api.gax.grpc.ApiCallSettings. Use /google/src/head/depot/google3/tools/java/remove_unused_imports.py to automatically remove unused imports.\nSubscriberApi.java:192: error: Line is longer than 100 characters (found 102).\nSubscriberApi.java:509: error: Line is longer than 100 characters (found 101).\nSubscriberApi.java:631: error: Line is longer than 100 characters (found 102).\nSubscriberSettings.java:225: error: Line is longer than 100 characters (found 101).\nSubscriberSettings.java:319:7: warning: Name 'LIST_SUBSCRIPTIONS_PAGE_STR_DESC' must match pattern '^[a-z][a-zA-Z0-9]*_?$'.\nPublisherApi.java:36:8: error: Unused import: com.google.api.gax.grpc.ApiCallSettings. Use /google/src/head/depot/google3/tools/java/remove_unused_imports.py to automatically remove unused imports.\nPublisherApi.java:189: error: Line is longer than 100 characters (found 101).\ntesting/LocalPublisherImpl.java:82: error: Line is longer than 100 characters (found 109).\nPublisherSettings.java:289:7: warning: Name 'LIST_TOPICS_PAGE_STR_DESC' must match pattern '^[a-z][a-zA-Z0-9]*_?$'.\nPublisherSettings.java:314:7: warning: Name 'LIST_TOPIC_SUBSCRIPTIONS_PAGE_STR_DESC' must match pattern '^[a-z][a-zA-Z0-9]*_?$'.\nSubscriberApi.java:36:8: error: Unused import: com.google.api.gax.grpc.ApiCallSettings. Use /google/src/head/depot/google3/tools/java/remove_unused_imports.py to automatically remove unused imports.\nSubscriberApi.java:192: error: Line is longer than 100 characters (found 102).\nSubscriberApi.java:509: error: Line is longer than 100 characters (found 101).\nSubscriberApi.java:631: error: Line is longer than 100 characters (found 102).\nSubscriberSettings.java:225: error: Line is longer than 100 characters (found 101).\nSubscriberSettings.java:319:7: warning: Name 'LIST_SUBSCRIPTIONS_PAGE_STR_DESC' must match pattern '^[a-z][a-zA-Z0-9]*_?$'.\nPublisherApi.java:36:8: error: Unused import: com.google.api.gax.grpc.ApiCallSettings. Use /google/src/head/depot/google3/tools/java/remove_unused_imports.py to automatically remove unused imports.\nPublisherApi.java:189: error: Line is longer than 100 characters (found 101).\nPublisherSettings.java:289:7: warning: Name 'LIST_TOPICS_PAGE_STR_DESC' must match pattern '^[a-z][a-zA-Z0-9]*_?$'.\nPublisherSettings.java:314:7: warning: Name 'LIST_TOPIC_SUBSCRIPTIONS_PAGE_STR_DESC' must match pattern '^[a-z][a-zA-Z0-9]*_?$'.\nAudit done.\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/753",
        "number": 753,
        "title": "Script for updating main README",
        "labels": [
            "api: core",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "While working on the documentation for the DNS, I am realizing that keeping the snippets, module-specific readme, and main readme consistent is quite difficult and time consuming. I wonder if for the future use, we could benefit from a script which would generate the main readme from the module specific ones. The main readme would look somewhat as follows:\n\n```\nDoing Magic\n==========\n{include magic-module:first-part}\n{include magic-module:second-part}\n```\n\nThe module specific one:\n\n```\n...\n{block magic-module:first-part}\nThis is the first part...\n{/block}\n...\n{block magic-module:second-part}\nThis is the second part...\n{/block}\n...\n```\n\nThe script would simply do replacements making the main readme this:\n\n```\nDoing Magic\n==========\nThis is the first part...\nThis is the second part...\n```\n\nand it would also erase annotations from the second module-specific readme. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/752",
        "number": 752,
        "title": "Improve PR coverage tooling",
        "labels": [],
        "state": "closed",
        "body": "The Coveralls plugin version 4.1.0 is very slow, much slower than version 3.1.0.  As a result, we don't get coverage results in a timely fashion when reviewing PRs.  Downgrading the Maven Coveralls version to 3.1.0 seems to make the coverage reports appear faster.  Alternatively, we can see whether using a different coverage analysis tool might be faster than using Cobertura.  One possibility is to use Jacoco rather than Cobertura (perhaps the input is parsed faster by Coveralls).  Jacoco seems to [work with Coveralls](https://github.com/trautonen/coveralls-maven-plugin/issues/93) and also seems to have a [couple additional features](https://confluence.atlassian.com/display/CLOVER/Comparison+of+code+coverage+tools) that Cobertura doesn't.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/751",
        "number": 751,
        "title": "Enhance docs with possible values of Compute operation's .error.errors[].code",
        "labels": [
            "api: compute",
            "api: core",
            "priority: p2"
        ],
        "state": "closed",
        "body": "We should figure out possible values that can be assumed by [error.errors[].code](https://cloud.google.com/compute/docs/reference/latest/globalOperations#error.errors.code).\nThe field is only documented as:\n\n> The error type identifier for this error.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/740",
        "number": 740,
        "title": "Standardize \"maxResults\"/\"pageSize\" option terminology",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "We use \"pageSize\" in Resource Manager and \"maxResults\" in Storage and BigQuery to mean \"max results per page\".  We should standardize our terminology.  I slightly prefer the term \"pageSize\" because a user could want some total number of results that's greater than what the service allows as the pageSize.  As a result, the user might set a \"maxResults\" field, get less results than they asked for, and perhaps assume (without checking the page token) that they got all the results that existed, even if there is another page of results.\n\nWe should standardize the javadoc to include that it's \"the maximum number of results returned per page.\"\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/739",
        "number": 739,
        "title": "Possible Gcloud Java bug in signurl?",
        "labels": [
            "api: storage",
            "auth"
        ],
        "state": "closed",
        "body": "So I'm using gcloud storage in a managed VM app and generally loving it, but I've hit something that I really think it is a bug so I wanted to throw it out there and see what people think.\n\nI'm doing a few things with Storage and most of them are working perfectly  Reads work perfectly, writes work perfectly, creates work perfectly.  However, when I attempt to sign a URL like so:\n\nStorage storage = StorageOptions.defaultInstance().service();\n\nURL url = storage.signUrl(\n        BlobInfo.builder(BUCKET_NAME,\n                OBJECT_NAME).build(),\n        30,\n        TimeUnit.MINUTES,\n        Storage.SignUrlOption.httpMethod(HttpMethod.GET));\n\nI end up getting a \"Signing key not provided\" exception: \n\njava.lang.IllegalArgumentException: Signing key was not provided and could not be derived\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\n    at com.google.gcloud.storage.StorageImpl.signUrl(StorageImpl.java:531)\n        ...\n\nThis occurs on a deployed Managed VM server. It also occurs locally when gcloud is authorized either to myself or to a service account.  In other words, it appears that storage.signUrl is not picking up signing authorization from the standard locations.  I have not yet tried to manually add a signing option from a generated key, but that seems like it should not required.  Additionally, the signUrl example from the gcloud-java source in maven has no additional signingKey in the SignUrlOptions which leads me to believe that it is intended for signUrl to pick up its authorization from the environment.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/737",
        "number": 737,
        "title": "Rename Identity's \"id\" to \"value\"",
        "labels": [
            "iam"
        ],
        "state": "closed",
        "body": "In gcloud-java-core, Identity has an [\"id\" field](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/gcloud/Identity.java#L104).  We should change this field's name to something else (like \"value\") to avoid the repeated terminology.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/735",
        "number": 735,
        "title": "Should we rename \"identity\" as \"reference\" in javadoc?",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "In services that have model objects with \"id\" as a field, we try to differentiate between that \"id\" field and the \"identity\" of that object (the information necessary to reconstruct/access that object via the service).  For example, blobs have \"id\" fields, but `gcloud-java-storage` also has a `BlobId` class that contains the bucket name, blob name, and generation.\n\nIn the javadoc, we use \"identity\" to describe classes like `BlobId`.  I feel that \"reference\" is a slightly better word than \"identity\" because \"reference\" is a more commonly used word and thus would make the javadoc read more nicely.  Also, \"id\" is a shorthand for \"identity\" (and a user could potentially assume they're related), whereas \"reference\" might differentiate the two items more clearly.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/733",
        "number": 733,
        "title": "Datastore Javadoc includes example programs and more...",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "It's nice to have around, but a clean API for Javadoc is also very useful.\n\nIdeally, you would have just the API JavaDoc as the Reference Doc, and then if you want another doc w/ examples.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/732",
        "number": 732,
        "title": "Image's deprecationStatus can hold wrongly formatted timestamps",
        "labels": [
            "api: compute",
            "type: bug"
        ],
        "state": "closed",
        "body": "When a Compute Image is [deprecated](https://cloud.google.com/compute/docs/reference/latest/images/deprecate) a [DeprecationStatus](https://cloud.google.com/compute/docs/reference/latest/images/deprecate#request_properties_JSON) must be provided in the request body. Part of deprecation status are 3 timestamps (deprecated, obsolete, deleted) that are documented to be:\n\n> An optional RFC3339 timestamp on or after which the deprecation state of this resource will be changed to DEPRECATED/OBSOLETE/DELETED.\n\nHowever, the service does no validation and any string can be submitted for such fields. In fact older images (e.g. `backports-debian-7-wheezy-v20131127`) have non-RFC3339 timestamp values:\n\n``` JSON\n\"deprecated\": {\n  \"state\": \"DEPRECATED\",\n  \"replacement\": \"https://content.googleapis.com/compute/v1/projects/debian-cloud/global/images/backports-debian-7-wheezy-v20131127\",\n  \"deprecated\": \"1970-01-01\",\n  \"obsolete\": \"1970-01-02\",\n  \"deleted\": \"1970-01-03\"\n}\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/731",
        "number": 731,
        "title": "NPE when generationNotMatch fails",
        "labels": [],
        "state": "closed",
        "body": "The following:\n\n```\nbucket.create(\"file\", new byte[0], \"text/plain\");\nBlob blob = bucket.get(\"file\");\nbucket.storage().create(blob, new byte[0], BlobTargetOption.generationNotMatch());\n```\n\nCauses a:\n\n```\ncom.google.gcloud.storage.StorageException: java.lang.NullPointerException\n    at com.google.gcloud.storage.StorageException.translateAndThrow(StorageException.java:74)\n    at com.google.gcloud.storage.StorageImpl.create(StorageImpl.java:150)\n    at com.google.gcloud.storage.StorageImpl.create(StorageImpl.java:129)\n    ...\n```\n\nThe `translateAndThrow()` call suppresses the underlying stack trace, but this shouldn't trigger an NPE. I do expect it to fail, but it should fail with a meaningful error message.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/727",
        "number": 727,
        "title": "Compute's operation.creationTimestamp field is never set",
        "labels": [
            "api: compute",
            "type: bug"
        ],
        "state": "closed",
        "body": "While [documented](https://cloud.google.com/compute/docs/reference/latest/globalOperations#creationTimestamp) the `operation.creationTimestamp` appears to never be set.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/724",
        "number": 724,
        "title": "Small Blobs silently stored as ShortBlobs - Need option to force full Blob",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Maybe there is an option but someone will have to point it out to me: how can I ensure that my Blobs are stored as full Blob objects and not ShortBlobs?  \n\nThe issue for me is that I'm writing entities to the datastore using gcloud-java and then reading them with Objectify.  When reading I see the error: `Expected class com.google.appengine.api.datastore.Blob, got class com.google.appengine.api.datastore.ShortBlob: <ShortBlob: 247 bytes>`\n\nI'm inserting my Blobs like this:\n`entityBuilder.set(\"compressedText\", BlobValue.builder(Blob.copyFrom(compressedtext)).build());`\nwhere compressedtext is a byte[]\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/723",
        "number": 723,
        "title": "storage: read blob in chunk will get exception when reach the end the blob",
        "labels": [],
        "state": "closed",
        "body": "Following code is used to read blob chunk by chunk:\n\n``` java\ntry (ReadChannel reader = blob.reader()) {\n  WritableByteChannel channel = Channels.newChannel(outputStream);\n  ByteBuffer bytes = ByteBuffer.allocate(64 * 1024);\n  while (reader.read(bytes) > 0) {\n    bytes.flip();\n    channel.write(bytes);\n    bytes.clear();\n  }\n}\n```\n\nreader.read() will throw exception:\n\ncom.google.gcloud.storage.StorageException: java.lang.NullPointerException\n\n```\nat com.google.gcloud.storage.StorageException.translateAndThrow(StorageException.java:74)\nat com.google.gcloud.storage.BlobReadChannel.read(BlobReadChannel.java:159)\n```\n\nThe root cause is, reader is blindly reading chunks from cloud storage, if it reaches beyond the end of the blob, then cloud storage will throw an error: 416 Requested range not satisfiable.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/722",
        "number": 722,
        "title": "Determine why create and list permissions causes bad request.",
        "labels": [
            "api: cloudresourcemanager",
            "iam"
        ],
        "state": "closed",
        "body": "In resource manager, using `resourcemanager.projects.create` or `resourcemanager.projects.list` in a `testPermissions` call leads to a 400 Bad Request error.  \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/721",
        "number": 721,
        "title": "DatastoreOptions.defaultInstance().service() fails in static methods.",
        "labels": [],
        "state": "closed",
        "body": "```\ncom.google.gcloud.datastore.DatastoreException: I/O error\n    at com.google.gcloud.spi.DefaultDatastoreRpc.translate(DefaultDatastoreRpc.java:110)\n    at com.google.gcloud.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:147)\n    at com.google.gcloud.datastore.DatastoreOptions.normalize(DatastoreOptions.java:128)\n    at com.google.gcloud.datastore.DatastoreOptions.access$400(DatastoreOptions.java:36)\n    at com.google.gcloud.datastore.DatastoreOptions$Builder.build(DatastoreOptions.java:89)\n    at com.google.gcloud.datastore.DatastoreOptions.defaultInstance(DatastoreOptions.java:175)\n    at com.industryopenings.seeker.driver.Driver.main(Driver.java:97)\nCaused by: com.google.api.services.datastore.client.DatastoreException: I/O error\n    at com.google.api.services.datastore.client.RemoteRpc.makeException(RemoteRpc.java:115)\n    at com.google.api.services.datastore.client.RemoteRpc.call(RemoteRpc.java:83)\n    at com.google.api.services.datastore.client.BaseDatastoreFactory$RemoteRpc.call(BaseDatastoreFactory.java:41)\n    at com.google.api.services.datastore.client.Datastore.lookup(Datastore.java:93)\n    at com.google.gcloud.spi.DefaultDatastoreRpc.lookup(DefaultDatastoreRpc.java:145)\n    ... 5 more\nCaused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\n    at sun.security.ssl.Alerts.getSSLException(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.fatal(Unknown Source)\n    at sun.security.ssl.Handshaker.fatalSE(Unknown Source)\n    at sun.security.ssl.Handshaker.fatalSE(Unknown Source)\n    at sun.security.ssl.ClientHandshaker.serverCertificate(Unknown Source)\n    at sun.security.ssl.ClientHandshaker.processMessage(Unknown Source)\n    at sun.security.ssl.Handshaker.processLoop(Unknown Source)\n    at sun.security.ssl.Handshaker.process_record(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.readRecord(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.performInitialHandshake(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source)\n    at sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source)\n    at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source)\n    at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(Unknown Source)\n    at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(Unknown Source)\n    at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(Unknown Source)\n    at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77)\n    at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972)\n    at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:121)\n    at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:97)\n    at com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:74)\n    at com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:65)\n    at com.google.gcloud.ServiceOptions$1.initialize(ServiceOptions.java:533)\n    at com.google.api.services.datastore.client.RemoteRpc.call(RemoteRpc.java:76)\n    ... 8 more\nCaused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\n    at sun.security.validator.PKIXValidator.doBuild(Unknown Source)\n    at sun.security.validator.PKIXValidator.engineValidate(Unknown Source)\n    at sun.security.validator.Validator.validate(Unknown Source)\n    at sun.security.ssl.X509TrustManagerImpl.validate(Unknown Source)\n    at sun.security.ssl.X509TrustManagerImpl.checkTrusted(Unknown Source)\n    at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(Unknown Source)\n    ... 29 more\nCaused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target\n    at sun.security.provider.certpath.SunCertPathBuilder.build(Unknown Source)\n    at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(Unknown Source)\n    at java.security.cert.CertPathBuilder.build(Unknown Source)\n    ... 35 more\n```\n\nDropping `DatastoreOptions.defaultInstance().service()` into a simple main() method will yield the error.  I'm on 0.1.4.  Inside class instance methods it's working fine.  I'm running outside of App Engine.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/720",
        "number": 720,
        "title": "storage: \"Failed to parse Content-Range header\" when chunk-size upload is used",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "Here is the log:\n\nCaused by: com.google.gcloud.storage.StorageException: 400 Bad Request\nFailed to parse Content-Range header.\n    at com.google.gcloud.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:94)\n    at com.google.gcloud.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:499)\n    at com.google.gcloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:49)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at com.google.gcloud.RetryHelper.doRetry(RetryHelper.java:181)\n    at com.google.gcloud.RetryHelper.runWithRetries(RetryHelper.java:247)\n    at com.google.gcloud.RetryHelper.runWithRetries(RetryHelper.java:237)\n    at com.google.gcloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:46)\n    at com.google.gcloud.BaseWriteChannel.close(BaseWriteChannel.java:147)\n\nIf I uploaded a file with size is exactly 2 x 1024 x 1024, and 1024 x 1024 as the chunk size, then I'll get above exception. However, if I changed the file size to 2 x 1024 x 1024 + 1, then the problem will go away.\n\nApparently, there is a bug in BlobWriteChannel->flushbuffer, if there is no data available, then there is no need to call options().rpc().write.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/711",
        "number": 711,
        "title": "Compute's aggregate lists do not support resource's field selection",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "Aggregate lists' `fields` option only allows to select the following fields:\n\n```\nid\nitems\nkind\nnextPageToken\nselfLink\n```\n\nShouldn't selecting fields of the listed resources be supported as well?\nIt would be nice to be able to write a `field` option like: `items(selfLink),nextPageToken` that only returns the next page token and the selfLink field for each resource.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/710",
        "number": 710,
        "title": "Auth issue when using revoked Cloud SDK creds with local test helpers.",
        "labels": [
            "auth",
            "type: question"
        ],
        "state": "closed",
        "body": "When running code that uses local service emulators, users that have Google Cloud SDK installed but have out-of-date or revoked credentials (and don't specify other credentials in any other way) will see error messages when making API calls that send requests to the local emulator.  This is because we detect the Google Cloud SDK json credentials file exists, and use those to set credentials in `ServiceOptions`.  As a result, requests attempt to use these credentials (even though they aren't necessary) and fail.  \n\nShould we:\n1) Document that you should use `gcloud auth login` when using local test helpers?\nor \n2) Figure out how to parse the credentials to figure out that they're valid or revoked?\nI notice that under \".config/gcloud/legacy_credentials\", the folder corresponding to my gcloud email account is removed when I revoke credentials.  However, I'm unsure that that's a valid way to check for revoked credentials.  The other files related to credentials in that directory don't seem to indicate whether they are valid or revoked.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/703",
        "number": 703,
        "title": "BaseServiceException should not extend RuntimeException",
        "labels": [],
        "state": "closed",
        "body": "Maybe this ship has already sailed, but if it's still possible `BaseServiceException` should not extend `RuntimeException`. As is, I can't confidently make _any_ calls to a gcloud-java method without wrapping them in a try-catch block, and should I accidentally miss one it could cause my whole application to crash. I would suggest it extend `IOException` instead, but just extending `Exception` would be great.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/702",
        "number": 702,
        "title": "Operations on Buckets should use Storage.*Option types",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "Some of the static classes in `Storage`, such as `BlobTargetOption` which is used by `Storage.create()`, are also being erroneously used in `Bucket`. This is problematic because `Bucket` keys of of path `Strings`, not `BlobInfo` instances, and therefore isn't able to extract information like the blob's generation, causing a line like this:\n\n```\nbucket.create(file, data, null, BlobTargetOption.generationMatch());\n```\n\nto fail:\n\n```\n java.lang.IllegalArgumentException: Option ifGenerationMatch is missing a value\n     at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\n     at com.google.gcloud.storage.StorageImpl.addToOptionMap(StorageImpl.java:651)\n     at com.google.gcloud.storage.StorageImpl.addToOptionMap(StorageImpl.java:643)\n     at com.google.gcloud.storage.StorageImpl.optionMap(StorageImpl.java:681)\n     at com.google.gcloud.storage.StorageImpl.optionMap(StorageImpl.java:660)\n     at com.google.gcloud.storage.StorageImpl.optionMap(StorageImpl.java:695)\n     at com.google.gcloud.storage.StorageImpl.optionMap(StorageImpl.java:703)\n     at com.google.gcloud.storage.StorageImpl.create(StorageImpl.java:140)\n     at com.google.gcloud.storage.StorageImpl.create(StorageImpl.java:129)\n     at com.google.gcloud.storage.Bucket.create(Bucket.java:360)\n```\n\nAnd there is no way in `Storage.BlobTargetOption` to actually specify a generation.\n\nI don't think `Bucket` should have any dependency on the `Storage.*Option` types. There's clearly a good amount of overlap, but I don't think that's a good enough reason for them to share these types. Even where they behave the same it's confusing for the caller.\n\nThey could extend from a shared parent if we wanted, but that should be an implementation detail.\n\nI can put together a patch to remove the dependencies on `Storage.*Option` from `Bucket` if that's desired.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/701",
        "number": 701,
        "title": "Is it possible to use ApplicationDefaultCredentials for SignUrlOption?",
        "labels": [
            "api: storage",
            "auth"
        ],
        "state": "closed",
        "body": "Currently [Storage.SignUrlOption](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/storage/Storage.java#L782) receives `com.google.gcloud.AuthCredentials.ServiceAccountAuthCredentials`, but how to use ApplicationDefaultAuthCredentials with that method? I think we should allow using ApplicationDefaultAuthCredentials if possible.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/698",
        "number": 698,
        "title": "What parameters should Zone/ZoneInfo builder require",
        "labels": [
            "api: dns",
            "type: question"
        ],
        "state": "closed",
        "body": "There are 3 things mandatory for Zone: name, dnsName and description. In my opinion, it either makes sense to allow for creating zone with name being mandatory and the rest to be part of the builder, or require all three in `ZoneInfo.builder(String name, String dnsName, String description)`. I am inclined to the first option. Should we ask for name only, or for all three?\n\n/cc @ajkannan @aozarov @mziccard \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/695",
        "number": 695,
        "title": "Compute's DiskType.id field is never set",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "[DiskType.id](https://cloud.google.com/compute/docs/reference/latest/diskTypes#id) is documented but never returned by the service. See for instance the result of a GET:\n\n``` json\n{\n \"kind\": \"compute#diskType\",\n \"creationTimestamp\": \"2014-10-17T16:09:45.266-07:00\",\n \"name\": \"local-ssd\",\n \"description\": \"Local SSD\",\n \"validDiskSize\": \"375GB-375GB\",\n \"zone\": \"https://content.googleapis.com/compute/v1/projects/gcloud-devel/zones/us-central1-a\",\n \"selfLink\": \"https://content.googleapis.com/compute/v1/projects/gcloud-devel/zones/us-central1-a/diskTypes/local-ssd\",\n \"defaultDiskSizeGb\": \"375\"\n}\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/693",
        "number": 693,
        "title": "Get baseUrl for Compute's identities",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "For resource identities we use the following base url in `ResourceId`:\n\n``` java\n private static final String BASE_URL = \"https://www.googleapis.com/compute/v1/projects/\";\n```\n\nAs noticed by @aozarov this could be derived from service  (e.g. [com.google.api.services.compute.Compute]() has a `getBaseUrl` method).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/692",
        "number": 692,
        "title": "Support the delimiter parameter and prefixes result field for bucket listing",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "See [`delimiter`](https://cloud.google.com/storage/docs/json_api/v1/objects/list) - this is necessary to be able to list \"directories\".\n\nIn addition to `BlobListOption.delimiter(String)` it'd be nice if there were an argument-less method that uses `/` as the delimiter, since that's what ~99% of usages will want. I'd suggest `directories()` as that method name, so users can write `bucket.list(\"...\", BlobListOption.directories())`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/689",
        "number": 689,
        "title": "Remove user info scope from DatastoreOptions in v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The user info scope will not be necessary in v1beta3.  This should be tested against both the local emulator and the actual Datastore.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/687",
        "number": 687,
        "title": "Add a flag to enable/disable versioned Blob listing.",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "see \"versions\" in [here](https://cloud.google.com/storage/docs/json_api/v1/objects/list).\n\nAlso, it looks like the SPI already [sets](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/spi/DefaultStorageRpc.java#L158) this option if provided.\n\nRelated StackOverflow [issue](http://stackoverflow.com/questions/35690777/get-archived-versions-from-google-cloud-storage).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/684",
        "number": 684,
        "title": "Provide an in-memory or local-disk emulator of the storage APIs for testing",
        "labels": [
            "api: storage",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "Easy to describe, hard to do :) Presently the only way I can verify my `gcloud-java` code is to run it against a real GCS bucket, which costs money and requires being authenticated.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/683",
        "number": 683,
        "title": "Understand possible DiskType.validDiskSize formats",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "[DiskType.validDiskSize](https://cloud.google.com/compute/docs/reference/latest/diskTypes#validDiskSize) is documented as:\n\n> An optional textual description of the valid disk size, such as \"10GB-10TB\".\n\nWe should understand the format this field can have so that we can split it into two numbers (e.g. `minSize` and `maxSize`).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/682",
        "number": 682,
        "title": "TaskQueues API Please!",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Is it part of the roadmap to fold in the TaskQueue library?  This is what I see right now...\n\nhttps://developers.google.com/api-client-library/java/apis/taskqueue/v1beta2\n\nIt would great if this was part of gcloud-java.  \n\nUpdate: I noticed gcloud-python as pub/sub API support... which made me think... should I be using pub/sub instead of task queues for new development?  \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/681",
        "number": 681,
        "title": "Error with gcloud-java for datastore access from compute engine: \u201cLookupRequest overrides final method getUnknownFields\u201d",
        "labels": [],
        "state": "closed",
        "body": "I started a brand new Java project (Java 8) and used maven to pull down my dependencies:\n\n```\n<dependency>\n  <groupId>com.google.gcloud</groupId>\n  <artifactId>gcloud-java</artifactId>\n  <version>0.1.4</version>\n</dependency>\n```\n\nI then wrote a very simple test call to write to the datastore... but there seems to be something structurally wrong with the library... here is the exception I ran into:\n\n```\njava.lang.VerifyError: class com.google.api.services.datastore.DatastoreV1$LookupRequest overrides final method getUnknownFields.\n\n()Lcom/google/protob\nuf/UnknownFieldSet;\n        at java.lang.ClassLoader.defineClass1(Native Method)\n        at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n        at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n        at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n        at com.google.gcloud.datastore.DatastoreOptions.normalize(DatastoreOptions.java:123)\n        at com.google.gcloud.datastore.DatastoreOptions.access$400(DatastoreOptions.java:36)\n        at com.google.gcloud.datastore.DatastoreOptions$Builder.build(DatastoreOptions.java:89)\n        at com.google.gcloud.datastore.DatastoreOptions.defaultInstance(DatastoreOptions.java:175)\n\n    ... my code here which called Datastore datastore = DatastoreOptions.defaultInstance().service();\n\n```\n\nI have plenty of jars but my environment is clean... I don't have any of the legacy google.appengine.\\* jars around. Just to make sure:\n\n`find . -name \"*.jar\" -exec grep -Hsli LookupRequest {} \\;`\nreturned only:\n\n`./google-api-services-datastore-protobuf-v1beta2-rev1-4.0.0.jar`\n\nIs the Google distribution broken? Is this a me thing? Any help appreciated.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/680",
        "number": 680,
        "title": "DefaultCredentialsProvider doesn't respect the CLOUDSDK_CONFIG environment variable",
        "labels": [
            "auth",
            "type: bug"
        ],
        "state": "closed",
        "body": "`ServiceOptions.googleCloudProjectId()` first checks to see if `CLOUDSDK_CONFIG` has been set, and uses that in place of `~/.config/gcloud` if it has. However `DefaultCredentialsProvider.getWellKnownCredentialsFile()` does not, instead only looking in the default directory.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/679",
        "number": 679,
        "title": "Create functional class for DNS ChangeRequest",
        "labels": [
            "api: dns",
            "type: question"
        ],
        "state": "closed",
        "body": "If this has been already discussed I am sorry for bringing it up again.\n\nA DNS change request is now mapped using a single non-functional class `ChangeRequest`. I see a benefit in having a functional class for change requests as well. It would be cool to be able to write:\n\n``` java\nChangeRequest change = dns.applyChangeRequest(ChangeRequestInfo.builder...);\nwhile (!change. isDone()) {\n  Thread.sleep (1000L);\n}\n// change request is DONE\n```\n\nIn the same way we do for bigquery's jobs and as I plan to do with compute's operations. What do you think?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/678",
        "number": 678,
        "title": "Fix codacy issues in DNS",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "See [here](https://www.codacy.com/app/mziccard/gcloud-java/dashboard?bid=3123104).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/677",
        "number": 677,
        "title": "Support TransactionOptions in v1beta3",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See discussion in #637 for more context.\n\nThis is blocked on transaction options being supported in a subsequent release of v1beta3.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/676",
        "number": 676,
        "title": "Add serialization tests to gcloud-core",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "Probably at the same time we do #657 we should also add serialization tests to core classes such as\n`IamPolicy`, `PageImpl`, ...\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/675",
        "number": 675,
        "title": "Implement support for alpha features in datastore (geopt)",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "https://cloud.google.com/appengine/docs/java/datastore/geosearch is an alpha feature unusable by gcloud library since the GeoPt is not a valid property type.\n\nI was not able to run com.google.appengine.api.datastore locally (using emulator or java-sdk), and found that using com.google.gcloud.datastore work against my gcloud datastore and sdk without hassle.\n\nBut now I am stuck unable to implement the geopt as the 2 are incompatible.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/673",
        "number": 673,
        "title": "Make integration tests for creating invalid change request in DNS",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "When retry functionality of the `DnsException` is implemented, add this test.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/672",
        "number": 672,
        "title": "LocalDnsHelper does not create a change for new records",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "The service does. Add a change.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/671",
        "number": 671,
        "title": "Clean tests for local DNS helper",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Only keep the RPC ones.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/667",
        "number": 667,
        "title": "Add support for Storage transfer",
        "labels": [
            "api: storage",
            "priority: p1",
            "type: feature request"
        ],
        "state": "closed",
        "body": "see: https://cloud.google.com/storage/transfer/\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/666",
        "number": 666,
        "title": "In Channel reader and writer throw ClosedChannelException for validateOpen instead of IOException(\"stream is closed\")",
        "labels": [
            "api: core",
            "api: storage"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/665",
        "number": 665,
        "title": "List operations do not return nextPageToken which prevents proper paging",
        "labels": [
            "api: cloudresourcemanager",
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "When implementing integration tests for DNS, I noticed that if one restricts the fields to be retrieved for a list operation, `iterateAll()` does not work properly. The following test would always fail:\n\n``` java\ndnsRecordIterator = DNS.listDnsRecords(zone.name(),\n    Dns.DnsRecordListOption.fields(Dns.DnsRecordField.TYPE),\n    Dns.DnsRecordListOption.pageSize(1)).iterateAll(); // to force the iterator fetch next page\n  int counter = 0;\n  while (dnsRecordIterator.hasNext()) {\n    counter++;\n  }\nassertEquals(2, counter);\n```\n\nThis is because the field selector silently prevents the service from returning the `nextPageToken`:\n\n`builder.append(\"rrsets(\").append(DnsRecordField.selector(fields)).append(')');`\n\ninstead of\n\n`builder.append(\"nextPageToken,rrsets(\").append(DnsRecordField.selector(fields)).append(')');`\n\nI recall seeing the same handling in resource manage. Having discussed this with @ajkannan, this is likely a bug. The same bug may be present in other parts of the library when a combination of listing and field restriction is possible.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/664",
        "number": 664,
        "title": "Return an empty collection instead of null.",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Some of the the resource metadata properties are collections/maps.\n\nI think currently we are not consistent and in some cases we return `null` if there is no value (e.g.\n`BlobInfo` and `BucketInfo`) and in some cases we return an empty collection (e.g. `ProjectInfo`).\n\nMy preference would be to never return `null` for a collection as I think the value of being able to\ndistinct the case of \"unassigned\" and \"assigned and empty\" is very small and does not justify\nthe cost for checking for `null` _and_ empty.\n\nIn any case, I think we should be consistent.\n\n/cc @mziccard @ajkannan @mderka \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/662",
        "number": 662,
        "title": "Figure out Compute possible error codes",
        "labels": [
            "api: compute",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "I couldn't manage to find a page with all errors codes that the Compute service can return. Possible error codes should be known, in particular we need to identify retryable ones.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/660",
        "number": 660,
        "title": "Support signed android api keys",
        "labels": [
            "android",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "If you create an android api key in the cloud console, and restrict its usage using your package and sha1 cert, then all calls to google apis using that key need to be signed. It'd be great if gcloud-java could support signing the requests in android, so that it can be used with restricted android api keys.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/657",
        "number": 657,
        "title": "Refactor serialization test code.",
        "labels": [
            "api: compute",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "There is repeated code to serialize and deserialize arrays of objects in each modules' serialization tests.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/655",
        "number": 655,
        "title": "Test local service implementation against gcloud-java-dns",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/642",
        "number": 642,
        "title": "Provide getter for a key's parent",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The `BaseKey` `parent()` method's return type will be `BaseKey`, and the `IncompleteKey` and `Key` classes can override this method to return a parent of type `Key`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/640",
        "number": 640,
        "title": "Provide methods to set list values of the same type",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "For example, we could expose a method:\n`set(String value1, String value2, String others...)` to create a `ListValue` of String Values instead of having to write:\n`entityBuilder.set(\"property\", StringValue.of(\"val1\"), StringValue.of(\"val2\"), ...)`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/639",
        "number": 639,
        "title": "Expose consistency setting in LocalGcdHelper",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The default is 0.9, but it's often useful to set it to 1.0 for test utility methods (i.e. clearing all entities using a non-ancestor query in between unit tests).\n\nThis can be set in [LocalGcdHelper.startGcd(..)](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-datastore/src/main/java/com/google/gcloud/datastore/testing/LocalGcdHelper.java#L488) using the following option:\n\n--consistency=...\nThe fraction of job application attempts that will succeed, with 0.0 resulting in no attempts succeeding, and 1.0 resulting in all attempts succeeding. Defaults to 0.9. Note that setting this to 1.0 may mask incorrect assumptions about the consistency of non-ancestor queries; non-ancestor queries are eventually consistent.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/638",
        "number": 638,
        "title": "Support put for parameters of type FullEntity<IncompleteKey> in v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/637",
        "number": 637,
        "title": "Support ReadOptions in v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Read options for lookups and queries should be disabled within transactions.  Transaction options should only be available when creating a new transaction.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/631",
        "number": 631,
        "title": "Implement serialization test",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Include Zone and ZoneInfo.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/630",
        "number": 630,
        "title": "Remove acessors to nameServerSet when creating a managed zone",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Most users do not need this.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/628",
        "number": 628,
        "title": "Should we standardize builder vs toBuilder in Datastore?",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "This is a minor issue, but Datastore uses a static \"builder\" in cases that we would have a non-static \"toBuilder\" method in other modules.  For example, in Datastore's `Key`, there's [`public static Builder builder(Key copyFrom)`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-datastore/src/main/java/com/google/gcloud/datastore/Key.java#L185).\n\nDo we care about standardizing this at some point before version 1.0.0 is released?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/626",
        "number": 626,
        "title": "Adding checkstyle and other code analysis tools to our PR.",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I think that it would be nice if we have more metrics on PR (including threshold that would flag the PR as red if exceeded). Checkstyle is one of these metrics.\n\nI was looking at the checkstyle github [page](https://github.com/checkstyle/checkstyle), just to see\nif they checkstyle their own code for PR and I think they do, but I didn't invest more time on it.\n\nI also saw that they integrate with some other github friendly sites (and free to open source projects) such as:\n\nhttps://www.versioneye.com/ - for dependency out-of-date notifications\nhttps://www.codacy.com/ - for code analysis\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/624",
        "number": 624,
        "title": "ITBigQueryTest failing due to missing query plan for query job statistics",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "The BigQuery service response for query jobs is missing the query plan field under job statistics.  `testQueryJob()` and `testQuery()` fail because they contain asserts that the query plan for queries is not null.\n\nFor now we will disable the tests that are failing.  This issue should be kept open until the tests are re-enabled.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/623",
        "number": 623,
        "title": "Add tests for README code in google-cloud-examples/",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be nice to test that the commands we run in gcloud-java/gcloud-java-examples/README work.  We could do this by creating a script that runs each command and parses the output looking for errors. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/619",
        "number": 619,
        "title": "Rename getProjectInfo() to getProject()",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Rename getProjectInfo() to getProject() in Dns service class and the entire stack.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/618",
        "number": 618,
        "title": "Remove examples if-then-else pattern",
        "labels": [],
        "state": "closed",
        "body": "In bigquery example we have the following patttern:\n\n``` java\nTable table = getTable(...);\nif (table == null) {\n  // create table\n} else {\n  // load data\n}\n```\n\nin storage we have:\n\n``` java\nBlob blob = getBlob(...);\nif (blob == null) {\n  // create blob\n} else {\n  // get and update blob's content\n}\n```\n\nIn both cases we should remove the `else` branch and rather execute it after table/blob creation.\n\nAlso in datastore we do:\n\n``` java\nEntity entity = getEntity(...);\nif (entity = null) {\n  // create entity\n} else {\n  // update entity access type\n}\n```\n\n@ajkannan @aozarov @mderka Do you guys think we should remove the `else` branch also for datastore's example? It makes slightly less sense to me.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/617",
        "number": 617,
        "title": "Create integration tests",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "This will be calling DefaultDnsRpc methods.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/615",
        "number": 615,
        "title": "Should we move Tuple<X, Y> from Rpc interfaces to common level?",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Whenever we need to retrieve data in pages, the Rpc interface contains a nested class `Tupe<X,Y>` which is afaik used to associate a page token with page iterable data. It is repeated code which I found in `BigQueryRpc`, `ProjectManagerRpc`, and I am now creating another copy in `DnsRpc`. We should consider moving it to the core.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/613",
        "number": 613,
        "title": "Add Page implementation for testing",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "Add Page a simple `PageImpl` under https://github.com/GoogleCloudPlatform/gcloud-java/tree/master/gcloud-java-core/src/main/java/com/google/gcloud/testing that gets one or more list of values.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/612",
        "number": 612,
        "title": "Include getProjectNumber and getProjectId in Service",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "They should be available in ServiceOptions. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/611",
        "number": 611,
        "title": "Update api client library for Resource Manager",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "We should use the [new revision](http://search.maven.org/#artifactdetails%7Ccom.google.apis%7Cgoogle-api-services-cloudresourcemanager%7Cv1beta1-rev10-1.21.0%7Cjar) of the api client library for Resource Manager.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/610",
        "number": 610,
        "title": "Should we overload methods for manipulating managed zone for both id and name?",
        "labels": [
            "api: dns",
            "type: question"
        ],
        "state": "closed",
        "body": "The service API allows for identifying managed zones by both unsigned long id and String name. Our original intention was to overload methods for manipulating managed zones to accept both BigInteger id or String name. We are currently leaning towards not doing this, treating id as read-only value and identifying zones by name only for the purposes of manipulation (get, delete, apply change, list changes). \n\nAlso, there is a suggestion for providing ID as String instead of BigInteger which seems to be consistent with gcloud-python and other services.\n\nOpening this base on discussion in PR #606. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/608",
        "number": 608,
        "title": "Provide a way to create AuthCredentials given an AccessToken",
        "labels": [
            "api: core",
            "auth",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`GoogleCredentials` supports creating an instance using a temporary [`AccessToken`](https://github.com/google/google-auth-library-java/blob/281d485e679545ed06f46e6090fc5d47f4a140e8/oauth2_http/java/com/google/auth/oauth2/AccessToken.java).\n\nIt would be nice to support it.\n\nWe could do that by getting the token string and expiration time and adding ourselves as `AuthCredentials.CredentialsChangedListener` to capture token updates.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/607",
        "number": 607,
        "title": "Test snippet code",
        "labels": [],
        "state": "closed",
        "body": "It would be nice to link the snippets in the READMEs to code that we can test in Travis. That way we'd know our snippets are up to date after changes. As @mziccard points out, it's not easy to do because the snippets that we have now are simple end-to-end usage showcases (e.g. update a blob if it exists or create it if not). On the other hand our examples are more complex and command-line oriented to show the usage of each single functionality. Snippets could be part of IT tests but they will need changes anyway: asserts, data definitions, etc.\n\n@mziccard suggests that we could create a snippet package in `gcloud-java-examples` where we put each snippet as a class+main with a meaningful name (e.g. `CreateOrUpdateBlob`). We can then reference those files before the snippet.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/605",
        "number": 605,
        "title": "Merge Zone and ZoneInfo",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Similarly to what was done ProjectManager, we will merge the functional and info objects here.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/604",
        "number": 604,
        "title": "Add sorting options for listing changes when available",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Currently, the service API allows for only one sorting key which is the change sequence (time of the changes being received by the server). When more sorting options become available, they should be implement.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/603",
        "number": 603,
        "title": "Make storage functional objects a subclass of the metadata objects",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/602",
        "number": 602,
        "title": "Clarify name filters for listing",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "In Dns interface, we should provide options for listing zone with a specified domain name only. However, this must be unique within project, so this operation would just become get. Similarly, when listing DNS records, one can specify type which has to be accompanied by a fully qualified domain name, and it turns into get. A question was sent to the service owners. These options should be either included if there is sense in such filters, or removed, if list becomes get (possibly with get being overloaded if appropriate). \n\n@benvitale \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/599",
        "number": 599,
        "title": "Make Project.Quota serializable",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/596",
        "number": 596,
        "title": "Add methods to DnsService interface",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "Complete implementation when the options PR is approved.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/595",
        "number": 595,
        "title": "Complete implementation of DnsServiceOptions",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "As of now, the class is only a stub with the necessary declarations.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/594",
        "number": 594,
        "title": "Add methods to DnsServiceRpc",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/593",
        "number": 593,
        "title": "Add translation and retry functionality to DnsException",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/581",
        "number": 581,
        "title": "Change TTL to accept unit",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "As per suggestion of @jgeewax, change ttl in DnsRecord to accept duration as a number and TimeUnit. For an example, see e.g. here:\n\nhttps://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/storage/Storage.java#L1475\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/580",
        "number": 580,
        "title": "Move integration tests to different packages",
        "labels": [],
        "state": "closed",
        "body": "While keeping unit tests in the same package as code is useful (so that we can test package scope code), this is less important for integration tests.  Moving integration tests to a separate package would provide some benefits, such as allowing us to catch issues related to member variable access.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/579",
        "number": 579,
        "title": "Rename ManagedZone to Zone",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "As per suggestion by @jgeewax , we should rename ManagedZone to just Zone. The same thing holds for the metadata object ManageZoneInfo to ZoneInfo. This concern documentation too.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/566",
        "number": 566,
        "title": "Add of() method to Acl for both BigQuery and Storage",
        "labels": [
            "api: bigquery",
            "api: storage"
        ],
        "state": "closed",
        "body": "We should use a static factory method `of()` also to create `Acl` in both gcloud-java-storage and gcloud-java-bigquery (now we use a public constructor).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/564",
        "number": 564,
        "title": "BaseTableInfo subclasses are missing equals and hashCode methods",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "`hashCode` and `equals` methods must be overridden in `TableInfo`, `ViewInfo` and `ExternalTableInfo`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/560",
        "number": 560,
        "title": "rename Storage apply method (for sending a batch) to submit",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "This will make it consistent with Datastore and seems to be the preferred verb.\nSame is planned to be done for DNS.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/553",
        "number": 553,
        "title": "storage in 0.1.1: com.google.gcloud.storage.StorageException: Read timed out",
        "labels": [],
        "state": "closed",
        "body": "I started getting Read time outs so I looked for a way to increase them via StorageOptions.\n\nAccording to this: https://github.com/GoogleCloudPlatform/gcloud-java/pull/234/files#r41651397 I see you added readTimeout and ConnectionTimeout methods but I don't think they have not made it into the released 0.1.1\n\nHow can I extend readTimeout on the storage API?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/552",
        "number": 552,
        "title": "Move LoadConfiguration.projectionFields to a FormatOptions subclass",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "`LoadConfiguration.projectionFields()` should be moved to a dedicated `DatastoreBackupOptions` class (subclass of `FormatOptions`).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/550",
        "number": 550,
        "title": "Add unit tests for Query classes",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "For example, the builders for `StructuredQuery` don't seem to be tested.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/548",
        "number": 548,
        "title": "Lazy loading of entities when running a query",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "I just want to scroll all entities of a specific kind in a lazy way. I have tried to add a limit but as intended I have only the number of specified results and not the entire dataset.\n\n``` java\nStructuredQuery<Entity> query = Query.entityQueryBuilder()\n    .kind(\"user\")\n    .limit(100)\n    .build();\n\nQueryResults<Entity> results = datastore.run(query);\n```\n\nHow to do it ? Did you plan to add a `fetchSize()` parameter ?\n\nWithout `limit()` I have a DatastoreException: Server returned an error INTERNAL 500\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/541",
        "number": 541,
        "title": "Create snippets for Cloud Datastore page",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The Datastore docs page has a whole new set of snippets for the \"getting started\" guide and for the concepts snippets.\n\nCan we implement all the necessary snippets (~50) in the [docs github](https://github.com/GoogleCloudPlatform/java-docs-samples)?\n\nWhoever plans on owning this can ping me via email and I can give you all the necessary instructions / access to the staging docs. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/537",
        "number": 537,
        "title": "Link to SparkJava example from README and website",
        "labels": [],
        "state": "closed",
        "body": "https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/managedvms/sparkjava\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/532",
        "number": 532,
        "title": "Should we use \"get\" instead of \"load\" in the functional classes.",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "This seems to be more consistent with the service API.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/531",
        "number": 531,
        "title": "Provide builder for ProjectListOption.filter()",
        "labels": [
            "api: cloudresourcemanager",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Then the user doesn't have to enter large strings that combine multiple filters themselves.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/530",
        "number": 530,
        "title": "Should we merge the functional object with the metadata objects.",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Current when possible we use the following pattern for google cloud resource:\n\nXXX resource metadata - An immutable (using the standard builder pattern) and serializable class named XXXInfo with only data accessors.\n\nXXX resource - An immutable, no serializable class pinned to a specific metadata and service implementation.\n\nAs both classes are immutable and as service can always be re-created via its options should we unify them and make the main service API always return the functional objects? \n\n/cc @mziccard @ajkannan @mderka\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/525",
        "number": 525,
        "title": "Missing configuration for dryRun jobs causes NPE",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "type: bug"
        ],
        "state": "closed",
        "body": "A query job created with `dryRun = true` has no `configuration` field. The following is the response I get from [Jobs: insert](https://cloud.google.com/bigquery/docs/reference/v2/jobs/insert).\n\n``` json\n{\n \"kind\": \"bigquery#job\",\n \"etag\": \"\\\"Bop49sEVg6UBKwr7tLdL8AavHaw/LRPbO11E3VlTAE5UxM2F_Mfu01M\\\"\",\n \"jobReference\": {\n  \"projectId\": \"gcloud-devel\"\n },\n \"status\": {\n  \"state\": \"DONE\"\n },\n \"statistics\": {\n  \"creationTime\": \"1452067884640\",\n  \"totalBytesProcessed\": \"26\",\n  \"query\": {\n   \"totalBytesProcessed\": \"26\",\n   \"totalBytesBilled\": \"0\",\n   \"cacheHit\": false\n  }\n }\n}\n```\n\nWhile if I create the same job with `dryRun = false` the configuration is present instead:\n\n``` json\n{\n \"kind\": \"bigquery#job\",\n \"etag\": \"\\\"Bop49sEVg6UBKwr7tLdL8AavHaw/OI0lGTx2GlKc0VoAAYS-fIXHWok\\\"\",\n \"id\": \"gcloud-devel:job_nixqXTMu-mS9U26Ixnxr9KZxCyc\",\n \"selfLink\": \"https://www.googleapis.com/bigquery/v2/projects/gcloud-devel/jobs/job_nixqXTMu-mS9U26Ixnxr9KZxCyc\",\n \"jobReference\": {\n  \"projectId\": \"gcloud-devel\",\n  \"jobId\": \"job_nixqXTMu-mS9U26Ixnxr9KZxCyc\"\n },\n \"configuration\": {\n  \"query\": {\n   \"query\": \"select StringField from gcloud_test_dataset_temp_6c127c49_9574_4e17_ad2b_8e85071997aa.testing_table\",\n   \"destinationTable\": {\n    \"projectId\": \"gcloud-devel\",\n    \"datasetId\": \"_6bb2fc157573f6bd0fed98f3b039c1e71f26d7d1\",\n    \"tableId\": \"anon5f489e91b602aaed3dc62a46d51ba3c070e5d03f\"\n   },\n   \"createDisposition\": \"CREATE_IF_NEEDED\",\n   \"writeDisposition\": \"WRITE_TRUNCATE\"\n  },\n  \"dryRun\": false\n },\n \"status\": {\n  \"state\": \"RUNNING\"\n },\n \"statistics\": {\n  \"creationTime\": \"1452070358348\",\n  \"startTime\": \"1452070358585\"\n },\n \"user_email\": \"...\"\n}\n```\n\nWhile this does not affect the functionality itself I was wondering whether configuration should be returned also for dry-run jobs for consistency? /cc @jcondit @jtigani\n\nFor what concerns `gcloud-java` the absence of a configuration causes a NPE to be thrown at [JobInfo:297](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-bigquery/src/main/java/com/google/gcloud/bigquery/JobInfo.java#L297).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/519",
        "number": 519,
        "title": "Remove period (\".\") from @return, @throws and @param javadoc",
        "labels": [],
        "state": "closed",
        "body": "We should take care of removing (and avoid it in the future) the period (\".\") at the end of `@return`, `@throws` and `@param` paragraphs.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/515",
        "number": 515,
        "title": "testInsertAllWithSuffix is failing",
        "labels": [
            "api: bigquery",
            "type: bug"
        ],
        "state": "closed",
        "body": "The BigQuery integration test for `insertAllWithSuffix` gives the following error in Travis CI: \n\n```\nRunning com.google.gcloud.bigquery.ITBigQueryTest\nTests run: 24, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 101.531 sec <<< FAILURE! - in com.google.gcloud.bigquery.ITBigQueryTest\ntestInsertAllWithSuffix(com.google.gcloud.bigquery.ITBigQueryTest)  Time elapsed: 0.418 sec  <<< FAILURE!\njava.lang.AssertionError: null\n    at org.junit.Assert.fail(Assert.java:86)\n    at org.junit.Assert.assertTrue(Assert.java:41)\n    at org.junit.Assert.assertNotNull(Assert.java:712)\n    at org.junit.Assert.assertNotNull(Assert.java:722)\n    at com.google.gcloud.bigquery.ITBigQueryTest.testInsertAllWithSuffix(ITBigQueryTest.java:508)\nResults :\nFailed tests: \n  ITBigQueryTest.testInsertAllWithSuffix:508 null\nTests run: 24, Failures: 1, Errors: 0, Skipped: 0\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/511",
        "number": 511,
        "title": "Include package info example for BigQuery",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "BigQuery is missing a package info example.\n\nThe PR that adds this could also fix the weird spacing on the package info examples in general (i.e. at the bottom of the [storage javadoc](http://googlecloudplatform.github.io/gcloud-java/0.1.1/apidocs/com/google/gcloud/storage/package-summary.html)).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/505",
        "number": 505,
        "title": "create a new release to include resource manager and bigquery",
        "labels": [],
        "state": "closed",
        "body": "This should also fix the broken javadoc links for the two.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/504",
        "number": 504,
        "title": "Speed up ResourceManager tests on Travis",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "Tests that use the mock resource manager helper take a relatively long time to complete on Travis.  `LocalResourceManagerHelperTest` takes ~100 seconds and `ResourceManagerImplTest` takes ~45 seconds.  When running locally, these tests only tend to take 3-5 seconds.  This is likely because the `HttpServer` library used for the mock spins up threads and also uses sockets, and Travis probably handles these operations more slowly.  We should think of a way to speed up these tests.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/499",
        "number": 499,
        "title": "Make methods that return BaseTableInfo or JobInfo generic",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "The following method in `BigQuery` should be made generic:\n- `BaseTableInfo create(BaseTableInfo table, TableOption... options)`\n- `BaseTableInfo update(BaseTableInfo table, TableOption... options)`\n- `BaseTableInfo getTable(String datasetId, String tableId, TableOption... options)`\n- `BaseTableInfo getTable(TableId tableId, TableOption... options)`\n- `JobInfo create(JobInfo job, JobOption... options)`\n- `JobInfo getJob(String jobId, JobOption... options)`\n- `JobInfo getJob(JobId jobId, JobOption... options)`\n\nFor instance:\n\n``` java\n<T extends BaseTableInfo> T create(T table, TableOption... options) throws BigQueryException;\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/493",
        "number": 493,
        "title": "Async non-blocking call to datastore?",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Will there be any support for async non-blocking calls to the datastore?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/490",
        "number": 490,
        "title": "Adding functional Dataset, Table and Job to bigquery",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "We should add functional classes (`Dataset`, `Table` and `Job`) to gcloud-java-bigquery, to make using the library easier. Functional classes should allow something like:\n\n``` java\n// get an existing dataset\nDataset dataset = Dataset.load(bigquery, \"my_dataset_id\");\n// create a table\nTable table = dataset.create(\"my_table_id\", Schema.of(field1, field2));\n// copy a table\nJob copyJob = table.copy(TableId.of(\"my_dataset_id\", \"my_copy_table_id\");\n// cancel a job\ncopyJob.cancel();\n// load data into the table\nJob loadJob = table.load(FormatOptions.csv(), ImmutableList.of(\"gs://my-bucket/my-file.csv\"));\n// wait for job to complete\nwhile (!loadJob.isDone()) {\n  loadJob = loadJob.reload();\n  Thread.sleep(1000);\n}\n```\n\nComments are welcome:)\n/cc @jtigani\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/489",
        "number": 489,
        "title": "Add format parameter to ExtractJobInfo and LoadJobInfo factory methods",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "We have several `of` factory methods for `ExtractJobInfo` and `LoadJobInfo`. All take the id of the table involved and one or more GCS URIs. We should probably add a `format` parameter to make them more flexible. Thoughts?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/486",
        "number": 486,
        "title": "Update gcloud-java-examples apps to use defaultInstance().service()",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "This would reflect the most up-to-date way to create the service objects.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/485",
        "number": 485,
        "title": "Refactor BasePageFetcher",
        "labels": [
            "api: core",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "Some page-based cursor services, such as `gcloud-java-storage` and `gcloud-java-resourcemanager`, currently have duplicated code for the `BasePageFetcher`.  We should refactor the `BasePageFetcher` code to be in `gcloud-java-core`.  We can use Generics for the specific Options type O and provide an abstract method to return the PAGE_TOKEN option.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/484",
        "number": 484,
        "title": "Remove check for \"Unnamed\" name in ProjectInfo.fromPb()",
        "labels": [
            "api: cloudresourcemanager",
            "priority: p2"
        ],
        "state": "closed",
        "body": "Currently, when using `ListProjects`, projects without a name are given the name \"Unnamed\" when returned by `ListProjects`.  As a result, we explicitly set the name to null if a project's name is \"Unnamed\" in `ProjectInfo.fromPb` When this is fixed, we can stop this behavior.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/483",
        "number": 483,
        "title": "Add support for adding listeners to the service api class for close()",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/481",
        "number": 481,
        "title": "Multiple instances of \"all X goes through this method\"",
        "labels": [
            "api: core",
            "api: logging",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "This is a protodoc issue.\nSee writeLogEntries for an example.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/480",
        "number": 480,
        "title": "Add auto-generated, params, etc to create/extract path methods",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "These are generated separately from other methods, but should contain these comments/tags regardless.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/479",
        "number": 479,
        "title": "Consider Suppressing \"generated from ...proto\" if file doesn't exist",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "Some proto files have not been made publicly available. We might want to suppress generating \"generated from\" comment for them to prevent confusion.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/478",
        "number": 478,
        "title": "Make DatastoreException message more informative",
        "labels": [
            "api: core",
            "api: datastore"
        ],
        "state": "closed",
        "body": "In `DefaultDatastoreRpc.translate(DatastoreException exception)`, we lose helpful error messages because we only throw a DatastoreRpcException based on the associated `Reason`.  For example, in a malformed query request, the user gets an exception with the message \"Invalid request\".  The original exception thrown and translated by the method mentioned above may include a message such as \"must specify all group by orderings before any non group by orderings\", which is far more helpful for the user.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/477",
        "number": 477,
        "title": "Add throws tag if method throws any known exception",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/476",
        "number": 476,
        "title": "Consider writing names in {@code} block",
        "labels": [
            "api: core",
            "api: logging",
            "api: pubsub",
            "priority: p2",
            "triaged for GA"
        ],
        "state": "closed",
        "body": "A way to do this is to reformat everything in form `foobar` to {@code foobar}\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/475",
        "number": 475,
        "title": "writeLogEntries: what happens if no logName is provided?",
        "labels": [
            "api: core",
            "api: logging"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/474",
        "number": 474,
        "title": "Better doc for extract functions",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "\"Extracts the log from the given fully-qualified path which represents a logName resource\" is confusing. I am open to any suggestions.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/473",
        "number": 473,
        "title": "Wording for updateSink is confusing",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "\"If the sink doesn't exist, it is created\". This means it's possible to \"update\" a sink that doesn't exist. The user must still provide the sink to the method.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/472",
        "number": 472,
        "title": "Use Logging emulator to test",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "We should move to using emulator for testing. Manually written mocks for client libraries testing do not scale.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/471",
        "number": 471,
        "title": "Delete Google-internal path from documentation",
        "labels": [
            "api: logging"
        ],
        "state": "closed",
        "body": "Some doc comments pulled from protobuf has references to file paths used at Google. These should go away as Logging API matures, and we will regenerate the libraries.\n- [x] gcloud-java-logging/src/main/java/com/google/gcloud/logging/spi/v2/ConfigServiceV2Api.java\n- [x] gcloud-java-logging/src/main/java/com/google/gcloud/logging/spi/v2/MetricsServiceV2Api.java\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/470",
        "number": 470,
        "title": "Figure out how to use RetryHelper in insertAll",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Right now `bigquery.insertAll` does not use `RetryHelper`. Retrying a failed `insertAll` operation might insert duplicates into the table unless an ID is associated to each row.\n\nWe have 2 options here:\n1. Use `RetryHelper` and document that unless row IDs are used, duplicates might be inserted\n2. Use `RetryHelper` and when retrying add a [randomUUID()](https://docs.oracle.com/javase/7/docs/api/java/util/UUID.html#randomUUID%28%29) to all rows that have no ID specified\n\nIt is worth noting that BigQuery duplicate detection based on row ID is best effort. Opinions/suggestions are welcome!\n\n/cc @jtigani\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/469",
        "number": 469,
        "title": "Add support for etag checks",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "BigQuery supports setting the `if-match` and `if-none-match` headers (see [here](https://cloud.google.com/bigquery/docs/data)) to check for etag match or mismatch when requesting some resource.\n\nWe should add support for `etagMatch` and `etagNotMatch` options. This support can be provided once the following issues are closed:\n- [ ] #340 \n- [ ] #466\n- [ ] #468 \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/468",
        "number": 468,
        "title": "Dataset.delete, Table.delete and Job.cancel ignore the if-non-match header",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It seems to me that the following apis\n- [Dataset.delete](https://cloud.google.com/bigquery/docs/reference/v2/datasets/delete)\n- [Table.delete](https://cloud.google.com/bigquery/docs/reference/v2/tables/delete)\n- [Job.cancel](https://cloud.google.com/bigquery/docs/reference/v2/datasets/delete)\n\nIgnore the HTTP `if-none-match` header (they fail as expected if `if-match` header does not match).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/467",
        "number": 467,
        "title": "Write Integration Tests for Resource Manager",
        "labels": [
            "api: cloudresourcemanager",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Until issue #431 is solved, we'll have to use a JSON file already generated by the Google Cloud SDK, placed in the proper directory.  Once this issue is resolved, we should fix the CI to user a JSON file from any location.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/466",
        "number": 466,
        "title": "Create and get dataset/table return the same resource but different etags",
        "labels": [
            "api: bigquery",
            "priority: p2",
            "triaged for GA",
            "type: bug"
        ],
        "state": "closed",
        "body": "Creating a dataset returns:\n\n``` json\n{\n \"kind\": \"bigquery#dataset\",\n \"etag\": \"\\\"Bop49sEVg6UBKwr7tLdL8AavHaw/xpdkOhgn_hczcTdfFCaB6fS1A2Q\\\"\",\n \"id\": \"gcloud-devel:test_create_dataset_tag\",\n \"selfLink\": \"https://www.googleapis.com/bigquery/v2/projects/gcloud-devel/datasets/test_create_dataset_tag\",\n \"datasetReference\": {\n  \"datasetId\": \"test_create_dataset_tag\",\n  \"projectId\": \"gcloud-devel\"\n },\n \"access\": [\n  {\n   \"role\": \"OWNER\",\n   \"specialGroup\": \"projectOwners\"\n  },\n  {\n   \"role\": \"WRITER\",\n   \"specialGroup\": \"projectWriters\"\n  },\n  {\n   \"role\": \"READER\",\n   \"specialGroup\": \"projectReaders\"\n  }\n ],\n \"creationTime\": \"1450265774254\",\n \"lastModifiedTime\": \"1450265774254\"\n}\n```\n\nGetting that same dataset immediately after creation returns:\n\n``` json\n{\n \"kind\": \"bigquery#dataset\",\n \"etag\": \"\\\"Bop49sEVg6UBKwr7tLdL8AavHaw/MTQ1MDI2NTc3NDI1NA\\\"\",\n \"id\": \"gcloud-devel:test_create_dataset_tag\",\n \"selfLink\": \"https://www.googleapis.com/bigquery/v2/projects/gcloud-devel/datasets/test_create_dataset_tag\",\n \"datasetReference\": {\n  \"datasetId\": \"test_create_dataset_tag\",\n  \"projectId\": \"gcloud-devel\"\n },\n \"access\": [\n  {\n   \"role\": \"OWNER\",\n   \"specialGroup\": \"projectOwners\"\n  },\n  {\n   \"role\": \"WRITER\",\n   \"specialGroup\": \"projectWriters\"\n  },\n  {\n   \"role\": \"READER\",\n   \"specialGroup\": \"projectReaders\"\n  }\n ],\n \"creationTime\": \"1450265774254\",\n \"lastModifiedTime\": \"1450265774254\"\n}\n```\n\nAs you can see the resources are identical but the etag is different.\nThis behaviour is unexpected to me and might cause troubles when using the etag value in `etagMatch` or `etagNotMatch` options.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/465",
        "number": 465,
        "title": "Add support for BigQuery query plan explanation",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "Based on the recent [BigQuery update](http://googlecloudplatform.blogspot.com/2015/12/BigQuery-cost-controls-now-let-you-set-a-daily-maximum-for-query-costs.html) we should add support for query plan explanation. Plan explanation is contained in the [queryPlan field](https://cloud.google.com/bigquery/docs/reference/v2/jobs#statistics.query.queryPlan) inside query job's statistics.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/464",
        "number": 464,
        "title": "Add support for BigQuery table templates",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "Based on the recent [BigQuery update](https://cloud.google.com/bigquery/docs/reference/v2/tabledata/insertAll#templateSuffix) we should add support for table templates.\n\nMore in details we should provide support for the `templateSuffix` parameter in [TableData: insertAll](https://cloud.google.com/bigquery/docs/reference/v2/tabledata/insertAll#templateSuffix).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/459",
        "number": 459,
        "title": "Figure out the work needed for Google Translate",
        "labels": [
            "api: translation"
        ],
        "state": "closed",
        "body": "For REST api see [here](https://developers.google.com/resources/api-libraries/documentation/translate/v2/java/latest/).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/458",
        "number": 458,
        "title": "Should we set a default retry strategy?",
        "labels": [
            "api: core",
            "type: question"
        ],
        "state": "closed",
        "body": "Right now, the default setting when creating a service is to not retry at all.  Should we instead set a default retry strategy?  While retrying is important for some services, setting the default to retry may increase the costs for users.  \n\nAlternatively, we could have two shortcut methods to get the options, `defaultInstanceNoRetries` and `defaultInstanceWithRetries`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/456",
        "number": 456,
        "title": "Add a common interface for resource field enums",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "We should consider creating an interface for all field enums (e.g. `DatasetField` in gcloud-java-bigquery and`BlobField` in gcloud-java-storage).\n\n``` java\ninterface ResourceField {\n  String selector();\n}\n```\n\nSelector's creation code (at least part of it) should be moved to a common static method.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/455",
        "number": 455,
        "title": "Add integration tests for Datastore v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/451",
        "number": 451,
        "title": "Synchronize LocalResourceManagerHelper",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "Right now, the mock works fine if there's only one connection to it.  However, if there are multiple connections, there are potential race conditions in some of the handler methods (such as `delete`).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/450",
        "number": 450,
        "title": "Put test apps in a repository with directions on how to run them",
        "labels": [],
        "state": "closed",
        "body": "We should establish a repository of apps used to test `gcloud-java` on App Engine, Compute Engine, and the desktop (for service/build/auth-related testing).  We should also have directions on how to run the apps.  We can use gcloud-devel as our shared project.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/449",
        "number": 449,
        "title": "Figure out if using URLFetch if running on AppEngine is necessary",
        "labels": [
            "api: core",
            "running on app engine",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "If we can always use NetHttpTransport, we can remove the logic in `DefaultHttpTransportFactory.create` (in [`ServiceOptions`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/gcloud/ServiceOptions.java)) to check if we're running on App Engine.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/447",
        "number": 447,
        "title": "Remove StreamingBuffer filed from ExternalTable",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "Streaming inserts to an external table is not supported, we should remove the `StreamingBuffer` field.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/445",
        "number": 445,
        "title": "Figure out the work needed for Container Engine admin",
        "labels": [],
        "state": "closed",
        "body": "Based on [this](https://cloud.google.com/container-engine/reference/rest/) api.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/444",
        "number": 444,
        "title": "Tie BigQueryError to BigQueryException",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "`BigQueryError`s are returned as part of a job state, as the result of a [query operation](https://cloud.google.com/bigquery/docs/reference/v2/jobs/query) and as a response to [insert all](https://cloud.google.com/bigquery/docs/reference/v2/tabledata/insertAll). In all the above cases a `BigQueryException` is not thrown.\n\nWhen a request fails the service returns an error in the form:\n\n``` json\n{\n \"error\": {\n  \"errors\": [\n   {\n    \"domain\": \"global\",\n    \"reason\": \"notFound\",\n    \"message\": \"Not found: Table gcloud-devel:dataset.view\"\n   }\n  ],\n  \"code\": 404,\n  \"message\": \"Not found: Table gcloud-devel:dataset.view\"\n }\n}\n```\n\nSo we could add a `BigQueryError` field to `BigQueryException` containing the error that caused the exception.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/440",
        "number": 440,
        "title": "Cloud Resource Manager error message swap",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "403 forbidden (permission denied) is returned instead of 404 not found when a project doesn't exist.  For the time being, we will assume 403 means the project wasn't found.  We should change back our implementation once this is fixed.\n\nAlso, 400 bad request is returned when attempting to perform actions on a project that is in an incorrect lifecycle state.  This may make more sense with error code 412 (precondition failed) according to the [public documentation](https://cloud.google.com/resource-manager/v1/errors/core_errors#PRECONDITION_FAILED), since the error message contains the message \"precondition check failed.\"\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/439",
        "number": 439,
        "title": "Figure out the work needed for IAM Policy support",
        "labels": [
            "iam"
        ],
        "state": "closed",
        "body": "https://cloud.google.com/iam/docs/managing-policies\n\nNote: the maven artifact for this service is bundled with the Resource Manager artifact ([com.google.api.services.cloudresourcemanager](https://developers.google.com/resources/api-libraries/documentation/cloudresourcemanager/v1beta1/java/latest/)). \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/436",
        "number": 436,
        "title": "gcloud-java not compiling with gradle",
        "labels": [],
        "state": "closed",
        "body": "I'm using this line in gradle:\n**compile 'com.google.gcloud:gcloud-java:jar:0.1.0'**\n\nIt's giving compiling error:\n**Error:(35, 13) Failed to resolve: com.google.gcloud:gcloud-java:jar**\n\nI've also created a stackoverflow question\nhttp://goo.gl/9nOA4a\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/434",
        "number": 434,
        "title": "Put PublisherApi/SubscriberApi classes under a java package path which contains the service version",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "We need to distinguish the Service Api classes by the major version of the service, in case multiple versions need to co-exist for situations like migrations. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/431",
        "number": 431,
        "title": "Support UserCredentials",
        "labels": [
            "api: cloudresourcemanager",
            "api: core",
            "auth",
            "priority: p2"
        ],
        "state": "closed",
        "body": "The `google-auth-library-java` library has a type of credentials called `UserCredentials` which we should wrap in `gcloud-java-core`.  However, this requires [this issue](https://github.com/google/google-auth-library-java/issues/52) to be fixed.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/429",
        "number": 429,
        "title": "Check retryable exceptions",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "There are some exceptions (i.e. 403, with reason \"rateLimitExceeded\") currently unlisted which may be retryable.  We should check best practices with the Cloud Resource Manager team.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/428",
        "number": 428,
        "title": "We should add unit-tests for api-client based spi classes",
        "labels": [
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "spi tests that are based on the api-client can provide an `HttpTransportFactory` with a mock `HttpTransport`.\n\nFor more info see [this](https://developers.google.com/api-client-library/java/google-http-java-client/unit-testing).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/422",
        "number": 422,
        "title": "Should we repackage the spi layer?",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Right now all services' spi layers are bundled into one package (`com.google.gcloud.spi`).  While this provides the convenience of separating the spi javadoc from the api javadoc, the one package may not make sense as we add more and more services.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/421",
        "number": 421,
        "title": "Support page size and page token",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "When the Cloud Resource Manager supports paging, we should add in page size and page token as list options.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/420",
        "number": 420,
        "title": "Run unit tests for non-master branch PRs",
        "labels": [],
        "state": "closed",
        "body": "Right now, we only run unit tests for PRs that are on the master branch.  We should run the unit tests.  We can optionally include a coverage report, but since PRs in other branches tend to be \"work in progress\" it's not as vital.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/419",
        "number": 419,
        "title": "Support parent in Project",
        "labels": [
            "api: cloudresourcemanager",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "When public documentation is ready for ResourceId and a Project's parent, we should add support for parents.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/418",
        "number": 418,
        "title": "Consider using AutoValue for immutable value types.",
        "labels": [
            "type: cleanup"
        ],
        "state": "closed",
        "body": "We should evaluate if using `AutoValue` is a good fit for us.\n\nThis will help to eliminate boilerplate code (though IDE's today typically help in the initial part and some\neven in the maintenance part).\n\nWe should consider IDE support/behavior when the referred auto generated class is missing, \nflexibility in copying set values (e.g. passed collection to immutable collection), replacing `null` with api-client `Data.nullOf`,..).\n\nAlso, it introduce the dependency of \"@Nullable\" annotation and I think once users see that in the code they expect it in other places (so, we should go and change the code to use it consistently when applicable).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/415",
        "number": 415,
        "title": "blobInfo.toBuilder().build() is not equal to blobInfo",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "We have this situation:\n\n``` java\nBlobInfo blobInfo = BlobInfo.builder(BlobId.of(\"b\", \"n\")).build();\nassertEquals(blobInfo, blobInfo.toBuilder().build()); // This fails!\n```\n\nThis is due to the fact that `toBuilder` uses builder's setters that initialize (some of them) fields to `Data.nullOf()` if `null` is passed. This can be fixed by checking for `null` before calling setters in `toBuilder()`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/413",
        "number": 413,
        "title": "Move some exception translation logic to BaseServiceException",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "In `DefaultStorageRpc` (and also other services as `DefaultBigQueryRpc`) we have code handling the translation of `IOException` to service specific exceptions:\n\n``` java\nprivate static BigQueryException translate(IOException exception) {\n  BigQueryException translated;\n  if (exception instanceof GoogleJsonResponseException\n      && ((GoogleJsonResponseException) exception).getDetails() != null) {\n    translated = translate(((GoogleJsonResponseException) exception).getDetails());\n  } else {\n    translated =\n        new BigQueryException(BigQueryException.UNKNOWN_CODE, exception.getMessage(), false);\n  }\n  translated.initCause(exception);\n  return translated;\n}\n\nprivate static BigQueryException translate(GoogleJsonError exception) {\n  boolean retryable = RETRYABLE_CODES.contains(exception.getCode());\n  return new BigQueryException(exception.getCode(), exception.getMessage(), retryable);\n}\n```\n\nPart of this logic should be moved to `BaseServiceException`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/410",
        "number": 410,
        "title": "We should retry on read/connection timeout.",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "The `ExceptionHandler` of datastore and storage should be configured to retry on read/connection timeouts.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/409",
        "number": 409,
        "title": "Add to LocalGcdHelper an option to dump the generated indexes",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "We should explore to option to configure `LocalGcdHelper` to run with a `datastore-indexes.xml` that is configured with `autoGenerate=\"true\"` and then provide an option to save the generated indexes in a desired place.\n\nFor more info see [this](https://cloud.google.com/datastore/docs/tools/indexconfig).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/408",
        "number": 408,
        "title": "Provide a pointer for composite index creation",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "composite index creation is documented [here](https://cloud.google.com/datastore/docs/tools/indexconfig).\nIt would be a good to add a reference to it in `Query.java` and [here](https://github.com/GoogleCloudPlatform/gcloud-java/tree/master/gcloud-java-datastore#running-a-query).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/407",
        "number": 407,
        "title": "Add support for Datastore Index management.",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Once DatastoreAdmin API is available we should support its functionality (mainly index management).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/406",
        "number": 406,
        "title": "Update the release process to support releases of individual modules",
        "labels": [],
        "state": "closed",
        "body": "Having the option to have a separate version (and release) for each module would be very nice.\nThis would allow a particular service client to get updated independently (though we should probably\nalso update the gcloud-java \"all\" module).\n\n/cc @mziccard \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/403",
        "number": 403,
        "title": "Remove the HttpIntializer dependency from AuthCredentials",
        "labels": [
            "api: core",
            "auth"
        ],
        "state": "closed",
        "body": "After we resolve #334 We should also change `AuthCredentials` and replace `protected abstract HttpRequestInitializer httpRequestInitializer` with `public abstract Credentials credentials()` returning `com.google.auth.Credentials.Credentials`.\n\nWe should also change `ServiceOptions.httpRequestInitializer` to get the credentials from `AuthCredentials` and wrap them inside `HttpCredentialsAdapter`.\n\nIf we can't find a way to deal with the deferred scoping, we can consider returning `GoogleCredentials`\ninstead of `credentials`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/402",
        "number": 402,
        "title": "Add step-by-step guide+examples for storage",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "The guide would be similar in format to #399 \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/400",
        "number": 400,
        "title": "Use pubsub fake written by the pubsub team instead of LocalPublisherImpl",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "It isn't available in open source quite yet. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/398",
        "number": 398,
        "title": "In ServiceApi classes, follow the google style guide for java",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "http://google.github.io/styleguide/javaguide.html\n\nSpecifically, wrapping is not done correctly. This may require a fair amount of redesign and refactoring in the code generator, or maybe some kind of post-processing step, because the code generator is language-independent. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/397",
        "number": 397,
        "title": "In ServiceApi classes, consider creating a helper class for each resource path to get and set subvariables",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/396",
        "number": 396,
        "title": "In ServiceApi classes, consider how to expose the underlying gRPC layer for advanced use cases.",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "We may want to expose the channel and 1 or more gRPC stubs for advanced use cases not met by the generated methods in the wrapper. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/395",
        "number": 395,
        "title": "In ServiceApi classes, add helper methods to extract variables from fully-qualified resource paths",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/394",
        "number": 394,
        "title": "In ServiceApi classes, provide a way to control timeouts. ",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/392",
        "number": 392,
        "title": "Add more usage examples to gcloud-java-datastore",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "We could copy/modify the usage examples from the new `v1beta3` datastore-api-quickstart site (not published yet) and add them to the datastore modules `README.md`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/391",
        "number": 391,
        "title": "javadoc issue",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "I see:\ncom.\u200bgoogle.\u200bgcloud.\u200bdatastore\npublic class FullEntity<K extends IncompleteKey> extends BaseEntity<K>\nA full entity is a BaseEntity that with a complete set of properties.\n\nNot sure what the last sentence means.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/388",
        "number": 388,
        "title": "Create a unified way to set service options for both ServiceApi classes and handwritten service wrappers.",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "- ServiceApi classes currently use ServiceApiSettings\n- handwritten service wrappers currently use ServiceOptions\n\nWe should create a unified way to configure these. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/387",
        "number": 387,
        "title": "SubscriptionApi.createSubscription: avoid reference to deleted topics",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The documentation for the \"topic\" parameter of the flattened form of createSubscription says \"The value of this field will be `_deleted-topic_` if the topic has been deleted.\" This is not relevant to the createSubscription operation and should be avoided somehow. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/386",
        "number": 386,
        "title": "In ServiceApi classes, make clear how to cancel requests",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Specifically, the documentation of SubscriberApi.pull says \"The client may cancel the request if it does not wish to wait any longer for the response.\" This is currently only possible if the api caller uses the ApiCallable, and calls cancel on the ClientCall. The other method forms still make reference to canceling though, even though it's not possible. Possibly the interface needs to be updated somehow, or also the documentation needs to be adjusted. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/385",
        "number": 385,
        "title": "In ServiceApi classes, fix wording of documentation about returning errors vs throwing exceptions.",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "Currently, the documentation as copied from the proto includes wording like this:\n- \"Returns NOT_FOUND if the topic does not exist.\n- \"If the subscription already exists, returns ALREADY_EXISTS.\"\n- \"If the corresponding topic doesn't exist, returns NOT_FOUND.\"\n- \"The server may return UNAVAILABLE if there are too many concurrent pull requests pending for the given subscription.\"\n\nThese returns are referring to the service, not the api wrapper, which is confusing. The api wrapper actually throws exceptions in these circumstances. The wording of the documentation on the proto needs to be made more idiom-independent. Additionally, if the markup in the proto could indicate the error cases in a structured way, it would make it a lot easier to generate `@throws` documentation for the errors. That may be a longer-stretch task, though. Before that point, at least a general `@throws` clause needs to be added. Additionally, the documentation needs to make clear how to get the exact error that occurred (specifically, getting the status code). \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/384",
        "number": 384,
        "title": "Implement client-side buffering for publishing messages",
        "labels": [
            "api: pubsub",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This functionality needs to support these settings:\n- max batched messages\n- max batched bytes\n- max batching delay\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/383",
        "number": 383,
        "title": "In ServiceApi classes, provide a way to control retry settings. ",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "For existing gcloud services, RetrySettings is used. We probably want to keep advanced settings internal, but set them to different values for individual services, probably controlled by some kind of static service configuration or code gen configuration. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/382",
        "number": 382,
        "title": "In ServiceApi classes, provide a mechanism to determine if an api method call can be retried on failure",
        "labels": [
            "api: logging",
            "api: pubsub"
        ],
        "state": "closed",
        "body": "An api method call should be retryable if it is idempotent, not retryable if not idempotent. We need to figure out the best way to surface this, whether in an exception, the ApiCallable, the ClientCall, some registry, or somewhere else. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/381",
        "number": 381,
        "title": "Update service address for pubsub",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": "The service address for pubsub is currently set to pubsub-experimental.googleapis.com, but needs to be updated to pubsub.googleapis.com when pubsub has gRPC support in GA. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/373",
        "number": 373,
        "title": "DefaultStorageRpc.read setting wrong range",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "In [DefaultStorageRpc.read](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/spi/DefaultStorageRpc.java#L418) we set the content range as:\n\n``` java\npublic byte[] read(StorageObject from, Map<Option, ?> options, long position, int bytes)\n    throws StorageException {\n  ...\n  downloader.setContentRange(position, (int) position + bytes);\n  ...\n}\n```\n\nAccorting to [here](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.35) positions are inclusive, so we should probably do: `downloader.setContentRange(position, (int) position + bytes - 1);`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/372",
        "number": 372,
        "title": "Storage.delete returns false on NotFound, BatchRequest.delete shows failure",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "If we try to delete a non-existing blob `storage.delete(nonExistingBlob)` returns `false`.\nIf we try to delete a non-existing blob with a batch request:\n\n``` java\nBatchRequest batchRequest = BatchRequest.builder()\n    .delete(nonExistingBlob)\n    .build();\n...\nbatchResponse.deletes().get(0).failed(); // This is true\n```\n\nThe deletion of a non-existing-blob is considered a failure in `BatchResponse`.\nWouldn't it be better to make this two ways of deleting a blob exhibit the same behavior?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/371",
        "number": 371,
        "title": "Use RetryHelper for batch operation",
        "labels": [
            "api: storage",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Currently `StorageImpl` does not use `RetryHelper` for batch operation.\n\nWe should consider using `RetryHelper` when invoking the rpc but also when getting the result.\nWe can iterate over the failed results and retry all the ones which are retryable.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/365",
        "number": 365,
        "title": "Limit google-api-client batch deletes to ~100.",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Suggestion made by @Capstan \n\nWe should change [`DefaultStorageRpc`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/spi/DefaultStorageRpc.java) and potentially invoke multiple sequential batch requests to avoid sending more than 100 delete requests per google-api-client batch.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/364",
        "number": 364,
        "title": "Consider other options for Batch requests.",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Suggestion was raised by @Capstan \n\nWe could add a `Batch`/`BatchContext`/`BatchHelper` class that gets storage as an input and have the same `delete`/`get`/`update` methods as `BatchRequest.Builder` but instead of returning `this` for chaining return a `Future` ([this](http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/util/concurrent/SettableFuture.html) could help with that) and have a `void apply()` method.\n\nAny further calls on such instance should fail after a successful `apply`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/363",
        "number": 363,
        "title": "We should include generation as part of the BlobId.",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "And we should use that generation (if supplied) in applicable operations such as delete, compose, copy (and use the google-api-client \"generation\" field).\n\nAlso, that means that we need to change `BlobSourceOption` and `BlobGetOption` `generationMatch` and `generationNotMatch` to be based on the value given in `BlobId`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/362",
        "number": 362,
        "title": "Add support for all IAM Policy member types",
        "labels": [
            "iam"
        ],
        "state": "closed",
        "body": "Right now, Cloud IAM Policy does not yet support members of type `allUsers`, `allAuthenticatedUsers`, or `domain` (see [here](https://cloud.google.com/iam/docs/managing-policies#code_example)).  When that is supported, we should allow gcloud-java users to create Members of those types.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/361",
        "number": 361,
        "title": "Create an app under gcloud-java-examples that uses gcloud-java-resourcemanager",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "It should be similar in style to `DatastoreExample` and `StorageExample`.  This should be done when `gcloud-java-resourcemanager` is complete and ready for use.\n\nAlso be sure to update the global README and `gcloud-java-examples`' README.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/360",
        "number": 360,
        "title": "Add example to Resource Manager's README",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "Also address the other TODOs mentioned in the README.  This should be done when the package is complete and ready for use.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/359",
        "number": 359,
        "title": "BlobReadChannel should fail if content comes from different generations. ",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Feedback from @Capstan:\n\nIf someone updates the object when the client is in the middle of a read and hadn\u2019t specified a precondition, you will simply read from the new object. You need to record the generation upon the first read and then choose what the behavior is for future reads\u2026 if the generation still exists (e.g., it\u2019s now a history object), do you still allow reads or do you balk (because the original request is talking about the \u201ccurrent\u201d object which has changed)?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/358",
        "number": 358,
        "title": "Standardize code snippets in package-info ",
        "labels": [],
        "state": "closed",
        "body": "Right now, the example in the Datastore's and Storage's package-info.java files explicitly sets the service options' project IDs but not the auth credentials.  The user will probably specify both or none, depending on whether they run the code from App/Compute Engine or not.\n\nI think we should have two examples in each package info, one with both left unset and the other with both explicitly set.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/354",
        "number": 354,
        "title": "Replace BucketInfo.StorageClass and BucketInfo.Location classes with plain strings.",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Issue was raised by @mfschwartz and @thobrla which find the enum as a reference for the current\nset of values confusing.\n\nWhen replaced to strings we should add a link in the Javadoc of the relevant BucketInfo.Builder setter to a page with the list of values.\n\nFor location we can use - https://cloud.google.com/storage/docs/bucket-locations\n\nFor Storage class we can use - https://cloud.google.com/storage/docs/storage-classes\n(and/or https://cloud.google.com/storage/docs/json_api/v1/buckets#resource as unfortunatly\nthe documentation of possible values is not as good as location - @mfschwartz is it possible to fix that?)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/353",
        "number": 353,
        "title": "Add an option for crc32/md5 client side validation for Storage.readAllBytes",
        "labels": [
            "api: storage",
            "priority: p2",
            "status: blocked",
            "type: feature request"
        ],
        "state": "closed",
        "body": "From @Capstan \"Read-side validation of checksums (crc32c) is a very nice-to-have\".\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/351",
        "number": 351,
        "title": "We should better document the Storage API",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Feedback from @mfschwartz\n\nAre you planning to flesh out all the javadoc?  These classes are full of methods and fields with no javadoc. That doesn\u2019t seem adequate for a public API. Even someone (such as myself) already familiar with other GCS APIs won\u2019t know what to make of some of your classes (e.g., what\u2019s a BlobSourceOption?), and someone not familiar with the other GCS APIs would have to read those other APIs\u2019 documentation to figure out what they can specify for things like cache-control, ACL fields, etc. Also, in places where you re-model abstractions (e.g., replacing LifecycleConfig with DeleteRule), someone not really knowledgeable about GCS would have a hard time understanding what this API is for with the minimal javadoc currently present.\n\nRelated note: The fact that you remodel abstractions makes it harder for someone to know where to go for documentation about details like whether we have any SLA guarantees for lifecycle management operations, etc. I think it\u2019s fine to re-model abstractions but I think your documentation needs to let users find out the more detailed information like this that we have documented elsewhere.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/350",
        "number": 350,
        "title": "Make Objectify work with google-cloud-datastore",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "[Objectify](https://github.com/objectify/objectify) is a popular data access API for Google Cloud Datastore.\n\nIt would be great if we are able to make it work with gcloud-java-datastore.\n\n/cc @stickfigure\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/349",
        "number": 349,
        "title": "We should consider adding performance tests.",
        "labels": [],
        "state": "closed",
        "body": "This can be part of the integration tests or triggered separately.\n\nIf we only care about the client overhead we could test that with a mock SPI but being able\nto get also server-observed performance would be nice.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/342",
        "number": 342,
        "title": "in the README the datastore sample does not compile.",
        "labels": [],
        "state": "closed",
        "body": "For example, Datastore datastore = DatastoreOptions.getDefaultInstance().service();\ndoes not seem to work with 0.0.10\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/341",
        "number": 341,
        "title": "Scopes not configured for service account error",
        "labels": [
            "api: core",
            "auth",
            "type: bug"
        ],
        "state": "closed",
        "body": "This error occurs to me when I try to use default credentials created from the GOOGLE_APPLICATION_CREDENTIALS variable. This is the error I get whenever I try to issue a request:\n\n```\njava.io.IOException: Scopes not configured for service account. Scoped should be specifed by calling createScoped or passing scopes to constructor.\n    at com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:183)\n    at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:76)\n    at com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:53)\n    at com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:40)\n    at com.google.gcloud.ServiceOptions$1.initialize(ServiceOptions.java:510)\n    at com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\n    at com.google.gcloud.spi.DefaultStorageRpc.list(DefaultStorageRpc.java:148)\n```\n\nIt seems that to create default credentials based on the env variable we must supply the service scopes. This can be done by changing [this line](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/gcloud/AuthCredentials.java#L249) to:\n\n``` java\nGoogleCredentials.getApplicationDefault().createScoped(scopes);\n```\n\nThis would require, however, to change our `AuthCredentials.createApplicationDefaults` method to accept a set of scopes as a parameter.\n\nNoticeably, scopes are not required to be passed when Google Cloud SDK credentials are used. Is this a desired behavior of the auth library? Should we add this `scopes` parameter?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/340",
        "number": 340,
        "title": "Tables create does not return a complete Table resource",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": "Playing around with table creation I stumbled upon this:\n\nWhen I successfully create a table I get the following response:\n\n``` json\n{  \n   \"kind\":\"bigquery#table\",\n   \"etag\":\"\\\"AxMVOKw7qC1yJvFAglg_iwWnfXE/1uI1j9CjWrEth7qwtgYXqgfPkQo\\\"\",\n   \"id\":\"gcloud-devel:gcloud_test_dataset_temp_179c9ccb_4acc_4c8e_b0f3_41d8e9d8ae76.testTable\",\n   \"selfLink\":\"https://www.googleapis.com/bigquery/v2/projects/gcloud-devel/datasets/gcloud_test_dataset_temp_179c9ccb_4acc_4c8e_b0f3_41d8e9d8ae76/tables/testTable\",\n   \"tableReference\":{\n      \"projectId\":\"gcloud-devel\",\n      \"datasetId\":\"gcloud_test_dataset_temp_179c9ccb_4acc_4c8e_b0f3_41d8e9d8ae76\",\n      \"tableId\":\"testTable\"\n   },\n   \"schema\":{\n      \"fields\":[\n         {  \n            \"name\":\"oneField\",\n            \"type\":\"INTEGER\"\n         }\n      ]\n   },\n   \"type\":\"TABLE\"\n}\n```\n\nThis is not a complete [table resource](https://cloud.google.com/bigquery/docs/reference/v2/tables) as some fields (creationTime, numBytes, numRows, ...) are missing. Do you have any idea why some fields are not set in create's response?\n\nIf I get the just created table the response is complete, as expected.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/338",
        "number": 338,
        "title": "I can not use the tag \"gcloud-java\" in StackOverflow when I ask a question",
        "labels": [],
        "state": "closed",
        "body": "This link http://stackoverflow.com/questions/tagged/gcloud-java has cero questions because no one can use the tag \"gcloud-java\" \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/335",
        "number": 335,
        "title": "Remove RemoteGcsHelper specific environment variables for setting projectId and key.",
        "labels": [
            "api: storage",
            "auth"
        ],
        "state": "closed",
        "body": "As discussed in #331 we should depend on the already existing `GOOGLE_APPLICATION_CREDENTIALS` and `GCLOUD_PROJECT` environment variables instead of the `RemoteGcsHelper` specific `GCLOUD_TESTS_KEY` and`GCLOUD_TESTS_PROJECT_ID` environment variables.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/334",
        "number": 334,
        "title": "Remove checks for old-style Compute/App Engine auth credentials",
        "labels": [
            "auth",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "Because [this bug is resolved](https://github.com/google/google-auth-library-java/issues/2), we can simplify our code that attempts to locate default credentials.  The [Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials) does this work for us now.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/331",
        "number": 331,
        "title": "We should mention GOOGLE_APPLICATION_CREDENTIALS in the Authentication section.",
        "labels": [
            "auth"
        ],
        "state": "closed",
        "body": "The main gcloud-java [README.md](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/README.md) contains an authentication section however this section does not\nmention the option of using the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to point to a key file.\n\n@mziccard I now wonder if we need the `GCLOUD_TESTS_KEY` and `GCLOUD_TESTS_PROJECT_ID` in the `RemoteGcsHelper` as `GOOGLE_APPLICATION_CREDENTIALS` could be used instead of the former and `GCLOUD_PROJECT` could be used instead of the latter.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/330",
        "number": 330,
        "title": "Provide a convenient way to get all results from a com.google.gcloud.Page",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "In cases when paging between different requests is not necessary (all results are consumed in the same request/thread) a common usage-pattern would be as such:\n\n``` java\nPage<V> page = .... get first page\nwhile (page != null) {\n  for (V v : page.values()) {\n    ...do something...\n  }\n   page = page.nextPage();\n}\n```\n\nor\n\n``` java\nPage<V> page = .... get first page\ndo {\n  for (V v : page.values()) {\n    ...do something...\n  }\n  page = page.nextPage();\n} while (page != null);\n```\n\nTo avoid this boilerplate code It would be nice to add to the `Page` class a method to return\nan `Iterator` for all the results (and let that Iterator do the paging).\n\nSome options:\n\n(1) add a static method such as Page.iterateAll(page)\n(2) an instance method such as `page.allValues()` or `page.iterateAll()` or `page.fetchAll()`\n\nAny preference or other suggestions?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/328",
        "number": 328,
        "title": "Update the location of config file",
        "labels": [
            "api: core",
            "auth"
        ],
        "state": "closed",
        "body": "The gcloud SDK moved the location of its config file from ~/.config/gcloud/properties to ~/.config/gcloud/configurations/config_default.  As a result, the file we read to get the default project ID in gcloud-java-core may be wrong, depending on whether the user updated their version of the gcloud SDK CLI.\n\nWe should first check if a config file exists in the new location.  If so, we take that projectID.  If it doesn't exist, we will try to read the old file.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/323",
        "number": 323,
        "title": "Can we get coveralls status for PRs",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/321",
        "number": 321,
        "title": "Use consistent \"update\" verbs in our API based on the underlying RPC (PUT/PATCH).",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "When it comes to metadata, some apiary libraries provide \"patch\" operations, some provide \"update\" and others provide both.\n\nIn GCS API we picked the verb \"update\" for PATCH operation and we don't provide a \"replace\"/PUT\n(which exists now in the apiary world but is probably going to be removed for gRPC).\n\nI would like to avoid confusion when using different services, and suggests we always use the same\nverb for metadata \"patch\" operations and a different one for metadata \"replace\" operations.\n\nSome options for API names:\n\n|  | Patch RPC | Update RPC |\n| --- | :-: | :-: |\n| 1 | patch | update |\n| 2 | patch | put |\n| 3 | update | replace |\n| 4 | update | set |\n| 5 | update | put |\n\nOther options are welcomed.\n\ngRPC does not provide the apiary level PATCH support (it is up to the service), and One Platform\nsuggests to use HTTP PATCH for update operations that are partial _or_ non-idempotent.\n\nMy preference is option (3)\n\n/cc @mziccard @ajkannan @jgeewax \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/319",
        "number": 319,
        "title": "Add \"Organization\" to gcloud-java-resourcemanager",
        "labels": [
            "api: cloudresourcemanager",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "(when it becomes publicly available)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/315",
        "number": 315,
        "title": "Move ListResult and BaseListResult to core module",
        "labels": [
            "api: core",
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "`ListResult` and `BaseListResult` might be useful also for other modules so it might make sense to move them from `com.google.gcloud.storage` to `com.google.gcloud.core`. What do you think?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/310",
        "number": 310,
        "title": "Identify a BigQuery dataset",
        "labels": [
            "api: bigquery",
            "type: question"
        ],
        "state": "closed",
        "body": "A [BigQuery dataset](https://cloud.google.com/bigquery/docs/reference/v2/datasets?hl=en) has an `id` field of the form `projectId:datasetId` and a `datasetReference` field:\n\n> \"datasetReference\": {\n>     \"datasetId\": string,\n>     \"projectId\": string\n>   }\n\nthis suggests that a user should be able to init a `DatasetId` object as: `DatasetId.of(\"projectId\", \"datasetId\")`. \n\nHowever, a `ServiceOptions` object is already tied to a specific project (and hence project id) so this makes me think that the user should not be allowed to access datasets for projects other than the one of the `ServiceOptions` object he is using. And also we should avoid asking a user to provide the project id every time he wants to instantiate a dataset object. This leads to something like `DatasetId.of(\"projectId\")` and for every remote operation `projectId` is taken from `ServiceOptions`.\nBut I think this is undesirable as our API representation would make no distinction between datasets of different projects or cause weird situations like:\n\n``` java\nDatasetId remoteId = bigqueryService.get(\"someId\").id(); // includes projectId\nDatasetId localId = DatasetId.of(\"someId\"); // does not include projectId\nremoteId.equals(localId); // false\n```\n\nThoughts?\n\nA workaround I see is having a factory method in `bigqueryService` that takes a string `datasetId` and sets the `projectId` by fetching it from `ServiceOptions`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/308",
        "number": 308,
        "title": "We should set ServiceOptions.applicationName as the user-agent in Datastore requests.",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "PR #307 provides a way to get a string in the following format \"gcloud-java/xxxx\" (xxxx stands for the version) from the service options. We should set it for every service.\n\nThe typical way to set it for apiary clients is via `setApplicationName` on the apiary service builder.\n\nWhen #300 is fixed that should be simple as we will have access directly to the apiary (or gRPC) client\nthough it would be nice a way to specify it even before that.\n\nFor more info see #278\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/306",
        "number": 306,
        "title": "Copy operation ignores stored object settings if content-type is null",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "GCS Copy (and ReWrite) operations includes copying the original blob's metadata but also provides \na way to override the blob's metadata (such as content-type, contentLanguage, metadata fields).\n\nWhen using the apiary copy or rewrite operations and supplying a `StorageObject` content it is going\nto be used for blob's metadata overriding values. However, in this case content-type is required (and operation will fail if one is not provided).\n\nCurrently the implementation will silently ignore any overriding metadata if content-type is missing (as\nin that case it will not pass the `StorageObject` content).\n\nThis is unexpected and not documented.\n\nSeveral options:\n\n1) Just document this behaviour in the `Storage.CopyRequest.Builder.target` method.\n\n2) Change `Storage.CopyRequest.Builder` target settings to get either `BlobId` or `BlobInfo` (and in case of the latter also provide in the same setter `BlobTargetOption`... [and overload it with Iterable<BlobTargetOption>]. In this case we could either leave it with the javadoc suggestion (but only\napplies to the target that accepts `BlobInfo`) and maybe also throw `IllegalArgumentException` in such case.\n\n3) Based on [2] and instead of client side check we could change the RPC message to accept a flag to indicate if overriding the source metadata is desired.\n\n4) Probably also based on [2] and instead of client side check we could use the source metadata (by issuing a separate get request) and \"patch\" it manually.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/302",
        "number": 302,
        "title": "Create API for GCE Metadata",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": "There's a great metadata service for getting access to information on the VM. It would be great to have a structured API for this:\nhttps://cloud.google.com/compute/docs/metadata?hl=en\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/300",
        "number": 300,
        "title": "Remove dependency on Datastore's client",
        "labels": [
            "api: datastore",
            "priority: p2"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/298",
        "number": 298,
        "title": "Dependency info page shows instructions to add pom artifact",
        "labels": [
            "type: bug"
        ],
        "state": "closed",
        "body": "Our [Dependency Info](http://googlecloudplatform.github.io/gcloud-java/0.0.10/dependency-info.html) page shows information on how to add `gcloud-java-pom` artifact as a dependency, not `gcloud-java`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/297",
        "number": 297,
        "title": "Figure out the work needed for Resource Manager service",
        "labels": [
            "api: cloudresourcemanager"
        ],
        "state": "closed",
        "body": "https://cloud.google.com/resource-manager/\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/295",
        "number": 295,
        "title": "Show how to add gcloud-java as a dependency in gradle and sbt",
        "labels": [],
        "state": "closed",
        "body": "We already show this [here](http://googlecloudplatform.github.io/gcloud-java/0.0.10/dependency-info.html) but it's quite hidden. \nWhat do you think about adding this information to the README and to the landing page (as a tabbed view?)?\n\nI know this is something that a user can construct from maven's dependency but we could make it easier.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/292",
        "number": 292,
        "title": "Investigate adding support for BucketAccessControls: insert",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "This is for discussion.\nDo we need to provide support for [BucketAccessControls: insert](https://cloud.google.com/storage/docs/json_api/v1/bucketAccessControls/insert) or rather expect users to rely on bucket update/patch?\n\nI think update/patch method should be enough. We can always add _BucketAccessControls: insert_ later if someone requests it.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/291",
        "number": 291,
        "title": "Provide support for objects rewrite",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Support for [rewrite](https://cloud.google.com/storage/docs/json_api/v1/objects/rewrite) should be added.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/290",
        "number": 290,
        "title": "Fix int casting of lastBytePos in DefaultStorageRpc.read",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "This depends on https://github.com/google/google-api-java-client/issues/937. `MediaHttpDownloader.setContentRange` takes `firstBytePos` as a long while `lastBytePos` as an int. As soon as this gets fixed we need to remove `int` casting.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/289",
        "number": 289,
        "title": "Use setProjection in DefaultStorageRpc.compose",
        "labels": [
            "api: storage",
            "priority: p2",
            "status: blocked",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This depends on b/20659000. The projection parameter is not supported by compose API. As soon as this is fixed we should add `setProjection` to `DefaultStorageRpc.compose`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/288",
        "number": 288,
        "title": "Remove setContentType from DefaultStorageRpc.compose",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "This depends on b/20681287. Compose API needs a `contentType` to be always provided. As soon as the bug gets fixed we should remove `setContentType(\"application/octet-stream\")`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/286",
        "number": 286,
        "title": "Consider Gradle build system",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Maven is very popular and idiomatic as a build system for Java. Gradle is also becoming very popular for Java. Has there been any discussion among owners of the project about potentially moving to Gradle? \n\nSome reasons this might be interesting:\n1. GRPC Java (https://github.com/grpc/grpc-java) uses it and there may be opportunity to leverage extensions for consuming gRPC components.\n2. There is at least one significant performance difference in that \"mvn install\" can take minutes, while the Gradle equivalent takes less than 30 seconds.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/283",
        "number": 283,
        "title": "Create test for deferred results in Datastore's \"get\" method",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/282",
        "number": 282,
        "title": "Clean up todos",
        "labels": [],
        "state": "closed",
        "body": "There are ~7-8 todo statements in the codebase, most of which don't have associated issues.  We should create issues for them and address them when we get the chance.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/280",
        "number": 280,
        "title": "BatchResponse.equals does not compare getResult",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "`BatchResponse.equals` compares twice `updateResult` rather than comparing `getResult`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/278",
        "number": 278,
        "title": "Where do we set the user agent in the request?",
        "labels": [
            "api: core",
            "type: question"
        ],
        "state": "closed",
        "body": "Do we set it as `gcloud-java/[version]` ?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/268",
        "number": 268,
        "title": "Write tests for LocalGcdHelper and RemoteGcsHelper",
        "labels": [],
        "state": "closed",
        "body": "Since these classes were moved into production, it'd be good to write tests for these classes.  Users may have more expectations for this code since it was moved to the production package.  Also, our test coverage may be limited without these tests.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/267",
        "number": 267,
        "title": "BlobWriteChannel CRC32C and MD5 hash mismatch error",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "The following code:\n\n``` java\nBlobId blobId = BlobId.of(\"bucket\", \"blob_name\");\nBlobInfo blobInfo = BlobInfo.builder(blobId).contentType(\"test/plain\").build();\nstorage.create(blobInfo, \"Hello, Cloud Storage!\".getBytes(UTF_8));\nBlobInfo updatedBlobInfo = storage.get(blobId);\nWritableByteChannel channel = storage.writer(updatedBlobInfo);\nchannel.write(ByteBuffer.wrap(\"Updated content\".getBytes(UTF_8)));\nchannel.close();\n```\n\ncauses an error:\n\n> Caused by: com.google.gcloud.storage.StorageException: 400 Bad Request\n> {\n>  \"error\": {\n>   \"errors\": [\n>    {\n>     \"domain\": \"global\",\n>     \"reason\": \"invalid\",\n>     \"message\": \"Provided CRC32C \\\"IgKckQ==\\\" doesn't match calculated CRC32C \\\"c5cgUw==\\\".\"\n>    },\n>    {\n>     \"domain\": \"global\",\n>     \"reason\": \"invalid\",\n>     \"message\": \"Provided MD5 hash \\\"paCw+9t7LhjISSAPBaeazA==\\\" doesn't match calculated MD5 hash \\\"SFCAEvYjPzpCjkKQr6MGGg==\\\".\"\n>    }\n>   ],\n>   \"code\": 400,\n>   \"message\": \"Provided CRC32C \\\"IgKckQ==\\\" doesn't match calculated CRC32C \\\"c5cgUw==\\\".\"\n>  }\n> }\n\nIf a stale `BlobInfo` object is passed to `storage.writer(blobInfo)` instead:\n\n``` java\n// ...\nBlobInfo blobInfo = BlobInfo.builder(blobId).contentType(\"test/plain\").build();\nstorage.create(blobInfo, \"Hello, Cloud Storage!\".getBytes(UTF_8));\nWritableByteChannel channel = storage.writer(blobInfo);\nchannel.write(ByteBuffer.wrap(\"Updated content\".getBytes(UTF_8)));\nchannel.close();\n```\n\nNo error occurs.\n\nIt seems to me that if a \"complete\" `StorageObject` is passed to `DefaultStorageRpc.open` then its `md5Hash` and `crc32c` fields are used to request the upload id (see [this](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/spi/DefaultStorageRpc.java#L495) line). At the end of the upload if that data do not match with the uploaded one the whole upload fails. \nDo you think this is a desirable default behavior? \nI think it is not, I would rather add some options to `storage.writer(...)` to allow users to explicitly choose to check `md5Hash` and `crc32c` if they have already computed them and put them into the `BlobInfo` object (i.e. if they know what they're doing).\nThoughts?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/260",
        "number": 260,
        "title": "ClassNotFoundException when using com.google.gcloud.AuthCredentials in 0.0.9",
        "labels": [],
        "state": "closed",
        "body": "I've just upgraded to 0.0.9 from 0.0.8-SNAPSHOT and I get\n\n```\njava.lang.ClassNotFoundException: net.sourceforge.cobertura.coveragedata.TouchCollector\n```\n\ncalling\n\n``` java\nAuthCredentials.createFor()\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/259",
        "number": 259,
        "title": "Add Javadocs in StructuredQuery to denote \"set\" operations",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "We should document that the methods `projection` and `distinct` are \"set\" operations, as opposed to `addProjection` and `addDistinct`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/258",
        "number": 258,
        "title": "Remove check for severe-level log duplicates from LocalGcdHelper",
        "labels": [
            "api: datastore",
            "type: cleanup"
        ],
        "state": "closed",
        "body": "As of now, gcd.sh will log some messages (i.e. \"too much contention on entities\") at both the INFO and SEVERE level.  When this is fixed in the next gcd release, we can remove the duplication check from LocalGcdHelper.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/255",
        "number": 255,
        "title": "Add contentType param to Bucket.create(blob, content, options)",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "This was discussed with @aozarov in #251.\nSince `contentType` is a required field we should add it to `Bucket`'s `create(blob, content, options)`:\n\n```\nBlob create(String blob, byte[] content, String contentType, BlobTrargetOptions... options)\n```\n\nIf `contentType` is set to `null` the default content type is used, and we can document this in the javadoc.\nI propose we use `application/octet-stream` as default.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/254",
        "number": 254,
        "title": "Pub/Sub API",
        "labels": [],
        "state": "closed",
        "body": "Integration with gcloud pub/sub service!\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/253",
        "number": 253,
        "title": "Change Blob to eagerly get a BlobInfo if constructed with only id.",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "I wonder if in the cases where `BlobInfo` is not provided to `Blob` we should actually get it from the service, and use empty if not exists (and document that).\n\nMy reason is, considering the following `Blob` operations:\n`info`, `exists`, `content`, `update`, `delete`, `copyTo`, `reader`, `writer` and `signUrl`\n\nIn all cases info matters if options are used (created #252 for `exists` method) and in many cases info matters even without the options (e.g. `info`, `copyTo`).\nAlso, considering our example, I think this will make the API cleaner (and will not require\nthe explicit blob = blob.reload() pattern).\n\nThe reasons I think we don't want to force-get when BlobInfo is provided are:\n- we don't want to double-reload when our API is returning the Blob. I guess we can get around that with a \"special\" constructor...\n- That is the way for a user to force a new Info (e.g. for write).\n\nNow when we clearly separate between blob identity and blob metadata, I think it is not\nthat unexpected that if one supply the metadata we should respect it as is (though documentation should make it clear).\n\nThis issue was discussed in #251 and @mziccard suggested that instead of getting the info in the identity constructors (`BlobId` or bucket & name) to provide a `Blob.fetch(storage, identity)` methods and only have one constructor that accepts `BlobInfo` (no force loading in that one).\n\nI am in favor of the above suggestion though maybe we should name it `load` to be consistent with the existing `reload`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/252",
        "number": 252,
        "title": "Add a var-arg BlobSourceOptions to Blob.exists",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/249",
        "number": 249,
        "title": "Don't allow projectId and namespace to be null in Datastore v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Do not allow users to set project ID or namespace to null.  If the user doesn't set it at all, we should default to the empty string.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/248",
        "number": 248,
        "title": "Provide GeoPointValue in Datastore v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "The geo point value is a new value type supported by Datastore v1beta3.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/245",
        "number": 245,
        "title": "Figure out the work needed for DNS service",
        "labels": [
            "api: dns"
        ],
        "state": "closed",
        "body": "https://developers.google.com/resources/api-libraries/documentation/dns/v1/java/latest/\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/244",
        "number": 244,
        "title": "When DatastoreImpl.runQuery()  gets a 503 it does not retry",
        "labels": [],
        "state": "closed",
        "body": "I'm getting a \"Could not reach service\" DatastoreException when retrying would run the query successfully.\n\n```\ncom.google.gcloud.datastore.DatastoreException: Could not reach service\n    at com.google.gcloud.datastore.DatastoreException$Code.translate(DatastoreException.java:87)\n    at com.google.gcloud.datastore.DatastoreException.translateAndThrow(DatastoreException.java:140)\n    at com.google.gcloud.datastore.DatastoreException.translateAndThrow(DatastoreException.java:120)\n    at com.google.gcloud.datastore.DatastoreImpl.runQuery(DatastoreImpl.java:113)\n    at com.google.gcloud.datastore.QueryResultsImpl.sendRequest(QueryResultsImpl.java:66)\n    at com.google.gcloud.datastore.QueryResultsImpl.(QueryResultsImpl.java:56)\n    at com.google.gcloud.datastore.DatastoreImpl.run(DatastoreImpl.java:102)\n    at com.google.gcloud.datastore.DatastoreImpl.run(DatastoreImpl.java:98)\n...\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/232",
        "number": 232,
        "title": "Provide a way to configure connection and readTimeout",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "This should be a setting in [`ServiceOptions`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/gcloud/ServiceOptions.java]).\n\nOnce we get it from the user we can set it by  the [`HttpRequestInitializer`](https://developers.google.com/api-client-library/java/google-http-java-client/reference/1.20.0/com/google/api/client/http/HttpRequestInitializer).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/229",
        "number": 229,
        "title": "Add a usage example for gcloud-java-examples README.md",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/228",
        "number": 228,
        "title": "Modify the title, description and javadoc reference for each module",
        "labels": [],
        "state": "closed",
        "body": "Currently the `README.md` for each module contains the same title and description\nas the main `README.md` page. \n\nWe should change it to be more specific to the service.\ne.g. for Datastore\n\n**Current Title:** Google Cloud Java Client\n**Proposed Title:**  Google Cloud Java Client for Datastore\n\n**Current Description:** Java idiomatic client for Google Cloud Platform services.\n**Proposed Description:** Java idiomatic client for Google Cloud Datastore.\n- Also, change link reference.\n\nAlso, we can remove the \"This client supports Google Cloud Datastore\" statement for the module\nand we should update the javadoc reference to the specific service, similar to what we do for example\n(e.g. Datastore reference should be something like http://googlecloudplatform.github.io/gcloud-java/0.0.7/apidocs/index.html?com/google/gcloud/datastore/package-summary.html).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/220",
        "number": 220,
        "title": "Test fail on ITStorageTest.testUpdateBlob",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "After merging #211 travis build for `oraclejdk7` failed with an error in `ITStorageTest.testUpdate`:\n\n```\ntestUpdateBlob(com.google.gcloud.storage.ITStorageTest)  Time elapsed: 10.421 sec  <<< ERROR!\ncom.google.gcloud.storage.StorageException: Backend Error\n    at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145)\n    at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\n    at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\n    at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\n    at com.google.gcloud.spi.DefaultStorageRpc.patch(DefaultStorageRpc.java:231)\n    at com.google.gcloud.storage.StorageImpl$11.call(StorageImpl.java:343)\n    at com.google.gcloud.storage.StorageImpl$11.call(StorageImpl.java:340)\n    at com.google.gcloud.RetryHelper.doRetry(RetryHelper.java:181)\n    at com.google.gcloud.RetryHelper.runWithRetries(RetryHelper.java:247)\n    at com.google.gcloud.RetryHelper.runWithRetries(RetryHelper.java:237)\n    at com.google.gcloud.storage.StorageImpl.update(StorageImpl.java:340)\n    at com.google.gcloud.storage.ITStorageTest.testUpdateBlob(ITStorageTest.java:150)\n```\n\nI never experienced this error locally and it seems not to occur always (builds for other java versions and next builds succeeded). The error message `Backend Error` makes me think that the problem resides outside of our library. I open this issue just to double check with you guys, can we consider this as a sporadic error?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/219",
        "number": 219,
        "title": "Add methods to perform batch gets/deletes/updates of blobs",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "To simplify some common use cases of batch requests we could add to `Blob` class some static methods to do batch gets/deletes/updates:\n\n``` java\nBlob.get(storage, blobInfo1, blobInfo2, ...)\nBlob.update(storage, blobInfo1, blobInfo2, ...)\nBlob.delete(storage, blob1Info, blob2Info, ...)\n```\n\nWe could also consider putting these methods in a dedicated `Blobs` class, what do you think?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/217",
        "number": 217,
        "title": "Create a tests bundle for maven",
        "labels": [],
        "state": "closed",
        "body": "Right now, test classes are not pushed to maven.  However, some test classes are useful for users to test their own code locally, like `LocalGcdHelper`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/216",
        "number": 216,
        "title": "Support AE dev appserver",
        "labels": [
            "api: core",
            "auth",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We need to understand what is the desired expectation when using gcloud-java on AE dev appserver.\n\nThe options are:\n1. use local services\n2. use production services\n\nAn issue with option (1) is that currently local dev app services such as Datastore are not accesible via  the cloud interface (apiary or gRpc).\n\nAn issue with option (2) is that the current implementation detects that we are running on AE and automatically chooses the projectid and authentication mode.\nThis is nice and convenient in production but is an issue with dev appserver as the [AppEngineAuthCredentials](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-core/src/main/java/com/google/gcloud/AuthCredentials.java#L49) is based on AppIdentity which\nwill not work against production when used by dev appserver.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/213",
        "number": 213,
        "title": "Create README for release process",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/208",
        "number": 208,
        "title": "testGetArray test is flaky",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Travis very recently has started to complain that the \"deadline is exceeded\" and fails when running `DatastoreTests.testGetArray()` in some runs.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/201",
        "number": 201,
        "title": "Storage resumable upload URI API not checking for (meta)generation match",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "This is a question on the Cloud Storage APIs.\nWhile trying to fix #200 I did a POST request to get a resumable upload URI:\n\n```\nhttps://www.googleapis.com/upload/storage/v1/b/bucket/o?uploadType=resumable&name=file&ifGenerationMatch=42\n```\n\nThe request returned status 200 even though the object I was requesting the upload URI for had different generation. So, does this API actually check for (meta)generation matches? Is this behavior intended? \nIf so we can avoid passing `options` to the `StorageRpc.open` method. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/200",
        "number": 200,
        "title": "StorageRpc.open not setting the correct match parameters",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "The following code:\n\n```\nstorage.writer(BlobInfo.builder(\"bucket\", \"name\").generation(42L).build(), \n  Storage.BlobTargetOption.generationMatch());\n```\n\nissues a POST request to the URL:\n\n```\nhttps://www.googleapis.com/upload/storage/v1/b/bucket/o?uploadType=resumable&name=name&ifGenerationNotMatch=42\n```\n\nwhere `ifGenerationNotMatch` instead of `ifGenerationMatch` is set.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/199",
        "number": 199,
        "title": "StorageImpl methods should throw StorageException",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "As per title, `StorageImpl` methods should throw `StorageException` in case of errors. The methods that use `runWithRetries` throw `RetryHelperException` instead.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/197",
        "number": 197,
        "title": "Remove use of special RELEASE version for joda-time",
        "labels": [],
        "state": "closed",
        "body": "Using the special maven keyword of RELEASE for a dependency version means that builds are not repeatable.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/195",
        "number": 195,
        "title": "Storage.copy not failing on source (meta)generation mismatch",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "The following code:\n\n``` java\nStorage.CopyRequest req = new Storage.CopyRequest.Builder()\n  .source(bucket, sourceBlobName)\n  .target(destinationBlob)\n  .sourceOptions(Storage.BlobSourceOption.generationMatch(42L))\n  .build();\nstorage.copy(req);\n```\n\nIs not throwing an exception if the source blob generation is not 42. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/194",
        "number": 194,
        "title": "Should functional blob and bucket operations enforce metageneration match upon updates",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "This topic was also discussed in #171.\n\nCurrently the functional blob and bucket pin to their metadata and provide the user with the option of enforcing metadata version check in updates operation. However this check is not triggered by default.\n\nAn alternative to what we have now is to enforce the version check by default and to provide options to disable the check instead.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/193",
        "number": 193,
        "title": "Add support in Storage RPC level for request with selected fields.",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "This topic was also discussed in #171.\n\nStorage service allows getting partial blob or gcs object data using  [selected fields](https://developers.google.com/resources/api-libraries/documentation/storage/v1/java/latest/com/google/api/services/storage/StorageRequest.html#setFields%28java.lang.String%29).\n\nWe could use that for exists checks and for listing calls + lazy load of the metadata when requested in the functional blobs.\n\nThis issue is an optimization only. If we think we want to expose the selected fields feature in the user level we should create a separate issue (and discuses how to make sure one does not override metadata\nwith partial metadata there). \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/187",
        "number": 187,
        "title": "Test exception handling in datastore",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/184",
        "number": 184,
        "title": "blobInfo.equals(BlobInfo.fromPb(blobInfo.toPb())) return false",
        "labels": [],
        "state": "closed",
        "body": "While testing `StorageImpl` I noticed that:\n\n``` java\nBlobInfo blobInfo = BlobInfo.of(\"b\", \"n\");\nassertEquals(blobInfo, BlobInfo.fromPb(blobInfo.toPb()));\n```\n\nWas failing. \nSame problem also occurs with `BucketInfo`. \nIn `BucketInfo` the `fromPb` method also throws NPE under some circumstances:\n\n``` java\nBucketInfo bucketInfo = BucketInfo.of(\"b\");\nBucketInfo.fromPb(bucketInfo.toPb());\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/182",
        "number": 182,
        "title": "Should we use  javax.annotation.Nullable and javax.annotation.concurrent.Immutable",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "Part of JSR-305.\n\nThese annotations are part of Java 8, but could be used before by including this dependency\n\n```\n<groupId>com.google.code.findbugs</groupId>\n<artifactId>jsr305</artifactId>\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/179",
        "number": 179,
        "title": "Adding a createFromFile method to AuthCredentials",
        "labels": [
            "api: core",
            "type: feature request"
        ],
        "state": "closed",
        "body": "We now have a `createFor(String account, PrivateKey privateKey)` to create `AuthCredentials`, what about adding a `createFor(File)` for creating `AuthCredentials` from a service account JSON file? \n\nNotably `GoogleCredential` already has `fromStream` that reads credentials from a stream of the JSON file. If you prefer, we can go for `createFor(Stream)` rather than `createFor(File)`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/177",
        "number": 177,
        "title": "IllegalArgumentException when Cors contain OPTIONS",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "When we try to get a bucket that has OPTIONS among its `cors` methods the following exception is thrown:\n\n> java.lang.IllegalArgumentException: No enum constant com.google.gcloud.storage.HttpMethod.OPTIONS\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/175",
        "number": 175,
        "title": "Error from storage.delete( bucket, blob)",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "I'm calling:\n\n``` java\nstorage.delete( \"my-bucket\", \"6c7a1892629811e5b40202420adc0211.itm\" )\n```\n\n\"my-bucket\" exists in zone EU and the blob \"6c7a1892629811e5b40202420adc0211.itm\" exists in this bucket.\nI can delete this blob using the Developers Console.\nMyClass.java created the bucket and blob shortly before the delete() was called.\n\nAm I doing something wrong?\n\n```\nCaused by: com.google.gcloud.RetryHelper$NonRetriableException: com.google.gcloud.storage.StorageException: \n    at com.google.gcloud.RetryHelper.doRetry(RetryHelper.java:193)\n    at com.google.gcloud.RetryHelper.runWithRetries(RetryHelper.java:247)\n    at com.google.gcloud.RetryHelper.runWithRetries(RetryHelper.java:237)\n    at com.google.gcloud.storage.StorageImpl.delete(StorageImpl.java:313)\n    at com.mycode(MyClass.java:150)\\n\"}\n    ... 5 more\nCaused by: com.google.gcloud.storage.StorageException: \\\n    at com.google.gcloud.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:104)\n    at com.google.gcloud.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:93)\n    at com.google.gcloud.spi.DefaultStorageRpc.delete(DefaultStorageRpc.java:270)\n    at com.google.gcloud.storage.StorageImpl$13.call(StorageImpl.java:316)\\\n    at com.google.gcloud.storage.StorageImpl$13.call(StorageImpl.java:313)\n    at com.google.gcloud.RetryHelper.doRetry(RetryHelper.java:181)\n    ... 9 more\\n\"}\nCaused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 412 \n\n      \\\"code\\\" : 412,\n    \"  \\\"errors\\\" : [ {\n        \\\"domain\\\" : \\\"global\\\",\n        \\\"location\\\" : \\\"If-Match\\\",\n        \\\"locationType\\\" : \\\"header\\\",\n       \\\"message\\\" : \\\"\\\",\n        \\\"reason\\\" : \\\"conditionNotMet\\\"\n      } ],\n      \\\"message\\\" : \\\"\\\"\n\n    at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145)\n    at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113)\n    at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321)\n    at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352)\n    at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469)\n    at com.google.gcloud.spi.DefaultStorageRpc.delete(DefaultStorageRpc.java:267)\n    .. 12 more\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/174",
        "number": 174,
        "title": "NPE From some Storage methods",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "For example the following calls when listing a bucket that is empty or getting an item from a bucket that exists but the item does not:\n\n``` java\n    storage.list( bucketName )\n    storage.get( bucketName, itemName )\n```\n\nThe NPE is generated from the Preconditions class called via transform() in the Iterables class:\n\n``` java\npublic static <T> T checkNotNull(T reference) {\n        if(reference == null) {\n            throw new NullPointerException();\n        } else {\n            return reference;\n        }\n    }\n```\n\nIt would be nicer to return a null to the caller perhaps.  wdyt?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/172",
        "number": 172,
        "title": "Add create to Storage that takes an InputStream",
        "labels": [
            "api: storage",
            "type: feature request"
        ],
        "state": "closed",
        "body": "`Storage` class now has a method to create an object:\n\n``` Java\ncreate(BlobInfo blobInfo, final byte[] content, BlobTargetOption... options)\n```\n\nI know that we already provide a `BlobWriteChannel` but it might be useful to also have:\n\n``` Java\ncreate(BlobInfo blobInfo, InputStream content, BlobTargetOption... options)\n```\n\nfor uploading small files without reading their bytes. Thoughts? \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/166",
        "number": 166,
        "title": "NullPointerException in BucketInfo.toBuilder",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "As per title `toBuilder` throws `NullPointerException` if `deleteRules` are not set in the bucket object.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/165",
        "number": 165,
        "title": "Document how to test with the various services",
        "labels": [],
        "state": "closed",
        "body": "e.g. for datastore how to use LocalGcdHelper\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/164",
        "number": 164,
        "title": "Adding a storage example to the readme",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "It would be nice to add a storage usage example in both the main and the storage READMEs.\n\nIs there any reason for not having this that I am missing? If not, I can take care of adding it.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/163",
        "number": 163,
        "title": "Datastore tests not running on Windows",
        "labels": [
            "api: datastore",
            "type: bug"
        ],
        "state": "closed",
        "body": "Running datastore tests on Windows Server 2012 leads causes the following error:\n\n> java.io.IOException: Cannot run program \"cmd\": NULL: (The filename, directory name, or volume label syntax is incorrect)\n\nCaused by the `NULL:` at line:\nhttps://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-datastore/src/test/java/com/google/gcloud/datastore/LocalGcdHelper.java#L171\n\n`NUL:` (with one `L`) seems to be a valid null device across Windows versions.\n\n@aozarov shall we close this with #162 (as soon as it's ready) or create a dedicated PR?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/160",
        "number": 160,
        "title": "Type-safe Keys",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "I ran across [this FR](https://code.google.com/p/googleappengine/issues/detail?id=1458) for the GAE Java libraries. Basically, they want Keys to use generics so that a Key referencing an Entity with kind K is actually a Key<K>.\n\nI wanted to see what y'all thought about this.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/159",
        "number": 159,
        "title": "Should we create a branch for the datastore v1beta3 update?",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "The datastore update from v1beta2 to v1beta3 requires touching a lot of code.  It would be useful to create a branch off the master branch to provide people with ample opportunity to comment on the changes before it is merged into the master branch.  Moreover, a separate branch would allow for smaller PRs, reducing the chance that important changes are buried.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/158",
        "number": 158,
        "title": "Datastore Entity Builder: Support unindexed properties",
        "labels": [],
        "state": "closed",
        "body": "Unindexed properties are essential when storing large blob properties as they can exceed the maximum allowed length for indexed values.  Using a local gcd I get: \n\n`INFO: Exception executing rpc.\ncom.google.apphosting.client.serviceapp.RpcException: Indexed blob value has more than permitted 500 bytes.`\n\nI can't see how to select the indexing policy using the EntityBuilder.  I guess we need the ability to set the indexed attribute on each _Builder.set( String name, Value value, boolean indexed )_\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/156",
        "number": 156,
        "title": "Update gcloud-java-datastore to use v1beta3",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "This update can proceed once a snapshot version of datastore v1beta3 is pushed to maven.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/153",
        "number": 153,
        "title": "Explore automating maven releases",
        "labels": [],
        "state": "closed",
        "body": "Right now, releases to maven are done manually, and it would be nice to do this within a script triggered by Travis.  This may be a bit tricky because deploying requires signing the bits. \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/152",
        "number": 152,
        "title": "Automate version updates",
        "labels": [],
        "state": "closed",
        "body": "There should be a script to update the versions in the pom.xml and README files.  Currently all those files have to be updated manually to release a new version.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/140",
        "number": 140,
        "title": "Travis times out when deploying website to gh-pages",
        "labels": [],
        "state": "closed",
        "body": "Maven's site-deploy plugin takes more than 20 minutes to push a new website to gh-pages.  As a result, Travis times out and does not push the website.  We should experiment with pushing the website to github using bash code rather than maven's plugin.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/136",
        "number": 136,
        "title": "Consider using gerrit for code reviews",
        "labels": [],
        "state": "closed",
        "body": "http://gerrithub.io/\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/135",
        "number": 135,
        "title": "Consider Jenkins instead of Travis",
        "labels": [],
        "state": "closed",
        "body": "Investigate whether Jenkins may work better for this project than Travis CI.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/132",
        "number": 132,
        "title": "Add gcloud-java link to other landing pages",
        "labels": [],
        "state": "closed",
        "body": "Right now, the drop down menus in the top left corner of the Node.js, Python, and Ruby landing pages do not include gcloud-java.  Now that gcloud-java has a new landing page, those links should be added.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/131",
        "number": 131,
        "title": "Make version in landing page dynamic",
        "labels": [],
        "state": "closed",
        "body": "Currently the version listed under \"Quickstart with Maven\" is static.  This should be made dynamic to avoid having to manually update this each time a new version is released.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/130",
        "number": 130,
        "title": "Update google-api-services-datastore to v1beta2-rev25-1.20.0",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/129",
        "number": 129,
        "title": "Add tabbed view for example in landing page",
        "labels": [],
        "state": "closed",
        "body": "We need a tabbed view for the example on the landing page, like on the Node.js page (see https://googlecloudplatform.github.io/gcloud-node/).  One tab should be devoted to Compute Engine because the user does not have to provide the project ID and auth code.  Other platforms require the user to provide additional information.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/128",
        "number": 128,
        "title": "Creating javadoc for each module",
        "labels": [],
        "state": "closed",
        "body": "An aggregate Javadoc is created and linked in the website.  However, we do not generate and link specific Javadocs for the modules (i.e. gcloud-java-core, gcloud-java-datastore, etc).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/127",
        "number": 127,
        "title": "Icon for landing page",
        "labels": [],
        "state": "closed",
        "body": "We need an icon for the Java cloud platform landing page that is similar in style to the Node.js, Ruby, and Python pages.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/126",
        "number": 126,
        "title": "gcloud-java-storage pulls guava-jdk5",
        "labels": [],
        "state": "closed",
        "body": "When including gcloud-java-storage, it is necessary to exclude guava-jdk5 or else it will conflict with guava-18.0.jar. For some reason guava-jdk5 is being pulled by gcloud-java when apparently it shouldn't.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/123",
        "number": 123,
        "title": "Avoid downloading gcd.sh if cloud SDK is availble",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "Cloud SDK now supports running a local datastore by invoking  `gcloud beta emulators datastore`.\nIf we detect that gcloud is available we should run the datastore using it rather than fetching/caching and invoking `gcd.sh`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/121",
        "number": 121,
        "title": "rename default_project_id  to GCLOUD_PROJECT",
        "labels": [],
        "state": "closed",
        "body": "For more background see GoogleCloudPlatform/gcloud-meta/issues/17\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/119",
        "number": 119,
        "title": "Push tagged builds automatically",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "It'd be really nice to make our doc builds and the maven push all automagical based on the tags we have in the git repository.\n\n/cc @stephenplusplus : Maybe you can add more color on how we did this for node.\n\n(This stems from the discussion on #51)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/118",
        "number": 118,
        "title": "0.0.6",
        "labels": [],
        "state": "closed",
        "body": "Hello,\nWhen i add\n    \"com.google.gcloud\" % \"gcloud-java-datastore\" % \"0.0.6\",\ninto my project, i got\n\nsbt.ResolveException: unresolved dependency: joda-time#joda-time;RELEASE: not found\n\nHere is full log:\n\n[info] Resolving com.google.oauth-client#google-oauth-client-appengine;1.20.0 ..[info] Resolving joda-time#joda-time;RELEASE ...\n[warn]  module not found: joda-time#joda-time;RELEASE\n[warn] ==== local: tried\n[warn]   /Users/axxxx/.ivy2/local/joda-time/joda-time/RELEASE/ivys/ivy.xml\n[warn] ==== public: tried\n[warn]   https://repo1.maven.org/maven2/joda-time/joda-time/RELEASE/joda-time-RELEASE.pom\n[info] Resolving com.google.apis#google-api-services-datastore-protobuf;v1beta2-[info] Resolving com.google.http-client#google-http-client-protobuf;1.15.0-rc ..[info] Resolving com.google.apis#google-api-services-datastore;v1beta2-rev23-1.1[info] Resolving com.github.jsimone#webapp-runner;7.0.34.1 ...\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]  ::          UNRESOLVED DEPENDENCIES         ::\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]  :: joda-time#joda-time;RELEASE: not found\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn] \n[warn]  Note: Unresolved dependencies path:\n[warn]      joda-time:joda-time:RELEASE\n[warn]        +- com.google.gcloud:gcloud-java-core:0.0.6\n[warn]        +- com.google.gcloud:gcloud-java-datastore:0.0.6 \n[warn]        +- usernameinuse:my-project_2.11:0.1\n[trace] Stack trace suppressed: run last *:update for the full output.\n[error](*:update) sbt.ResolveException: unresolved dependency: joda-time#joda-time;RELEASE: not found\n[error] Total time: 2 s, completed Jul 2, 2015 2:22:14 PM\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/112",
        "number": 112,
        "title": "README.md - examples don't work w/ the latest (0.0.5) gcloud-java-datastore",
        "labels": [],
        "state": "closed",
        "body": "There are no:\n- com.google.gcloud.datastore.Datastore\n- com.google.gcloud.datastore.DatastoreFactory\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/111",
        "number": 111,
        "title": "README.md - rather than referring to LATEST version...",
        "labels": [],
        "state": "closed",
        "body": "Either call out the specific version, or link to all available versions.\nSuch as here.. http://mvnrepository.com/artifact/com.google.gcloud/gcloud-java\n\nUsing LATEST could be dangerous.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/109",
        "number": 109,
        "title": "Why are Storage classes Serializable?",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "For example [SignedUrIOption](https://github.com/GoogleCloudPlatform/gcloud-java/blob/master/gcloud-java-storage/src/main/java/com/google/gcloud/storage/Storage.java#L218)\n\nThis does not seem like something that would need to marshalled for transmission between processes.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/108",
        "number": 108,
        "title": "Use Java8 features in APIs now",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "There have been a couple of issues recently where more elegant solutions could be provided using features from Java 8. These have included\n- use of lambda functions for datastore transaction\n- direct use of standard function classes rather than Guava equivalents\n- use of new Time classes\n- use of Optional rather than JSR-305 annotations\n\nTo do this we would need to raise the minimum JDK version from 7 to 8 which cause may problems for users who still use older Java runtimes. However, Oracle have already EOLed their public version of Java 7.\n\nThe main advantage of doing this now rather than waiting is that it avoids needing to rev a new version of the API to make use of these idioms and avoids having to support two API versions.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/107",
        "number": 107,
        "title": "Signed reference expiration time is measured in seconds since epoch",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Java measures time in milliseconds from the epoch not seconds and using this as a base would be simpler. The example:\n\n``` java\n      Calendar cal = Calendar.getInstance();\n      cal.add(Calendar.DATE, 1);\n      long expiration = cal.getTimeInMillis() / 1000;\n      storage.signUrl(blobInfo, expiration));\n```\n\nwould become:\n\n``` java\n      Calendar cal = Calendar.getInstance();\n      cal.add(Calendar.DATE, 1);\n      storage.signUrl(blobInfo, cal.getTime()));\n```\n\nHowever, given this is actually just performing an interval calculation we could also support:\n\n``` java\n    storage.signUrl(blobInfo, 1, TimeUnit.DAYS);\n```\n\nIdeally we would also support the time classes added in Java 8:\n\n``` java\n    storage.signUrl(blobInfo, Instant.now().plus(24, ChronoUnit.HOURS));\n    storage.signUrl(blobInfo, Duration.ofDays(1));\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/106",
        "number": 106,
        "title": "Separate use-cases for generating signed object references",
        "labels": [
            "api: storage",
            "status: will not fix"
        ],
        "state": "closed",
        "body": "There's currently one method for generating signed references:\n\n``` java\nURL signUrl(BlobInfo blobInfo, long expirationTimeInSeconds, SignUrlOption... options);\n```\n\nThere are a number of `SignUrlOption` types but its not clear from the interface which ones can be used in combination. For example:\n- specifying md5 and contentType should not be allowed for a GET, HEAD or DELETE\n- for PUT, md5 and contentType take their values from BlobInfo but the object hasn't been created yet\n\nI also don't see how extension headers or the base URL would be specified.\n\nInstead, can we use a method chain for this:\n\n``` java\n  URI get = datastore.signedReference(bucketName, objectName, expiration).toURI();\n  String put = datastore.signedReference(bucketName, objectName, expiration)\n      .forPut().ofContentType(\"text/plain\").toString();\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/105",
        "number": 105,
        "title": "ExceptionHandler.Interceptor.RetryResult should have a third value, used instead of null",
        "labels": [],
        "state": "closed",
        "body": "The methods of [ExceptionHandler.Interceptor](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/ExceptionHandler.Interceptor.html) return a value that is one of `RetryResult.RETRY`, `RetryResult.ABORT`, or `null`. Instead of `null`, there should be a third `RetryResult` constant. Returning null from the `beforeEval` or `afterEval` methods would then provoke a `NullPointerException`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/104",
        "number": 104,
        "title": "We probably don't need both KeyFactory and Key.Builder",
        "labels": [],
        "state": "closed",
        "body": "You can make a Key either using [Key.Builder](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/Key.Builder.html) or using [KeyFactory](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/KeyFactory.html). KeyFactory can also be used to make an IncompleteKey. I suggest that we don't really need `Key.Builder` or `IncompleteKey.Builder` and we could remove them in favour of just KeyFactory.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/103",
        "number": 103,
        "title": "API documentation exposes non-public types",
        "labels": [],
        "state": "closed",
        "body": "For example, [KeyFactory](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/KeyFactory.html) has a bunch of methods that return `B`, which is actually a type parameter of the non-public parent class. But nothing indicates that in the API documentation. We should eliminate cases like this, which might sometimes involve overriding methods just to specify a concrete return type and return `super.whatever()`.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/102",
        "number": 102,
        "title": "Value.meaning() is deprecated",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "[Value.meaning()](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/Value.html#meaning%28%29) is deprecated, which is surprising for a new API. The reason is that it exposes datastore functionality that is slated for deletion, but which people might want to use meanwhile. I suggest that the `@deprecated` tag should include text saying explicitly that this method will be deleted at some point, and if possible giving a planned date for the deletion.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/101",
        "number": 101,
        "title": "Should QueryResults extend Iterable rather than Iterator?",
        "labels": [
            "api: datastore",
            "type: feature request"
        ],
        "state": "closed",
        "body": "If [`QueryResults<T>`](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/QueryResults.html) extended `Iterable<T>` rather than `Iterator<T>` then it could be used in a for-each loop:\n\n``` java\nQueryResults<Entity> results = datastore.run(query);\nfor (Entity result : results) {...}\n```\n\nHowever, this is potentially confusing, because the `Iterable` interface implies that the result can be iterated more than once, so we would either have to document that an attempt to do so will fail, or make it so that every time you call `iterator()` a new query is issued. Neither of these is very desirable, so perhaps we should just add a note to `QueryResults` that heads off this obvious question that users are going to ask.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/100",
        "number": 100,
        "title": "API includes protobuf references",
        "labels": [],
        "state": "closed",
        "body": "Explicitly, or implicitly. For example, [StructuredQuery](http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/StructuredQuery.html) has protected methods `fromPb`, `populatePb`, and `toPb` which should not appear in the API.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/99",
        "number": 99,
        "title": "Method names in StructuredQuery.PropertyFilter are non-obvious",
        "labels": [],
        "state": "closed",
        "body": "StructuredQuery.PropertyFilter includes these static methods:\n- `eq`\n- `gt`\n- `gte`\n- `le`\n- `lte`\n\nI think it's very non-obvious that `le` in particular means less-than rather than less-than-or-equal. I propose spelling out these names:\n- `equals(String property, T value)`\n- `greaterThan`\n- `greaterThanOrEqual`\n- `lessThan`\n- `lessThanOrEqual`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/96",
        "number": 96,
        "title": "Separate API classes into separate modules from implementations",
        "labels": [],
        "state": "closed",
        "body": "When using injection, application code would generally not need to interact with the implementation classes. For example, it would receive a `Datastore` or `Storage` instance directly and never need to interact with any of the factory or `ServiceOptions` classes e.g.\n\n``` java\nclass MyApp {\n  @Resource Datastore dataset;\n  @Inject Bucket data;\n  void doSomething() {\n    // just use dataset and data fields ...\n  }\n}\n```\n\nBy separating the API classes that it would use into a separate jar, the user can avoid having a dependency on the implementation itself and on any of the libraries that the implementation happens to use.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/95",
        "number": 95,
        "title": "Determine if .gitattributes is needed and what it should contain",
        "labels": [],
        "state": "closed",
        "body": "Consider adding a .gitattributes file at the root and determine what it should contain:\n- `text=lf` to force line endings?\n- which file types are text\n- anything else?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/88",
        "number": 88,
        "title": "Decouple Bucket from storage operations",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Applications typically interact with resources in a single bucket (there are some exceptions). The Storage interface only provides ways to deal with global resources forcing the application to pass the bucket name around as an additional string. We should add a Bucket interface that supports common operations (CRUD, Copy, Move) within a single bucket.\n\nFor example:\n\n``` java\n@Resource Bucket data;\n\nvoid download(String path) {\n  // do something like data.reader(path);\n}\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/85",
        "number": 85,
        "title": "FIgure out the work needed for Compute admin service",
        "labels": [
            "api: compute"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/84",
        "number": 84,
        "title": "Figure out the work needed for Cloud Search service",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/83",
        "number": 83,
        "title": "FIgure out the work needed for Cloud SQL service",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/82",
        "number": 82,
        "title": "Figure out the work needed for Big Query service",
        "labels": [
            "api: bigquery"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/81",
        "number": 81,
        "title": "FIgure out the work needed for BigTable service",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/80",
        "number": 80,
        "title": "Add docstring with example of signing a URL",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "The change in #77 added the ability to sign a URL, but I don't see a docstring and example of how we'd use this. See https://github.com/GoogleCloudPlatform/gcloud-node/blob/master/lib/storage/file.js#L1010 for a comparable example.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/72",
        "number": 72,
        "title": "Provide a way to stream read/write requests using a single RPC call",
        "labels": [
            "api: storage",
            "performance",
            "priority: p2",
            "type: question"
        ],
        "state": "closed",
        "body": "This topic was also discussed in #61. Current implementation of the streaming API for both reads and writes is done via multiple RPC calls. Writes are done in chucks (resumable-writes) which is good for error handling (save-points) but at a cost of multiple RPC instead of one. Reads are also segmented (via range requests) instead one RPC for the whole content. \n\nThings to consider:\n1. some platforms may have restrictions on RPC  requests (e.g. AE 10MB upstream and 32MB downstream, as well as time-to-live restrictions).\n2. Current implementation of the apiary client does not expose the underlying stream and will copy its content to the caller.\n3. Rate of errors and cost-benefit evaluation (if the recommended size per one RPC is small enough it might be that the option of create with content or load all is sufficient).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/71",
        "number": 71,
        "title": "Optimize and minimize the library dependencies",
        "labels": [],
        "state": "closed",
        "body": "I see we depend on a lot of transitive libs like JDO/Servlet 2.5 and others. \nA quick test allows me to run all the tests with for example these exclusions:\n  <dependency>\n      <groupId>com.google.api-client</groupId>\n      <artifactId>google-api-client-appengine</artifactId>\n      <version>1.20.0</version>\n      <scope>compile</scope>\n      <exclusions>\n        <exclusion>\n          <artifactId>guava-jdk5</artifactId>\n          <groupId>com.google.guava</groupId>\n        </exclusion>\n        <exclusion>\n          <groupId>javax.servlet</groupId>\n          <artifactId>servlet-api</artifactId>\n        </exclusion>\n        <exclusion>\n          <groupId>javax.jdo</groupId>\n          <artifactId>jdo2-api</artifactId>\n        </exclusion>\n        <exclusion>\n          <groupId>com.google.api-client</groupId>\n          <artifactId>google-api-client-servlet</artifactId>\n        </exclusion>\n        <exclusion>\n          <groupId>com.google.http-client</groupId>\n          <artifactId>google-http-client-jdo</artifactId>\n        </exclusion>\n      </exclusions>\n    </dependency>\n\nThis one:google-api-client-appengine  (and other) dep might have to be optimized at the source level i.e https://github.com/google/google-api-java-client/tree/dev/google-api-client-appengine\n(Main developer is Daniel Wang in CL2...)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/70",
        "number": 70,
        "title": "any plan to export individual APIs as separate artifacts?",
        "labels": [],
        "state": "closed",
        "body": "I've noticed the the datastore and storage packages aren't setup to generate their own artifacts. Are there any plans to do this?  Java developers would typically expect each service API to be broken out and included as their own artifact.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/66",
        "number": 66,
        "title": "Create a landing page for gcloud-java",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "And add a landing page for  http://googlecloudplatform.github.io/gcloud-java and add a link to it from the other Veneer landing pages (in the existing top-left drop-down).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/65",
        "number": 65,
        "title": "Consider rename XXXService to XXX ",
        "labels": [],
        "state": "closed",
        "body": "Currently the service naming style in gcloud-java is as follow:\n\nAPI:\nXXXServiceFactory\nXXXService\nXXXServiceOptions\nXXXServiceException\n\nSPI:\nXXXRpc\nXXXRpcFactory\n\nwhere XXX represent the service such as Datastore, Storage,...\n\nI think it would be nicer if we drop the \"Service\" part and make the API names shorter, such as:\n\nDatastoreFactory, Datastore, DatastoreOptions, DatastoreException\nStorageFactory, Storage, StorageOptions, StorageException\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/63",
        "number": 63,
        "title": "Expose support for asynchronous interactions",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Servlet 3.1 and frameworks like Spring 4 support non-blocking request execution. This partially supported by the raw Storage API which exposes its HttpRequest objects with their executeAsync() operation. However, this does not support non-blocking transfers.\n\nFull async support would allow an application to transfer data to/from Cloud Storage without having to consume a Thread while waiting for IO to complete.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/62",
        "number": 62,
        "title": "Identify resources consistently, ideally the same way gsutil does",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "The StorageService API identifies objects using a either (bucket, name) combination e.g. the reader(bucket, name) method or as using a Blob object e.g. the writer(Blob) method.\n\nWe should use a consistent representation of an object's identity. It would be nice if that also have a string representation that was consistent with how objects are identified in other tools such as gsutil.\n\nWe could use a URI for this:\n\n``` java\n  URI id = URI.create(\"gs://bucket/path/to/object\");\n  storage.reader(id);\n  storage.writer(id);\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/61",
        "number": 61,
        "title": "Provide streamed access to object data",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "The BlobReadChannel and BlobWriteChannel implementations buffer data and perform separate RPC calls when they need to flush the buffer. This allows for retries of the transfer operations but uses more billable operations than just writing the data in a continuous stream.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/60",
        "number": 60,
        "title": "The result of a patch metadata is a union rather than replacement.",
        "labels": [
            "api: storage",
            "type: bug"
        ],
        "state": "closed",
        "body": "It looks like patch operations do not work well with Map attributes (such as metadata) and instead of replacing the map content (which is backed by repeated message) it merges it.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/59",
        "number": 59,
        "title": "Support @Resouce injection for Datastore",
        "labels": [],
        "state": "closed",
        "body": "It would be nice to be able to inject a reference to Datastore\n\n``` java\n@Resource DataStore datastore;\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/57",
        "number": 57,
        "title": "Did we misname Blob as it is really holding the Blob's metadata (name, etc)?",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "Right now, Blob's are not actually the objects themselves but pointers and metadata about the blob... That being the case, should we re-evaluate the naming of the Blob class?\n\nSome of the options:\n- **`Blob`** (This is what it is today)\n- Object\n- StorageObject\n- ObjectMetadata\n- BlobMetadata\n- StorageObjectMetadata\n- BlobInfo\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/56",
        "number": 56,
        "title": "Is StorageService.load the right name?",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "Right now, to load a Blob into a byte array, we use the `load` method:\n\n``` java\nStorageService storage = ...;\nbytes[] bytes = storage.load(\"bucket-name\", \"blob-name\");\n```\n\nIs `load` the right verb for this? (Not saying it's wrong, just want to discuss this one here.)\n\nSome of the options:\n- **`load`** (This is what it is today)\n- `download`\n- `read`\n- `getBytes`\n- `readBytes`\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/55",
        "number": 55,
        "title": "Should Blobs and Buckets be stateless or keep a reference to a StorageService ?",
        "labels": [
            "api: storage",
            "type: question"
        ],
        "state": "closed",
        "body": "Right now, it looks like our `Blob` and `Bucket` objects are stateless, in that they don't keep a reference to a `StorageService` object. What this means is, given we have the following:\n\n``` java\nStorageService storage = ... // Get a storage service (irrelevant how here)\nBucket bucket = storage.get(\"bucket-name\");\nBlob blob = storage.get(\"bucket-name\", \"blobname\");\n```\n\nThe only way to interact with these objects is by keeping a reference to the `StorageService`:\n\n``` java\nBlobReadChannel channel = storage.reader(\"bucket\", \"blob\");\n// or \nBlobReadChannel channel = storage.reader(blob); // I think?\n```\n\nThere's no way to do:\n\n``` java\nBlobReadChannel channel = blob.getReadChannel(); // Or anything like this.\n```\n\nThe purpose of this issue is to discuss whether or not these objects should hold a reference to the `StorageService` which would make things like `blob.getReadChannel()` or `blob.delete()` possible rather than always calling `storage.getReadChannel(blob)` and `storage.delete(blob)`.\n\nThe benefits of this are friendlier-looking code (IMO at least....). The downsides are (I think) serialization becomes a bit more confusing, and what does it mean to send one \"`StorageService`-aware\" `Blob` into another `StorageService` method, ie:\n\n``` java\nStorageService storageA = ... // Authenticated with read permissions only.\nStorageService storageB = ... // Authenticated with read *and* write permissions.\nBlob blobA = storageA.get(\"bucket-name\", \"blob\");\nblobA.delete(); // This should fail: blobA is tied to storageA, which has read-only permissions.\nstorageB.delete(blobA); // Should this \"override\" the `StorageService`?\n```\n\nI have no idea what the right answer is, but wanted to open the floor for discussion.\n\n/cc @aozarov @jboynes \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/54",
        "number": 54,
        "title": "Provide a .buildStorageService() method on the StorageServiceOptions class?",
        "labels": [
            "api: storage",
            "auth",
            "type: question"
        ],
        "state": "closed",
        "body": "Right now, to create a `StorageService` object, I need to do:\n\n``` java\nStorageServiceOptions options =  StorageServiceOptions.builder()\n    .projectId(\"project\")\n    .build();\nStorageService storage = StorageServiceFactory.instance().get(options);\n```\n\nWould it be worthwhile to do this as\n\n``` java\nStorageService storage =  StorageServiceOptions.builder()\n    .projectId(\"project\")\n    .build().buildStorageService();\n```\n\nOr maybe we can have a `StorageServiceBuilder`?\n\n``` java\nStorageService storage = StorageService.builder()\n    .projectId(\"project\")\n    .build();\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/51",
        "number": 51,
        "title": "Configure Travis to automatically push new tags to Maven",
        "labels": [
            "type: feature request"
        ],
        "state": "closed",
        "body": "Logic here is that we wouldn't want Maven lagging behind the GH repository.\n\nI don't know if it's standard to have a nightly (or master) type build available on Maven (other libraries like gcloud-node don't do that), but at the very least all git tagged versions should be automatically pushed to Maven...\n\n/cc @jboynes \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/50",
        "number": 50,
        "title": "Remove example code from release library",
        "labels": [],
        "state": "closed",
        "body": "The DatastoreExample class ends up in the released jar. See #31 \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/49",
        "number": 49,
        "title": "Use try-with-resources for Transactions",
        "labels": [
            "api: datastore",
            "priority: p2",
            "type: feature request"
        ],
        "state": "closed",
        "body": "It would be nice to be able to use the resource pattern around a Transaction:\n\n``` java\ntry (Transaction tx = datastore.newTransaction()) {\n  // do stuff\n  tx.commit();\n}\n```\n\nDefault behaviour of close() would be to roll back a transaction. This is to avoid potential errors caused by the application failing to catch unexpected Throwables causing incomplete work to be auto-committed.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/46",
        "number": 46,
        "title": "Have someone from Google review the Cloud Storage implementation",
        "labels": [
            "api: storage"
        ],
        "state": "closed",
        "body": "Tracking bug for getting a review and feedback from someone on the Cloud Storage team @ Google.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/45",
        "number": 45,
        "title": "No obvious way to pass the project ID to the datastore options",
        "labels": [],
        "state": "closed",
        "body": "Hi there,\n\nI was looking at the datastore example and the DatastoreServiceOptions class and didn't see an obvious way to configure the project ID other than using a system environment variable.  Is that intentional or am I missing something?\n\nthx.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/42",
        "number": 42,
        "title": "Testing PubsubService",
        "labels": [],
        "state": "closed",
        "body": "I would like to contribute to this project by helping out on the Pubsub feature. I forked the repo and implemented a PubsubRpc client. I will now move on to create a PubsubService and Examples with documentation. But, I have a question with testing:\n\nTo unit test I can make a mock PubsubRpc client that simulates response json from the rest api, however, I was thinking a better way could be to have a Pubsub emulation available as a local development environment like the Datastore local dev server. I know as a user of GCP that would make my life much easier for testing things out. So not only do we get a good unit testing mechanism, but it will be a valuable tool for developers in general. What are your thoughts on this functionality, and if I decide to add this local dev pubsub environment, do you think it belongs in gcloud-java or somewhere else?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/41",
        "number": 41,
        "title": "DatastoreExample does a put, but does not do the get to retrieve it",
        "labels": [],
        "state": "closed",
        "body": "DatastoreExample does a put, but does not call the get to retrieve it:-)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/40",
        "number": 40,
        "title": "javadoc with code snippets incorrect",
        "labels": [],
        "state": "closed",
        "body": "For example, see Query&lt;Entity&gt; query\nin gqlquery.\nSince the snippet is in code, there is not need to escape <    >\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/39",
        "number": 39,
        "title": "Should we use jarjar to repackage specific dependency versions",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": "I did a simple java main Maven project.\nI see many dependencies in my project jars, for example guava 18, httpclient401,jodatime27 etc...\nIf I wand to use for my other application logic guava 12 or 25 for whatever reasons, we will have a version conflict...\nJarJar processing? How is it done for other runtimes? Seems to be a generic Veneer issue.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/38",
        "number": 38,
        "title": "LocalGcdHelper should display errors from gcd.sh",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/37",
        "number": 37,
        "title": "Provide a way to specify port for LocalGcdHelper",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/36",
        "number": 36,
        "title": "Entity.builder().set(String, long) doesn't exist?",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "I have the following code:\n\n``` java\n\nentity = Entity.builder(key)\n  .set(\"name\", \"John Doe\")\n  .set(\"age\", 30L) // I also tried 30 the int value, which failed similarly.\n  .set(\"updated\", false)\n  .build();\n```\n\nThis fails with the following error:\n\n``` bash\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:compile (default-compile) on project hello-datastore: Compilation failure: Compilation failure:\n[ERROR] /usr/local/google/home/jjg/gcdjavasample/hello-datastore/src/main/java/org/geewax/hellodatastore/HelloDatastore.java:[18,58] error: incompatible types\n[ERROR] \n[ERROR] could not parse error message:   required: KeyFactory\n[ERROR] found:    Builder\n[ERROR] /usr/local/google/home/jjg/gcdjavasample/hello-datastore/src/main/java/org/geewax/hellodatastore/HelloDatastore.java:29: error: no suitable method found for set(String,long)\n[ERROR] .set(\"age\", 30L)\n[ERROR] ^\n[ERROR] \n[ERROR] method Builder.set(String,Blob) is not applicable\n[ERROR] (actual argument long cannot be converted to Blob by method invocation conversion)\n[ERROR] method Builder.set(String,List) is not applicable\n[ERROR] (actual argument long cannot be converted to List by method invocation conversion)\n[ERROR] method Builder.set(String,FullEntity) is not applicable\n[ERROR] (actual argument long cannot be converted to FullEntity by method invocation conversion)\n[ERROR] method Builder.set(String,Key) is not applicable\n[ERROR] (actual argument long cannot be converted to Key by method invocation conversion)\n[ERROR] method Builder.set(String,DateTime) is not applicable\n[ERROR] (actual argument long cannot be converted to DateTime by method invocation conversion)\n[ERROR] method Builder.set(String,boolean) is not applicable\n[ERROR] (actual argument long cannot be converted to boolean by method invocation conversion)\n[ERROR] method Builder.set(String,String) is not applicable\n[ERROR] (actual argument long cannot be converted to String by method invocation conversion)\n[ERROR] method Builder.set(String,Value) is not applicable\n[ERROR] (actual argument long cannot be converted to Value by method invocation conversion)\n[ERROR] /usr/local/google/home/jjg/gcdjavasample/hello-datastore/src/main/java/org/geewax/hellodatastore/HelloDatastore.java:[32,15] error: cannot find symbol\n[ERROR] \n```\n\nIf I take away the `.set(\"name\", \"John Doe\")` I get a different error... \n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/35",
        "number": 35,
        "title": "KeyFactory.kind() requires a cast... didn't expect that at all...",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "Code I had was:\n\n``` java\nKeyFactory keyFactory = datastore.newKeyFactory().kind(\"Person\");\n```\n\nError I was getting was:\n\n``` bash\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:compile (default-compile) on project hello-datastore: Compilation failure\n[ERROR] /usr/local/google/home/jjg/gcdjavasample/hello-datastore/src/main/java/org/geewax/hellodatastore/HelloDatastore.java:[19,58] error: incompatible types\n[ERROR] -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:compile (default-compile) on project hello-datastore: Compilation failure\n/usr/local/google/home/jjg/gcdjavasample/hello-datastore/src/main/java/org/geewax/hellodatastore/HelloDatastore.java:[19,58] error: incompatible types\n\n\n        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:213)\n        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)\n        at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)\n        at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)\n        at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)\n        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320)\n        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156)\n        at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537)\n        at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196)\n        at org.apache.maven.cli.MavenCli.main(MavenCli.java:141)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\n        at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\n        at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\n        at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\nCaused by: org.apache.maven.plugin.CompilationFailureException: Compilation failure\n/usr/local/google/home/jjg/gcdjavasample/hello-datastore/src/main/java/org/geewax/hellodatastore/HelloDatastore.java:[19,58] error: incompatible types\n\n\n        at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:516)\n        at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:114)\n        at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)\n        at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209)\n        ... 19 more\n[ERROR] \n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n```\n\nChanging this to \n\n``` java\nKeyFactory keyFactory = (KeyFactory) datastore.newKeyFactory().kind(\"Person\");\n```\n\nfixed the problem\n\nHowever the docs at http://googlecloudplatform.github.io/gcloud-java/apidocs/com/google/gcloud/datastore/package-summary.html say I shouldn't need to do this :(\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/34",
        "number": 34,
        "title": "What's the best way for a total n00b to start with this library?",
        "labels": [
            "api: core",
            "auth"
        ],
        "state": "closed",
        "body": "I'm having trouble getting a HelloDatastore project working. Hoping that you can help me get this going...\n\nHere's what I did:\n\n``` bash\n$ git clone https://github.com/GoogleCloudPlatform/gcloud-java.git\n$ cd gcloud-java\n$ sudo apt-get install maven\n$ mvn install\n$ export CLASSPATH=~/gcdjavasample/gcloud-java/target/gcloud-java-0.0.3.jar\n```\n\nHere's the file I'm trying to run (HelloDatastore.java):\n\n``` java\nimport com.google.gcloud.datastore.DatastoreService;\nimport com.google.gcloud.datastore.DatastoreServiceFactory;\nimport com.google.gcloud.datastore.DatastoreServiceOptions;\nimport com.google.gcloud.datastore.Entity;\nimport com.google.gcloud.datastore.Key;\nimport com.google.gcloud.datastore.KeyFactory;\n\n\n\npublic class HelloDatastore {\n  private static final String DATASET = \"gcloud-datastore-demo\";\n\n  public static void main(String[] args) {\n    DatastoreServiceOptions options = DatastoreServiceOptions.builder().dataset(DATASET).build();\n    DatastoreService datastore = DatastoreServiceFactory.getDefault(options);\n    KeyFactory keyFactory = datastore.newKeyFactory().kind(\"Person\");\n    Key key = keyFactory.newKey(\"Jimmy\");\n\n    System.out.println(\"Trying to get the entity by its key!\");\n\n    Entity entity = datastore.get(key);\n\n    if (entity == null) {\n      System.out.println(\"Entity not found! Creating it!\");\n      entity = Entity.builder(key)\n          .set(\"name\", \"John Doe\")\n          .set(\"age\", 30)\n          .set(\"updated\", false)\n          .build();\n      datastore.put(entity);\n    } else {\n      System.out.println(\"Entity found! Updating it!\");\n      boolean updated = entity.getBoolean(\"updated\");\n      if (!updated) {\n        String[] name = entity.getString(\"name\").split(\" \");\n        entity = Entity.builder(entity)\n            .set(\"name\", name[0])\n            .set(\"last_name\", name[1])\n            .set(\"updated\", true)\n            .remove(\"old_property\")\n            .set(\"new_property\", 1.1)\n            .build();\n        datastore.update(entity);\n      }\n    }\n\n    System.out.println(\"Done!\");\n  }\n}\n```\n\nI can get it to compile just fine, then I run into problems running the class. Apparently I need Guava? And google-auth-library-java ? And google-api-java-client ?\n\nWhat exactly is the best way to get this so that I can run... `java HelloDatastore` and I'll see some stuff happening.... ? \n\n(Sorry for the dumb question....)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/33",
        "number": 33,
        "title": "mvn install fails with \"secret key not available\" ?",
        "labels": [
            "api: core",
            "type: bug"
        ],
        "state": "closed",
        "body": "What I did:\n\n``` bash\n$ sudo apt-get install mvn2\n$ git clone https://github.com/GoogleCloudPlatform/gcloud-java.git\n$ cd gcloud-java\n$ mvn install\n```\n\nError I got:\n\n``` bash\n[INFO] Building jar: /usr/local/google/home/jjg/gcdjavasample/gcloud-java/target/gcloud-java-0.0.3-javadoc.jar\n[INFO] [failsafe:integration-test {execution: default}]\n[INFO] [failsafe:verify {execution: default}]\n[INFO] Failsafe report directory: /usr/local/google/home/jjg/gcdjavasample/gcloud-java/target/failsafe-reports\n[INFO] [gpg:sign {execution: sign-artifacts}]\ngpg: no default secret key: secret key not available\ngpg: signing failed: secret key not available\n[INFO] ------------------------------------------------------------------------\n[ERROR] BUILD ERROR\n[INFO] ------------------------------------------------------------------------\n[INFO] Exit code: 2\n[INFO] ------------------------------------------------------------------------\n[INFO] Trace\norg.apache.maven.lifecycle.LifecycleExecutionException: Exit code: 2\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:719)\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:556)\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:535)\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:387)\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:348)\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:180)\n    at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:328)\n    at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:138)\n    at org.apache.maven.cli.MavenCli.main(MavenCli.java:362)\n    at org.apache.maven.cli.compat.CompatibleMain.main(CompatibleMain.java:60)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)\n    at org.codehaus.classworlds.Launcher.launch(Launcher.java:255)\n    at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)\n    at org.codehaus.classworlds.Launcher.main(Launcher.java:375)\nCaused by: org.apache.maven.plugin.MojoExecutionException: Exit code: 2\n    at org.apache.maven.plugin.gpg.GpgSigner.generateSignatureForFile(GpgSigner.java:168)\n    at org.apache.maven.plugin.gpg.AbstractGpgSigner.generateSignatureForArtifact(AbstractGpgSigner.java:205)\n    at org.apache.maven.plugin.gpg.GpgSignAttachedMojo.execute(GpgSignAttachedMojo.java:140)\n    at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:490)\n    at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:694)\n    ... 17 more\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 39 seconds\n[INFO] Finished at: Thu Mar 19 11:10:53 EDT 2015\n[INFO] Final Memory: 75M/1366M\n[INFO] ------------------------------------------------------------------------\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/32",
        "number": 32,
        "title": "Usable auth (pre-google-auth-kit)",
        "labels": [
            "auth"
        ],
        "state": "closed",
        "body": "In ruby: https://github.com/GoogleCloudPlatform/gcloud-ruby/issues/102\n\nIn python: we leave everything to oauth2client, which follows the same order.\n\ncraigcitro@ knows the specifics for Python.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/31",
        "number": 31,
        "title": "Create an example site and reference it from the main site",
        "labels": [],
        "state": "closed",
        "body": "e.g. https://github.com/GoogleCloudPlatform/gcloud-python -> https://github.com/GoogleCloudPlatform/gcloud-python-expenses-demo\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/30",
        "number": 30,
        "title": "Google Cloud Datastore - consider renaming Query to BaseQuery and StructuredQuery to Query",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/29",
        "number": 29,
        "title": "Google Cloud Datastore - consider passing FullEntity<Key> to put/update operations",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/28",
        "number": 28,
        "title": "Consider a different name for FullEntity in Datastore",
        "labels": [
            "api: datastore",
            "type: question"
        ],
        "state": "closed",
        "body": "Alternative can be: PersistedEntity\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/27",
        "number": 27,
        "title": "Google Cloud Datastore - consider renaming delete to remove (for collection consistency)",
        "labels": [
            "type: question"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/26",
        "number": 26,
        "title": "ListValue can't specify the index property",
        "labels": [],
        "state": "closed",
        "body": "Neither True or False could be set.\nsee b18704917\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/25",
        "number": 25,
        "title": "Datastore - Allow EntityValue to be indexed",
        "labels": [],
        "state": "closed",
        "body": "depends on b/8730533\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/24",
        "number": 24,
        "title": "drop Datastore StructuredQuery#Aggregate as it is going away",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/23",
        "number": 23,
        "title": "Add a client to Google Cloud Search",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/22",
        "number": 22,
        "title": "Figure out work needed for Cloud Task Queue client",
        "labels": [],
        "state": "closed",
        "body": "Consider a unified client for both PubSub and Task Queue (JMS like?)...\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/21",
        "number": 21,
        "title": "Use google-auth-library-java for oauth",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/20",
        "number": 20,
        "title": "Provide a client for Google Big Query",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/19",
        "number": 19,
        "title": "Provide a client for Compute Engine",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/18",
        "number": 18,
        "title": "FIgure out the work needed for PubSub service",
        "labels": [
            "api: pubsub"
        ],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/17",
        "number": 17,
        "title": "implement gql-query nextQuery (pagination)",
        "labels": [],
        "state": "closed",
        "body": "This needs to wait until Datastore expose Query in QueryResult (see b/18705483)\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/16",
        "number": 16,
        "title": "populate \"force\" in allocateId requests once datasore api expose it.",
        "labels": [
            "api: datastore"
        ],
        "state": "closed",
        "body": "see b/18594027\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/15",
        "number": 15,
        "title": "Provide a test for Datastore query pagination",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/14",
        "number": 14,
        "title": "complete Google Cloud storage implementation (and tests)",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/13",
        "number": 13,
        "title": "Create a Datastore interface to represent the RPC layer and load it via ServiceLoader",
        "labels": [],
        "state": "closed",
        "body": "This would enable different Datastore implementation (such as CapeDwarf) to be plugged instead of Google Cloud Datastore.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/12",
        "number": 12,
        "title": "Add a reference to the maven repository from README.md site",
        "labels": [],
        "state": "closed",
        "body": "glcloud-java-0.0.1 was pushed to maven (https://oss.sonatype.org/#nexus-search;quick~gcloud-java) we should provide a reference to it and consider a way to update it automatically every deploy (mvn clean deploy).\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/11",
        "number": 11,
        "title": "Remove binary blobs from history?",
        "labels": [],
        "state": "closed",
        "body": "The repo is currently 274MB when cloned, and just the `src` tree (i.e., excluding past versions in `.git`) is 85MB \u2014 the actual code takes up negligible space, and the vast majority of that space is taken up by [`src/test/resources/gcd-head.zip`](https://github.com/GoogleCloudPlatform/gcloud-java/blob/e68feca168ed2e0d1948dc008ffc78575958835b/src/test/resources/gcd-head.zip).\n\nThis makes it take an unusually large amount of time to clone the repo, and it will likely grow every time this blob is updated to a new version.\n\nWould it be possible to not version these large files (and ideally remove them from history while there are few forks), and get them from Maven or other sources, pinned to a specific version?\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/9",
        "number": 9,
        "title": "Repository is missing a LICENSE file",
        "labels": [
            "api: core",
            "type: bug"
        ],
        "state": "closed",
        "body": "See https://github.com/GoogleCloudPlatform/gcloud-python/blob/master/LICENSE for an example\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/8",
        "number": 8,
        "title": "Bad link to documentation and examples",
        "labels": [],
        "state": "closed",
        "body": "The documentation links to https://googlecloudeplatform.github.com/gcloud-java/apidocs which doesn't exist.\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/7",
        "number": 7,
        "title": "ReadMe file as a snippet of code that is incomplete",
        "labels": [
            "api: core"
        ],
        "state": "closed",
        "body": "It would be great to get a working snippet in the readme page(without looking at the javadoc first):\n1/ a static method after the imports?\n2/ some real content for the \"...\" section (or some comments in the snippet to describe what would be the value for \"...\"\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/6",
        "number": 6,
        "title": "datastore.Datetime.now seems broken",
        "labels": [
            "api: datastore",
            "type: bug"
        ],
        "state": "closed",
        "body": "When running this method locally (on a Mac) it returns 14th of January 1970 (1970-01-14T10:49:17.451+01:00)\n\nI suspect that the problem is that it is implemented as: \n\n``` java\npublic static DateTime now() {\n  return new DateTime(System.nanoTime() / 1000L);  // nanoTime() may be the culprit?\n}\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/5",
        "number": 5,
        "title": "Update README.md to fit consistent style",
        "labels": [
            "api: core",
            "type: feature request"
        ],
        "state": "closed",
        "body": "See https://github.com/GoogleCloudPlatform/gcloud-meta/issues/3 for the format\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/4",
        "number": 4,
        "title": "Update gh-pages landing page to look like gcloud-node?",
        "labels": [
            "api: core",
            "type: feature request"
        ],
        "state": "closed",
        "body": "Will Java developers be put off if the landing page looks like this?\n\nLanding page (for reference) is here: http://googlecloudplatform.github.io/gcloud-node/#/\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/3",
        "number": 3,
        "title": "Make authentication simpler",
        "labels": [
            "api: core",
            "auth",
            "type: feature request"
        ],
        "state": "closed",
        "body": "What we do today:\n\n``` java\nfinal KeyStore keystore = KeyStore.getInstance(\"PKCS12\");\nfinal FileInputStream fis = new FileInputStream(\"/path/to/key.p12\");\nkeystore.load(fis, \"password\".toCharArray());\nfinal PrivateKey key = (PrivateKey) keystore.getKey(\"privatekey\", \"password\".toCharArray());\n\nfinal AuthConfig ac = AuthConfig.createFor(\"email@developer.gserviceaccount.com\", key);\n\nfinal DatastoreServiceOptions options = DatastoreServiceOptions.builder()\n    .dataset(datasetId)\n    .authConfig(ac)\n    .build();\n\nfinal DatastoreService datastore = DatastoreServiceFactory.getDefault(options);\n```\n\nWhat we'd like to do:\n\n``` java\nfinal Credential credential = DatastoreHelper.getServiceAccountCredential(\n    \"email@developer.gserviceaccount.com\", \"/path/to/key.p12\");\nfinal DatastoreOptions options = DatastoreHelper.getOptionsfromEnv()\n  .dataset(datasetId)\n  .credential(credential)\n  .build();\nfinal Datastore datastore = DatastoreFactory.get().create(options);\n```\n"
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/2",
        "number": 2,
        "title": "Make this library public :)",
        "labels": [],
        "state": "closed",
        "body": ""
    },
    {
        "html_url": "https://github.com/googleapis/google-cloud-java/issues/1",
        "number": 1,
        "title": "Generate Javadocs and put them in the gh-pages branch?",
        "labels": [],
        "state": "closed",
        "body": ""
    }
]